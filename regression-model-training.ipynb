{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "\n",
    "from utils import make_mi_scores\n",
    "\n",
    "from fnn_modules.utils import RMSLELoss,RMSELoss\n",
    "from fnn_modules.training import train\n",
    "from fnn_modules.models import FeedFowardModel1,FeedFowardModel2, FeedFowardModel4, FeedFowardModel5\n",
    "from fnn_modules.pipeline import DataPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data-processed/data.csv')\n",
    "\n",
    "#I am dropping the logarithmized version of the target variable since neural networks can handle data that is not normally distributed.\"\n",
    "df.drop(columns='SalePrice_log',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor():\n",
    "    \"\"\"\n",
    "    Simple class to execute preprocessing tasks on the input dataset such as:\n",
    "        - Creating dummy variables\n",
    "        - Cutting of the non important features based on MI scores\n",
    "        - Spliting the data into a train and a test set\n",
    "        - Performing standard scaling on the numeric features (beside the dummy variables)\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input dataset.\n",
    "    - target_variable (str): The name of the target variable.\n",
    "    - top_n_feature (int, optional): Number of top features to select based on mutual information scores. Default is None, in this case\n",
    "      no feature will be dropped\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, target_variable, top_n_feature=None):\n",
    "        \n",
    "        self.target_variable = target_variable\n",
    "        self.numeric_features = data.select_dtypes(include=['float','integer']).columns\n",
    "        self.numeric_features = [feature for feature in self.numeric_features if feature != target_variable]\n",
    "        self.categorical_features = data.select_dtypes(include=['object','string']).columns\n",
    "        self.data = data\n",
    "        self.scaler = None  # Placeholder for StandardScaler object\n",
    "        self.mi_scores = None\n",
    "        self.top_n_feature = top_n_feature\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"\n",
    "        It performs the whole preprocessing process\n",
    "\n",
    "        Returns:\n",
    "        - X_train, X_test, y_train, y_test (pd.DataFrame): Processed training and testing data and target variables.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.data = self._get_df_with_dummies()\n",
    "        \n",
    "        if self.top_n_feature:\n",
    "            self.data = self._cut_based_on_mi_scores()\n",
    "        \n",
    "\n",
    "        X_train, X_test, y_train, y_test = self._split_data()\n",
    "        X_train, X_test = self._standard_scaling(X_train, X_test)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def _cut_based_on_mi_scores(self):\n",
    "        \"\"\"\n",
    "        Performs feature selection based on mutual information scores.\n",
    "\n",
    "        Returns:\n",
    "        - pd.DataFrame: Dataframe containing selected features and the target variable.\n",
    "        \"\"\"\n",
    "\n",
    "        self.mi_scores = make_mi_scores(\n",
    "            X=self.data.drop(columns=self.target_variable),\n",
    "            y=self.data[self.target_variable]\n",
    "        )\n",
    "\n",
    "\n",
    "        features_to_keep = self.mi_scores[:self.top_n_feature].index.to_list()\n",
    "\n",
    "        self.numeric_features = [feat for feat in self.numeric_features if feat in features_to_keep]\n",
    "\n",
    "        return self.data[features_to_keep + [self.target_variable]]\n",
    "\n",
    "\n",
    "\n",
    "    def _get_df_with_dummies(self):\n",
    "        \"\"\"\n",
    "        Encodes categorical features using one-hot encoding.\n",
    "\n",
    "         Returns:\n",
    "        - pd.DataFrame: Dataframe with encoded categorical features.\n",
    "        \"\"\"\n",
    "\n",
    "        categorical_features = self.data.select_dtypes(include=['object','string']).columns\n",
    "\n",
    "        return pd.get_dummies(\n",
    "                    self.data, \n",
    "                    drop_first=True, \n",
    "                    dtype=float, \n",
    "                    columns=categorical_features\n",
    "                )\n",
    "\n",
    "    def _split_data(self):\n",
    "        \"\"\"\n",
    "        Splits the data into training and testing sets.\n",
    "        \n",
    "        Returns:\n",
    "        - X_train, X_test, y_train, y_test (pd.DataFrame): Training and testing data and target variables.\n",
    "        \"\"\"\n",
    "\n",
    "        X = self.data.drop(columns=[self.target_variable])\n",
    "        y = self.data[self.target_variable]\n",
    "\n",
    "        return train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "    \n",
    "\n",
    "    def _standard_scaling(self, X_train, X_test):\n",
    "        \"\"\"\n",
    "        Performs standard scaling on numeric features.\n",
    "        \n",
    "        Args:\n",
    "        - X_train (pd.DataFrame): Training data with numeric features.\n",
    "        - X_test (pd.DataFrame): Testing data with numeric features.\n",
    "        \n",
    "        Returns:\n",
    "        - X_train, X_test (pd.DataFrame): Scaled training and testing data.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "        # I fit only on the training data, to keep the test data isolated. \n",
    "        self.scaler.fit(X_train[self.numeric_features])\n",
    "\n",
    "        X_train[self.numeric_features] = self.scaler.transform(X_train[self.numeric_features])\n",
    "        X_test[self.numeric_features] = self.scaler.transform(X_test[self.numeric_features])\n",
    "\n",
    "        return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this dataset doesn't contain a lot of observations, and the training process is relatively fast, I create a loop to try out several model variations with different hyperparameters. Then, I can examine the ones with the best scores.\n",
    "\n",
    "There for I create an utility method that helps me to perform the whole training process in the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the results of each model\n",
    "list_of_results = []\n",
    "\n",
    "# I create a method, that .\n",
    "def train_a_model(\n",
    "    top_n_feature,\n",
    "    batch_size,\n",
    "    model_number,\n",
    "    show_plots,\n",
    "    verbose,\n",
    "    append_result_list:True\n",
    "):\n",
    "    \n",
    "    \"\"\" \n",
    "    Initalizes the model and performs the whole training process\n",
    "    \"\"\"\n",
    "    \n",
    "    df_preprocessed = DataPreprocessor(df, 'SalePrice', top_n_feature)\n",
    "    X_train, X_test, y_train, y_test = df_preprocessed.preprocess_data()\n",
    "\n",
    "    test_pipeline = DataPipeline(X_train, X_test, y_train, y_test, batch_size)\n",
    "\n",
    "    # I use RMSLE becasue its benificial over the standard RMSE \n",
    "    # It handles the varying price ranges in this context better and makes sure extreme values don't disproportionately affect the model's training. \n",
    "    # This leads to a more reliable and accurate model\n",
    "    loss_fn = RMSLELoss()\n",
    "\n",
    "    models = []\n",
    "\n",
    "    models.append(FeedFowardModel1(\n",
    "        input_size = test_pipeline.feature_num,\n",
    "        hidden_size1 = 200,\n",
    "        hidden_size2 = 100,\n",
    "        hidden_size3 = 50,\n",
    "        weight_init_method = 'normal'\n",
    "    ))\n",
    "\n",
    "    models.append(FeedFowardModel1(\n",
    "        input_size = test_pipeline.feature_num,\n",
    "        hidden_size1 = 500,\n",
    "        hidden_size2 = 250,\n",
    "        hidden_size3 = 200,\n",
    "        weight_init_method = 'normal'\n",
    "    ))\n",
    "\n",
    "    models.append(FeedFowardModel2(\n",
    "        input_size = test_pipeline.feature_num,\n",
    "        hidden_size1 = 500,\n",
    "        hidden_size2 = 1000,\n",
    "        hidden_size3 = 1000,\n",
    "        hidden_size4 = 200,\n",
    "        weight_init_method = 'normal'\n",
    "    ))\n",
    "\n",
    "    models.append(FeedFowardModel4(\n",
    "        input_size = test_pipeline.feature_num,\n",
    "        hidden_size1 = 500,\n",
    "        hidden_size2 = 1000,\n",
    "        hidden_size3 = 1000,\n",
    "        hidden_size4 = 200,\n",
    "        weight_init_method = 'normal'\n",
    "    ))\n",
    "\n",
    "    models.append(FeedFowardModel4(\n",
    "        input_size = test_pipeline.feature_num,\n",
    "        hidden_size1 = 500,\n",
    "        hidden_size2 = 2000,\n",
    "        hidden_size3 = 2000,\n",
    "        hidden_size4 = 200,\n",
    "        weight_init_method = 'normal'\n",
    "    ))\n",
    "\n",
    "    models.append(FeedFowardModel5(\n",
    "        input_size = test_pipeline.feature_num,\n",
    "        hidden_size1 = 500,\n",
    "        hidden_size2 = 1000,\n",
    "        hidden_size3 = 1000,\n",
    "        hidden_size4 = 200,\n",
    "        weight_init_method = 'normal'\n",
    "    ))\n",
    "\n",
    "    models.append(FeedFowardModel5(\n",
    "        input_size = test_pipeline.feature_num,\n",
    "        hidden_size1 = 500,\n",
    "        hidden_size2 = 2000,\n",
    "        hidden_size3 = 2000,\n",
    "        hidden_size4 = 200,\n",
    "        weight_init_method = 'normal'\n",
    "    ))\n",
    "\n",
    "\n",
    "    model = models[model_number]\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            # weight_decay= 0.0001,\n",
    "                            lr=0.01\n",
    "            )\n",
    "    \n",
    "    results = train(\n",
    "        model=model, \n",
    "        train_dataloader=test_pipeline.train_loader, \n",
    "        test_dataloader=test_pipeline.test_loader, \n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        epochs=5000,\n",
    "        patience=15,\n",
    "        verbose=verbose,\n",
    "        show_plots=show_plots\n",
    "    )\n",
    "    if append_result_list:\n",
    "        list_of_results.append(results)\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for top_n_feature in range(60,160,10):\n",
    "    for batch_size in [32,64,128]:\n",
    "        for model_number in [0,1,2,3,4,5,6]:\n",
    "            train_a_model(\n",
    "                top_n_feature,\n",
    "                batch_size,\n",
    "                model_number,\n",
    "                verbose=False,\n",
    "                show_plots=False,\n",
    "                append_result_list=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>weight_init</th>\n",
       "      <th>input_size</th>\n",
       "      <th>hidden_sizes</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>run_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>FeedFowardModel5</td>\n",
       "      <td>normal</td>\n",
       "      <td>100</td>\n",
       "      <td>[500, 2000, 2000, 200]</td>\n",
       "      <td>128</td>\n",
       "      <td>999</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.110156</td>\n",
       "      <td>0.130062</td>\n",
       "      <td>18.789975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FeedFowardModel5</td>\n",
       "      <td>normal</td>\n",
       "      <td>70</td>\n",
       "      <td>[500, 2000, 2000, 200]</td>\n",
       "      <td>128</td>\n",
       "      <td>983</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.112881</td>\n",
       "      <td>0.133451</td>\n",
       "      <td>18.051475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>FeedFowardModel5</td>\n",
       "      <td>normal</td>\n",
       "      <td>100</td>\n",
       "      <td>[500, 1000, 1000, 200]</td>\n",
       "      <td>128</td>\n",
       "      <td>1030</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.109549</td>\n",
       "      <td>0.133678</td>\n",
       "      <td>10.825526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>FeedFowardModel5</td>\n",
       "      <td>normal</td>\n",
       "      <td>70</td>\n",
       "      <td>[500, 2000, 2000, 200]</td>\n",
       "      <td>64</td>\n",
       "      <td>504</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.129024</td>\n",
       "      <td>0.133928</td>\n",
       "      <td>16.234461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FeedFowardModel5</td>\n",
       "      <td>normal</td>\n",
       "      <td>70</td>\n",
       "      <td>[500, 1000, 1000, 200]</td>\n",
       "      <td>64</td>\n",
       "      <td>515</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.130303</td>\n",
       "      <td>0.134424</td>\n",
       "      <td>8.995642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>FeedFowardModel5</td>\n",
       "      <td>normal</td>\n",
       "      <td>90</td>\n",
       "      <td>[500, 1000, 1000, 200]</td>\n",
       "      <td>128</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.109813</td>\n",
       "      <td>0.134656</td>\n",
       "      <td>10.506224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>FeedFowardModel1</td>\n",
       "      <td>normal</td>\n",
       "      <td>100</td>\n",
       "      <td>[500, 250, 200]</td>\n",
       "      <td>128</td>\n",
       "      <td>90</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.097753</td>\n",
       "      <td>0.135682</td>\n",
       "      <td>0.668066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FeedFowardModel1</td>\n",
       "      <td>normal</td>\n",
       "      <td>60</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>128</td>\n",
       "      <td>243</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.109307</td>\n",
       "      <td>0.135721</td>\n",
       "      <td>1.783610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>FeedFowardModel4</td>\n",
       "      <td>normal</td>\n",
       "      <td>100</td>\n",
       "      <td>[500, 2000, 2000, 200]</td>\n",
       "      <td>64</td>\n",
       "      <td>516</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.062450</td>\n",
       "      <td>0.135826</td>\n",
       "      <td>16.816580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>FeedFowardModel4</td>\n",
       "      <td>normal</td>\n",
       "      <td>100</td>\n",
       "      <td>[500, 1000, 1000, 200]</td>\n",
       "      <td>64</td>\n",
       "      <td>494</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.049266</td>\n",
       "      <td>0.136008</td>\n",
       "      <td>8.317291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_type weight_init  input_size            hidden_sizes  \\\n",
       "104  FeedFowardModel5      normal         100  [500, 2000, 2000, 200]   \n",
       "41   FeedFowardModel5      normal          70  [500, 2000, 2000, 200]   \n",
       "103  FeedFowardModel5      normal         100  [500, 1000, 1000, 200]   \n",
       "34   FeedFowardModel5      normal          70  [500, 2000, 2000, 200]   \n",
       "33   FeedFowardModel5      normal          70  [500, 1000, 1000, 200]   \n",
       "82   FeedFowardModel5      normal          90  [500, 1000, 1000, 200]   \n",
       "99   FeedFowardModel1      normal         100         [500, 250, 200]   \n",
       "14   FeedFowardModel1      normal          60          [200, 100, 50]   \n",
       "95   FeedFowardModel4      normal         100  [500, 2000, 2000, 200]   \n",
       "94   FeedFowardModel4      normal         100  [500, 1000, 1000, 200]   \n",
       "\n",
       "     batch_size  epochs  learning_rate  train_loss  test_loss   run_time  \n",
       "104         128     999           0.01    0.110156   0.130062  18.789975  \n",
       "41          128     983           0.01    0.112881   0.133451  18.051475  \n",
       "103         128    1030           0.01    0.109549   0.133678  10.825526  \n",
       "34           64     504           0.01    0.129024   0.133928  16.234461  \n",
       "33           64     515           0.01    0.130303   0.134424   8.995642  \n",
       "82          128    1005           0.01    0.109813   0.134656  10.506224  \n",
       "99          128      90           0.01    0.097753   0.135682   0.668066  \n",
       "14          128     243           0.01    0.109307   0.135721   1.783610  \n",
       "95           64     516           0.01    0.062450   0.135826  16.816580  \n",
       "94           64     494           0.01    0.049266   0.136008   8.317291  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame.from_dict(list_of_results)\n",
    "df_results.sort_values(by='test_loss').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the top 10 model, we can make the following conclusions:\n",
    " - All of the first 10 model, has a really low test_loss\n",
    " - it's beneficial to reduce the complexity with cuting off the less/non important features\n",
    "\n",
    "I will go further with the one with the less test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 10.9427 | test_loss: 9.6119 | \n",
      "Epoch: 10 | train_loss: 7.8308 | test_loss: 7.7520 | \n",
      "Epoch: 20 | train_loss: 6.9496 | test_loss: 6.8833 | \n",
      "Epoch: 30 | train_loss: 6.3689 | test_loss: 6.3168 | \n",
      "Epoch: 40 | train_loss: 5.9456 | test_loss: 5.8983 | \n",
      "Epoch: 50 | train_loss: 5.6144 | test_loss: 5.5687 | \n",
      "Epoch: 60 | train_loss: 5.3444 | test_loss: 5.3003 | \n",
      "Epoch: 70 | train_loss: 5.1031 | test_loss: 5.0684 | \n",
      "Epoch: 80 | train_loss: 4.9089 | test_loss: 4.8715 | \n",
      "Epoch: 90 | train_loss: 4.7230 | test_loss: 4.6850 | \n",
      "Epoch: 100 | train_loss: 4.5556 | test_loss: 4.5237 | \n",
      "Epoch: 110 | train_loss: 4.4089 | test_loss: 4.3755 | \n",
      "Epoch: 120 | train_loss: 4.2639 | test_loss: 4.2394 | \n",
      "Epoch: 130 | train_loss: 4.1402 | test_loss: 4.1129 | \n",
      "Epoch: 140 | train_loss: 4.0195 | test_loss: 3.9939 | \n",
      "Epoch: 150 | train_loss: 3.9097 | test_loss: 3.8859 | \n",
      "Epoch: 160 | train_loss: 3.7969 | test_loss: 3.7786 | \n",
      "Epoch: 170 | train_loss: 3.7046 | test_loss: 3.6756 | \n",
      "Epoch: 180 | train_loss: 3.6033 | test_loss: 3.5806 | \n",
      "Epoch: 190 | train_loss: 3.5126 | test_loss: 3.4882 | \n",
      "Epoch: 200 | train_loss: 3.4240 | test_loss: 3.4067 | \n",
      "Epoch: 210 | train_loss: 3.3449 | test_loss: 3.3176 | \n",
      "Epoch: 220 | train_loss: 3.2633 | test_loss: 3.2394 | \n",
      "Epoch: 230 | train_loss: 3.1852 | test_loss: 3.1607 | \n",
      "Epoch: 240 | train_loss: 3.1090 | test_loss: 3.0871 | \n",
      "Epoch: 250 | train_loss: 3.0386 | test_loss: 3.0153 | \n",
      "Epoch: 260 | train_loss: 2.9644 | test_loss: 2.9452 | \n",
      "Epoch: 270 | train_loss: 2.9032 | test_loss: 2.8785 | \n",
      "Epoch: 280 | train_loss: 2.8396 | test_loss: 2.8150 | \n",
      "Epoch: 290 | train_loss: 2.7739 | test_loss: 2.7497 | \n",
      "Epoch: 300 | train_loss: 2.7144 | test_loss: 2.6883 | \n",
      "Epoch: 310 | train_loss: 2.6482 | test_loss: 2.6266 | \n",
      "Epoch: 320 | train_loss: 2.5853 | test_loss: 2.5675 | \n",
      "Epoch: 330 | train_loss: 2.5280 | test_loss: 2.5054 | \n",
      "Epoch: 340 | train_loss: 2.4722 | test_loss: 2.4503 | \n",
      "Epoch: 350 | train_loss: 2.4112 | test_loss: 2.3954 | \n",
      "Epoch: 360 | train_loss: 2.3628 | test_loss: 2.3392 | \n",
      "Epoch: 370 | train_loss: 2.3056 | test_loss: 2.2871 | \n",
      "Epoch: 380 | train_loss: 2.2520 | test_loss: 2.2340 | \n",
      "Epoch: 390 | train_loss: 2.2010 | test_loss: 2.1814 | \n",
      "Epoch: 400 | train_loss: 2.1499 | test_loss: 2.1338 | \n",
      "Epoch: 410 | train_loss: 2.1011 | test_loss: 2.0793 | \n",
      "Epoch: 420 | train_loss: 2.0477 | test_loss: 2.0347 | \n",
      "Epoch: 430 | train_loss: 1.9988 | test_loss: 1.9842 | \n",
      "Epoch: 440 | train_loss: 1.9450 | test_loss: 1.9376 | \n",
      "Epoch: 450 | train_loss: 1.9044 | test_loss: 1.8917 | \n",
      "Epoch: 460 | train_loss: 1.8562 | test_loss: 1.8392 | \n",
      "Epoch: 470 | train_loss: 1.8102 | test_loss: 1.7912 | \n",
      "Epoch: 480 | train_loss: 1.7709 | test_loss: 1.7434 | \n",
      "Epoch: 490 | train_loss: 1.7240 | test_loss: 1.7108 | \n",
      "Epoch: 500 | train_loss: 1.6767 | test_loss: 1.6575 | \n",
      "Epoch: 510 | train_loss: 1.6326 | test_loss: 1.6118 | \n",
      "Epoch: 520 | train_loss: 1.5959 | test_loss: 1.5710 | \n",
      "Epoch: 530 | train_loss: 1.5500 | test_loss: 1.5274 | \n",
      "Epoch: 540 | train_loss: 1.5081 | test_loss: 1.4911 | \n",
      "Epoch: 550 | train_loss: 1.4654 | test_loss: 1.4395 | \n",
      "Epoch: 560 | train_loss: 1.4199 | test_loss: 1.4107 | \n",
      "Epoch: 570 | train_loss: 1.3788 | test_loss: 1.3527 | \n",
      "Epoch: 580 | train_loss: 1.3392 | test_loss: 1.3222 | \n",
      "Epoch: 590 | train_loss: 1.2973 | test_loss: 1.2759 | \n",
      "Epoch: 600 | train_loss: 1.2576 | test_loss: 1.2435 | \n",
      "Epoch: 610 | train_loss: 1.2167 | test_loss: 1.1984 | \n",
      "Epoch: 620 | train_loss: 1.1843 | test_loss: 1.1701 | \n",
      "Epoch: 630 | train_loss: 1.1427 | test_loss: 1.1261 | \n",
      "Epoch: 640 | train_loss: 1.1029 | test_loss: 1.0880 | \n",
      "Epoch: 650 | train_loss: 1.0620 | test_loss: 1.0463 | \n",
      "Epoch: 660 | train_loss: 1.0263 | test_loss: 1.0073 | \n",
      "Epoch: 670 | train_loss: 0.9862 | test_loss: 0.9767 | \n",
      "Epoch: 680 | train_loss: 0.9540 | test_loss: 0.9372 | \n",
      "Epoch: 690 | train_loss: 0.9138 | test_loss: 0.9061 | \n",
      "Epoch: 700 | train_loss: 0.8779 | test_loss: 0.8623 | \n",
      "Epoch: 710 | train_loss: 0.8455 | test_loss: 0.8258 | \n",
      "Epoch: 720 | train_loss: 0.8079 | test_loss: 0.7941 | \n",
      "Epoch: 730 | train_loss: 0.7734 | test_loss: 0.7632 | \n",
      "Epoch: 740 | train_loss: 0.7410 | test_loss: 0.7321 | \n",
      "Epoch: 750 | train_loss: 0.7021 | test_loss: 0.6885 | \n",
      "Epoch: 760 | train_loss: 0.6744 | test_loss: 0.6588 | \n",
      "Epoch: 770 | train_loss: 0.6473 | test_loss: 0.6342 | \n",
      "Epoch: 780 | train_loss: 0.6064 | test_loss: 0.5963 | \n",
      "Epoch: 790 | train_loss: 0.5695 | test_loss: 0.5666 | \n",
      "Epoch: 800 | train_loss: 0.5435 | test_loss: 0.5296 | \n",
      "Epoch: 810 | train_loss: 0.5109 | test_loss: 0.4951 | \n",
      "Epoch: 820 | train_loss: 0.4810 | test_loss: 0.4735 | \n",
      "Epoch: 830 | train_loss: 0.4479 | test_loss: 0.4430 | \n",
      "Epoch: 840 | train_loss: 0.4163 | test_loss: 0.4065 | \n",
      "Epoch: 850 | train_loss: 0.3916 | test_loss: 0.3830 | \n",
      "Epoch: 860 | train_loss: 0.3592 | test_loss: 0.3651 | \n",
      "Epoch: 870 | train_loss: 0.3320 | test_loss: 0.3333 | \n",
      "Epoch: 880 | train_loss: 0.3046 | test_loss: 0.3048 | \n",
      "Epoch: 890 | train_loss: 0.2797 | test_loss: 0.2927 | \n",
      "Epoch: 900 | train_loss: 0.2526 | test_loss: 0.2490 | \n",
      "Epoch: 910 | train_loss: 0.2280 | test_loss: 0.2248 | \n",
      "Epoch: 920 | train_loss: 0.2100 | test_loss: 0.2090 | \n",
      "Epoch: 930 | train_loss: 0.1867 | test_loss: 0.2034 | \n",
      "Epoch: 940 | train_loss: 0.1677 | test_loss: 0.1750 | \n",
      "Epoch: 950 | train_loss: 0.1559 | test_loss: 0.1721 | \n",
      "Epoch: 960 | train_loss: 0.1445 | test_loss: 0.1577 | \n",
      "Epoch: 970 | train_loss: 0.1297 | test_loss: 0.1508 | \n",
      "Epoch: 980 | train_loss: 0.1240 | test_loss: 0.1439 | \n",
      "Epoch: 990 | train_loss: 0.1219 | test_loss: 0.1414 | \n",
      "Epoch: 1000 | train_loss: 0.1126 | test_loss: 0.1378 | \n",
      "Epoch: 1010 | train_loss: 0.1190 | test_loss: 0.1433 | \n",
      "Epoch: 1020 | train_loss: 0.1079 | test_loss: 0.1403 | \n",
      "Epoch: 1030 | train_loss: 0.1084 | test_loss: 0.1354 | \n",
      "Early stopping: No improvement in 15 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGzCAYAAACPa3XZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFP0lEQVR4nO3dd3hUVf7H8fedmt4oCYGEhN5CL4KgKAgioqJbdNEFd9ctYmHtrj9dG2JfXey6iu4qrrpiW0RZFJAqIMUgBKSGEnoyqZPM3Pv7IxqNoLTJ3CTzeT3PPJJ7T+Z+5/jIfDz3nHMNy7IsRERERMLEYXcBIiIiElkUPkRERCSsFD5EREQkrBQ+REREJKwUPkRERCSsFD5EREQkrBQ+REREJKwUPkRERCSsFD5EREQkrBQ+REREJKwUPkTkuEybNg3DMFi+fLndpYhIA6XwISIiImGl8CEiIiJhpfAhIiG3cuVKRo0aRUJCAnFxcQwbNowlS5bUalNVVcVdd91F+/btiYqKokmTJgwePJjZs2fXtCkoKODyyy+nVatWeL1eWrRowfnnn8/WrVvD/IlEJJRcdhcgIo3L2rVrGTJkCAkJCdx000243W6effZZhg4dyrx58xgwYAAAd955J1OmTOF3v/sd/fv3x+fzsXz5cr744gvOOussAC666CLWrl3L1VdfTVZWFnv37mX27Nls376drKwsGz+liJwMw7Isy+4iRKThmDZtGpdffjnLli2jb9++h50fO3YsM2fOZN26dbRp0waA3bt307FjR3r16sW8efMA6NmzJ61ateKDDz444nUKCwtJTk7moYce4oYbbqi7DyQiYafbLiISMsFgkI8//pgLLrigJngAtGjRgl/96lcsWLAAn88HQFJSEmvXrmXjxo1HfK/o6Gg8Hg9z587l0KFDYalfRMJD4UNEQmbfvn2UlZXRsWPHw8517twZ0zTJz88H4O6776awsJAOHTqQk5PDjTfeyJo1a2rae71eHnjgAT788ENSU1M57bTTePDBBykoKAjb5xGRuqHwISK2OO2009i0aRMvvvgi3bp144UXXqB379688MILNW0mTZrEhg0bmDJlClFRUdx+++107tyZlStX2li5iJwshQ8RCZlmzZoRExNDXl7eYefWr1+Pw+EgIyOj5lhKSgqXX34506dPJz8/n+7du3PnnXfW+r22bdty/fXX8/HHH5Obm0tlZSWPPPJIXX8UEalDCh8iEjJOp5MRI0bw7rvv1loOu2fPHl577TUGDx5MQkICAAcOHKj1u3FxcbRr1w6/3w9AWVkZFRUVtdq0bduW+Pj4mjYi0jBpqa2InJAXX3yRWbNmHXb8zjvvZPbs2QwePJgrr7wSl8vFs88+i9/v58EHH6xp16VLF4YOHUqfPn1ISUlh+fLlvPXWW1x11VUAbNiwgWHDhvGLX/yCLl264HK5mDFjBnv27OHiiy8O2+cUkdDTUlsROS7fLrX9Mfn5+ezbt49bb72VhQsXYpomAwYMYPLkyQwcOLCm3eTJk3nvvffYsGEDfr+f1q1bc9lll3HjjTfidrs5cOAAf/3rX5kzZw75+fm4XC46derE9ddfz89//vNwfFQRqSMKHyIiIhJWmvMhIiIiYaXwISIiImGl8CEiIiJhpfAhIiIiYaXwISIiImGl8CEiIiJhVe82GTNNk127dhEfH49hGHaXIyIiIsfAsiyKi4tJT0/H4fjpsY16Fz527dpV69kPIiIi0nDk5+fTqlWrn2xT78JHfHw8UF38t8+AEBERkfrN5/ORkZFR8z3+U+pd+Pj2VktCQoLCh4iISANzLFMmNOFUREREwkrhQ0RERMJK4UNERETCqt7N+RAREakrlmURCAQIBoN2l9Igud1unE7nSb+PwoeIiESEyspKdu/eTVlZmd2lNFiGYdCqVSvi4uJO6n0UPkREpNEzTZMtW7bgdDpJT0/H4/FoI8vjZFkW+/btY8eOHbRv3/6kRkAUPkREpNGrrKzENE0yMjKIiYmxu5wGq1mzZmzdupWqqqqTCh+acCoiIhHjaNt+y08L1WiR/i2IiIhIWCl8iIiISFgpfIiIiESIrKwsHnvsMbvL0IRTERGR+mzo0KH07NkzJKFh2bJlxMbGnnxRJyliwse+Yj9Pzf0ar8vJLaM62V2OiIhISFiWRTAYxOU6+ld6s2bNwlDR0UXMbRdfRRUvLdzKa0u32V2KiIjYzLIsyioDtrwsyzrmOidMmMC8efN4/PHHMQwDwzCYNm0ahmHw4Ycf0qdPH7xeLwsWLGDTpk2cf/75pKamEhcXR79+/fjf//5X6/1+eNvFMAxeeOEFxo4dS0xMDO3bt+e9994LVTf/qIgZ+XB+szzIPPZ/5yIi0kiVVwXpcsdHtlz7q7tHEuM5tq/fxx9/nA0bNtCtWzfuvvtuANauXQvALbfcwsMPP0ybNm1ITk4mPz+fc845h8mTJ+P1ennllVcYM2YMeXl5ZGZm/ug17rrrLh588EEeeughpk6dyrhx49i2bRspKSkn/2F/RMSMfDgd1eEjqPQhIiINRGJiIh6Ph5iYGNLS0khLS6vZ3Ovuu+/mrLPOom3btqSkpNCjRw/+8Ic/0K1bN9q3b88999xD27ZtjzqSMWHCBC655BLatWvHfffdR0lJCZ9//nmdfq7IGflQ+BARkW9Eu518dfdI264dCn379q31c0lJCXfeeSf//e9/2b17N4FAgPLycrZv3/6T79O9e/eaP8fGxpKQkMDevXtDUuOPibzwcRz32kREpHEyDOOYb33UVz9ctXLDDTcwe/ZsHn74Ydq1a0d0dDQ/+9nPqKys/Mn3cbvdtX42DAPTNENe7/c17J4/Dg5DIx8iItLweDwegsHgUdstXLiQCRMmMHbsWKB6JGTr1q11XN2Jibg5HwCmAoiIiDQQWVlZLF26lK1bt7J///4fHZVo3749b7/9NqtWrWL16tX86le/qvMRjBMVOeHjew/D0a0XERFpKG644QacTiddunShWbNmPzqH49FHHyU5OZlBgwYxZswYRo4cSe/evcNc7bGJnNsu34tZQdMiRPN9RERE6lSHDh1YvHhxrWMTJkw4rF1WVhaffPJJrWMTJ06s9fMPb8Mcac+RwsLCE6rzeETOyMf3b7to5ENERMQ2ERM+HN+/7aI5HyIiIraJmPBRe8KpjYWIiIhEuMgJH5pwKiIiUi9ETPhwOHTbRUREpD6ImPAB4NIW6yIiIraLqPDh0BbrIiIitouo8PHtvA/tcCoiImKfyAofuu0iIiJiu4gKH9/OOdVtFxEREftEVPj4duRDt11ERKShGDp0KJMmTQrZ+02YMIELLrggZO93IiIyfGjkQ0RExD4RFT6+3WJdcz5ERCKcZUFlqT2v4/gf4AkTJjBv3jwef/xxDMPAMAy2bt1Kbm4uo0aNIi4ujtTUVC677DL2799f83tvvfUWOTk5REdH06RJE4YPH05paSl33nknL7/8Mu+++27N+82dO7cOOvinRcxTbeH7t11sLkREROxVVQb3pdtz7b/sAk/sMTV9/PHH2bBhA926dePuu+8GwO12079/f373u9/xt7/9jfLycm6++WZ+8Ytf8Mknn7B7924uueQSHnzwQcaOHUtxcTGfffYZlmVxww03sG7dOnw+Hy+99BIAKSkpdfZRf0xEhY+akQ/ddhERkQYgMTERj8dDTEwMaWlpANx777306tWL++67r6bdiy++SEZGBhs2bKCkpIRAIMCFF15I69atAcjJyalpGx0djd/vr3k/O0RU+NBSWxERAcAdUz0CYde1T8Lq1av59NNPiYuLO+zcpk2bGDFiBMOGDSMnJ4eRI0cyYsQIfvazn5GcnHxS1w2liAof2l5dREQAMIxjvvVR35SUlDBmzBgeeOCBw861aNECp9PJ7NmzWbRoER9//DFTp07ltttuY+nSpWRnZ9tQ8eGOe8Lp/PnzGTNmDOnp6RiGwTvvvFPrvGVZ3HHHHbRo0YLo6GiGDx/Oxo0bQ1XvSXEofIiISAPj8XgIBoM1P/fu3Zu1a9eSlZVFu3btar1iY6sDlWEYnHrqqdx1112sXLkSj8fDjBkzjvh+djju8FFaWkqPHj148sknj3j+wQcf5O9//zvPPPMMS5cuJTY2lpEjR1JRUXHSxZ6smu3VNedDREQaiKysLJYuXcrWrVvZv38/EydO5ODBg1xyySUsW7aMTZs28dFHH3H55ZcTDAZZunQp9913H8uXL2f79u28/fbb7Nu3j86dO9e835o1a8jLy2P//v1UVVWF/TMdd/gYNWoU9957L2PHjj3snGVZPPbYY/zf//0f559/Pt27d+eVV15h165dh42Q2EEjHyIi0tDccMMNOJ1OunTpQrNmzaisrGThwoUEg0FGjBhBTk4OkyZNIikpCYfDQUJCAvPnz+ecc86hQ4cO/N///R+PPPIIo0aNAuCKK66gY8eO9O3bl2bNmrFw4cKwf6aQzvnYsmULBQUFDB8+vOZYYmIiAwYMYPHixVx88cWH/Y7f78fv99f87PP5QllSLc5vopZWu4iISEPRoUMHFi9efNjxt99++4jtO3fuzKxZs370/Zo1a8bHH38csvpOREg3GSsoKAAgNTW11vHU1NSacz80ZcoUEhMTa14ZGRmhLKkWPdVWRETEfrbvcHrrrbdSVFRU88rPz6+za+m2i4iIiP1CGj6+3bBkz549tY7v2bPnRzcz8Xq9JCQk1HrVFU04FRERsV9Iw0d2djZpaWnMmTOn5pjP52Pp0qUMHDgwlJc6Id+NfNhciIiISAQ77gmnJSUlfP311zU/b9myhVWrVpGSkkJmZiaTJk3i3nvvpX379mRnZ3P77beTnp5u++N74buRD004FRGJTJb+/j8poeq/4w4fy5cv54wzzqj5+brrrgNg/PjxTJs2jZtuuonS0lJ+//vfU1hYyODBg5k1axZRUVEhKfhkfLe9uoY+REQiidvtBqCsrIzo6Gibq2m4KisrAXA6nSf1PscdPoYOHfqTyccwDO6+++6ap+/VJy5ndfgIBJV8RUQiidPpJCkpib179wIQExOD8c1ouBwb0zTZt28fMTExuFwnt1NHRD3bxf3NRh9VCh8iIhHn24UP3wYQOX4Oh4PMzMyTDm4RFT48rurwURmwd097EREJP8MwaNGiBc2bN7dlS/HGwOPx4HCc/FqViAof3m9GPiq13EVEJGI5nc6TnrMgJydywkeFjx6lC/E5DlAZ6GB3NSIiIhHL9h1Ow6Z4N+O3/4WH3M9SqTkfIiIitomc8OH0AOChisqAbruIiIjYJXLCh6t6nxGvwoeIiIitIih8eKv/YZgEAn6bixEREYlcERc+AIJVCh8iIiJ2iZzw4fwufBCotK8OERGRCBdB4cOFaVSv67aqKmwuRkREJHJFTvgATEf1ihdTt11ERERsE2Hho/qphgQ18iEiImKXyAof38z7sLTaRURExDaRFT6+ue1iBDXhVERExC4RFT6sb5fbBnTbRURExC4RFT6+XW6rCaciIiL2iajwYXyzxbqW2oqIiNgnssKH+9sJp5rzISIiYpeICh8Od/XIhxEot7kSERGRyBVZ4cMbB4DXqtCTbUVERGwSWeEjOhGAeMoprwzaXI2IiEhkiqjw4YxKACDeKKO0MmBzNSIiIpEposIH34SPOMopU/gQERGxRWSFD288UD3yUabbLiIiIraIsPDx3chHqV/hQ0RExA4RFj6qRz4SjDLddhEREbFJZIWPWnM+NPIhIiJih8gKH9/cdolHIx8iIiJ2icjwEWdo5ENERMQuERY+qud8xFFOmV8jHyIiInaIyPDhMYL4K0ptLkZERCQyRVb48MRhYQAQLC+2uRgREZHIFFnhw+Gg0hkDgFVRZHMxIiIikSmywgdQ5a6+9WJVaORDRETEDhEXPoI14aPQ3kJEREQiVMSFDzMqsfoP5YW21iEiIhKpIi58GFFJADgqNedDRETEDhEXPhyxyQC4FT5ERERsEXHhwx2bAkBUoJhA0LS5GhERkcgTceHDE1cdPhIoo6i8yuZqREREIk/EhQ9nTPVtl0SjhENlCh8iIiLhFnHhg9imADQziigqr7S5GBERkcgTeeEjLg2A5hziUKlGPkRERMIt8sJH/DfhwyikUHM+REREwi5iw0es4afUd8jmYkRERCJP5IUPTywVjuqHywWKdttcjIiISOSJvPABlHurJ50GfQofIiIi4RaR4aMyujkAVvEemysRERGJPBEZPqzYVABcZQofIiIi4RaR4cORUD3pNKpin82ViIiIRJ6Qh49gMMjtt99OdnY20dHRtG3blnvuuQfLskJ9qRPmbZIBQELVvnpVl4iISCRwhfoNH3jgAZ5++mlefvllunbtyvLly7n88stJTEzkmmuuCfXlTkhM0+rw0ZyDFJZVkRzrsbkiERGRyBHy8LFo0SLOP/98Ro8eDUBWVhbTp0/n888/D/WlTpg7qTp8pHOAfSV+hQ8REZEwCvltl0GDBjFnzhw2bNgAwOrVq1mwYAGjRo06Ynu/34/P56v1qnOJLQFINQ6yz1de99cTERGRGiEf+bjlllvw+Xx06tQJp9NJMBhk8uTJjBs37ojtp0yZwl133RXqMn5aXComDjxGkKL9u6B98/BeX0REJIKFfOTjjTfe4NVXX+W1117jiy++4OWXX+bhhx/m5ZdfPmL7W2+9laKioppXfn5+qEs6nNNNsSsFgNL9YbieiIiI1Aj5yMeNN97ILbfcwsUXXwxATk4O27ZtY8qUKYwfP/6w9l6vF6/XG+oyjqosKpXEkv34D2wP+7VFREQiWchHPsrKynA4ar+t0+nENM1QX+qkBOJaAGAV7bS5EhERkcgS8pGPMWPGMHnyZDIzM+natSsrV67k0Ucf5Te/+U2oL3VSHImtoADcpQV2lyIiIhJRQh4+pk6dyu23386VV17J3r17SU9P5w9/+AN33HFHqC91UqK/2WgspmIPlmVhGIbNFYmIiESGkIeP+Ph4HnvsMR577LFQv3VIxadmAtCcAxwsraRJXPjnnYiIiESiiHy2C4A7uTp8tGQ/Ow5prw8REZFwidjwQXIWAOnGfnYcKLS1FBERkUgSueEjLpVKw4vTsDi0a4vd1YiIiESMyA0fhoEvunqbdf/er20uRkREJHJEbvgAKhNaA2Ac2mpvISIiIhEkosOHI6UNADGl2uVUREQkXCI6fMSmtQMgxb+TykD92oFVRESksYro8BHXoj0AmcZedhVqua2IiEg4RHT4ML657ZJp7GX7gVKbqxEREYkMER0+SMzAxEGM4Wfv7m12VyMiIhIRIjt8uDwUequfbluxe53NxYiIiESGyA4fQFli9aRTa+96mysRERGJDBEfPpypXQCILdJGYyIiIuEQ8eEjqXUOAC0D2zhUWmlzNSIiIo1fxIeP6JbdAOhg7GD9bp/N1YiIiDR+ER8+aNoBEwfJRgnbt+sBcyIiInVN4cMdTVFU9QPmfPlf2lyMiIhI46fwAfiTO1T/QSteRERE6pzCB+BpUb3iJb54E6Zp2VyNiIhI46bwASRmVq94aUM+2w+W2VyNiIhI46bwATjTugLQydjO+t1FNlcjIiLSuCl8ADTrSJXhIcEoZ/dWbbMuIiJSlxQ+AJxuDsVXTzoN7FhpczEiIiKNm8LHN8y0HgDEHtByWxERkbqk8PGNhDb9AGjt38hBbbMuIiJSZxQ+vhHTug8A3Rxb+HJHob3FiIiINGIKH99q3pkqw02iUca2r9faXY2IiEijpfDxre9NOi3ftsLmYkRERBovhY/vsdJ6AhC9P9feQkRERBoxhY/vSWrbF4Dsqo3s9VXYXI2IiEjjpPDxPd6M3gDkaNKpiIhInVH4+L7mXagyPCQZpWzdsMbuakRERBolhY/vc3k4mFy92Vhg83ybixEREWmcFD5+wNtuCADphSsorwzaXI2IiEjjo/DxA4mdhgLQz1jHF9sO2luMiIhII6Tw8QNGRn8Chps04xDr1q62uxwREZFGR+Hjh9zRHErKAaBy82c2FyMiItL4KHwcgadt9byPFoUrKKsM2FyNiIhI46LwcQQJ38z7OMVYyxdbD9lbjIiISCOj8HEERuuBVBkeWhgHyftKz3kREREJJYWPI3FHc7BJ9W6nwY2f2FyMiIhI46Lw8SNiOg0DINu3nAMlfpurERERaTwUPn5EfJezADjF8RWf5e2yuRoREZHGQ+Hjx6R1p9yVQLxRzuZV2mpdREQkVBQ+fozDSUWr6iW33u2fURkwbS5IRESkcVD4+AmJ3UYA0N9azZLNB2yuRkREpHFQ+PgJjrZDAehlfM38LzfbW4yIiEgjofDxU5KzKIvLxGWYFK37BMuy7K5IRESkwVP4OApPx+pVL30qlpC702dzNSIiIg2fwsdRuLqeB8BZzhV8sm6nzdWIiIg0fAofR9N6MH53Ik2MYvJXztGtFxERkZNUJ+Fj586dXHrppTRp0oTo6GhycnJYvnx5XVyq7jldGJ1GA5Djm6dbLyIiIicp5OHj0KFDnHrqqbjdbj788EO++uorHnnkEZKTk0N9qbDxdL8QgDHOxbyzfIvN1YiIiDRsrlC/4QMPPEBGRgYvvfRSzbHs7OxQXya82pyBP7o5KeV7KV7zPoEx3XE5dcdKRETkRIT8G/S9996jb9++/PznP6d58+b06tWL559//kfb+/1+fD5frVe943Th6j0OgLOr/sfCTdpwTERE5ESFPHxs3ryZp59+mvbt2/PRRx/xpz/9iWuuuYaXX375iO2nTJlCYmJizSsjIyPUJYWEs/dlAJzuWM3cZavsLUZERKQBM6wQL9/weDz07duXRYsW1Ry75pprWLZsGYsXLz6svd/vx+//7pH1Pp+PjIwMioqKSEhICGVpJ6346eHE71nGo+bFXPGXJ4iPcttdkoiISL3g8/lITEw8pu/vkI98tGjRgi5dutQ61rlzZ7Zv337E9l6vl4SEhFqv+irulAkAjOVT3l2pPT9ERERORMjDx6mnnkpeXl6tYxs2bKB169ahvlTYGV3HUumMIduxh9ULP9SeHyIiIicg5OHjz3/+M0uWLOG+++7j66+/5rXXXuO5555j4sSJob5U+HlisbpWL7vtXziT1TuKbC5IRESk4Ql5+OjXrx8zZsxg+vTpdOvWjXvuuYfHHnuMcePGhfpStvD2Gw/AaOdS/rNovc3ViIiINDwh3+cD4Nxzz+Xcc8+ti7e2X6t+lCe2JaZoE9bat/FV9CFBE09FRESOmXbKOl6GQdQ3ox9j+YS3V+ywuSAREZGGReHjBBg9LsY0nPRxbOSzeR9TFTTtLklERKTBUPg4EfGpWDm/AOCX5f/m/dW7bC5IRESk4VD4OEHO067HwmCEcwUfzpmDaWrZrYiIyLFQ+DhRTdsT6HQeAGN805m9bo/NBYmIiDQMCh8nwT30RgDOdSzhnf/N06ZjIiIix0Dh42Sk5VDZZgQOw+KMfa+yWE+7FREROSqFj5PkOeMmAMY6F/Dv/y20uRoREZH6T+HjZGX0oyJjCG4jSJ8d/2R1fqHdFYmIiNRrCh8hEHXmzQD80jmXl2Yt1twPERGRn6DwEQpZgylP64vXqKLrtleYu2Gf3RWJiIjUWwofoWAYRA+7BYBfO2fz5sefafRDRETkRyh8hEq74fgzh+A1qjh/71P8e1m+3RWJiIjUSwofoWIYeM99CBMnI53LWTLnP1QG9MwXERGRH1L4CKXmnTH7/haAK8uf58X5eTYXJCIiUv8ofISYa9hf8HuS6ODYycG5T7OrsNzukkREROoVhY9Qi07Gc9ZfAbjKeJMn3l9ic0EiIiL1i8JHHTD6jKe8SVcSjDK65f2dZVsP2l2SiIhIvaHwURccTqLPexiAi52f8tzrb1PiD9hclIiISP2g8FFXWg+istNYHIbFVWVP8sT/1tldkYiISL2g8FGHPOdMocodTw/HZowlT7O+wGd3SSIiIrZT+KhLCS1wjboPgGsdb/DQq/+loipoc1EiIiL2UvioY0avy6hsfTpRRhV/KPobf5u93u6SREREbKXwUdcMA88FUwm4YujvyKNy0bOs263bLyIiErkUPsIhuTWuEXcDcIvzNe75x5scKq20uSgRERF7KHyES7/fUdnmLLxGFX+p/Du3z1hJ0NSTb0VEJPIofISLYeAZ+yRVniS6ObbSe/2jvLJ4q91ViYiIhJ3CRzjFp+Ie+wQAv3HNYuPHz7G7SM9+ERGRyKLwEW6dx2CddjMAN/IK1//jI83/EBGRiKLwYQPj9JvwN+1CslHCtYVTuOOd1Zia/yEiIhFC4cMOThfei/9J0B3HAMd6Mr96jqfmfm13VSIiImGh8GGXpu1wnvsIAH92vcW6Oa+wZPMBm4sSERGpewofdur+S6weF+MyTB51PcXzr05nb3GF3VWJiIjUKYUPOxkGxvlPE+gwGq8R4P7AA1z//Af4A3r+i4iINF4KH3ZzOHBd9ByVTbvQzPBxa+Hd3DJ9MVVB0+7KRERE6oTCR33gjcNz6b/xe5vQxbGNERvu5MY3VmoFjIiINEoKH/VFUibecdMJOtyMci4je+1UrYAREZFGSeGjPskcgHPM4wBc65rBgU/+zqzcApuLEhERCS2Fj/qm1zg4vXoH1L+6XmH+vx/h47UKICIi0ngofNRHQ2/FPOUqAO51PM/M159k+daDNhclIiISGgof9ZFh4Bh5L2bv8TgMi4ccTzJt2rN8uaPI7spEREROmsJHfWUYOM79G4EuF+E2gjxiPcKjz7/Ayu2H7K5MRETkpCh81GcOJ66LnqWq7Ui8RhVTeZDnp73IzsJyuysTERE5YQof9Z3TjfviVwhmnU6cUcFjwck8+ORTfL23xO7KRERETojCR0PgjsJ56ZuUtT0HjxHkwcop/Oupe1i322d3ZSIiIsdN4aOhcHmJuWQaFW3PxmtUcSfP8M/nHiJ3pyahiohIw6Lw0ZC4vERd+jr+Pn8A4C7zSf7+3LNahisiIg2KwkdDYxh4R99PVZcLcRtBHuchXvrHk9qITEREGgyFj4bI4cB94bME240g2qhkquMRFr52H/9ass3uykRERI5K4aOhcnlwXjKdYK/qjcjucr9MxQc388hH6/Q0XBERqdcUPhoypwvneY9jDfsrAL9zfUiXBVdzzT8XUl4ZtLk4ERGRI6vz8HH//fdjGAaTJk2q60tFJsPAGHId1oUvEHS4GeVcxu82XcMfn53JvmK/3dWJiIgcpk7Dx7Jly3j22Wfp3r17XV5GAKP7z3H++l0C3iR6OjYxef8k/jz1NTbuKba7NBERkVrqLHyUlJQwbtw4nn/+eZKTk+vqMvJ9Wafi+v0nVCW2oZWxn2f8t/Dk039j0df77a5MRESkRp2Fj4kTJzJ69GiGDx/+k+38fj8+n6/WS05Ck7a4/zCHqoxTq7dj5xFWvHwj73yRb3dlIiIiQB2Fj9dff50vvviCKVOmHLXtlClTSExMrHllZGTURUmRJSYF94T3CPT/IwBXO98mdsZ47n97CYGgaXNxIiIS6UIePvLz87n22mt59dVXiYqKOmr7W2+9laKioppXfr7+Dz0knC5c5zyAef5TVBkeznKu4FerLuW2p14hr0DzQERExD6GZVkh3RTinXfeYezYsTidzppjwWAQwzBwOBz4/f5a537I5/ORmJhIUVERCQkJoSwtcu1aSdmrlxJTugO/5eJhfs3gX93K6R2b212ZiIg0Esfz/R3y8FFcXMy2bbV32rz88svp1KkTN998M926dfvJ31f4qCPlhZS++UdiN38IwAfBASzqfAf/97NTiPG4bC5OREQauuP5/g75bZf4+Hi6detW6xUbG0uTJk2OGjykDkUnEXvZdAIj7iNguDjXuZTfr/8N9z4/XfuBiIhIWGmH00hiGLgGTcT124/xx7Yky7GHv+6dxLOP3sb8vL12VyciIhEi5LddTpZuu4RJ2UGK//174rfNBuC94EBWdL+LWy/oS5T7x+fkiIiIHImtt12kgYhJIX7CmwSG30MQJ+c5FzP+y19z49R/ajWMiIjUKYWPSGYYuAZfg/O3s6iIaUEbRwGPFF3He0/eyNOf5mlPEBERqRMKHwIZ/Ym6ahEV7UbjMYLc6JxO709/zZ+efIdN+0rsrk5ERBoZhQ+pFpNC1LhXsc5/kipnDAMc63n0wJU8N3Uy/1q8lXo2NUhERBowhQ/5jmFg9LoU98RFVKb3J94o5wHHU6TMvIJf/O2/rNut5+6IiMjJU/iQw6Vk4/ndLMwz78A0XJzj/Jwniiby0FNP8fKirZimRkFEROTEKXzIkTmcOE67HscVcwikdCDVKORF5xSSP/wj1z/1OusLNAoiIiInRuFDflp6T1x/mo/V//cAnOdczN37/swTUx/m0Y/Way6IiIgcN4UPOTp3NMY5D8EVn+JPH0C8Uc4T7sfpt+C3/OGx11m+9aDdFYqISAOi8CHHrmVvvL95H06/maDDwxBnLk8VXsnOf4xj6hsz8VVU2V2hiIg0ANpeXU7MwS1U/vcmPJs+BqDCcvO4awKtzprIJf2zcDgMmwsUEZFw0vbqUvdSsvFc9ib8fh6HWgwmyqji5uDzdJ75M65+5B8s/Hq/5oOIiMgRKXzIyUnvSfIV71M1/F6qHNH0dnzNk6XXs37aVVw1bT5b9pfaXaGIiNQzuu0ioePbTeVHd+BZ+wYARVYMDwZ/hdXrMv4wtD2tm8TaXKCIiNSV4/n+VviQ0NvwEZUf3IDHtx2Az82O3GdcwXlnDWfcKZl4XU6bCxQRkVDTnA+xV4eReCatgrPvJ+iKob8jj3eMG2j50e+47IHX+O+a3XZXKCIiNtLIh9StwnzMmTdhbPgQA4sqy8k/g2exvPUV/HpYL05p08TuCkVEJAR020Xqn315VH14G+7NswHwWdE8GxjDqlaX8pfze9I1PdHmAkVE5GQofEj9tekTyv97G9EHvwJgl5XCE4GxGL0v5bendaBNszibCxQRkROh8CH1m2lC7n8Ifnw7zpLq+R95ZivuD44j5/SL+MPpbYn1umwuUkREjofChzQMVRWw4iUCn96Py18IwPxgDq8ymvanjuWa4R3wuDQnWkSkIVD4kIal/BDW/IexljyDwwoAsDDYlUcd4xk4aChXD2un5bkiIvWcwoc0TAe3EFw4FVb+E6dZCcAHwQG85ryAM4edzaWntCbKrRAiIlIfKXxIw3ZoK+bsO3F8NaPm0PvBU3jLM5bhw8/mVwNa49SD60RE6hWFD2kc9qwlOP9RnGvfqjm0KNiF6VG/pNPA0Vw6MIvEaLeNBYqIyLcUPqRx2b2G4KInIfctnN/MCVlrtuZ583xiel3EtWd1IjUhyuYiRUQim8KHNE6F+QQ+ewxW/QtXsAKAr810njPPg+6/4PIh7emUFo9h6JaMiEi4KXxI41Z2EGvpswQWPYW7ygfATqsJbwSGsrP1+Yw+bSBDOzZTCBERCSOFD4kMFT7MZS9SueDvRPkPABCwHDwfHM0XmeMZf0YvBrdvanORIiKRQeFDIktVBXz5Jv4FT+A9uB6AQiuWV4PD+KLZhVxy1iCGdmyGy6kNy0RE6orCh0SmylL44hUqP38Rz8ENQPVIyEdmX6Z7fkaXPqdxcb8MPT9GRKQOKHxIZDODkDeTyoVP4dmxqObwdrMZ/zTPhp6/4ux+nejTOsXGIkVEGheFD5Fv7VmLOe+hWhuW+S0XLwTPYVWLi/nN2adwSpsUTU4VETlJCh8iP3RwM9byl6hY9R+iy3YCUGG5mWkOYE3ahXQ/ZQRjerbErXkhIiInROFD5MdYFqydQeXCJ/DsXlFz+HOzI0+5fs1pZ47ml/0yiPW6bCxSRKThUfgQORrLgu2L8S2eRkzeDFxW9YPs1pjZvGmMxN/5Qi4Z1IFemck2Fyoi0jAofIgcj6KdBD+ZDGvewGlVAVBqeZkRHMzc5J9x2qBBnN+jJYkxeo6MiMiPUfgQORGlBzBX/ovKRc8QVbar5vDCYFf+wQW0O2U0Z+ek0ysjSRNURUR+QOFD5GSYQdi2EP/8x3Fv+RQHQQC2mKm8GTydDWmjOXdwP87rkY7DoRAiIgIKHyKhc2gb1qKpBFe+hitQCoBpGSwwu/FBzAVkDRjDRX1b66m6IhLxFD5EQq2yFNbOwL/8X3h3Lq45nG8243XzTHZlXcR5Q3oxtIMeaCcikUnhQ6QuHdpK1aKnsVa9huebp+oC/C/Yi7mxo0jIOYef9c/WNu4iElEUPkTCobIUcv+Df/FzePd9WXN4n5XAW8HTWZp8HuefOYgLerbUaIiINHoKHyLhtnc9lctewlzzFlH+/TWH5wdzmB01Em/X0YzsmUWfzGRNUhWRRknhQ8QuwSrYMAv/khfwbptbc7jASuad4GBWxp9BTr/T+EW/DJrHa5KqiDQeCh8i9cHBLQSWTyOwcjpR5XtqDm8yW7CEHLa3HceZQ4bQP1sPthORhk/hQ6Q+qaqAvP9S+eUM3HkfYPDdf3ILg135PPZ04ruM4JQ+venWMtHGQkVETpzCh0h9VbIPa8cyihZPI2HbbByYAAQsB7PMfixOPp+cU89ldI904qO0nbuINBwKHyINQeF2Kla8Stma90kpWltzeJPZgresM7HaDaNT91M4u1saUW6njYWKiBydwodIQ1OQS8Xi53HkvoEnWFZz+AuzHXMYwKFOl/DLITl0b5Wo+SEiUi8pfIg0VP5irDVvUrri38QULKt5rky55eFTsydLooYQ3WUkY/p3omt6goKIiNQbtoaPKVOm8Pbbb7N+/Xqio6MZNGgQDzzwAB07djym31f4EPmGbxfm+pmUL3yW2KINNYfLLC/vBE/l/fif06tHby7pn0lGSoyNhYqI2Bw+zj77bC6++GL69etHIBDgL3/5C7m5uXz11VfExsYe9fcVPkR+wLJg92qqct+havVbxJTm15zaaqYyz+zO7uan07zXKC7sk0lSjMfGYkUkUtWr2y779u2jefPmzJs3j9NOO+2o7RU+RH6CacLmTwksegrX5v/VOrXbSuE/wSEcyBzF0NOHMbh9M5zaTVVEwuR4vr9ddV1MUVERACkpKUc87/f78fv9NT/7fL4jthMRwOGAdsNwtRsGvl2Qv5TSlf/Bue0zWlQd5CrXu7DrXda/msELRj8OdbqEvj160DMziaZxXrurFxEB6njkwzRNzjvvPAoLC1mwYMER29x5553cddddhx3XyIfIcQj4sdbPpHjpK8TumI/TCtSc+sJsx+xgX/ZkjqJLl+6M7dWSJgoiIhJi9ea2y5/+9Cc+/PBDFixYQKtWrY7Y5kgjHxkZGQofIieq7CDmxtn4Fr9EQsESHN/sqBq0DL6w2vMuQyFrCGcPHsjAdk11a0ZEQqJehI+rrrqKd999l/nz55OdnX3Mv6c5HyIhVFxA1dp3ObD8bdL2L6l16msznX9ZZ1OSPogRpw3hjE7NcTsdNhUqIg2dreHDsiyuvvpqZsyYwdy5c2nfvv1x/b7Ch0gd2bsea80bFOd9Ssy+Nbj47tbMErMz7xtnUJg+mBEDenJ2tzS8Lu2qKiLHztbwceWVV/Laa6/x7rvv1trbIzExkejo6KP+vsKHSBhU+Agsf4nSNR8Qt3cFzm82M4Pq7d1XR/fD12082R17MCA7Rdu7i8hR2Ro+fmzHxZdeeokJEyYc9fcVPkTCrGgnweXTqFg3i+j9X9bMETEtgyVmZz60TsGfPZx+PbpzZqfmmqwqIkdUL+Z8nCiFDxEblR6geNm/KF71HumFy2udWmm2Y6XZji2pwzl92HkMbt9UIyIiUkPhQ0RO3r48rLxZ+FdOJ+rAulqn1pmZ/Dt4Bs4mWXQaPJbTOrUgNSHKpkJFpD5Q+BCR0Dq4GVb+C/+mz/Du+rzWqa1mKu+ZA9nU7Cy69RzIyG4tyGyiZ82IRBqFDxGpO3vXY81/iMDuXJwHNtY8eRdgh9WUucEefNlkJHHth9A/O4WhHZtp5YxIBFD4EJHw8BfDho8oX/UWrs1zcFuVNac2mi2Za/ZgRdQpNO1yOmP7ZNIrIxmHNjUTaZQUPkQk/CrLYOsCKla9geer/+DArDnls6JZYXZgPr35qulIxg3twRkdmxEf5baxYBEJJYUPEbFX+SHYPJfA+o+w8mbiriyqORW0DJZbHfk42JdDmWfRu0cvhndOJS1RE1ZFGjKFDxGpP8wgFHxJYPN8qhY9Q3TZzlqn15mZfGz25WDGWcRm9mJop1S6t0rUMl6RBkbhQ0Tqr8LtWOtnUpH7Pt4diw+bsLrE7MJXRnu2Zv2cUzukcW53LeMVaQgUPkSkYSg7iLXhI0pWv0vUtk9xmxU1p0zL4D/BIayhHaXZo8hsncWp7ZrSLyvFxoJF5McofIhIw1NVDpvnYm35DHPZiziD5bVObzRbMtPsT5mnKQWtRnFWn04M75Km2zMi9YTCh4g0bJVlkL8EK+9DyjYtIvZA7mFN1pqt+QcXkNyqA9k5p3Juj5YkxXhsKFZEQOFDRBoTy4LiAlj1KlW7c3FsmIkz6K/VZJXZlreDQzjQtB8tO/bhlDYpnNa+GS6nw6aiRSKPwoeINF7lh+DAZszct6lY9zExRRtqnV5rtma+2Z1cZxdiOg1nRI/WdEyN15bvInVM4UNEIkfRTpj3AGW7viJqzxc4rO9Wz/gtF3PM3iw2u7AjeSBnDh5I/6wU2jSLxa1REZGQUvgQkchUsg/Wv09g9Ruwew2uQGmt07lmFnPNHqw0umGkdubUnl04OyedFonRNhUs0ngofIiI+EtgxzLI+5Dybcvx7llVa08RqF5BM80cTXzL9iS37cfwXu1p2yzOpoJFGjaFDxGRHyo9ABtmEdg8j+Cm+XjLdh/WZHawN596hnIg4ywGdUjnjI7NyUiJxjD0MDyRo1H4EBE5mvJCrGX/oOzL97F8O4nz76055bNiWGdlstlswX5vBns6XsppXVsztGNzPC7NFRE5EoUPEZHjEayqHhVZ9TrGxo9xmpW1Thdb0Xxk9mOD1YriZn1p2b4ng7q1oWt6Al6XNjkTAYUPEZETV1UB2xfBzi+oLCsikPsuMSXbajUxLYPPzBzm0wtvm1MZMGgo/bObEu1REJHIpfAhIhIqpglb5mKun0n5zlwc+9YRXVVYq4nPimGB1Z0NKWfg6TCMzm1bM6htE42KSERR+BARqUsFXxLc+D+K13xA/L6VOL+3iqbc8rDU7MwWZ2us1Bw8XUZzZo82pCdpOa80bgofIiLhUlmKtW0RpUtfxrl9EdGVB2qftpwsNrsy2z0U2g2nY5sshrRrSusmMVpFI42KwoeIiB2CVZD/OeaW+ezfvp74/E+JDhTVarLezGCp2Ylcdw5G60EM6dWVXplJtErW9u/SsCl8iIjUB8EqWDuDqi2LKPv6MxKLvz6syQ6rKQuC3dgc1RVv8zYMPON8+rVpou3fpcFR+BARqY9K98O2RVR8PZ/glgVEH1qPg9p/BS83O7DZkcneuK5UdjiHfp3a0CcrhRiPy6aiRY6NwoeISENQegC2fkbF6v9Q4dtPfMHSWpNXAbaZzZlPLwpajcaTfQr92zSle6tEYr0KI1K/KHyIiDREBzZhrvsvB7Z9iTd/EQkVO2qdLrc8bLXSmBXsR26TEWS1bsOQblkMad8Mp0OTV8VeCh8iIg2daULpXqy8WRSun0f85v/iMv2HNVtltmGF2ZH9Kb1I7zuGnm1a0qlFvOaMSNgpfIiINDbBABRuw9qxjJJPHyO+cN1hTXxWDPPNHA4ZySy0ckjMzGHkkFMYkN1Et2mkzil8iIg0dlUVsG8dVcumUVLsw5P/GbH+fYc122cl8LF5CvtTehLfsjOdeg+hd+sUotzafVVCS+FDRCTSmCZs/oTg7lzK184kpmAZDszDmu2wmvJpsCcFsZ1o3mUIAwcMIjnWS7N4rw1FS2Oi8CEiEunMIFSVYa17n7I17xO7eeYRm1VZThaY3aiMbs6Ozr+lVYde9MpMokmsV5NY5bgofIiIyOEqSzFX/5ttXy7AVbiFNN8a3ARqNfnaTGe9lck2qzlxqW2g0xg6tMlmQHYKDoUR+QkKHyIicnS+XVhfvYt/55e41v4Hl1lxxGa7rRQ+dQzkUPY5eNM6MbRHR1omxxDt0bwR+Y7Ch4iIHL+SfbBrJfu3rMZXsJmkXfNJ8e84rNkGsyXrrCyCCa2g7Zlk9z6TTulNFEYinMKHiIicPNOEonzKdqzGt+Itkrd/jNcsP6xZueVhkdmVld6+RLfoTMcBI+nSqgktEqP05N4IovAhIiKhF6wCfzFVuTNg8ZNU+Ctxl+8nyqodSPyWm0VmF7ZYLdiaPIjO7dvRvltferZuhkubnzVaCh8iIhIepon51XuUr/oP1s4VxJXvPGKzCsvN/8w+rEs+A29GL7p06U7P1ik0jdMS38ZC4UNEROwRrILdqzmYOxvn1nm4968jJlB4WLMyy8sGqxUbPJ0xmnbAaNWXtl1606pZivYcaaAUPkREpP4oP0Rw/YeUbfyMyvyVJJRswm1VHtbMb7lYb2WS5+5MRctBNOl6BqfmtCcpxmND0XK8FD5ERKT+Cgbg4GYOfL0M/8Z5OHYto0nF9sP2HAEotGLJdXbBF90KT3wzvNn9adX7bLKaxmkyaz2j8CEiIg2LZcHBzVRsW87+NbOI37mQxKo9R2y61UxltdWWZvFenCmtcWYNpkWn/rRs1TrMRcv3KXyIiEjDZllQvJuSHV+xJ28J+/buomnhl2SX5+I8wjNrqiwnVbgodiawpdlwErqeRYucM0lOTrah+Mik8CEiIo3TwS0cWPsJGzeux2X6abf7A5KCB47YtMSK4qCRRBoHqfAkU9S8H96mWSR3PgN3x+FhLrzxU/gQEZHIYJqARdmudeRuK8Cz9i0SDq4hqSKfFHw/+mvbnK05ENceIzkLo9tYsrsOINbjxOUwQHNJTojCh4iIRDTLNPFtWsq+vEXs3rufXcUBsoq/oGlgN205fC+Sg1YcFg7iHJWsbTqKqLgkYlJakJDdh5ROp4FLK26ORuFDRETkCEzTYvem1WxbMx/3wQ002b+cTH8eriPMI/lWBR5KHAm4DZOK2HR8SV1pEVWFN2sA7sx+UFUGyVmQlBG+D1IPKXyIiIgcI6vCx5bcJewrrcK1YwmJBUvwBZzElBeQau0j2Sg5pvcpdjelxNOU8ugWJCQ3Iwo/sc2yKIlOx5PRE6/DqB5BcXqh/CC07APu6Dr+dOGj8CEiIhICZRV+8lf9j22FQdbvr6TZoZU0KV7P3goHI4zPSaSUIA5iDP8JvX+FM56gO4ZKVzwxVYcIumOpdMYQ5Y3CU+Wj0p2Iw6rC7YnCSMoATyxWYT5GdDJUlWFWFIMrCisxA6e/sPpNLRNim4EZqP6zOwacbnC4wOkmYDko9zYhfsifQtdRKHyIiIjUKcuyOFBayfItB9hXWoXjwAaiDuaRf6icwL5NdPTspVVgO8VmFJnGXrIcezhgxePHTRwVJBhlttZf4M4g7bbckL7n8Xx/u0J65e958skneeihhygoKKBHjx5MnTqV/v3719XlREREwsYwDJrGeTk7J/2bI62Bs2q1qQqaFBRVkJoQxc7iClbvKGLL/lIOlFRiWAEo2Yu/rJhgeRGOkt3sIYV4sxRK9+IyggQsJ6YrGtMMYJrQ3DhEPOXsogkp+DBxUEQsSZTgIUCsUYEDC58VTbRRSSwV7LcS8RqVuAniIoibAC6CVLma8Et/gFhvncWAn1QnV/33v//NddddxzPPPMOAAQN47LHHGDlyJHl5eTRv3rwuLikiIlKvuJ0OMlJiAGiZHEPL5Jhj/t2i8ioCQZOUWA+VQZP9JZXsLiynosokLdHLwdIqDpb6aZkUg4XFlv2lxHhcuJ0GhWVVlFYGiHI5iQqYmJZFQVEFXpcDX8CkW8sEzuyUisflqKuPflR1cttlwIAB9OvXjyeeeAIA0zTJyMjg6quv5pZbbvnJ39VtFxERkYbneL6/Qx57KisrWbFiBcOHf7d7nMPhYPjw4SxevPiw9n6/H5/PV+slIiIijVfIw8f+/fsJBoOkpqbWOp6amkpBQcFh7adMmUJiYmLNKyMjstdJi4iINHb23fD5xq233kpRUVHNKz8/3+6SREREpA6FfMJp06ZNcTqd7NlT+1HIe/bsIS0t7bD2Xq8Xr9cb6jJERESkngr5yIfH46FPnz7MmTOn5phpmsyZM4eBAweG+nIiIiLSwNTJUtvrrruO8ePH07dvX/r3789jjz1GaWkpl19+eV1cTkRERBqQOgkfv/zlL9m3bx933HEHBQUF9OzZk1mzZh02CVVEREQij7ZXFxERkZNm6z4fIiIiIj9F4UNERETCSuFDREREwkrhQ0RERMJK4UNERETCqk6W2p6Mbxff6AFzIiIiDce339vHsoi23oWP4uJiAD1gTkREpAEqLi4mMTHxJ9vUu30+TNNk165dxMfHYxhGSN/b5/ORkZFBfn6+9hAJMfVt3VHf1h31bd1Qv9ad+ty3lmVRXFxMeno6DsdPz+qodyMfDoeDVq1a1ek1EhIS6t2/tMZCfVt31Ld1R31bN9Svdae+9u3RRjy+pQmnIiIiElYKHyIiIhJWERU+vF4vf/3rX/F6vXaX0uiob+uO+rbuqG/rhvq17jSWvq13E05FRESkcYuokQ8RERGxn8KHiIiIhJXCh4iIiISVwoeIiIiElcKHiIiIhFXEhI8nn3ySrKwsoqKiGDBgAJ9//rndJdV7U6ZMoV+/fsTHx9O8eXMuuOAC8vLyarWpqKhg4sSJNGnShLi4OC666CL27NlTq8327dsZPXo0MTExNG/enBtvvJFAIBDOj1Kv3X///RiGwaRJk2qOqV9P3M6dO7n00ktp0qQJ0dHR5OTksHz58przlmVxxx130KJFC6Kjoxk+fDgbN26s9R4HDx5k3LhxJCQkkJSUxG9/+1tKSkrC/VHqlWAwyO233052djbR0dG0bduWe+65p9ZDxNS3x2b+/PmMGTOG9PR0DMPgnXfeqXU+VP24Zs0ahgwZQlRUFBkZGTz44IN1/dGOnRUBXn/9dcvj8VgvvviitXbtWuuKK66wkpKSrD179thdWr02cuRI66WXXrJyc3OtVatWWeecc46VmZlplZSU1LT54x//aGVkZFhz5syxli9fbp1yyinWoEGDas4HAgGrW7du1vDhw62VK1daM2fOtJo2bWrdeuutdnykeufzzz+3srKyrO7du1vXXnttzXH164k5ePCg1bp1a2vChAnW0qVLrc2bN1sfffSR9fXXX9e0uf/++63ExETrnXfesVavXm2dd955VnZ2tlVeXl7T5uyzz7Z69OhhLVmyxPrss8+sdu3aWZdccokdH6nemDx5stWkSRPrgw8+sLZs2WK9+eabVlxcnPX444/XtFHfHpuZM2dat912m/X2229bgDVjxoxa50PRj0VFRVZqaqo1btw4Kzc315o+fboVHR1tPfvss+H6mD8pIsJH//79rYkTJ9b8HAwGrfT0dGvKlCk2VtXw7N271wKsefPmWZZlWYWFhZbb7bbefPPNmjbr1q2zAGvx4sWWZVX/R+ZwOKyCgoKaNk8//bSVkJBg+f3+8H6Aeqa4uNhq3769NXv2bOv000+vCR/q1xN38803W4MHD/7R86ZpWmlpadZDDz1Uc6ywsNDyer3W9OnTLcuyrK+++soCrGXLltW0+fDDDy3DMKydO3fWXfH13OjRo63f/OY3tY5deOGF1rhx4yzLUt+eqB+Gj1D141NPPWUlJyfX+vvg5ptvtjp27FjHn+jYNPrbLpWVlaxYsYLhw4fXHHM4HAwfPpzFixfbWFnDU1RUBEBKSgoAK1asoKqqqlbfdurUiczMzJq+Xbx4MTk5OaSmpta0GTlyJD6fj7Vr14ax+vpn4sSJjB49ulb/gfr1ZLz33nv07duXn//85zRv3pxevXrx/PPP15zfsmULBQUFtfo2MTGRAQMG1OrbpKQk+vbtW9Nm+PDhOBwOli5dGr4PU88MGjSIOXPmsGHDBgBWr17NggULGDVqFKC+DZVQ9ePixYs57bTT8Hg8NW1GjhxJXl4ehw4dCtOn+XH17qm2obZ//36CwWCtv6QBUlNTWb9+vU1VNTymaTJp0iROPfVUunXrBkBBQQEej4ekpKRabVNTUykoKKhpc6S+//ZcpHr99df54osvWLZs2WHn1K8nbvPmzTz99NNcd911/OUvf2HZsmVcc801eDwexo8fX9M3R+q77/dt8+bNa513uVykpKREdN/ecsst+Hw+OnXqhNPpJBgMMnnyZMaNGwegvg2RUPVjQUEB2dnZh73Ht+eSk5PrpP5j1ejDh4TGxIkTyc3NZcGCBXaX0uDl5+dz7bXXMnv2bKKiouwup1ExTZO+ffty3333AdCrVy9yc3N55plnGD9+vM3VNWxvvPEGr776Kq+99hpdu3Zl1apVTJo0ifT0dPWtHLdGf9uladOmOJ3Ow1YK7Nmzh7S0NJuqaliuuuoqPvjgAz799FNatWpVczwtLY3KykoKCwtrtf9+36alpR2x7789F4lWrFjB3r176d27Ny6XC5fLxbx58/j73/+Oy+UiNTVV/XqCWrRoQZcuXWod69y5M9u3bwe+65uf+vsgLS2NvXv31jofCAQ4ePBgRPftjTfeyC233MLFF19MTk4Ol112GX/+85+ZMmUKoL4NlVD1Y33/O6LRhw+Px0OfPn2YM2dOzTHTNJkzZw4DBw60sbL6z7IsrrrqKmbMmMEnn3xy2BBenz59cLvdtfo2Ly+P7du31/TtwIED+fLLL2v9hzJ79mwSEhIO+5KIFMOGDePLL79k1apVNa++ffsybty4mj+rX0/Mqaeeethy8A0bNtC6dWsAsrOzSUtLq9W3Pp+PpUuX1urbwsJCVqxYUdPmk08+wTRNBgwYEIZPUT+VlZXhcNT+ynA6nZimCahvQyVU/Thw4EDmz59PVVVVTZvZs2fTsWNH22+5AJGz1Nbr9VrTpk2zvvrqK+v3v/+9lZSUVGulgBzuT3/6k5WYmGjNnTvX2r17d82rrKysps0f//hHKzMz0/rkk0+s5cuXWwMHDrQGDhxYc/7bJaEjRoywVq1aZc2aNctq1qxZxC8J/aHvr3axLPXrifr8888tl8tlTZ482dq4caP16quvWjExMda//vWvmjb333+/lZSUZL377rvWmjVrrPPPP/+Iyxh79eplLV261FqwYIHVvn37iFsO+kPjx4+3WrZsWbPU9u2337aaNm1q3XTTTTVt1LfHpri42Fq5cqW1cuVKC7AeffRRa+XKlda2bdssywpNPxYWFlqpqanWZZddZuXm5lqvv/66FRMTo6W24TZ16lQrMzPT8ng8Vv/+/a0lS5bYXVK9Bxzx9dJLL9W0KS8vt6688korOTnZiomJscaOHWvt3r271vts3brVGjVqlBUdHW01bdrUuv76662qqqowf5r67YfhQ/164t5//32rW7dultfrtTp16mQ999xztc6bpmndfvvtVmpqquX1eq1hw4ZZeXl5tdocOHDAuuSSS6y4uDgrISHBuvzyy63i4uJwfox6x+fzWddee62VmZlpRUVFWW3atLFuu+22Wks51bfH5tNPPz3i363jx4+3LCt0/bh69Wpr8ODBltfrtVq2bGndf//94fqIR2VY1ve2pxMRERGpY41+zoeIiIjULwofIiIiElYKHyIiIhJWCh8iIiISVgofIiIiElYKHyIiIhJWCh8iIiISVgofIiIiElYKHyIiIhJWCh8iIiISVgofIiIiElb/DyuCYXrZy+6xAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_final = train_a_model(\n",
    "            top_n_feature=100,\n",
    "            batch_size=128,\n",
    "            model_number=6,\n",
    "            show_plots=True,\n",
    "            verbose=True,\n",
    "            append_result_list=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at our test datapoints and its predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the data \n",
    "df_preprocessed = DataPreprocessor(df, 'SalePrice', 100)\n",
    "X_train, X_test, y_train, y_test = df_preprocessed.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred</th>\n",
       "      <th>Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137976</td>\n",
       "      <td>154500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>312869</td>\n",
       "      <td>325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107393</td>\n",
       "      <td>115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171623</td>\n",
       "      <td>159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>326408</td>\n",
       "      <td>315500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>85577</td>\n",
       "      <td>75500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>225040</td>\n",
       "      <td>311500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>140694</td>\n",
       "      <td>146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>82989</td>\n",
       "      <td>84500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>125574</td>\n",
       "      <td>135500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>143259</td>\n",
       "      <td>145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100950</td>\n",
       "      <td>130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>99694</td>\n",
       "      <td>81000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>205133</td>\n",
       "      <td>214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>173277</td>\n",
       "      <td>181000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>136732</td>\n",
       "      <td>134500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>187865</td>\n",
       "      <td>183500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>136020</td>\n",
       "      <td>135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>112004</td>\n",
       "      <td>118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>210781</td>\n",
       "      <td>226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>175767</td>\n",
       "      <td>155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>209089</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>177951</td>\n",
       "      <td>173500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>127356</td>\n",
       "      <td>129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>198046</td>\n",
       "      <td>192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>168280</td>\n",
       "      <td>153900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>185965</td>\n",
       "      <td>181134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>104034</td>\n",
       "      <td>141000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>174636</td>\n",
       "      <td>181000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>202763</td>\n",
       "      <td>208900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pred   Truth\n",
       "0   137976  154500\n",
       "1   312869  325000\n",
       "2   107393  115000\n",
       "3   171623  159000\n",
       "4   326408  315500\n",
       "5    85577   75500\n",
       "6   225040  311500\n",
       "7   140694  146000\n",
       "8    82989   84500\n",
       "9   125574  135500\n",
       "10  143259  145000\n",
       "11  100950  130000\n",
       "12   99694   81000\n",
       "13  205133  214000\n",
       "14  173277  181000\n",
       "15  136732  134500\n",
       "16  187865  183500\n",
       "17  136020  135000\n",
       "18  112004  118400\n",
       "19  210781  226000\n",
       "20  175767  155000\n",
       "21  209089  210000\n",
       "22  177951  173500\n",
       "23  127356  129000\n",
       "24  198046  192000\n",
       "25  168280  153900\n",
       "26  185965  181134\n",
       "27  104034  141000\n",
       "28  174636  181000\n",
       "29  202763  208900"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "pred = model_final(torch.tensor(X_test.values.astype('float32')).to(device)).ravel().to('cpu').detach()\n",
    "grund_truth = y_test.values\n",
    "\n",
    "pd.DataFrame({'Pred':pred,'Truth':grund_truth}).applymap(lambda x: round(x)).head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's a regression problem, let's evaluate the r2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.91\n"
     ]
    }
   ],
   "source": [
    "print(f'r2_score: {r2_score(grund_truth,pred):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an R-squared score of 0.91, the model shows a robust predictive ability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-data-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
