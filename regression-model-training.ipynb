{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "\n",
    "from utils import make_mi_scores\n",
    "\n",
    "from fnn_modules.utils import RMSLELoss,RMSELoss\n",
    "from fnn_modules.training import train\n",
    "from fnn_modules.models import FeedFowardModel1,FeedFowardModel2, FeedFowardModel4, FeedFowardModel5\n",
    "from fnn_modules.pipeline import DataPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data-processed/data.csv')\n",
    "\n",
    "#I am dropping the logarithmized version of the target variable since neural networks can handle data that is not normally distributed.\"\n",
    "df.drop(columns='SalePrice_log',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor():\n",
    "    \"\"\"\n",
    "    Simple class to execute preprocessing tasks on the input dataset such as:\n",
    "        - Creating dummy variables\n",
    "        - Cutting of the non important features based on MI scores\n",
    "        - Spliting the data into a train and a test set\n",
    "        - Performing standard scaling on the numeric features (beside the dummy variables)\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input dataset.\n",
    "    - target_variable (str): The name of the target variable.\n",
    "    - top_n_feature (int, optional): Number of top features to select based on mutual information scores. Default is None, in this case\n",
    "      no feature will be dropped\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, target_variable, top_n_feature=None):\n",
    "        \n",
    "        self.target_variable = target_variable\n",
    "        self.numeric_features = data.select_dtypes(include=['float','integer']).columns\n",
    "        self.numeric_features = [feature for feature in self.numeric_features if feature != target_variable]\n",
    "        self.categorical_features = data.select_dtypes(include=['object','string']).columns\n",
    "        self.data = data\n",
    "        self.scaler = None  # Placeholder for StandardScaler object\n",
    "        self.mi_scores = None\n",
    "        self.top_n_feature = top_n_feature\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"\n",
    "        It performs the whole preprocessing process\n",
    "\n",
    "        Returns:\n",
    "        - X_train, X_test, y_train, y_test (pd.DataFrame): Processed training and testing data and target variables.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.data = self._get_df_with_dummies()\n",
    "        \n",
    "        if self.top_n_feature:\n",
    "            self.data = self._cut_based_on_mi_scores()\n",
    "        \n",
    "\n",
    "        X_train, X_test, y_train, y_test = self._split_data()\n",
    "        X_train, X_test = self._standard_scaling(X_train, X_test)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def _cut_based_on_mi_scores(self):\n",
    "        \"\"\"\n",
    "        Performs feature selection based on mutual information scores.\n",
    "\n",
    "        Returns:\n",
    "        - pd.DataFrame: Dataframe containing selected features and the target variable.\n",
    "        \"\"\"\n",
    "\n",
    "        self.mi_scores = make_mi_scores(\n",
    "            X=self.data.drop(columns=self.target_variable),\n",
    "            y=self.data[self.target_variable]\n",
    "        )\n",
    "\n",
    "\n",
    "        features_to_keep = self.mi_scores[:self.top_n_feature].index.to_list()\n",
    "\n",
    "        self.numeric_features = [feat for feat in self.numeric_features if feat in features_to_keep]\n",
    "\n",
    "        return self.data[features_to_keep + [self.target_variable]]\n",
    "\n",
    "\n",
    "\n",
    "    def _get_df_with_dummies(self):\n",
    "        \"\"\"\n",
    "        Encodes categorical features using one-hot encoding.\n",
    "\n",
    "         Returns:\n",
    "        - pd.DataFrame: Dataframe with encoded categorical features.\n",
    "        \"\"\"\n",
    "\n",
    "        categorical_features = self.data.select_dtypes(include=['object','string']).columns\n",
    "\n",
    "        return pd.get_dummies(\n",
    "                    self.data, \n",
    "                    drop_first=True, \n",
    "                    dtype=float, \n",
    "                    columns=categorical_features\n",
    "                )\n",
    "\n",
    "    def _split_data(self):\n",
    "        \"\"\"\n",
    "        Splits the data into training and testing sets.\n",
    "        \n",
    "        Returns:\n",
    "        - X_train, X_test, y_train, y_test (pd.DataFrame): Training and testing data and target variables.\n",
    "        \"\"\"\n",
    "\n",
    "        X = self.data.drop(columns=[self.target_variable])\n",
    "        y = self.data[self.target_variable]\n",
    "\n",
    "        return train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "    \n",
    "\n",
    "    def _standard_scaling(self, X_train, X_test):\n",
    "        \"\"\"\n",
    "        Performs standard scaling on numeric features.\n",
    "        \n",
    "        Args:\n",
    "        - X_train (pd.DataFrame): Training data with numeric features.\n",
    "        - X_test (pd.DataFrame): Testing data with numeric features.\n",
    "        \n",
    "        Returns:\n",
    "        - X_train, X_test (pd.DataFrame): Scaled training and testing data.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "        # I fit only on the training data, to keep the test data isolated. \n",
    "        self.scaler.fit(X_train[self.numeric_features])\n",
    "\n",
    "        X_train[self.numeric_features] = self.scaler.transform(X_train[self.numeric_features])\n",
    "        X_test[self.numeric_features] = self.scaler.transform(X_test[self.numeric_features])\n",
    "\n",
    "        return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this dataset doesn't contain a lot of observations, and the training process is relatively fast, I create a loop to try out several model variations with different hyperparameters. Then, I can examine the ones with the best scores.\n",
    "\n",
    "There for I create an utility method that helps me to perform the whole training process in the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the results of each model\n",
    "list_of_results = []\n",
    "\n",
    "# I create a method, that .\n",
    "def train_a_model(\n",
    "    top_n_feature,\n",
    "    batch_size,\n",
    "    model_number,\n",
    "    show_plots,\n",
    "    append_result_list:True\n",
    "):\n",
    "    \n",
    "    \"\"\" \n",
    "    Initalizes the model and performs the whole training process\n",
    "    \"\"\"\n",
    "    \n",
    "    df_preprocessed = DataPreprocessor(df, 'SalePrice', top_n_feature)\n",
    "    X_train, X_test, y_train, y_test = df_preprocessed.preprocess_data()\n",
    "\n",
    "    test_pipeline = DataPipeline(X_train, X_test, y_train, y_test, batch_size)\n",
    "\n",
    "    # I use RMSLE becasue its benificial over the standard RMSE \n",
    "    # It handles the varying price ranges in this context better and makes sure extreme values don't disproportionately affect the model's training. \n",
    "    # This leads to a more reliable and accurate model\n",
    "    loss_fn = RMSLELoss()\n",
    "\n",
    "    models = []\n",
    "\n",
    "    models.append(FeedFowardModel1(\n",
    "        input_size = test_pipeline.feature_num,\n",
    "        hidden_size1 = 200,\n",
    "        hidden_size2 = 100,\n",
    "        hidden_size3 = 50,\n",
    "        weight_init_method = 'normal'\n",
    "    ))\n",
    "\n",
    "    models.append(FeedFowardModel1(\n",
    "        input_size = test_pipeline.feature_num,\n",
    "        hidden_size1 = 500,\n",
    "        hidden_size2 = 250,\n",
    "        hidden_size3 = 200,\n",
    "        weight_init_method = 'normal'\n",
    "    ))\n",
    "\n",
    "    models.append(FeedFowardModel2(\n",
    "        input_size = test_pipeline.feature_num,\n",
    "        hidden_size1 = 500,\n",
    "        hidden_size2 = 1000,\n",
    "        hidden_size3 = 1000,\n",
    "        hidden_size4 = 200,\n",
    "        weight_init_method = 'normal'\n",
    "    ))\n",
    "\n",
    "    models.append(FeedFowardModel4(\n",
    "        input_size = test_pipeline.feature_num,\n",
    "        hidden_size1 = 500,\n",
    "        hidden_size2 = 1000,\n",
    "        hidden_size3 = 1000,\n",
    "        hidden_size4 = 200,\n",
    "        weight_init_method = 'normal'\n",
    "    ))\n",
    "\n",
    "    models.append(FeedFowardModel4(\n",
    "        input_size = test_pipeline.feature_num,\n",
    "        hidden_size1 = 500,\n",
    "        hidden_size2 = 2000,\n",
    "        hidden_size3 = 2000,\n",
    "        hidden_size4 = 200,\n",
    "        weight_init_method = 'normal'\n",
    "    ))\n",
    "\n",
    "    models.append(FeedFowardModel5(\n",
    "        input_size = test_pipeline.feature_num,\n",
    "        hidden_size1 = 500,\n",
    "        hidden_size2 = 1000,\n",
    "        hidden_size3 = 1000,\n",
    "        hidden_size4 = 200,\n",
    "        weight_init_method = 'normal'\n",
    "    ))\n",
    "\n",
    "    models.append(FeedFowardModel5(\n",
    "        input_size = test_pipeline.feature_num,\n",
    "        hidden_size1 = 500,\n",
    "        hidden_size2 = 2000,\n",
    "        hidden_size3 = 2000,\n",
    "        hidden_size4 = 200,\n",
    "        weight_init_method = 'normal'\n",
    "    ))\n",
    "\n",
    "\n",
    "    model = models[model_number]\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            # weight_decay= 0.0001,\n",
    "                            lr=0.01\n",
    "            )\n",
    "    \n",
    "    results = train(\n",
    "        model=model, \n",
    "        train_dataloader=test_pipeline.train_loader, \n",
    "        test_dataloader=test_pipeline.test_loader, \n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        epochs=5000,\n",
    "        patience=15,\n",
    "        show_plots = show_plots\n",
    "    )\n",
    "    if append_result_list:\n",
    "        list_of_results.append(results)\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 5.9374 | test_loss: 2.4817 | \n",
      "Epoch: 10 | train_loss: 0.1672 | test_loss: 0.1549 | \n",
      "Epoch: 20 | train_loss: 0.1474 | test_loss: 0.1486 | \n",
      "Epoch: 30 | train_loss: 0.1385 | test_loss: 0.1442 | \n",
      "Epoch: 40 | train_loss: 0.1312 | test_loss: 0.1395 | \n",
      "Epoch: 50 | train_loss: 0.1250 | test_loss: 0.1366 | \n",
      "Epoch: 60 | train_loss: 0.1196 | test_loss: 0.1430 | \n",
      "Epoch: 70 | train_loss: 0.1135 | test_loss: 0.1358 | \n",
      "Epoch: 80 | train_loss: 0.1052 | test_loss: 0.1370 | \n",
      "Epoch: 90 | train_loss: 0.0996 | test_loss: 0.1351 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.4465 | test_loss: 0.2896 | \n",
      "Epoch: 10 | train_loss: 0.1465 | test_loss: 0.1465 | \n",
      "Epoch: 20 | train_loss: 0.1235 | test_loss: 0.1407 | \n",
      "Epoch: 30 | train_loss: 0.1123 | test_loss: 0.1370 | \n",
      "Epoch: 40 | train_loss: 0.1061 | test_loss: 0.1397 | \n",
      "Epoch: 50 | train_loss: 0.1077 | test_loss: 0.1392 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 2.1027 | test_loss: 0.6419 | \n",
      "Epoch: 10 | train_loss: 0.1534 | test_loss: 0.1946 | \n",
      "Epoch: 20 | train_loss: 0.1416 | test_loss: 0.1533 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6573 | test_loss: 8.7125 | \n",
      "Epoch: 10 | train_loss: 5.9511 | test_loss: 5.8556 | \n",
      "Epoch: 20 | train_loss: 4.8866 | test_loss: 4.8417 | \n",
      "Epoch: 30 | train_loss: 4.2435 | test_loss: 4.2149 | \n",
      "Epoch: 40 | train_loss: 3.7763 | test_loss: 3.7404 | \n",
      "Epoch: 50 | train_loss: 3.3986 | test_loss: 3.3836 | \n",
      "Epoch: 60 | train_loss: 3.0834 | test_loss: 3.0618 | \n",
      "Epoch: 70 | train_loss: 2.8062 | test_loss: 2.7883 | \n",
      "Epoch: 80 | train_loss: 2.5530 | test_loss: 2.5361 | \n",
      "Epoch: 90 | train_loss: 2.3449 | test_loss: 2.2942 | \n",
      "Epoch: 100 | train_loss: 2.1152 | test_loss: 2.1082 | \n",
      "Epoch: 110 | train_loss: 1.9173 | test_loss: 1.8995 | \n",
      "Epoch: 120 | train_loss: 1.7318 | test_loss: 1.7044 | \n",
      "Epoch: 130 | train_loss: 1.5520 | test_loss: 1.5475 | \n",
      "Epoch: 140 | train_loss: 1.3825 | test_loss: 1.3766 | \n",
      "Epoch: 150 | train_loss: 1.2221 | test_loss: 1.1995 | \n",
      "Epoch: 160 | train_loss: 1.0633 | test_loss: 1.0632 | \n",
      "Epoch: 170 | train_loss: 0.9116 | test_loss: 0.8907 | \n",
      "Epoch: 180 | train_loss: 0.7681 | test_loss: 0.7619 | \n",
      "Epoch: 190 | train_loss: 0.6291 | test_loss: 0.6300 | \n",
      "Epoch: 200 | train_loss: 0.4933 | test_loss: 0.4852 | \n",
      "Epoch: 210 | train_loss: 0.3698 | test_loss: 0.3736 | \n",
      "Epoch: 220 | train_loss: 0.2680 | test_loss: 0.2774 | \n",
      "Epoch: 230 | train_loss: 0.1692 | test_loss: 0.1850 | \n",
      "Epoch: 240 | train_loss: 0.1162 | test_loss: 0.1464 | \n",
      "Epoch: 250 | train_loss: 0.0965 | test_loss: 0.1580 | \n",
      "Epoch: 260 | train_loss: 0.0980 | test_loss: 0.1447 | \n",
      "Epoch: 270 | train_loss: 0.0796 | test_loss: 0.1446 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6268 | test_loss: 8.7219 | \n",
      "Epoch: 10 | train_loss: 5.9298 | test_loss: 5.8146 | \n",
      "Epoch: 20 | train_loss: 4.8657 | test_loss: 4.8135 | \n",
      "Epoch: 30 | train_loss: 4.2245 | test_loss: 4.1904 | \n",
      "Epoch: 40 | train_loss: 3.7555 | test_loss: 3.7430 | \n",
      "Epoch: 50 | train_loss: 3.3833 | test_loss: 3.3360 | \n",
      "Epoch: 60 | train_loss: 3.0645 | test_loss: 3.0556 | \n",
      "Epoch: 70 | train_loss: 2.7858 | test_loss: 2.7612 | \n",
      "Epoch: 80 | train_loss: 2.5368 | test_loss: 2.5004 | \n",
      "Epoch: 90 | train_loss: 2.3098 | test_loss: 2.3402 | \n",
      "Epoch: 100 | train_loss: 2.0992 | test_loss: 2.0710 | \n",
      "Epoch: 110 | train_loss: 1.9013 | test_loss: 1.8856 | \n",
      "Epoch: 120 | train_loss: 1.7141 | test_loss: 1.6974 | \n",
      "Epoch: 130 | train_loss: 1.5405 | test_loss: 1.5373 | \n",
      "Epoch: 140 | train_loss: 1.3669 | test_loss: 1.3498 | \n",
      "Epoch: 150 | train_loss: 1.2109 | test_loss: 1.1897 | \n",
      "Epoch: 160 | train_loss: 1.0508 | test_loss: 1.0267 | \n",
      "Epoch: 170 | train_loss: 0.8997 | test_loss: 0.8930 | \n",
      "Epoch: 180 | train_loss: 0.7580 | test_loss: 0.7747 | \n",
      "Epoch: 190 | train_loss: 0.6172 | test_loss: 0.5846 | \n",
      "Epoch: 200 | train_loss: 0.4861 | test_loss: 0.4965 | \n",
      "Epoch: 210 | train_loss: 0.3645 | test_loss: 0.4063 | \n",
      "Epoch: 220 | train_loss: 0.2641 | test_loss: 0.2424 | \n",
      "Epoch: 230 | train_loss: 0.1646 | test_loss: 0.2149 | \n",
      "Epoch: 240 | train_loss: 0.1087 | test_loss: 0.1716 | \n",
      "Epoch: 250 | train_loss: 0.0927 | test_loss: 0.1539 | \n",
      "Epoch: 260 | train_loss: 0.0885 | test_loss: 0.1524 | \n",
      "Epoch: 270 | train_loss: 0.0886 | test_loss: 0.1465 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.7199 | test_loss: 8.6390 | \n",
      "Epoch: 10 | train_loss: 5.9939 | test_loss: 5.8980 | \n",
      "Epoch: 20 | train_loss: 4.9311 | test_loss: 4.8534 | \n",
      "Epoch: 30 | train_loss: 4.2838 | test_loss: 4.2308 | \n",
      "Epoch: 40 | train_loss: 3.8114 | test_loss: 3.7790 | \n",
      "Epoch: 50 | train_loss: 3.4401 | test_loss: 3.3965 | \n",
      "Epoch: 60 | train_loss: 3.1196 | test_loss: 3.0862 | \n",
      "Epoch: 70 | train_loss: 2.8404 | test_loss: 2.8113 | \n",
      "Epoch: 80 | train_loss: 2.5897 | test_loss: 2.5623 | \n",
      "Epoch: 90 | train_loss: 2.3649 | test_loss: 2.3351 | \n",
      "Epoch: 100 | train_loss: 2.1524 | test_loss: 2.1321 | \n",
      "Epoch: 110 | train_loss: 1.9551 | test_loss: 1.9218 | \n",
      "Epoch: 120 | train_loss: 1.7705 | test_loss: 1.7339 | \n",
      "Epoch: 130 | train_loss: 1.5903 | test_loss: 1.5696 | \n",
      "Epoch: 140 | train_loss: 1.4173 | test_loss: 1.3901 | \n",
      "Epoch: 150 | train_loss: 1.2570 | test_loss: 1.2403 | \n",
      "Epoch: 160 | train_loss: 1.1047 | test_loss: 1.0799 | \n",
      "Epoch: 170 | train_loss: 0.9572 | test_loss: 0.9228 | \n",
      "Epoch: 180 | train_loss: 0.8156 | test_loss: 0.7929 | \n",
      "Epoch: 190 | train_loss: 0.6726 | test_loss: 0.6616 | \n",
      "Epoch: 200 | train_loss: 0.5491 | test_loss: 0.5405 | \n",
      "Epoch: 210 | train_loss: 0.4330 | test_loss: 0.4137 | \n",
      "Epoch: 220 | train_loss: 0.3252 | test_loss: 0.3043 | \n",
      "Epoch: 230 | train_loss: 0.2445 | test_loss: 0.2293 | \n",
      "Epoch: 240 | train_loss: 0.2007 | test_loss: 0.1831 | \n",
      "Epoch: 250 | train_loss: 0.1701 | test_loss: 0.1527 | \n",
      "Epoch: 260 | train_loss: 0.1712 | test_loss: 0.1464 | \n",
      "Epoch: 270 | train_loss: 0.1564 | test_loss: 0.1397 | \n",
      "Epoch: 280 | train_loss: 0.1553 | test_loss: 0.1451 | \n",
      "Epoch: 290 | train_loss: 0.1533 | test_loss: 0.1423 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.7614 | test_loss: 8.7187 | \n",
      "Epoch: 10 | train_loss: 6.0354 | test_loss: 5.9265 | \n",
      "Epoch: 20 | train_loss: 4.9717 | test_loss: 4.8983 | \n",
      "Epoch: 30 | train_loss: 4.3204 | test_loss: 4.2752 | \n",
      "Epoch: 40 | train_loss: 3.8563 | test_loss: 3.8103 | \n",
      "Epoch: 50 | train_loss: 3.4803 | test_loss: 3.4357 | \n",
      "Epoch: 60 | train_loss: 3.1635 | test_loss: 3.1227 | \n",
      "Epoch: 70 | train_loss: 2.8794 | test_loss: 2.8533 | \n",
      "Epoch: 80 | train_loss: 2.6283 | test_loss: 2.5988 | \n",
      "Epoch: 90 | train_loss: 2.4024 | test_loss: 2.3730 | \n",
      "Epoch: 100 | train_loss: 2.1960 | test_loss: 2.1586 | \n",
      "Epoch: 110 | train_loss: 1.9941 | test_loss: 1.9533 | \n",
      "Epoch: 120 | train_loss: 1.8029 | test_loss: 1.7727 | \n",
      "Epoch: 130 | train_loss: 1.6279 | test_loss: 1.5918 | \n",
      "Epoch: 140 | train_loss: 1.4610 | test_loss: 1.4338 | \n",
      "Epoch: 150 | train_loss: 1.2937 | test_loss: 1.2702 | \n",
      "Epoch: 160 | train_loss: 1.1417 | test_loss: 1.1220 | \n",
      "Epoch: 170 | train_loss: 0.9894 | test_loss: 0.9681 | \n",
      "Epoch: 180 | train_loss: 0.8438 | test_loss: 0.8234 | \n",
      "Epoch: 190 | train_loss: 0.7093 | test_loss: 0.6862 | \n",
      "Epoch: 200 | train_loss: 0.5718 | test_loss: 0.5664 | \n",
      "Epoch: 210 | train_loss: 0.4590 | test_loss: 0.4386 | \n",
      "Epoch: 220 | train_loss: 0.3496 | test_loss: 0.3388 | \n",
      "Epoch: 230 | train_loss: 0.2624 | test_loss: 0.2361 | \n",
      "Epoch: 240 | train_loss: 0.1951 | test_loss: 0.1680 | \n",
      "Epoch: 250 | train_loss: 0.1776 | test_loss: 0.1505 | \n",
      "Epoch: 260 | train_loss: 0.1600 | test_loss: 0.1504 | \n",
      "Epoch: 270 | train_loss: 0.1602 | test_loss: 0.1496 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.4630 | test_loss: 4.9318 | \n",
      "Epoch: 10 | train_loss: 0.2022 | test_loss: 0.1832 | \n",
      "Epoch: 20 | train_loss: 0.1695 | test_loss: 0.1584 | \n",
      "Epoch: 30 | train_loss: 0.1558 | test_loss: 0.1507 | \n",
      "Epoch: 40 | train_loss: 0.1469 | test_loss: 0.1495 | \n",
      "Epoch: 50 | train_loss: 0.1435 | test_loss: 0.1459 | \n",
      "Epoch: 60 | train_loss: 0.1364 | test_loss: 0.1433 | \n",
      "Epoch: 70 | train_loss: 0.1323 | test_loss: 0.1433 | \n",
      "Epoch: 80 | train_loss: 0.1279 | test_loss: 0.1410 | \n",
      "Epoch: 90 | train_loss: 0.1220 | test_loss: 0.1391 | \n",
      "Epoch: 100 | train_loss: 0.1204 | test_loss: 0.1396 | \n",
      "Epoch: 110 | train_loss: 0.1156 | test_loss: 0.1375 | \n",
      "Epoch: 120 | train_loss: 0.1112 | test_loss: 0.1397 | \n",
      "Epoch: 130 | train_loss: 0.1097 | test_loss: 0.1368 | \n",
      "Epoch: 140 | train_loss: 0.1081 | test_loss: 0.1388 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.6925 | test_loss: 1.9147 | \n",
      "Epoch: 10 | train_loss: 0.1671 | test_loss: 0.1563 | \n",
      "Epoch: 20 | train_loss: 0.1443 | test_loss: 0.1470 | \n",
      "Epoch: 30 | train_loss: 0.1304 | test_loss: 0.1415 | \n",
      "Epoch: 40 | train_loss: 0.1219 | test_loss: 0.1462 | \n",
      "Epoch: 50 | train_loss: 0.1129 | test_loss: 0.1373 | \n",
      "Epoch: 60 | train_loss: 0.1061 | test_loss: 0.1435 | \n",
      "Epoch: 70 | train_loss: 0.1020 | test_loss: 0.1410 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.1957 | test_loss: 1.6302 | \n",
      "Epoch: 10 | train_loss: 0.1422 | test_loss: 0.1508 | \n",
      "Epoch: 20 | train_loss: 0.1194 | test_loss: 0.1617 | \n",
      "Epoch: 30 | train_loss: 0.1069 | test_loss: 0.1409 | \n",
      "Epoch: 40 | train_loss: 0.0895 | test_loss: 0.1424 | \n",
      "Epoch: 50 | train_loss: 0.2599 | test_loss: 0.2124 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2949 | test_loss: 9.1983 | \n",
      "Epoch: 10 | train_loss: 6.8916 | test_loss: 6.7958 | \n",
      "Epoch: 20 | train_loss: 5.8820 | test_loss: 5.8422 | \n",
      "Epoch: 30 | train_loss: 5.2750 | test_loss: 5.2227 | \n",
      "Epoch: 40 | train_loss: 4.8376 | test_loss: 4.8174 | \n",
      "Epoch: 50 | train_loss: 4.4933 | test_loss: 4.4530 | \n",
      "Epoch: 60 | train_loss: 4.2059 | test_loss: 4.1801 | \n",
      "Epoch: 70 | train_loss: 3.9585 | test_loss: 3.9485 | \n",
      "Epoch: 80 | train_loss: 3.7419 | test_loss: 3.7057 | \n",
      "Epoch: 90 | train_loss: 3.5465 | test_loss: 3.5497 | \n",
      "Epoch: 100 | train_loss: 3.3651 | test_loss: 3.3374 | \n",
      "Epoch: 110 | train_loss: 3.2035 | test_loss: 3.1817 | \n",
      "Epoch: 120 | train_loss: 3.0504 | test_loss: 3.0407 | \n",
      "Epoch: 130 | train_loss: 2.9079 | test_loss: 2.8965 | \n",
      "Epoch: 140 | train_loss: 2.7724 | test_loss: 2.7630 | \n",
      "Epoch: 150 | train_loss: 2.6460 | test_loss: 2.6213 | \n",
      "Epoch: 160 | train_loss: 2.5243 | test_loss: 2.5145 | \n",
      "Epoch: 170 | train_loss: 2.4087 | test_loss: 2.3847 | \n",
      "Epoch: 180 | train_loss: 2.2958 | test_loss: 2.2775 | \n",
      "Epoch: 190 | train_loss: 2.1902 | test_loss: 2.1787 | \n",
      "Epoch: 200 | train_loss: 2.0868 | test_loss: 2.0723 | \n",
      "Epoch: 210 | train_loss: 1.9846 | test_loss: 1.9674 | \n",
      "Epoch: 220 | train_loss: 1.8884 | test_loss: 1.8707 | \n",
      "Epoch: 230 | train_loss: 1.7940 | test_loss: 1.7864 | \n",
      "Epoch: 240 | train_loss: 1.7032 | test_loss: 1.6933 | \n",
      "Epoch: 250 | train_loss: 1.6127 | test_loss: 1.6071 | \n",
      "Epoch: 260 | train_loss: 1.5250 | test_loss: 1.5085 | \n",
      "Epoch: 270 | train_loss: 1.4406 | test_loss: 1.4371 | \n",
      "Epoch: 280 | train_loss: 1.3557 | test_loss: 1.3482 | \n",
      "Epoch: 290 | train_loss: 1.2732 | test_loss: 1.2765 | \n",
      "Epoch: 300 | train_loss: 1.1956 | test_loss: 1.1801 | \n",
      "Epoch: 310 | train_loss: 1.1145 | test_loss: 1.1117 | \n",
      "Epoch: 320 | train_loss: 1.0388 | test_loss: 1.0327 | \n",
      "Epoch: 330 | train_loss: 0.9624 | test_loss: 0.9532 | \n",
      "Epoch: 340 | train_loss: 0.8873 | test_loss: 0.8851 | \n",
      "Epoch: 350 | train_loss: 0.8136 | test_loss: 0.8187 | \n",
      "Epoch: 360 | train_loss: 0.7464 | test_loss: 0.7583 | \n",
      "Epoch: 370 | train_loss: 0.6702 | test_loss: 0.6672 | \n",
      "Epoch: 380 | train_loss: 0.6015 | test_loss: 0.6076 | \n",
      "Epoch: 390 | train_loss: 0.5357 | test_loss: 0.5553 | \n",
      "Epoch: 400 | train_loss: 0.4682 | test_loss: 0.4894 | \n",
      "Epoch: 410 | train_loss: 0.4061 | test_loss: 0.4220 | \n",
      "Epoch: 420 | train_loss: 0.3399 | test_loss: 0.3528 | \n",
      "Epoch: 430 | train_loss: 0.2861 | test_loss: 0.3292 | \n",
      "Epoch: 440 | train_loss: 0.2345 | test_loss: 0.2242 | \n",
      "Epoch: 450 | train_loss: 0.1755 | test_loss: 0.2273 | \n",
      "Epoch: 460 | train_loss: 0.1252 | test_loss: 0.1738 | \n",
      "Epoch: 470 | train_loss: 0.0934 | test_loss: 0.1589 | \n",
      "Epoch: 480 | train_loss: 0.0750 | test_loss: 0.1496 | \n",
      "Epoch: 490 | train_loss: 0.0649 | test_loss: 0.1458 | \n",
      "Epoch: 500 | train_loss: 0.0614 | test_loss: 0.1394 | \n",
      "Epoch: 510 | train_loss: 0.0622 | test_loss: 0.1431 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2274 | test_loss: 9.0034 | \n",
      "Epoch: 10 | train_loss: 6.8375 | test_loss: 6.7865 | \n",
      "Epoch: 20 | train_loss: 5.8255 | test_loss: 5.7840 | \n",
      "Epoch: 30 | train_loss: 5.2228 | test_loss: 5.1827 | \n",
      "Epoch: 40 | train_loss: 4.7828 | test_loss: 4.7547 | \n",
      "Epoch: 50 | train_loss: 4.4387 | test_loss: 4.3991 | \n",
      "Epoch: 60 | train_loss: 4.1507 | test_loss: 4.1073 | \n",
      "Epoch: 70 | train_loss: 3.9035 | test_loss: 3.8819 | \n",
      "Epoch: 80 | train_loss: 3.6858 | test_loss: 3.6631 | \n",
      "Epoch: 90 | train_loss: 3.4903 | test_loss: 3.4786 | \n",
      "Epoch: 100 | train_loss: 3.3133 | test_loss: 3.2956 | \n",
      "Epoch: 110 | train_loss: 3.1483 | test_loss: 3.1355 | \n",
      "Epoch: 120 | train_loss: 2.9968 | test_loss: 2.9603 | \n",
      "Epoch: 130 | train_loss: 2.8546 | test_loss: 2.8320 | \n",
      "Epoch: 140 | train_loss: 2.7197 | test_loss: 2.6991 | \n",
      "Epoch: 150 | train_loss: 2.5945 | test_loss: 2.5680 | \n",
      "Epoch: 160 | train_loss: 2.4728 | test_loss: 2.4488 | \n",
      "Epoch: 170 | train_loss: 2.3577 | test_loss: 2.3526 | \n",
      "Epoch: 180 | train_loss: 2.2452 | test_loss: 2.2255 | \n",
      "Epoch: 190 | train_loss: 2.1394 | test_loss: 2.1426 | \n",
      "Epoch: 200 | train_loss: 2.0357 | test_loss: 2.0257 | \n",
      "Epoch: 210 | train_loss: 1.9359 | test_loss: 1.9246 | \n",
      "Epoch: 220 | train_loss: 1.8390 | test_loss: 1.8202 | \n",
      "Epoch: 230 | train_loss: 1.7449 | test_loss: 1.7224 | \n",
      "Epoch: 240 | train_loss: 1.6544 | test_loss: 1.6545 | \n",
      "Epoch: 250 | train_loss: 1.5656 | test_loss: 1.5537 | \n",
      "Epoch: 260 | train_loss: 1.4750 | test_loss: 1.4775 | \n",
      "Epoch: 270 | train_loss: 1.3907 | test_loss: 1.3724 | \n",
      "Epoch: 280 | train_loss: 1.3067 | test_loss: 1.3043 | \n",
      "Epoch: 290 | train_loss: 1.2267 | test_loss: 1.2227 | \n",
      "Epoch: 300 | train_loss: 1.1454 | test_loss: 1.1306 | \n",
      "Epoch: 310 | train_loss: 1.0664 | test_loss: 1.0539 | \n",
      "Epoch: 320 | train_loss: 0.9884 | test_loss: 0.9636 | \n",
      "Epoch: 330 | train_loss: 0.9138 | test_loss: 0.8914 | \n",
      "Epoch: 340 | train_loss: 0.8386 | test_loss: 0.8361 | \n",
      "Epoch: 350 | train_loss: 0.7688 | test_loss: 0.8080 | \n",
      "Epoch: 360 | train_loss: 0.6966 | test_loss: 0.6670 | \n",
      "Epoch: 370 | train_loss: 0.6268 | test_loss: 0.6104 | \n",
      "Epoch: 380 | train_loss: 0.5608 | test_loss: 0.5542 | \n",
      "Epoch: 390 | train_loss: 0.4918 | test_loss: 0.4764 | \n",
      "Epoch: 400 | train_loss: 0.4258 | test_loss: 0.4120 | \n",
      "Epoch: 410 | train_loss: 0.3629 | test_loss: 0.3508 | \n",
      "Epoch: 420 | train_loss: 0.3078 | test_loss: 0.3049 | \n",
      "Epoch: 430 | train_loss: 0.2436 | test_loss: 0.2563 | \n",
      "Epoch: 440 | train_loss: 0.1878 | test_loss: 0.2428 | \n",
      "Epoch: 450 | train_loss: 0.1409 | test_loss: 0.1899 | \n",
      "Epoch: 460 | train_loss: 0.1083 | test_loss: 0.1693 | \n",
      "Epoch: 470 | train_loss: 0.0766 | test_loss: 0.1535 | \n",
      "Epoch: 480 | train_loss: 0.0670 | test_loss: 0.1490 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3024 | test_loss: 9.0532 | \n",
      "Epoch: 10 | train_loss: 6.9002 | test_loss: 6.8033 | \n",
      "Epoch: 20 | train_loss: 5.8945 | test_loss: 5.8434 | \n",
      "Epoch: 30 | train_loss: 5.2794 | test_loss: 5.2269 | \n",
      "Epoch: 40 | train_loss: 4.8524 | test_loss: 4.8037 | \n",
      "Epoch: 50 | train_loss: 4.4979 | test_loss: 4.4636 | \n",
      "Epoch: 60 | train_loss: 4.2113 | test_loss: 4.1850 | \n",
      "Epoch: 70 | train_loss: 3.9639 | test_loss: 3.9356 | \n",
      "Epoch: 80 | train_loss: 3.7456 | test_loss: 3.7243 | \n",
      "Epoch: 90 | train_loss: 3.5517 | test_loss: 3.5283 | \n",
      "Epoch: 100 | train_loss: 3.3708 | test_loss: 3.3506 | \n",
      "Epoch: 110 | train_loss: 3.2113 | test_loss: 3.1876 | \n",
      "Epoch: 120 | train_loss: 3.0575 | test_loss: 3.0357 | \n",
      "Epoch: 130 | train_loss: 2.9172 | test_loss: 2.8990 | \n",
      "Epoch: 140 | train_loss: 2.7746 | test_loss: 2.7559 | \n",
      "Epoch: 150 | train_loss: 2.6502 | test_loss: 2.6304 | \n",
      "Epoch: 160 | train_loss: 2.5327 | test_loss: 2.5141 | \n",
      "Epoch: 170 | train_loss: 2.4106 | test_loss: 2.3945 | \n",
      "Epoch: 180 | train_loss: 2.3035 | test_loss: 2.2808 | \n",
      "Epoch: 190 | train_loss: 2.1970 | test_loss: 2.1901 | \n",
      "Epoch: 200 | train_loss: 2.0906 | test_loss: 2.0738 | \n",
      "Epoch: 210 | train_loss: 1.9936 | test_loss: 1.9741 | \n",
      "Epoch: 220 | train_loss: 1.9007 | test_loss: 1.8775 | \n",
      "Epoch: 230 | train_loss: 1.8042 | test_loss: 1.7829 | \n",
      "Epoch: 240 | train_loss: 1.7062 | test_loss: 1.6985 | \n",
      "Epoch: 250 | train_loss: 1.6239 | test_loss: 1.6004 | \n",
      "Epoch: 260 | train_loss: 1.5380 | test_loss: 1.5212 | \n",
      "Epoch: 270 | train_loss: 1.4456 | test_loss: 1.4300 | \n",
      "Epoch: 280 | train_loss: 1.3652 | test_loss: 1.3509 | \n",
      "Epoch: 290 | train_loss: 1.2885 | test_loss: 1.2719 | \n",
      "Epoch: 300 | train_loss: 1.2082 | test_loss: 1.1827 | \n",
      "Epoch: 310 | train_loss: 1.1278 | test_loss: 1.1139 | \n",
      "Epoch: 320 | train_loss: 1.0516 | test_loss: 1.0365 | \n",
      "Epoch: 330 | train_loss: 0.9703 | test_loss: 0.9593 | \n",
      "Epoch: 340 | train_loss: 0.9006 | test_loss: 0.8835 | \n",
      "Epoch: 350 | train_loss: 0.8252 | test_loss: 0.8136 | \n",
      "Epoch: 360 | train_loss: 0.7599 | test_loss: 0.7423 | \n",
      "Epoch: 370 | train_loss: 0.6881 | test_loss: 0.6703 | \n",
      "Epoch: 380 | train_loss: 0.6270 | test_loss: 0.6070 | \n",
      "Epoch: 390 | train_loss: 0.5590 | test_loss: 0.5437 | \n",
      "Epoch: 400 | train_loss: 0.4962 | test_loss: 0.4837 | \n",
      "Epoch: 410 | train_loss: 0.4330 | test_loss: 0.4269 | \n",
      "Epoch: 420 | train_loss: 0.3787 | test_loss: 0.3694 | \n",
      "Epoch: 430 | train_loss: 0.3228 | test_loss: 0.3117 | \n",
      "Epoch: 440 | train_loss: 0.2689 | test_loss: 0.2642 | \n",
      "Epoch: 450 | train_loss: 0.2286 | test_loss: 0.2190 | \n",
      "Epoch: 460 | train_loss: 0.2050 | test_loss: 0.1911 | \n",
      "Epoch: 470 | train_loss: 0.1758 | test_loss: 0.1727 | \n",
      "Epoch: 480 | train_loss: 0.1485 | test_loss: 0.1575 | \n",
      "Epoch: 490 | train_loss: 0.1433 | test_loss: 0.1444 | \n",
      "Epoch: 500 | train_loss: 0.1351 | test_loss: 0.1382 | \n",
      "Epoch: 510 | train_loss: 0.1331 | test_loss: 0.1432 | \n",
      "Epoch: 520 | train_loss: 0.1287 | test_loss: 0.1363 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3535 | test_loss: 9.1187 | \n",
      "Epoch: 10 | train_loss: 6.9590 | test_loss: 6.8737 | \n",
      "Epoch: 20 | train_loss: 5.9505 | test_loss: 5.8863 | \n",
      "Epoch: 30 | train_loss: 5.3385 | test_loss: 5.2842 | \n",
      "Epoch: 40 | train_loss: 4.8909 | test_loss: 4.8493 | \n",
      "Epoch: 50 | train_loss: 4.5461 | test_loss: 4.5066 | \n",
      "Epoch: 60 | train_loss: 4.2587 | test_loss: 4.2280 | \n",
      "Epoch: 70 | train_loss: 4.0115 | test_loss: 3.9808 | \n",
      "Epoch: 80 | train_loss: 3.7892 | test_loss: 3.7621 | \n",
      "Epoch: 90 | train_loss: 3.5908 | test_loss: 3.5685 | \n",
      "Epoch: 100 | train_loss: 3.4092 | test_loss: 3.3941 | \n",
      "Epoch: 110 | train_loss: 3.2455 | test_loss: 3.2266 | \n",
      "Epoch: 120 | train_loss: 3.0948 | test_loss: 3.0811 | \n",
      "Epoch: 130 | train_loss: 2.9511 | test_loss: 2.9386 | \n",
      "Epoch: 140 | train_loss: 2.8206 | test_loss: 2.8040 | \n",
      "Epoch: 150 | train_loss: 2.6903 | test_loss: 2.6706 | \n",
      "Epoch: 160 | train_loss: 2.5716 | test_loss: 2.5539 | \n",
      "Epoch: 170 | train_loss: 2.4557 | test_loss: 2.4398 | \n",
      "Epoch: 180 | train_loss: 2.3468 | test_loss: 2.3329 | \n",
      "Epoch: 190 | train_loss: 2.2369 | test_loss: 2.2239 | \n",
      "Epoch: 200 | train_loss: 2.1361 | test_loss: 2.1186 | \n",
      "Epoch: 210 | train_loss: 2.0312 | test_loss: 2.0239 | \n",
      "Epoch: 220 | train_loss: 1.9371 | test_loss: 1.9259 | \n",
      "Epoch: 230 | train_loss: 1.8445 | test_loss: 1.8317 | \n",
      "Epoch: 240 | train_loss: 1.7538 | test_loss: 1.7395 | \n",
      "Epoch: 250 | train_loss: 1.6623 | test_loss: 1.6439 | \n",
      "Epoch: 260 | train_loss: 1.5713 | test_loss: 1.5566 | \n",
      "Epoch: 270 | train_loss: 1.4875 | test_loss: 1.4755 | \n",
      "Epoch: 280 | train_loss: 1.4052 | test_loss: 1.3845 | \n",
      "Epoch: 290 | train_loss: 1.3200 | test_loss: 1.3058 | \n",
      "Epoch: 300 | train_loss: 1.2433 | test_loss: 1.2264 | \n",
      "Epoch: 310 | train_loss: 1.1678 | test_loss: 1.1454 | \n",
      "Epoch: 320 | train_loss: 1.0857 | test_loss: 1.0747 | \n",
      "Epoch: 330 | train_loss: 1.0095 | test_loss: 0.9924 | \n",
      "Epoch: 340 | train_loss: 0.9395 | test_loss: 0.9260 | \n",
      "Epoch: 350 | train_loss: 0.8661 | test_loss: 0.8490 | \n",
      "Epoch: 360 | train_loss: 0.7995 | test_loss: 0.7842 | \n",
      "Epoch: 370 | train_loss: 0.7285 | test_loss: 0.7104 | \n",
      "Epoch: 380 | train_loss: 0.6593 | test_loss: 0.6403 | \n",
      "Epoch: 390 | train_loss: 0.5937 | test_loss: 0.5780 | \n",
      "Epoch: 400 | train_loss: 0.5209 | test_loss: 0.5083 | \n",
      "Epoch: 410 | train_loss: 0.4679 | test_loss: 0.4557 | \n",
      "Epoch: 420 | train_loss: 0.4065 | test_loss: 0.3950 | \n",
      "Epoch: 430 | train_loss: 0.3478 | test_loss: 0.3333 | \n",
      "Epoch: 440 | train_loss: 0.2969 | test_loss: 0.2822 | \n",
      "Epoch: 450 | train_loss: 0.2505 | test_loss: 0.2446 | \n",
      "Epoch: 460 | train_loss: 0.2112 | test_loss: 0.2037 | \n",
      "Epoch: 470 | train_loss: 0.1828 | test_loss: 0.1829 | \n",
      "Epoch: 480 | train_loss: 0.1564 | test_loss: 0.1542 | \n",
      "Epoch: 490 | train_loss: 0.1467 | test_loss: 0.1424 | \n",
      "Epoch: 500 | train_loss: 0.1409 | test_loss: 0.1437 | \n",
      "Epoch: 510 | train_loss: 0.1283 | test_loss: 0.1403 | \n",
      "Epoch: 520 | train_loss: 0.1288 | test_loss: 0.1477 | \n",
      "Epoch: 530 | train_loss: 0.1299 | test_loss: 0.1370 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3475 | test_loss: 7.3512 | \n",
      "Epoch: 10 | train_loss: 0.3230 | test_loss: 0.2598 | \n",
      "Epoch: 20 | train_loss: 0.1964 | test_loss: 0.1811 | \n",
      "Epoch: 30 | train_loss: 0.1764 | test_loss: 0.1636 | \n",
      "Epoch: 40 | train_loss: 0.1643 | test_loss: 0.1556 | \n",
      "Epoch: 50 | train_loss: 0.1570 | test_loss: 0.1525 | \n",
      "Epoch: 60 | train_loss: 0.1504 | test_loss: 0.1521 | \n",
      "Epoch: 70 | train_loss: 0.1487 | test_loss: 0.1497 | \n",
      "Epoch: 80 | train_loss: 0.1450 | test_loss: 0.1487 | \n",
      "Epoch: 90 | train_loss: 0.1427 | test_loss: 0.1473 | \n",
      "Epoch: 100 | train_loss: 0.1383 | test_loss: 0.1463 | \n",
      "Epoch: 110 | train_loss: 0.1363 | test_loss: 0.1442 | \n",
      "Epoch: 120 | train_loss: 0.1349 | test_loss: 0.1444 | \n",
      "Epoch: 130 | train_loss: 0.1314 | test_loss: 0.1427 | \n",
      "Epoch: 140 | train_loss: 0.1282 | test_loss: 0.1411 | \n",
      "Epoch: 150 | train_loss: 0.1252 | test_loss: 0.1401 | \n",
      "Epoch: 160 | train_loss: 0.1226 | test_loss: 0.1396 | \n",
      "Epoch: 170 | train_loss: 0.1218 | test_loss: 0.1388 | \n",
      "Epoch: 180 | train_loss: 0.1201 | test_loss: 0.1390 | \n",
      "Epoch: 190 | train_loss: 0.1171 | test_loss: 0.1377 | \n",
      "Epoch: 200 | train_loss: 0.1152 | test_loss: 0.1391 | \n",
      "Epoch: 210 | train_loss: 0.1119 | test_loss: 0.1371 | \n",
      "Epoch: 220 | train_loss: 0.1093 | test_loss: 0.1375 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.4064 | test_loss: 4.5817 | \n",
      "Epoch: 10 | train_loss: 0.2091 | test_loss: 0.1901 | \n",
      "Epoch: 20 | train_loss: 0.1646 | test_loss: 0.1577 | \n",
      "Epoch: 30 | train_loss: 0.1511 | test_loss: 0.1514 | \n",
      "Epoch: 40 | train_loss: 0.1422 | test_loss: 0.1477 | \n",
      "Epoch: 50 | train_loss: 0.1340 | test_loss: 0.1440 | \n",
      "Epoch: 60 | train_loss: 0.1306 | test_loss: 0.1434 | \n",
      "Epoch: 70 | train_loss: 0.1227 | test_loss: 0.1388 | \n",
      "Epoch: 80 | train_loss: 0.1186 | test_loss: 0.1381 | \n",
      "Epoch: 90 | train_loss: 0.1149 | test_loss: 0.1374 | \n",
      "Epoch: 100 | train_loss: 0.1104 | test_loss: 0.1361 | \n",
      "Epoch: 110 | train_loss: 0.1083 | test_loss: 0.1378 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.0907 | test_loss: 0.3854 | \n",
      "Epoch: 10 | train_loss: 0.1682 | test_loss: 0.1517 | \n",
      "Epoch: 20 | train_loss: 0.1325 | test_loss: 0.1431 | \n",
      "Epoch: 30 | train_loss: 0.1087 | test_loss: 0.1455 | \n",
      "Epoch: 40 | train_loss: 0.1248 | test_loss: 0.1345 | \n",
      "Epoch: 50 | train_loss: 0.0925 | test_loss: 0.1387 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 11.0386 | test_loss: 9.8251 | \n",
      "Epoch: 10 | train_loss: 7.8324 | test_loss: 7.7547 | \n",
      "Epoch: 20 | train_loss: 6.9231 | test_loss: 6.8555 | \n",
      "Epoch: 30 | train_loss: 6.3578 | test_loss: 6.3333 | \n",
      "Epoch: 40 | train_loss: 5.9510 | test_loss: 5.9322 | \n",
      "Epoch: 50 | train_loss: 5.6296 | test_loss: 5.6120 | \n",
      "Epoch: 60 | train_loss: 5.3635 | test_loss: 5.3445 | \n",
      "Epoch: 70 | train_loss: 5.1263 | test_loss: 5.0644 | \n",
      "Epoch: 80 | train_loss: 4.9180 | test_loss: 4.8898 | \n",
      "Epoch: 90 | train_loss: 4.7359 | test_loss: 4.7037 | \n",
      "Epoch: 100 | train_loss: 4.5712 | test_loss: 4.5413 | \n",
      "Epoch: 110 | train_loss: 4.4211 | test_loss: 4.4051 | \n",
      "Epoch: 120 | train_loss: 4.2846 | test_loss: 4.2692 | \n",
      "Epoch: 130 | train_loss: 4.1536 | test_loss: 4.1310 | \n",
      "Epoch: 140 | train_loss: 4.0352 | test_loss: 4.0026 | \n",
      "Epoch: 150 | train_loss: 3.9206 | test_loss: 3.9085 | \n",
      "Epoch: 160 | train_loss: 3.8167 | test_loss: 3.7903 | \n",
      "Epoch: 170 | train_loss: 3.7139 | test_loss: 3.6973 | \n",
      "Epoch: 180 | train_loss: 3.6174 | test_loss: 3.6071 | \n",
      "Epoch: 190 | train_loss: 3.5261 | test_loss: 3.5065 | \n",
      "Epoch: 200 | train_loss: 3.4382 | test_loss: 3.4352 | \n",
      "Epoch: 210 | train_loss: 3.3550 | test_loss: 3.3374 | \n",
      "Epoch: 220 | train_loss: 3.2732 | test_loss: 3.2566 | \n",
      "Epoch: 230 | train_loss: 3.1957 | test_loss: 3.1851 | \n",
      "Epoch: 240 | train_loss: 3.1210 | test_loss: 3.1036 | \n",
      "Epoch: 250 | train_loss: 3.0471 | test_loss: 3.0309 | \n",
      "Epoch: 260 | train_loss: 2.9765 | test_loss: 2.9639 | \n",
      "Epoch: 270 | train_loss: 2.9092 | test_loss: 2.8907 | \n",
      "Epoch: 280 | train_loss: 2.8422 | test_loss: 2.8211 | \n",
      "Epoch: 290 | train_loss: 2.7778 | test_loss: 2.7659 | \n",
      "Epoch: 300 | train_loss: 2.7134 | test_loss: 2.7082 | \n",
      "Epoch: 310 | train_loss: 2.6531 | test_loss: 2.6416 | \n",
      "Epoch: 320 | train_loss: 2.5918 | test_loss: 2.5804 | \n",
      "Epoch: 330 | train_loss: 2.5335 | test_loss: 2.5243 | \n",
      "Epoch: 340 | train_loss: 2.4755 | test_loss: 2.4599 | \n",
      "Epoch: 350 | train_loss: 2.4181 | test_loss: 2.3974 | \n",
      "Epoch: 360 | train_loss: 2.3627 | test_loss: 2.3519 | \n",
      "Epoch: 370 | train_loss: 2.3097 | test_loss: 2.3125 | \n",
      "Epoch: 380 | train_loss: 2.2551 | test_loss: 2.2522 | \n",
      "Epoch: 390 | train_loss: 2.2022 | test_loss: 2.1951 | \n",
      "Epoch: 400 | train_loss: 2.1512 | test_loss: 2.1390 | \n",
      "Epoch: 410 | train_loss: 2.1003 | test_loss: 2.0890 | \n",
      "Epoch: 420 | train_loss: 2.0504 | test_loss: 2.0437 | \n",
      "Epoch: 430 | train_loss: 2.0012 | test_loss: 1.9936 | \n",
      "Epoch: 440 | train_loss: 1.9525 | test_loss: 1.9439 | \n",
      "Epoch: 450 | train_loss: 1.9041 | test_loss: 1.8955 | \n",
      "Epoch: 460 | train_loss: 1.8576 | test_loss: 1.8587 | \n",
      "Epoch: 470 | train_loss: 1.8109 | test_loss: 1.8101 | \n",
      "Epoch: 480 | train_loss: 1.7647 | test_loss: 1.7512 | \n",
      "Epoch: 490 | train_loss: 1.7196 | test_loss: 1.7164 | \n",
      "Epoch: 500 | train_loss: 1.6740 | test_loss: 1.6678 | \n",
      "Epoch: 510 | train_loss: 1.6295 | test_loss: 1.6343 | \n",
      "Epoch: 520 | train_loss: 1.5855 | test_loss: 1.5731 | \n",
      "Epoch: 530 | train_loss: 1.5423 | test_loss: 1.5350 | \n",
      "Epoch: 540 | train_loss: 1.4999 | test_loss: 1.4970 | \n",
      "Epoch: 550 | train_loss: 1.4572 | test_loss: 1.4513 | \n",
      "Epoch: 560 | train_loss: 1.4157 | test_loss: 1.4033 | \n",
      "Epoch: 570 | train_loss: 1.3739 | test_loss: 1.3685 | \n",
      "Epoch: 580 | train_loss: 1.3337 | test_loss: 1.3256 | \n",
      "Epoch: 590 | train_loss: 1.2915 | test_loss: 1.2841 | \n",
      "Epoch: 600 | train_loss: 1.2512 | test_loss: 1.2485 | \n",
      "Epoch: 610 | train_loss: 1.2114 | test_loss: 1.2176 | \n",
      "Epoch: 620 | train_loss: 1.1722 | test_loss: 1.1721 | \n",
      "Epoch: 630 | train_loss: 1.1331 | test_loss: 1.1337 | \n",
      "Epoch: 640 | train_loss: 1.0935 | test_loss: 1.0958 | \n",
      "Epoch: 650 | train_loss: 1.0539 | test_loss: 1.0493 | \n",
      "Epoch: 660 | train_loss: 1.0166 | test_loss: 1.0289 | \n",
      "Epoch: 670 | train_loss: 0.9780 | test_loss: 0.9835 | \n",
      "Epoch: 680 | train_loss: 0.9404 | test_loss: 0.9393 | \n",
      "Epoch: 690 | train_loss: 0.9035 | test_loss: 0.9047 | \n",
      "Epoch: 700 | train_loss: 0.8665 | test_loss: 0.8637 | \n",
      "Epoch: 710 | train_loss: 0.8293 | test_loss: 0.8250 | \n",
      "Epoch: 720 | train_loss: 0.7933 | test_loss: 0.8000 | \n",
      "Epoch: 730 | train_loss: 0.7597 | test_loss: 0.7663 | \n",
      "Epoch: 740 | train_loss: 0.7223 | test_loss: 0.7237 | \n",
      "Epoch: 750 | train_loss: 0.6883 | test_loss: 0.6850 | \n",
      "Epoch: 760 | train_loss: 0.6534 | test_loss: 0.6531 | \n",
      "Epoch: 770 | train_loss: 0.6179 | test_loss: 0.6219 | \n",
      "Epoch: 780 | train_loss: 0.5846 | test_loss: 0.5992 | \n",
      "Epoch: 790 | train_loss: 0.5495 | test_loss: 0.5693 | \n",
      "Epoch: 800 | train_loss: 0.5186 | test_loss: 0.5219 | \n",
      "Epoch: 810 | train_loss: 0.4849 | test_loss: 0.5005 | \n",
      "Epoch: 820 | train_loss: 0.4528 | test_loss: 0.4639 | \n",
      "Epoch: 830 | train_loss: 0.4191 | test_loss: 0.4339 | \n",
      "Epoch: 840 | train_loss: 0.3869 | test_loss: 0.4091 | \n",
      "Epoch: 850 | train_loss: 0.3560 | test_loss: 0.3738 | \n",
      "Epoch: 860 | train_loss: 0.3257 | test_loss: 0.3468 | \n",
      "Epoch: 870 | train_loss: 0.2936 | test_loss: 0.3239 | \n",
      "Epoch: 880 | train_loss: 0.2673 | test_loss: 0.2875 | \n",
      "Epoch: 890 | train_loss: 0.2358 | test_loss: 0.2678 | \n",
      "Epoch: 900 | train_loss: 0.2057 | test_loss: 0.2561 | \n",
      "Epoch: 910 | train_loss: 0.1796 | test_loss: 0.2202 | \n",
      "Epoch: 920 | train_loss: 0.1531 | test_loss: 0.2064 | \n",
      "Epoch: 930 | train_loss: 0.1287 | test_loss: 0.1785 | \n",
      "Epoch: 940 | train_loss: 0.1079 | test_loss: 0.1611 | \n",
      "Epoch: 950 | train_loss: 0.0829 | test_loss: 0.1590 | \n",
      "Epoch: 960 | train_loss: 0.0685 | test_loss: 0.1547 | \n",
      "Epoch: 970 | train_loss: 0.0610 | test_loss: 0.1457 | \n",
      "Epoch: 980 | train_loss: 0.0535 | test_loss: 0.1434 | \n",
      "Epoch: 990 | train_loss: 0.0462 | test_loss: 0.1463 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8550 | test_loss: 9.3714 | \n",
      "Epoch: 10 | train_loss: 7.7196 | test_loss: 7.6452 | \n",
      "Epoch: 20 | train_loss: 6.8325 | test_loss: 6.7863 | \n",
      "Epoch: 30 | train_loss: 6.2392 | test_loss: 6.2014 | \n",
      "Epoch: 40 | train_loss: 5.8182 | test_loss: 5.7839 | \n",
      "Epoch: 50 | train_loss: 5.4902 | test_loss: 5.4625 | \n",
      "Epoch: 60 | train_loss: 5.2164 | test_loss: 5.1948 | \n",
      "Epoch: 70 | train_loss: 4.9839 | test_loss: 4.9769 | \n",
      "Epoch: 80 | train_loss: 4.7802 | test_loss: 4.7543 | \n",
      "Epoch: 90 | train_loss: 4.6005 | test_loss: 4.5836 | \n",
      "Epoch: 100 | train_loss: 4.4356 | test_loss: 4.4261 | \n",
      "Epoch: 110 | train_loss: 4.2862 | test_loss: 4.2669 | \n",
      "Epoch: 120 | train_loss: 4.1475 | test_loss: 4.1319 | \n",
      "Epoch: 130 | train_loss: 4.0211 | test_loss: 4.0036 | \n",
      "Epoch: 140 | train_loss: 3.9042 | test_loss: 3.8796 | \n",
      "Epoch: 150 | train_loss: 3.7914 | test_loss: 3.7783 | \n",
      "Epoch: 160 | train_loss: 3.6853 | test_loss: 3.6745 | \n",
      "Epoch: 170 | train_loss: 3.5871 | test_loss: 3.5826 | \n",
      "Epoch: 180 | train_loss: 3.4909 | test_loss: 3.4773 | \n",
      "Epoch: 190 | train_loss: 3.4010 | test_loss: 3.3870 | \n",
      "Epoch: 200 | train_loss: 3.3143 | test_loss: 3.3030 | \n",
      "Epoch: 210 | train_loss: 3.2307 | test_loss: 3.2123 | \n",
      "Epoch: 220 | train_loss: 3.1508 | test_loss: 3.1372 | \n",
      "Epoch: 230 | train_loss: 3.0734 | test_loss: 3.0616 | \n",
      "Epoch: 240 | train_loss: 2.9967 | test_loss: 2.9826 | \n",
      "Epoch: 250 | train_loss: 2.9255 | test_loss: 2.9156 | \n",
      "Epoch: 260 | train_loss: 2.8572 | test_loss: 2.8374 | \n",
      "Epoch: 270 | train_loss: 2.7873 | test_loss: 2.7742 | \n",
      "Epoch: 280 | train_loss: 2.7226 | test_loss: 2.7242 | \n",
      "Epoch: 290 | train_loss: 2.6581 | test_loss: 2.6379 | \n",
      "Epoch: 300 | train_loss: 2.5943 | test_loss: 2.5837 | \n",
      "Epoch: 310 | train_loss: 2.5328 | test_loss: 2.5120 | \n",
      "Epoch: 320 | train_loss: 2.4735 | test_loss: 2.4752 | \n",
      "Epoch: 330 | train_loss: 2.4176 | test_loss: 2.4285 | \n",
      "Epoch: 340 | train_loss: 2.3581 | test_loss: 2.3504 | \n",
      "Epoch: 350 | train_loss: 2.3030 | test_loss: 2.2951 | \n",
      "Epoch: 360 | train_loss: 2.2472 | test_loss: 2.2349 | \n",
      "Epoch: 370 | train_loss: 2.1935 | test_loss: 2.1797 | \n",
      "Epoch: 380 | train_loss: 2.1420 | test_loss: 2.1428 | \n",
      "Epoch: 390 | train_loss: 2.0907 | test_loss: 2.0669 | \n",
      "Epoch: 400 | train_loss: 2.0389 | test_loss: 2.0265 | \n",
      "Epoch: 410 | train_loss: 1.9864 | test_loss: 1.9790 | \n",
      "Epoch: 420 | train_loss: 1.9380 | test_loss: 1.9270 | \n",
      "Epoch: 430 | train_loss: 1.8914 | test_loss: 1.8670 | \n",
      "Epoch: 440 | train_loss: 1.8414 | test_loss: 1.8284 | \n",
      "Epoch: 450 | train_loss: 1.7937 | test_loss: 1.7800 | \n",
      "Epoch: 460 | train_loss: 1.7478 | test_loss: 1.7343 | \n",
      "Epoch: 470 | train_loss: 1.7019 | test_loss: 1.6989 | \n",
      "Epoch: 480 | train_loss: 1.6561 | test_loss: 1.6402 | \n",
      "Epoch: 490 | train_loss: 1.6111 | test_loss: 1.5988 | \n",
      "Epoch: 500 | train_loss: 1.5675 | test_loss: 1.5634 | \n",
      "Epoch: 510 | train_loss: 1.5228 | test_loss: 1.5163 | \n",
      "Epoch: 520 | train_loss: 1.4796 | test_loss: 1.4786 | \n",
      "Epoch: 530 | train_loss: 1.4375 | test_loss: 1.4300 | \n",
      "Epoch: 540 | train_loss: 1.3948 | test_loss: 1.3848 | \n",
      "Epoch: 550 | train_loss: 1.3538 | test_loss: 1.3390 | \n",
      "Epoch: 560 | train_loss: 1.3103 | test_loss: 1.3048 | \n",
      "Epoch: 570 | train_loss: 1.2691 | test_loss: 1.2476 | \n",
      "Epoch: 580 | train_loss: 1.2290 | test_loss: 1.2155 | \n",
      "Epoch: 590 | train_loss: 1.1879 | test_loss: 1.1850 | \n",
      "Epoch: 600 | train_loss: 1.1488 | test_loss: 1.1390 | \n",
      "Epoch: 610 | train_loss: 1.1096 | test_loss: 1.0981 | \n",
      "Epoch: 620 | train_loss: 1.0704 | test_loss: 1.0675 | \n",
      "Epoch: 630 | train_loss: 1.0314 | test_loss: 1.0205 | \n",
      "Epoch: 640 | train_loss: 0.9937 | test_loss: 0.9819 | \n",
      "Epoch: 650 | train_loss: 0.9557 | test_loss: 0.9552 | \n",
      "Epoch: 660 | train_loss: 0.9182 | test_loss: 0.9157 | \n",
      "Epoch: 670 | train_loss: 0.8813 | test_loss: 0.8776 | \n",
      "Epoch: 680 | train_loss: 0.8439 | test_loss: 0.8432 | \n",
      "Epoch: 690 | train_loss: 0.8072 | test_loss: 0.8123 | \n",
      "Epoch: 700 | train_loss: 0.7711 | test_loss: 0.7841 | \n",
      "Epoch: 710 | train_loss: 0.7361 | test_loss: 0.7402 | \n",
      "Epoch: 720 | train_loss: 0.6993 | test_loss: 0.6805 | \n",
      "Epoch: 730 | train_loss: 0.6649 | test_loss: 0.6703 | \n",
      "Epoch: 740 | train_loss: 0.6317 | test_loss: 0.6240 | \n",
      "Epoch: 750 | train_loss: 0.5953 | test_loss: 0.6082 | \n",
      "Epoch: 760 | train_loss: 0.5623 | test_loss: 0.5575 | \n",
      "Epoch: 770 | train_loss: 0.5290 | test_loss: 0.5261 | \n",
      "Epoch: 780 | train_loss: 0.4941 | test_loss: 0.4984 | \n",
      "Epoch: 790 | train_loss: 0.4624 | test_loss: 0.4403 | \n",
      "Epoch: 800 | train_loss: 0.4288 | test_loss: 0.4304 | \n",
      "Epoch: 810 | train_loss: 0.3965 | test_loss: 0.4027 | \n",
      "Epoch: 820 | train_loss: 0.3653 | test_loss: 0.3858 | \n",
      "Epoch: 830 | train_loss: 0.3343 | test_loss: 0.3339 | \n",
      "Epoch: 840 | train_loss: 0.3037 | test_loss: 0.3326 | \n",
      "Epoch: 850 | train_loss: 0.2732 | test_loss: 0.3199 | \n",
      "Epoch: 860 | train_loss: 0.2426 | test_loss: 0.2825 | \n",
      "Epoch: 870 | train_loss: 0.2153 | test_loss: 0.2614 | \n",
      "Epoch: 880 | train_loss: 0.1893 | test_loss: 0.2135 | \n",
      "Epoch: 890 | train_loss: 0.1596 | test_loss: 0.2199 | \n",
      "Epoch: 900 | train_loss: 0.1346 | test_loss: 0.1724 | \n",
      "Epoch: 910 | train_loss: 0.1072 | test_loss: 0.1754 | \n",
      "Epoch: 920 | train_loss: 0.0911 | test_loss: 0.1691 | \n",
      "Epoch: 930 | train_loss: 0.0819 | test_loss: 0.1491 | \n",
      "Epoch: 940 | train_loss: 0.0644 | test_loss: 0.1342 | \n",
      "Epoch: 950 | train_loss: 0.0469 | test_loss: 0.1422 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8507 | test_loss: 9.9277 | \n",
      "Epoch: 10 | train_loss: 7.7251 | test_loss: 7.6521 | \n",
      "Epoch: 20 | train_loss: 6.8286 | test_loss: 6.7903 | \n",
      "Epoch: 30 | train_loss: 6.2561 | test_loss: 6.2096 | \n",
      "Epoch: 40 | train_loss: 5.8367 | test_loss: 5.7891 | \n",
      "Epoch: 50 | train_loss: 5.5131 | test_loss: 5.4717 | \n",
      "Epoch: 60 | train_loss: 5.2449 | test_loss: 5.2101 | \n",
      "Epoch: 70 | train_loss: 5.0072 | test_loss: 4.9792 | \n",
      "Epoch: 80 | train_loss: 4.8040 | test_loss: 4.7796 | \n",
      "Epoch: 90 | train_loss: 4.6242 | test_loss: 4.6134 | \n",
      "Epoch: 100 | train_loss: 4.4621 | test_loss: 4.4355 | \n",
      "Epoch: 110 | train_loss: 4.3098 | test_loss: 4.2955 | \n",
      "Epoch: 120 | train_loss: 4.1761 | test_loss: 4.1556 | \n",
      "Epoch: 130 | train_loss: 4.0457 | test_loss: 4.0192 | \n",
      "Epoch: 140 | train_loss: 3.9328 | test_loss: 3.9069 | \n",
      "Epoch: 150 | train_loss: 3.8142 | test_loss: 3.7969 | \n",
      "Epoch: 160 | train_loss: 3.7111 | test_loss: 3.6933 | \n",
      "Epoch: 170 | train_loss: 3.6070 | test_loss: 3.5931 | \n",
      "Epoch: 180 | train_loss: 3.5156 | test_loss: 3.5032 | \n",
      "Epoch: 190 | train_loss: 3.4232 | test_loss: 3.3996 | \n",
      "Epoch: 200 | train_loss: 3.3398 | test_loss: 3.3224 | \n",
      "Epoch: 210 | train_loss: 3.2565 | test_loss: 3.2344 | \n",
      "Epoch: 220 | train_loss: 3.1755 | test_loss: 3.1484 | \n",
      "Epoch: 230 | train_loss: 3.0999 | test_loss: 3.0767 | \n",
      "Epoch: 240 | train_loss: 3.0244 | test_loss: 3.0012 | \n",
      "Epoch: 250 | train_loss: 2.9511 | test_loss: 2.9287 | \n",
      "Epoch: 260 | train_loss: 2.8831 | test_loss: 2.8550 | \n",
      "Epoch: 270 | train_loss: 2.8093 | test_loss: 2.7925 | \n",
      "Epoch: 280 | train_loss: 2.7453 | test_loss: 2.7239 | \n",
      "Epoch: 290 | train_loss: 2.6819 | test_loss: 2.6605 | \n",
      "Epoch: 300 | train_loss: 2.6225 | test_loss: 2.5980 | \n",
      "Epoch: 310 | train_loss: 2.5594 | test_loss: 2.5367 | \n",
      "Epoch: 320 | train_loss: 2.5035 | test_loss: 2.4762 | \n",
      "Epoch: 330 | train_loss: 2.4440 | test_loss: 2.4243 | \n",
      "Epoch: 340 | train_loss: 2.3901 | test_loss: 2.3597 | \n",
      "Epoch: 350 | train_loss: 2.3273 | test_loss: 2.3075 | \n",
      "Epoch: 360 | train_loss: 2.2717 | test_loss: 2.2496 | \n",
      "Epoch: 370 | train_loss: 2.2221 | test_loss: 2.1984 | \n",
      "Epoch: 380 | train_loss: 2.1662 | test_loss: 2.1444 | \n",
      "Epoch: 390 | train_loss: 2.1148 | test_loss: 2.0907 | \n",
      "Epoch: 400 | train_loss: 2.0586 | test_loss: 2.0404 | \n",
      "Epoch: 410 | train_loss: 2.0144 | test_loss: 1.9925 | \n",
      "Epoch: 420 | train_loss: 1.9649 | test_loss: 1.9388 | \n",
      "Epoch: 430 | train_loss: 1.9103 | test_loss: 1.8996 | \n",
      "Epoch: 440 | train_loss: 1.8689 | test_loss: 1.8485 | \n",
      "Epoch: 450 | train_loss: 1.8209 | test_loss: 1.8015 | \n",
      "Epoch: 460 | train_loss: 1.7748 | test_loss: 1.7569 | \n",
      "Epoch: 470 | train_loss: 1.7268 | test_loss: 1.7088 | \n",
      "Epoch: 480 | train_loss: 1.6862 | test_loss: 1.6623 | \n",
      "Epoch: 490 | train_loss: 1.6372 | test_loss: 1.6176 | \n",
      "Epoch: 500 | train_loss: 1.5944 | test_loss: 1.5709 | \n",
      "Epoch: 510 | train_loss: 1.5523 | test_loss: 1.5312 | \n",
      "Epoch: 520 | train_loss: 1.5112 | test_loss: 1.4882 | \n",
      "Epoch: 530 | train_loss: 1.4593 | test_loss: 1.4469 | \n",
      "Epoch: 540 | train_loss: 1.4194 | test_loss: 1.4020 | \n",
      "Epoch: 550 | train_loss: 1.3806 | test_loss: 1.3611 | \n",
      "Epoch: 560 | train_loss: 1.3375 | test_loss: 1.3212 | \n",
      "Epoch: 570 | train_loss: 1.2976 | test_loss: 1.2833 | \n",
      "Epoch: 580 | train_loss: 1.2546 | test_loss: 1.2451 | \n",
      "Epoch: 590 | train_loss: 1.2159 | test_loss: 1.1993 | \n",
      "Epoch: 600 | train_loss: 1.1745 | test_loss: 1.1507 | \n",
      "Epoch: 610 | train_loss: 1.1397 | test_loss: 1.1208 | \n",
      "Epoch: 620 | train_loss: 1.1010 | test_loss: 1.0845 | \n",
      "Epoch: 630 | train_loss: 1.0601 | test_loss: 1.0495 | \n",
      "Epoch: 640 | train_loss: 1.0226 | test_loss: 1.0073 | \n",
      "Epoch: 650 | train_loss: 0.9855 | test_loss: 0.9735 | \n",
      "Epoch: 660 | train_loss: 0.9474 | test_loss: 0.9293 | \n",
      "Epoch: 670 | train_loss: 0.9099 | test_loss: 0.8970 | \n",
      "Epoch: 680 | train_loss: 0.8799 | test_loss: 0.8622 | \n",
      "Epoch: 690 | train_loss: 0.8365 | test_loss: 0.8224 | \n",
      "Epoch: 700 | train_loss: 0.8060 | test_loss: 0.7914 | \n",
      "Epoch: 710 | train_loss: 0.7706 | test_loss: 0.7489 | \n",
      "Epoch: 720 | train_loss: 0.7326 | test_loss: 0.7265 | \n",
      "Epoch: 730 | train_loss: 0.6997 | test_loss: 0.6916 | \n",
      "Epoch: 740 | train_loss: 0.6657 | test_loss: 0.6581 | \n",
      "Epoch: 750 | train_loss: 0.6232 | test_loss: 0.6182 | \n",
      "Epoch: 760 | train_loss: 0.6003 | test_loss: 0.5955 | \n",
      "Epoch: 770 | train_loss: 0.5715 | test_loss: 0.5534 | \n",
      "Epoch: 780 | train_loss: 0.5298 | test_loss: 0.5249 | \n",
      "Epoch: 790 | train_loss: 0.5030 | test_loss: 0.4864 | \n",
      "Epoch: 800 | train_loss: 0.4690 | test_loss: 0.4645 | \n",
      "Epoch: 810 | train_loss: 0.4384 | test_loss: 0.4244 | \n",
      "Epoch: 820 | train_loss: 0.4037 | test_loss: 0.3990 | \n",
      "Epoch: 830 | train_loss: 0.3764 | test_loss: 0.3753 | \n",
      "Epoch: 840 | train_loss: 0.3535 | test_loss: 0.3435 | \n",
      "Epoch: 850 | train_loss: 0.3235 | test_loss: 0.3174 | \n",
      "Epoch: 860 | train_loss: 0.2907 | test_loss: 0.2857 | \n",
      "Epoch: 870 | train_loss: 0.2694 | test_loss: 0.2734 | \n",
      "Epoch: 880 | train_loss: 0.2432 | test_loss: 0.2395 | \n",
      "Epoch: 890 | train_loss: 0.2237 | test_loss: 0.2262 | \n",
      "Epoch: 900 | train_loss: 0.2029 | test_loss: 0.1916 | \n",
      "Epoch: 910 | train_loss: 0.1830 | test_loss: 0.1931 | \n",
      "Epoch: 920 | train_loss: 0.1718 | test_loss: 0.1746 | \n",
      "Epoch: 930 | train_loss: 0.1544 | test_loss: 0.1594 | \n",
      "Epoch: 940 | train_loss: 0.1426 | test_loss: 0.1548 | \n",
      "Epoch: 950 | train_loss: 0.1350 | test_loss: 0.1442 | \n",
      "Epoch: 960 | train_loss: 0.1278 | test_loss: 0.1400 | \n",
      "Epoch: 970 | train_loss: 0.1247 | test_loss: 0.1484 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.9038 | test_loss: 9.5806 | \n",
      "Epoch: 10 | train_loss: 7.7772 | test_loss: 7.6927 | \n",
      "Epoch: 20 | train_loss: 6.8860 | test_loss: 6.8167 | \n",
      "Epoch: 30 | train_loss: 6.3104 | test_loss: 6.2598 | \n",
      "Epoch: 40 | train_loss: 5.8875 | test_loss: 5.8274 | \n",
      "Epoch: 50 | train_loss: 5.5532 | test_loss: 5.5076 | \n",
      "Epoch: 60 | train_loss: 5.2838 | test_loss: 5.2412 | \n",
      "Epoch: 70 | train_loss: 5.0474 | test_loss: 5.0113 | \n",
      "Epoch: 80 | train_loss: 4.8472 | test_loss: 4.8108 | \n",
      "Epoch: 90 | train_loss: 4.6647 | test_loss: 4.6258 | \n",
      "Epoch: 100 | train_loss: 4.4956 | test_loss: 4.4687 | \n",
      "Epoch: 110 | train_loss: 4.3428 | test_loss: 4.3277 | \n",
      "Epoch: 120 | train_loss: 4.2131 | test_loss: 4.1813 | \n",
      "Epoch: 130 | train_loss: 4.0842 | test_loss: 4.0557 | \n",
      "Epoch: 140 | train_loss: 3.9618 | test_loss: 3.9361 | \n",
      "Epoch: 150 | train_loss: 3.8521 | test_loss: 3.8207 | \n",
      "Epoch: 160 | train_loss: 3.7468 | test_loss: 3.7201 | \n",
      "Epoch: 170 | train_loss: 3.6456 | test_loss: 3.6219 | \n",
      "Epoch: 180 | train_loss: 3.5526 | test_loss: 3.5248 | \n",
      "Epoch: 190 | train_loss: 3.4588 | test_loss: 3.4339 | \n",
      "Epoch: 200 | train_loss: 3.3729 | test_loss: 3.3464 | \n",
      "Epoch: 210 | train_loss: 3.2907 | test_loss: 3.2636 | \n",
      "Epoch: 220 | train_loss: 3.2061 | test_loss: 3.1838 | \n",
      "Epoch: 230 | train_loss: 3.1338 | test_loss: 3.1056 | \n",
      "Epoch: 240 | train_loss: 3.0562 | test_loss: 3.0343 | \n",
      "Epoch: 250 | train_loss: 2.9863 | test_loss: 2.9612 | \n",
      "Epoch: 260 | train_loss: 2.9189 | test_loss: 2.8826 | \n",
      "Epoch: 270 | train_loss: 2.8463 | test_loss: 2.8204 | \n",
      "Epoch: 280 | train_loss: 2.7774 | test_loss: 2.7551 | \n",
      "Epoch: 290 | train_loss: 2.7170 | test_loss: 2.6901 | \n",
      "Epoch: 300 | train_loss: 2.6517 | test_loss: 2.6248 | \n",
      "Epoch: 310 | train_loss: 2.5960 | test_loss: 2.5665 | \n",
      "Epoch: 320 | train_loss: 2.5292 | test_loss: 2.5081 | \n",
      "Epoch: 330 | train_loss: 2.4782 | test_loss: 2.4474 | \n",
      "Epoch: 340 | train_loss: 2.4159 | test_loss: 2.3917 | \n",
      "Epoch: 350 | train_loss: 2.3585 | test_loss: 2.3407 | \n",
      "Epoch: 360 | train_loss: 2.3030 | test_loss: 2.2832 | \n",
      "Epoch: 370 | train_loss: 2.2514 | test_loss: 2.2342 | \n",
      "Epoch: 380 | train_loss: 2.1988 | test_loss: 2.1820 | \n",
      "Epoch: 390 | train_loss: 2.1429 | test_loss: 2.1260 | \n",
      "Epoch: 400 | train_loss: 2.0944 | test_loss: 2.0799 | \n",
      "Epoch: 410 | train_loss: 2.0444 | test_loss: 2.0385 | \n",
      "Epoch: 420 | train_loss: 1.9957 | test_loss: 1.9863 | \n",
      "Epoch: 430 | train_loss: 1.9453 | test_loss: 1.9341 | \n",
      "Epoch: 440 | train_loss: 1.8976 | test_loss: 1.8820 | \n",
      "Epoch: 450 | train_loss: 1.8492 | test_loss: 1.8386 | \n",
      "Epoch: 460 | train_loss: 1.8020 | test_loss: 1.7885 | \n",
      "Epoch: 470 | train_loss: 1.7553 | test_loss: 1.7402 | \n",
      "Epoch: 480 | train_loss: 1.7145 | test_loss: 1.6953 | \n",
      "Epoch: 490 | train_loss: 1.6706 | test_loss: 1.6500 | \n",
      "Epoch: 500 | train_loss: 1.6201 | test_loss: 1.6083 | \n",
      "Epoch: 510 | train_loss: 1.5818 | test_loss: 1.5667 | \n",
      "Epoch: 520 | train_loss: 1.5386 | test_loss: 1.5213 | \n",
      "Epoch: 530 | train_loss: 1.4963 | test_loss: 1.4776 | \n",
      "Epoch: 540 | train_loss: 1.4508 | test_loss: 1.4374 | \n",
      "Epoch: 550 | train_loss: 1.4143 | test_loss: 1.3974 | \n",
      "Epoch: 560 | train_loss: 1.3671 | test_loss: 1.3555 | \n",
      "Epoch: 570 | train_loss: 1.3242 | test_loss: 1.3111 | \n",
      "Epoch: 580 | train_loss: 1.2850 | test_loss: 1.2718 | \n",
      "Epoch: 590 | train_loss: 1.2461 | test_loss: 1.2340 | \n",
      "Epoch: 600 | train_loss: 1.2099 | test_loss: 1.1974 | \n",
      "Epoch: 610 | train_loss: 1.1659 | test_loss: 1.1537 | \n",
      "Epoch: 620 | train_loss: 1.1268 | test_loss: 1.1215 | \n",
      "Epoch: 630 | train_loss: 1.0917 | test_loss: 1.0870 | \n",
      "Epoch: 640 | train_loss: 1.0549 | test_loss: 1.0359 | \n",
      "Epoch: 650 | train_loss: 1.0129 | test_loss: 0.9981 | \n",
      "Epoch: 660 | train_loss: 0.9770 | test_loss: 0.9743 | \n",
      "Epoch: 670 | train_loss: 0.9362 | test_loss: 0.9352 | \n",
      "Epoch: 680 | train_loss: 0.9063 | test_loss: 0.8890 | \n",
      "Epoch: 690 | train_loss: 0.8706 | test_loss: 0.8612 | \n",
      "Epoch: 700 | train_loss: 0.8330 | test_loss: 0.8220 | \n",
      "Epoch: 710 | train_loss: 0.7971 | test_loss: 0.7946 | \n",
      "Epoch: 720 | train_loss: 0.7619 | test_loss: 0.7439 | \n",
      "Epoch: 730 | train_loss: 0.7273 | test_loss: 0.7218 | \n",
      "Epoch: 740 | train_loss: 0.6882 | test_loss: 0.6830 | \n",
      "Epoch: 750 | train_loss: 0.6598 | test_loss: 0.6505 | \n",
      "Epoch: 760 | train_loss: 0.6246 | test_loss: 0.6189 | \n",
      "Epoch: 770 | train_loss: 0.5934 | test_loss: 0.5850 | \n",
      "Epoch: 780 | train_loss: 0.5680 | test_loss: 0.5655 | \n",
      "Epoch: 790 | train_loss: 0.5292 | test_loss: 0.5202 | \n",
      "Epoch: 800 | train_loss: 0.4965 | test_loss: 0.4929 | \n",
      "Epoch: 810 | train_loss: 0.4664 | test_loss: 0.4484 | \n",
      "Epoch: 820 | train_loss: 0.4336 | test_loss: 0.4305 | \n",
      "Epoch: 830 | train_loss: 0.4004 | test_loss: 0.4066 | \n",
      "Epoch: 840 | train_loss: 0.3725 | test_loss: 0.3764 | \n",
      "Epoch: 850 | train_loss: 0.3458 | test_loss: 0.3421 | \n",
      "Epoch: 860 | train_loss: 0.3184 | test_loss: 0.3143 | \n",
      "Epoch: 870 | train_loss: 0.2931 | test_loss: 0.2906 | \n",
      "Epoch: 880 | train_loss: 0.2665 | test_loss: 0.2837 | \n",
      "Epoch: 890 | train_loss: 0.2426 | test_loss: 0.2425 | \n",
      "Epoch: 900 | train_loss: 0.2226 | test_loss: 0.2297 | \n",
      "Epoch: 910 | train_loss: 0.2042 | test_loss: 0.2060 | \n",
      "Epoch: 920 | train_loss: 0.1857 | test_loss: 0.1958 | \n",
      "Epoch: 930 | train_loss: 0.1645 | test_loss: 0.1755 | \n",
      "Epoch: 940 | train_loss: 0.1538 | test_loss: 0.1651 | \n",
      "Epoch: 950 | train_loss: 0.1428 | test_loss: 0.1579 | \n",
      "Epoch: 960 | train_loss: 0.1370 | test_loss: 0.1472 | \n",
      "Epoch: 970 | train_loss: 0.1286 | test_loss: 0.1468 | \n",
      "Epoch: 980 | train_loss: 0.1235 | test_loss: 0.1518 | \n",
      "Epoch: 990 | train_loss: 0.1209 | test_loss: 0.1428 | \n",
      "Epoch: 1000 | train_loss: 0.1208 | test_loss: 0.1423 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 6.0385 | test_loss: 2.5621 | \n",
      "Epoch: 10 | train_loss: 0.1660 | test_loss: 0.1584 | \n",
      "Epoch: 20 | train_loss: 0.1449 | test_loss: 0.1489 | \n",
      "Epoch: 30 | train_loss: 0.1360 | test_loss: 0.1453 | \n",
      "Epoch: 40 | train_loss: 0.1302 | test_loss: 0.1409 | \n",
      "Epoch: 50 | train_loss: 0.1221 | test_loss: 0.1362 | \n",
      "Epoch: 60 | train_loss: 0.1134 | test_loss: 0.1390 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.5522 | test_loss: 0.3319 | \n",
      "Epoch: 10 | train_loss: 0.1464 | test_loss: 0.1447 | \n",
      "Epoch: 20 | train_loss: 0.1256 | test_loss: 0.1456 | \n",
      "Epoch: 30 | train_loss: 0.1113 | test_loss: 0.1382 | \n",
      "Epoch: 40 | train_loss: 0.1023 | test_loss: 0.1397 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 2.1245 | test_loss: 0.4685 | \n",
      "Epoch: 10 | train_loss: 0.1354 | test_loss: 0.1372 | \n",
      "Epoch: 20 | train_loss: 0.1035 | test_loss: 0.1439 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6187 | test_loss: 8.5960 | \n",
      "Epoch: 10 | train_loss: 5.9044 | test_loss: 5.8102 | \n",
      "Epoch: 20 | train_loss: 4.8455 | test_loss: 4.7950 | \n",
      "Epoch: 30 | train_loss: 4.2077 | test_loss: 4.1775 | \n",
      "Epoch: 40 | train_loss: 3.7414 | test_loss: 3.7021 | \n",
      "Epoch: 50 | train_loss: 3.3639 | test_loss: 3.3136 | \n",
      "Epoch: 60 | train_loss: 3.0465 | test_loss: 3.0016 | \n",
      "Epoch: 70 | train_loss: 2.7662 | test_loss: 2.7416 | \n",
      "Epoch: 80 | train_loss: 2.5187 | test_loss: 2.4969 | \n",
      "Epoch: 90 | train_loss: 2.2884 | test_loss: 2.2839 | \n",
      "Epoch: 100 | train_loss: 2.0783 | test_loss: 2.0817 | \n",
      "Epoch: 110 | train_loss: 1.8792 | test_loss: 1.8582 | \n",
      "Epoch: 120 | train_loss: 1.6941 | test_loss: 1.6694 | \n",
      "Epoch: 130 | train_loss: 1.5195 | test_loss: 1.4933 | \n",
      "Epoch: 140 | train_loss: 1.3486 | test_loss: 1.3511 | \n",
      "Epoch: 150 | train_loss: 1.1888 | test_loss: 1.1737 | \n",
      "Epoch: 160 | train_loss: 1.0307 | test_loss: 1.0507 | \n",
      "Epoch: 170 | train_loss: 0.8791 | test_loss: 0.8567 | \n",
      "Epoch: 180 | train_loss: 0.7342 | test_loss: 0.7156 | \n",
      "Epoch: 190 | train_loss: 0.6035 | test_loss: 0.6144 | \n",
      "Epoch: 200 | train_loss: 0.4673 | test_loss: 0.4646 | \n",
      "Epoch: 210 | train_loss: 0.3455 | test_loss: 0.3816 | \n",
      "Epoch: 220 | train_loss: 0.2308 | test_loss: 0.2546 | \n",
      "Epoch: 230 | train_loss: 0.1658 | test_loss: 0.1858 | \n",
      "Epoch: 240 | train_loss: 0.1151 | test_loss: 0.1572 | \n",
      "Epoch: 250 | train_loss: 0.0996 | test_loss: 0.1465 | \n",
      "Epoch: 260 | train_loss: 0.0853 | test_loss: 0.1392 | \n",
      "Epoch: 270 | train_loss: 0.0793 | test_loss: 0.1431 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6060 | test_loss: 8.6226 | \n",
      "Epoch: 10 | train_loss: 5.9000 | test_loss: 5.8322 | \n",
      "Epoch: 20 | train_loss: 4.8308 | test_loss: 4.7604 | \n",
      "Epoch: 30 | train_loss: 4.1947 | test_loss: 4.1348 | \n",
      "Epoch: 40 | train_loss: 3.7247 | test_loss: 3.7010 | \n",
      "Epoch: 50 | train_loss: 3.3481 | test_loss: 3.3192 | \n",
      "Epoch: 60 | train_loss: 3.0318 | test_loss: 3.0509 | \n",
      "Epoch: 70 | train_loss: 2.7531 | test_loss: 2.7451 | \n",
      "Epoch: 80 | train_loss: 2.5033 | test_loss: 2.4741 | \n",
      "Epoch: 90 | train_loss: 2.2783 | test_loss: 2.2565 | \n",
      "Epoch: 100 | train_loss: 2.0659 | test_loss: 2.0538 | \n",
      "Epoch: 110 | train_loss: 1.8665 | test_loss: 1.8335 | \n",
      "Epoch: 120 | train_loss: 1.6808 | test_loss: 1.7113 | \n",
      "Epoch: 130 | train_loss: 1.5032 | test_loss: 1.5149 | \n",
      "Epoch: 140 | train_loss: 1.3341 | test_loss: 1.3161 | \n",
      "Epoch: 150 | train_loss: 1.1728 | test_loss: 1.1709 | \n",
      "Epoch: 160 | train_loss: 1.0198 | test_loss: 0.9998 | \n",
      "Epoch: 170 | train_loss: 0.8689 | test_loss: 0.8564 | \n",
      "Epoch: 180 | train_loss: 0.7292 | test_loss: 0.7225 | \n",
      "Epoch: 190 | train_loss: 0.5901 | test_loss: 0.5546 | \n",
      "Epoch: 200 | train_loss: 0.4783 | test_loss: 0.4571 | \n",
      "Epoch: 210 | train_loss: 0.3453 | test_loss: 0.3446 | \n",
      "Epoch: 220 | train_loss: 0.2295 | test_loss: 0.2484 | \n",
      "Epoch: 230 | train_loss: 0.1472 | test_loss: 0.1700 | \n",
      "Epoch: 240 | train_loss: 0.1041 | test_loss: 0.1540 | \n",
      "Epoch: 250 | train_loss: 0.0920 | test_loss: 0.1439 | \n",
      "Epoch: 260 | train_loss: 0.0870 | test_loss: 0.1449 | \n",
      "Epoch: 270 | train_loss: 0.0856 | test_loss: 0.1416 | \n",
      "Epoch: 280 | train_loss: 0.0838 | test_loss: 0.1323 | \n",
      "Epoch: 290 | train_loss: 0.0851 | test_loss: 0.1386 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.7043 | test_loss: 8.6180 | \n",
      "Epoch: 10 | train_loss: 5.9721 | test_loss: 5.8625 | \n",
      "Epoch: 20 | train_loss: 4.9051 | test_loss: 4.8465 | \n",
      "Epoch: 30 | train_loss: 4.2622 | test_loss: 4.2228 | \n",
      "Epoch: 40 | train_loss: 3.7962 | test_loss: 3.7540 | \n",
      "Epoch: 50 | train_loss: 3.4229 | test_loss: 3.3905 | \n",
      "Epoch: 60 | train_loss: 3.1037 | test_loss: 3.0732 | \n",
      "Epoch: 70 | train_loss: 2.8370 | test_loss: 2.8047 | \n",
      "Epoch: 80 | train_loss: 2.5746 | test_loss: 2.5508 | \n",
      "Epoch: 90 | train_loss: 2.3459 | test_loss: 2.3180 | \n",
      "Epoch: 100 | train_loss: 2.1432 | test_loss: 2.1136 | \n",
      "Epoch: 110 | train_loss: 1.9400 | test_loss: 1.9189 | \n",
      "Epoch: 120 | train_loss: 1.7550 | test_loss: 1.7260 | \n",
      "Epoch: 130 | train_loss: 1.5774 | test_loss: 1.5569 | \n",
      "Epoch: 140 | train_loss: 1.4087 | test_loss: 1.3812 | \n",
      "Epoch: 150 | train_loss: 1.2468 | test_loss: 1.2242 | \n",
      "Epoch: 160 | train_loss: 1.0939 | test_loss: 1.0685 | \n",
      "Epoch: 170 | train_loss: 0.9438 | test_loss: 0.9209 | \n",
      "Epoch: 180 | train_loss: 0.8019 | test_loss: 0.7997 | \n",
      "Epoch: 190 | train_loss: 0.6645 | test_loss: 0.6438 | \n",
      "Epoch: 200 | train_loss: 0.5380 | test_loss: 0.5220 | \n",
      "Epoch: 210 | train_loss: 0.4200 | test_loss: 0.4065 | \n",
      "Epoch: 220 | train_loss: 0.3175 | test_loss: 0.3081 | \n",
      "Epoch: 230 | train_loss: 0.2445 | test_loss: 0.2274 | \n",
      "Epoch: 240 | train_loss: 0.1938 | test_loss: 0.1705 | \n",
      "Epoch: 250 | train_loss: 0.1740 | test_loss: 0.1554 | \n",
      "Epoch: 260 | train_loss: 0.1605 | test_loss: 0.1464 | \n",
      "Epoch: 270 | train_loss: 0.1502 | test_loss: 0.1448 | \n",
      "Epoch: 280 | train_loss: 0.1516 | test_loss: 0.1384 | \n",
      "Epoch: 290 | train_loss: 0.1389 | test_loss: 0.1327 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6613 | test_loss: 8.5716 | \n",
      "Epoch: 10 | train_loss: 5.9317 | test_loss: 5.8365 | \n",
      "Epoch: 20 | train_loss: 4.8657 | test_loss: 4.7947 | \n",
      "Epoch: 30 | train_loss: 4.2265 | test_loss: 4.1855 | \n",
      "Epoch: 40 | train_loss: 3.7570 | test_loss: 3.7130 | \n",
      "Epoch: 50 | train_loss: 3.3840 | test_loss: 3.3493 | \n",
      "Epoch: 60 | train_loss: 3.0647 | test_loss: 3.0352 | \n",
      "Epoch: 70 | train_loss: 2.7936 | test_loss: 2.7499 | \n",
      "Epoch: 80 | train_loss: 2.5385 | test_loss: 2.5101 | \n",
      "Epoch: 90 | train_loss: 2.3153 | test_loss: 2.2916 | \n",
      "Epoch: 100 | train_loss: 2.1002 | test_loss: 2.0741 | \n",
      "Epoch: 110 | train_loss: 1.8987 | test_loss: 1.8810 | \n",
      "Epoch: 120 | train_loss: 1.7192 | test_loss: 1.6896 | \n",
      "Epoch: 130 | train_loss: 1.5485 | test_loss: 1.5206 | \n",
      "Epoch: 140 | train_loss: 1.3732 | test_loss: 1.3559 | \n",
      "Epoch: 150 | train_loss: 1.2136 | test_loss: 1.1890 | \n",
      "Epoch: 160 | train_loss: 1.0585 | test_loss: 1.0380 | \n",
      "Epoch: 170 | train_loss: 0.9094 | test_loss: 0.8885 | \n",
      "Epoch: 180 | train_loss: 0.7733 | test_loss: 0.7584 | \n",
      "Epoch: 190 | train_loss: 0.6362 | test_loss: 0.6193 | \n",
      "Epoch: 200 | train_loss: 0.5099 | test_loss: 0.4863 | \n",
      "Epoch: 210 | train_loss: 0.3888 | test_loss: 0.3628 | \n",
      "Epoch: 220 | train_loss: 0.2944 | test_loss: 0.2840 | \n",
      "Epoch: 230 | train_loss: 0.2263 | test_loss: 0.1936 | \n",
      "Epoch: 240 | train_loss: 0.1872 | test_loss: 0.1590 | \n",
      "Epoch: 250 | train_loss: 0.1590 | test_loss: 0.1483 | \n",
      "Epoch: 260 | train_loss: 0.1509 | test_loss: 0.1330 | \n",
      "Epoch: 270 | train_loss: 0.1442 | test_loss: 0.1440 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.3035 | test_loss: 4.7157 | \n",
      "Epoch: 10 | train_loss: 0.1921 | test_loss: 0.1764 | \n",
      "Epoch: 20 | train_loss: 0.1645 | test_loss: 0.1556 | \n",
      "Epoch: 30 | train_loss: 0.1517 | test_loss: 0.1543 | \n",
      "Epoch: 40 | train_loss: 0.1446 | test_loss: 0.1462 | \n",
      "Epoch: 50 | train_loss: 0.1379 | test_loss: 0.1439 | \n",
      "Epoch: 60 | train_loss: 0.1326 | test_loss: 0.1423 | \n",
      "Epoch: 70 | train_loss: 0.1285 | test_loss: 0.1398 | \n",
      "Epoch: 80 | train_loss: 0.1239 | test_loss: 0.1389 | \n",
      "Epoch: 90 | train_loss: 0.1204 | test_loss: 0.1377 | \n",
      "Epoch: 100 | train_loss: 0.1141 | test_loss: 0.1370 | \n",
      "Epoch: 110 | train_loss: 0.1128 | test_loss: 0.1376 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.7420 | test_loss: 1.9247 | \n",
      "Epoch: 10 | train_loss: 0.1605 | test_loss: 0.1577 | \n",
      "Epoch: 20 | train_loss: 0.1399 | test_loss: 0.1480 | \n",
      "Epoch: 30 | train_loss: 0.1248 | test_loss: 0.1391 | \n",
      "Epoch: 40 | train_loss: 0.1180 | test_loss: 0.1361 | \n",
      "Epoch: 50 | train_loss: 0.1090 | test_loss: 0.1383 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.1564 | test_loss: 1.7317 | \n",
      "Epoch: 10 | train_loss: 0.1362 | test_loss: 0.1422 | \n",
      "Epoch: 20 | train_loss: 0.0980 | test_loss: 0.1415 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2867 | test_loss: 9.0456 | \n",
      "Epoch: 10 | train_loss: 6.8787 | test_loss: 6.8261 | \n",
      "Epoch: 20 | train_loss: 5.8787 | test_loss: 5.8312 | \n",
      "Epoch: 30 | train_loss: 5.2761 | test_loss: 5.2397 | \n",
      "Epoch: 40 | train_loss: 4.8375 | test_loss: 4.7878 | \n",
      "Epoch: 50 | train_loss: 4.4918 | test_loss: 4.4625 | \n",
      "Epoch: 60 | train_loss: 4.2083 | test_loss: 4.1984 | \n",
      "Epoch: 70 | train_loss: 3.9586 | test_loss: 3.9287 | \n",
      "Epoch: 80 | train_loss: 3.7408 | test_loss: 3.7155 | \n",
      "Epoch: 90 | train_loss: 3.5438 | test_loss: 3.5096 | \n",
      "Epoch: 100 | train_loss: 3.3665 | test_loss: 3.3265 | \n",
      "Epoch: 110 | train_loss: 3.2020 | test_loss: 3.1745 | \n",
      "Epoch: 120 | train_loss: 3.0496 | test_loss: 3.0282 | \n",
      "Epoch: 130 | train_loss: 2.9065 | test_loss: 2.8675 | \n",
      "Epoch: 140 | train_loss: 2.7720 | test_loss: 2.7505 | \n",
      "Epoch: 150 | train_loss: 2.6478 | test_loss: 2.6243 | \n",
      "Epoch: 160 | train_loss: 2.5252 | test_loss: 2.5148 | \n",
      "Epoch: 170 | train_loss: 2.4092 | test_loss: 2.3654 | \n",
      "Epoch: 180 | train_loss: 2.2984 | test_loss: 2.2660 | \n",
      "Epoch: 190 | train_loss: 2.1896 | test_loss: 2.1797 | \n",
      "Epoch: 200 | train_loss: 2.0862 | test_loss: 2.0687 | \n",
      "Epoch: 210 | train_loss: 1.9856 | test_loss: 1.9636 | \n",
      "Epoch: 220 | train_loss: 1.8892 | test_loss: 1.8653 | \n",
      "Epoch: 230 | train_loss: 1.7951 | test_loss: 1.7795 | \n",
      "Epoch: 240 | train_loss: 1.7028 | test_loss: 1.6857 | \n",
      "Epoch: 250 | train_loss: 1.6128 | test_loss: 1.5962 | \n",
      "Epoch: 260 | train_loss: 1.5259 | test_loss: 1.5092 | \n",
      "Epoch: 270 | train_loss: 1.4400 | test_loss: 1.4551 | \n",
      "Epoch: 280 | train_loss: 1.3543 | test_loss: 1.3504 | \n",
      "Epoch: 290 | train_loss: 1.2740 | test_loss: 1.2658 | \n",
      "Epoch: 300 | train_loss: 1.1928 | test_loss: 1.1870 | \n",
      "Epoch: 310 | train_loss: 1.1138 | test_loss: 1.0977 | \n",
      "Epoch: 320 | train_loss: 1.0358 | test_loss: 1.0399 | \n",
      "Epoch: 330 | train_loss: 0.9599 | test_loss: 0.9515 | \n",
      "Epoch: 340 | train_loss: 0.8858 | test_loss: 0.8747 | \n",
      "Epoch: 350 | train_loss: 0.8128 | test_loss: 0.8102 | \n",
      "Epoch: 360 | train_loss: 0.7402 | test_loss: 0.7509 | \n",
      "Epoch: 370 | train_loss: 0.6722 | test_loss: 0.7104 | \n",
      "Epoch: 380 | train_loss: 0.5999 | test_loss: 0.6002 | \n",
      "Epoch: 390 | train_loss: 0.5345 | test_loss: 0.5421 | \n",
      "Epoch: 400 | train_loss: 0.4684 | test_loss: 0.4852 | \n",
      "Epoch: 410 | train_loss: 0.4047 | test_loss: 0.3812 | \n",
      "Epoch: 420 | train_loss: 0.3434 | test_loss: 0.3686 | \n",
      "Epoch: 430 | train_loss: 0.2800 | test_loss: 0.3117 | \n",
      "Epoch: 440 | train_loss: 0.2358 | test_loss: 0.2247 | \n",
      "Epoch: 450 | train_loss: 0.1760 | test_loss: 0.2265 | \n",
      "Epoch: 460 | train_loss: 0.1231 | test_loss: 0.1799 | \n",
      "Epoch: 470 | train_loss: 0.0911 | test_loss: 0.1503 | \n",
      "Epoch: 480 | train_loss: 0.0729 | test_loss: 0.1399 | \n",
      "Epoch: 490 | train_loss: 0.0658 | test_loss: 0.1424 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2733 | test_loss: 9.0530 | \n",
      "Epoch: 10 | train_loss: 6.8759 | test_loss: 6.8119 | \n",
      "Epoch: 20 | train_loss: 5.8632 | test_loss: 5.7941 | \n",
      "Epoch: 30 | train_loss: 5.2557 | test_loss: 5.2181 | \n",
      "Epoch: 40 | train_loss: 4.8155 | test_loss: 4.7839 | \n",
      "Epoch: 50 | train_loss: 4.4695 | test_loss: 4.4342 | \n",
      "Epoch: 60 | train_loss: 4.1826 | test_loss: 4.1599 | \n",
      "Epoch: 70 | train_loss: 3.9333 | test_loss: 3.9040 | \n",
      "Epoch: 80 | train_loss: 3.7161 | test_loss: 3.6951 | \n",
      "Epoch: 90 | train_loss: 3.5199 | test_loss: 3.5071 | \n",
      "Epoch: 100 | train_loss: 3.3425 | test_loss: 3.3041 | \n",
      "Epoch: 110 | train_loss: 3.1788 | test_loss: 3.1718 | \n",
      "Epoch: 120 | train_loss: 3.0252 | test_loss: 3.0096 | \n",
      "Epoch: 130 | train_loss: 2.8841 | test_loss: 2.8786 | \n",
      "Epoch: 140 | train_loss: 2.7497 | test_loss: 2.7295 | \n",
      "Epoch: 150 | train_loss: 2.6243 | test_loss: 2.6143 | \n",
      "Epoch: 160 | train_loss: 2.5022 | test_loss: 2.4835 | \n",
      "Epoch: 170 | train_loss: 2.3879 | test_loss: 2.3840 | \n",
      "Epoch: 180 | train_loss: 2.2757 | test_loss: 2.2402 | \n",
      "Epoch: 190 | train_loss: 2.1704 | test_loss: 2.1625 | \n",
      "Epoch: 200 | train_loss: 2.0666 | test_loss: 2.0620 | \n",
      "Epoch: 210 | train_loss: 1.9662 | test_loss: 1.9569 | \n",
      "Epoch: 220 | train_loss: 1.8686 | test_loss: 1.8552 | \n",
      "Epoch: 230 | train_loss: 1.7741 | test_loss: 1.7621 | \n",
      "Epoch: 240 | train_loss: 1.6828 | test_loss: 1.6607 | \n",
      "Epoch: 250 | train_loss: 1.5946 | test_loss: 1.6006 | \n",
      "Epoch: 260 | train_loss: 1.5057 | test_loss: 1.4797 | \n",
      "Epoch: 270 | train_loss: 1.4213 | test_loss: 1.4103 | \n",
      "Epoch: 280 | train_loss: 1.3367 | test_loss: 1.3371 | \n",
      "Epoch: 290 | train_loss: 1.2552 | test_loss: 1.2511 | \n",
      "Epoch: 300 | train_loss: 1.1759 | test_loss: 1.1601 | \n",
      "Epoch: 310 | train_loss: 1.0960 | test_loss: 1.0851 | \n",
      "Epoch: 320 | train_loss: 1.0188 | test_loss: 1.0215 | \n",
      "Epoch: 330 | train_loss: 0.9453 | test_loss: 0.9461 | \n",
      "Epoch: 340 | train_loss: 0.8714 | test_loss: 0.8698 | \n",
      "Epoch: 350 | train_loss: 0.7975 | test_loss: 0.8016 | \n",
      "Epoch: 360 | train_loss: 0.7247 | test_loss: 0.7129 | \n",
      "Epoch: 370 | train_loss: 0.6560 | test_loss: 0.6643 | \n",
      "Epoch: 380 | train_loss: 0.5866 | test_loss: 0.6085 | \n",
      "Epoch: 390 | train_loss: 0.5189 | test_loss: 0.5313 | \n",
      "Epoch: 400 | train_loss: 0.4515 | test_loss: 0.4499 | \n",
      "Epoch: 410 | train_loss: 0.3900 | test_loss: 0.4323 | \n",
      "Epoch: 420 | train_loss: 0.3303 | test_loss: 0.3578 | \n",
      "Epoch: 430 | train_loss: 0.2666 | test_loss: 0.2864 | \n",
      "Epoch: 440 | train_loss: 0.2170 | test_loss: 0.2154 | \n",
      "Epoch: 450 | train_loss: 0.1625 | test_loss: 0.1946 | \n",
      "Epoch: 460 | train_loss: 0.1200 | test_loss: 0.1819 | \n",
      "Epoch: 470 | train_loss: 0.0873 | test_loss: 0.1460 | \n",
      "Epoch: 480 | train_loss: 0.0809 | test_loss: 0.1438 | \n",
      "Epoch: 490 | train_loss: 0.0683 | test_loss: 0.1445 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2861 | test_loss: 9.1616 | \n",
      "Epoch: 10 | train_loss: 6.8739 | test_loss: 6.7818 | \n",
      "Epoch: 20 | train_loss: 5.8740 | test_loss: 5.8028 | \n",
      "Epoch: 30 | train_loss: 5.2639 | test_loss: 5.2090 | \n",
      "Epoch: 40 | train_loss: 4.8313 | test_loss: 4.7761 | \n",
      "Epoch: 50 | train_loss: 4.4769 | test_loss: 4.4415 | \n",
      "Epoch: 60 | train_loss: 4.1960 | test_loss: 4.1511 | \n",
      "Epoch: 70 | train_loss: 3.9438 | test_loss: 3.9086 | \n",
      "Epoch: 80 | train_loss: 3.7247 | test_loss: 3.6989 | \n",
      "Epoch: 90 | train_loss: 3.5318 | test_loss: 3.5087 | \n",
      "Epoch: 100 | train_loss: 3.3496 | test_loss: 3.3285 | \n",
      "Epoch: 110 | train_loss: 3.1830 | test_loss: 3.1655 | \n",
      "Epoch: 120 | train_loss: 3.0379 | test_loss: 3.0141 | \n",
      "Epoch: 130 | train_loss: 2.8933 | test_loss: 2.8717 | \n",
      "Epoch: 140 | train_loss: 2.7560 | test_loss: 2.7361 | \n",
      "Epoch: 150 | train_loss: 2.6383 | test_loss: 2.6087 | \n",
      "Epoch: 160 | train_loss: 2.5119 | test_loss: 2.4979 | \n",
      "Epoch: 170 | train_loss: 2.3891 | test_loss: 2.3752 | \n",
      "Epoch: 180 | train_loss: 2.2835 | test_loss: 2.2678 | \n",
      "Epoch: 190 | train_loss: 2.1749 | test_loss: 2.1539 | \n",
      "Epoch: 200 | train_loss: 2.0703 | test_loss: 2.0518 | \n",
      "Epoch: 210 | train_loss: 1.9722 | test_loss: 1.9545 | \n",
      "Epoch: 220 | train_loss: 1.8755 | test_loss: 1.8583 | \n",
      "Epoch: 230 | train_loss: 1.7820 | test_loss: 1.7632 | \n",
      "Epoch: 240 | train_loss: 1.6899 | test_loss: 1.6716 | \n",
      "Epoch: 250 | train_loss: 1.5953 | test_loss: 1.5802 | \n",
      "Epoch: 260 | train_loss: 1.5159 | test_loss: 1.4969 | \n",
      "Epoch: 270 | train_loss: 1.4293 | test_loss: 1.4189 | \n",
      "Epoch: 280 | train_loss: 1.3449 | test_loss: 1.3251 | \n",
      "Epoch: 290 | train_loss: 1.2631 | test_loss: 1.2635 | \n",
      "Epoch: 300 | train_loss: 1.1838 | test_loss: 1.1699 | \n",
      "Epoch: 310 | train_loss: 1.1044 | test_loss: 1.0923 | \n",
      "Epoch: 320 | train_loss: 1.0300 | test_loss: 1.0172 | \n",
      "Epoch: 330 | train_loss: 0.9539 | test_loss: 0.9383 | \n",
      "Epoch: 340 | train_loss: 0.8859 | test_loss: 0.8703 | \n",
      "Epoch: 350 | train_loss: 0.8083 | test_loss: 0.7915 | \n",
      "Epoch: 360 | train_loss: 0.7433 | test_loss: 0.7316 | \n",
      "Epoch: 370 | train_loss: 0.6704 | test_loss: 0.6604 | \n",
      "Epoch: 380 | train_loss: 0.6025 | test_loss: 0.5929 | \n",
      "Epoch: 390 | train_loss: 0.5407 | test_loss: 0.5298 | \n",
      "Epoch: 400 | train_loss: 0.4755 | test_loss: 0.4678 | \n",
      "Epoch: 410 | train_loss: 0.4161 | test_loss: 0.3981 | \n",
      "Epoch: 420 | train_loss: 0.3664 | test_loss: 0.3433 | \n",
      "Epoch: 430 | train_loss: 0.3135 | test_loss: 0.2948 | \n",
      "Epoch: 440 | train_loss: 0.2646 | test_loss: 0.2431 | \n",
      "Epoch: 450 | train_loss: 0.2201 | test_loss: 0.2060 | \n",
      "Epoch: 460 | train_loss: 0.1872 | test_loss: 0.1904 | \n",
      "Epoch: 470 | train_loss: 0.1669 | test_loss: 0.1642 | \n",
      "Epoch: 480 | train_loss: 0.1502 | test_loss: 0.1494 | \n",
      "Epoch: 490 | train_loss: 0.1384 | test_loss: 0.1516 | \n",
      "Epoch: 500 | train_loss: 0.1280 | test_loss: 0.1426 | \n",
      "Epoch: 510 | train_loss: 0.1303 | test_loss: 0.1353 | \n",
      "Epoch: 520 | train_loss: 0.1329 | test_loss: 0.1391 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3126 | test_loss: 9.0774 | \n",
      "Epoch: 10 | train_loss: 6.9163 | test_loss: 6.8312 | \n",
      "Epoch: 20 | train_loss: 5.9030 | test_loss: 5.8231 | \n",
      "Epoch: 30 | train_loss: 5.2893 | test_loss: 5.2345 | \n",
      "Epoch: 40 | train_loss: 4.8575 | test_loss: 4.8066 | \n",
      "Epoch: 50 | train_loss: 4.5063 | test_loss: 4.4716 | \n",
      "Epoch: 60 | train_loss: 4.2156 | test_loss: 4.1803 | \n",
      "Epoch: 70 | train_loss: 3.9713 | test_loss: 3.9317 | \n",
      "Epoch: 80 | train_loss: 3.7461 | test_loss: 3.7157 | \n",
      "Epoch: 90 | train_loss: 3.5595 | test_loss: 3.5216 | \n",
      "Epoch: 100 | train_loss: 3.3795 | test_loss: 3.3426 | \n",
      "Epoch: 110 | train_loss: 3.2120 | test_loss: 3.1849 | \n",
      "Epoch: 120 | train_loss: 3.0623 | test_loss: 3.0354 | \n",
      "Epoch: 130 | train_loss: 2.9209 | test_loss: 2.8953 | \n",
      "Epoch: 140 | train_loss: 2.7795 | test_loss: 2.7624 | \n",
      "Epoch: 150 | train_loss: 2.6554 | test_loss: 2.6295 | \n",
      "Epoch: 160 | train_loss: 2.5305 | test_loss: 2.5110 | \n",
      "Epoch: 170 | train_loss: 2.4241 | test_loss: 2.3964 | \n",
      "Epoch: 180 | train_loss: 2.3058 | test_loss: 2.2873 | \n",
      "Epoch: 190 | train_loss: 2.2030 | test_loss: 2.1820 | \n",
      "Epoch: 200 | train_loss: 2.0994 | test_loss: 2.0747 | \n",
      "Epoch: 210 | train_loss: 2.0021 | test_loss: 1.9702 | \n",
      "Epoch: 220 | train_loss: 1.9058 | test_loss: 1.8845 | \n",
      "Epoch: 230 | train_loss: 1.8135 | test_loss: 1.7835 | \n",
      "Epoch: 240 | train_loss: 1.7183 | test_loss: 1.6959 | \n",
      "Epoch: 250 | train_loss: 1.6247 | test_loss: 1.6121 | \n",
      "Epoch: 260 | train_loss: 1.5414 | test_loss: 1.5139 | \n",
      "Epoch: 270 | train_loss: 1.4559 | test_loss: 1.4338 | \n",
      "Epoch: 280 | train_loss: 1.3727 | test_loss: 1.3529 | \n",
      "Epoch: 290 | train_loss: 1.2884 | test_loss: 1.2661 | \n",
      "Epoch: 300 | train_loss: 1.2155 | test_loss: 1.1929 | \n",
      "Epoch: 310 | train_loss: 1.1396 | test_loss: 1.1199 | \n",
      "Epoch: 320 | train_loss: 1.0542 | test_loss: 1.0336 | \n",
      "Epoch: 330 | train_loss: 0.9844 | test_loss: 0.9704 | \n",
      "Epoch: 340 | train_loss: 0.9078 | test_loss: 0.8890 | \n",
      "Epoch: 350 | train_loss: 0.8334 | test_loss: 0.8156 | \n",
      "Epoch: 360 | train_loss: 0.7658 | test_loss: 0.7470 | \n",
      "Epoch: 370 | train_loss: 0.7038 | test_loss: 0.6778 | \n",
      "Epoch: 380 | train_loss: 0.6339 | test_loss: 0.6204 | \n",
      "Epoch: 390 | train_loss: 0.5652 | test_loss: 0.5502 | \n",
      "Epoch: 400 | train_loss: 0.5070 | test_loss: 0.4850 | \n",
      "Epoch: 410 | train_loss: 0.4390 | test_loss: 0.4283 | \n",
      "Epoch: 420 | train_loss: 0.3877 | test_loss: 0.3647 | \n",
      "Epoch: 430 | train_loss: 0.3267 | test_loss: 0.3161 | \n",
      "Epoch: 440 | train_loss: 0.2805 | test_loss: 0.2647 | \n",
      "Epoch: 450 | train_loss: 0.2390 | test_loss: 0.2253 | \n",
      "Epoch: 460 | train_loss: 0.2044 | test_loss: 0.1958 | \n",
      "Epoch: 470 | train_loss: 0.1683 | test_loss: 0.1665 | \n",
      "Epoch: 480 | train_loss: 0.1493 | test_loss: 0.1522 | \n",
      "Epoch: 490 | train_loss: 0.1325 | test_loss: 0.1452 | \n",
      "Epoch: 500 | train_loss: 0.1294 | test_loss: 0.1405 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.5128 | test_loss: 7.6192 | \n",
      "Epoch: 10 | train_loss: 0.3875 | test_loss: 0.2980 | \n",
      "Epoch: 20 | train_loss: 0.1940 | test_loss: 0.1796 | \n",
      "Epoch: 30 | train_loss: 0.1742 | test_loss: 0.1633 | \n",
      "Epoch: 40 | train_loss: 0.1627 | test_loss: 0.1555 | \n",
      "Epoch: 50 | train_loss: 0.1559 | test_loss: 0.1515 | \n",
      "Epoch: 60 | train_loss: 0.1512 | test_loss: 0.1492 | \n",
      "Epoch: 70 | train_loss: 0.1460 | test_loss: 0.1470 | \n",
      "Epoch: 80 | train_loss: 0.1429 | test_loss: 0.1457 | \n",
      "Epoch: 90 | train_loss: 0.1401 | test_loss: 0.1446 | \n",
      "Epoch: 100 | train_loss: 0.1375 | test_loss: 0.1431 | \n",
      "Epoch: 110 | train_loss: 0.1334 | test_loss: 0.1431 | \n",
      "Epoch: 120 | train_loss: 0.1323 | test_loss: 0.1424 | \n",
      "Epoch: 130 | train_loss: 0.1299 | test_loss: 0.1417 | \n",
      "Epoch: 140 | train_loss: 0.1272 | test_loss: 0.1408 | \n",
      "Epoch: 150 | train_loss: 0.1257 | test_loss: 0.1401 | \n",
      "Epoch: 160 | train_loss: 0.1224 | test_loss: 0.1411 | \n",
      "Epoch: 170 | train_loss: 0.1202 | test_loss: 0.1397 | \n",
      "Epoch: 180 | train_loss: 0.1170 | test_loss: 0.1391 | \n",
      "Epoch: 190 | train_loss: 0.1148 | test_loss: 0.1394 | \n",
      "Epoch: 200 | train_loss: 0.1131 | test_loss: 0.1399 | \n",
      "Epoch: 210 | train_loss: 0.1113 | test_loss: 0.1407 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.3657 | test_loss: 4.5326 | \n",
      "Epoch: 10 | train_loss: 0.2044 | test_loss: 0.1841 | \n",
      "Epoch: 20 | train_loss: 0.1621 | test_loss: 0.1563 | \n",
      "Epoch: 30 | train_loss: 0.1486 | test_loss: 0.1495 | \n",
      "Epoch: 40 | train_loss: 0.1420 | test_loss: 0.1458 | \n",
      "Epoch: 50 | train_loss: 0.1330 | test_loss: 0.1429 | \n",
      "Epoch: 60 | train_loss: 0.1272 | test_loss: 0.1396 | \n",
      "Epoch: 70 | train_loss: 0.1211 | test_loss: 0.1370 | \n",
      "Epoch: 80 | train_loss: 0.1154 | test_loss: 0.1373 | \n",
      "Epoch: 90 | train_loss: 0.1090 | test_loss: 0.1363 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.1536 | test_loss: 0.3809 | \n",
      "Epoch: 10 | train_loss: 0.1689 | test_loss: 0.1593 | \n",
      "Epoch: 20 | train_loss: 0.1260 | test_loss: 0.1407 | \n",
      "Epoch: 30 | train_loss: 0.1004 | test_loss: 0.1403 | \n",
      "Epoch: 40 | train_loss: 0.0977 | test_loss: 0.1439 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8590 | test_loss: 9.3988 | \n",
      "Epoch: 10 | train_loss: 7.7448 | test_loss: 7.6753 | \n",
      "Epoch: 20 | train_loss: 6.8348 | test_loss: 6.7913 | \n",
      "Epoch: 30 | train_loss: 6.2605 | test_loss: 6.2125 | \n",
      "Epoch: 40 | train_loss: 5.8406 | test_loss: 5.8122 | \n",
      "Epoch: 50 | train_loss: 5.5128 | test_loss: 5.4846 | \n",
      "Epoch: 60 | train_loss: 5.2440 | test_loss: 5.2091 | \n",
      "Epoch: 70 | train_loss: 5.0108 | test_loss: 4.9980 | \n",
      "Epoch: 80 | train_loss: 4.8086 | test_loss: 4.7898 | \n",
      "Epoch: 90 | train_loss: 4.6270 | test_loss: 4.6167 | \n",
      "Epoch: 100 | train_loss: 4.4647 | test_loss: 4.4623 | \n",
      "Epoch: 110 | train_loss: 4.3159 | test_loss: 4.3015 | \n",
      "Epoch: 120 | train_loss: 4.1784 | test_loss: 4.1582 | \n",
      "Epoch: 130 | train_loss: 4.0649 | test_loss: 4.0782 | \n",
      "Epoch: 140 | train_loss: 3.9364 | test_loss: 3.9184 | \n",
      "Epoch: 150 | train_loss: 3.8247 | test_loss: 3.8074 | \n",
      "Epoch: 160 | train_loss: 3.7185 | test_loss: 3.7047 | \n",
      "Epoch: 170 | train_loss: 3.6190 | test_loss: 3.6071 | \n",
      "Epoch: 180 | train_loss: 3.5255 | test_loss: 3.5069 | \n",
      "Epoch: 190 | train_loss: 3.4338 | test_loss: 3.4222 | \n",
      "Epoch: 200 | train_loss: 3.3476 | test_loss: 3.3319 | \n",
      "Epoch: 210 | train_loss: 3.2639 | test_loss: 3.2483 | \n",
      "Epoch: 220 | train_loss: 3.1845 | test_loss: 3.1708 | \n",
      "Epoch: 230 | train_loss: 3.1066 | test_loss: 3.0978 | \n",
      "Epoch: 240 | train_loss: 3.0326 | test_loss: 3.0120 | \n",
      "Epoch: 250 | train_loss: 2.9601 | test_loss: 2.9516 | \n",
      "Epoch: 260 | train_loss: 2.8899 | test_loss: 2.8812 | \n",
      "Epoch: 270 | train_loss: 2.8233 | test_loss: 2.8205 | \n",
      "Epoch: 280 | train_loss: 2.7573 | test_loss: 2.7454 | \n",
      "Epoch: 290 | train_loss: 2.6928 | test_loss: 2.6775 | \n",
      "Epoch: 300 | train_loss: 2.6310 | test_loss: 2.6262 | \n",
      "Epoch: 310 | train_loss: 2.5698 | test_loss: 2.5592 | \n",
      "Epoch: 320 | train_loss: 2.5098 | test_loss: 2.4949 | \n",
      "Epoch: 330 | train_loss: 2.4512 | test_loss: 2.4448 | \n",
      "Epoch: 340 | train_loss: 2.3949 | test_loss: 2.3782 | \n",
      "Epoch: 350 | train_loss: 2.3372 | test_loss: 2.3223 | \n",
      "Epoch: 360 | train_loss: 2.2824 | test_loss: 2.2755 | \n",
      "Epoch: 370 | train_loss: 2.2286 | test_loss: 2.2170 | \n",
      "Epoch: 380 | train_loss: 2.1761 | test_loss: 2.1700 | \n",
      "Epoch: 390 | train_loss: 2.1233 | test_loss: 2.1043 | \n",
      "Epoch: 400 | train_loss: 2.0728 | test_loss: 2.0717 | \n",
      "Epoch: 410 | train_loss: 2.0245 | test_loss: 2.0148 | \n",
      "Epoch: 420 | train_loss: 1.9726 | test_loss: 1.9556 | \n",
      "Epoch: 430 | train_loss: 1.9243 | test_loss: 1.9146 | \n",
      "Epoch: 440 | train_loss: 1.8754 | test_loss: 1.8641 | \n",
      "Epoch: 450 | train_loss: 1.8295 | test_loss: 1.8213 | \n",
      "Epoch: 460 | train_loss: 1.7820 | test_loss: 1.7696 | \n",
      "Epoch: 470 | train_loss: 1.7358 | test_loss: 1.7193 | \n",
      "Epoch: 480 | train_loss: 1.6903 | test_loss: 1.6881 | \n",
      "Epoch: 490 | train_loss: 1.6452 | test_loss: 1.6365 | \n",
      "Epoch: 500 | train_loss: 1.6009 | test_loss: 1.5965 | \n",
      "Epoch: 510 | train_loss: 1.5575 | test_loss: 1.5546 | \n",
      "Epoch: 520 | train_loss: 1.5150 | test_loss: 1.4911 | \n",
      "Epoch: 530 | train_loss: 1.4717 | test_loss: 1.4698 | \n",
      "Epoch: 540 | train_loss: 1.4293 | test_loss: 1.4248 | \n",
      "Epoch: 550 | train_loss: 1.3872 | test_loss: 1.3822 | \n",
      "Epoch: 560 | train_loss: 1.3453 | test_loss: 1.3398 | \n",
      "Epoch: 570 | train_loss: 1.3053 | test_loss: 1.3036 | \n",
      "Epoch: 580 | train_loss: 1.2631 | test_loss: 1.2605 | \n",
      "Epoch: 590 | train_loss: 1.2244 | test_loss: 1.2209 | \n",
      "Epoch: 600 | train_loss: 1.1838 | test_loss: 1.1818 | \n",
      "Epoch: 610 | train_loss: 1.1444 | test_loss: 1.1423 | \n",
      "Epoch: 620 | train_loss: 1.1074 | test_loss: 1.1086 | \n",
      "Epoch: 630 | train_loss: 1.0672 | test_loss: 1.0716 | \n",
      "Epoch: 640 | train_loss: 1.0287 | test_loss: 1.0241 | \n",
      "Epoch: 650 | train_loss: 0.9909 | test_loss: 0.9899 | \n",
      "Epoch: 660 | train_loss: 0.9527 | test_loss: 0.9561 | \n",
      "Epoch: 670 | train_loss: 0.9158 | test_loss: 0.9132 | \n",
      "Epoch: 680 | train_loss: 0.8819 | test_loss: 0.8841 | \n",
      "Epoch: 690 | train_loss: 0.8425 | test_loss: 0.8405 | \n",
      "Epoch: 700 | train_loss: 0.8053 | test_loss: 0.8175 | \n",
      "Epoch: 710 | train_loss: 0.7705 | test_loss: 0.7776 | \n",
      "Epoch: 720 | train_loss: 0.7343 | test_loss: 0.7417 | \n",
      "Epoch: 730 | train_loss: 0.7022 | test_loss: 0.7004 | \n",
      "Epoch: 740 | train_loss: 0.6667 | test_loss: 0.6750 | \n",
      "Epoch: 750 | train_loss: 0.6299 | test_loss: 0.6295 | \n",
      "Epoch: 760 | train_loss: 0.5956 | test_loss: 0.6045 | \n",
      "Epoch: 770 | train_loss: 0.5637 | test_loss: 0.5648 | \n",
      "Epoch: 780 | train_loss: 0.5325 | test_loss: 0.5469 | \n",
      "Epoch: 790 | train_loss: 0.4956 | test_loss: 0.4958 | \n",
      "Epoch: 800 | train_loss: 0.4639 | test_loss: 0.4709 | \n",
      "Epoch: 810 | train_loss: 0.4315 | test_loss: 0.4525 | \n",
      "Epoch: 820 | train_loss: 0.3986 | test_loss: 0.4070 | \n",
      "Epoch: 830 | train_loss: 0.3692 | test_loss: 0.3798 | \n",
      "Epoch: 840 | train_loss: 0.3361 | test_loss: 0.3544 | \n",
      "Epoch: 850 | train_loss: 0.3036 | test_loss: 0.3271 | \n",
      "Epoch: 860 | train_loss: 0.2748 | test_loss: 0.3186 | \n",
      "Epoch: 870 | train_loss: 0.2504 | test_loss: 0.3011 | \n",
      "Epoch: 880 | train_loss: 0.2192 | test_loss: 0.2472 | \n",
      "Epoch: 890 | train_loss: 0.1876 | test_loss: 0.2292 | \n",
      "Epoch: 900 | train_loss: 0.1626 | test_loss: 0.1937 | \n",
      "Epoch: 910 | train_loss: 0.1350 | test_loss: 0.1790 | \n",
      "Epoch: 920 | train_loss: 0.1110 | test_loss: 0.1703 | \n",
      "Epoch: 930 | train_loss: 0.0968 | test_loss: 0.1542 | \n",
      "Epoch: 940 | train_loss: 0.0734 | test_loss: 0.1475 | \n",
      "Epoch: 950 | train_loss: 0.0584 | test_loss: 0.1373 | \n",
      "Epoch: 960 | train_loss: 0.0452 | test_loss: 0.1389 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8274 | test_loss: 9.5016 | \n",
      "Epoch: 10 | train_loss: 7.7148 | test_loss: 7.6622 | \n",
      "Epoch: 20 | train_loss: 6.8090 | test_loss: 6.7919 | \n",
      "Epoch: 30 | train_loss: 6.2351 | test_loss: 6.1889 | \n",
      "Epoch: 40 | train_loss: 5.8196 | test_loss: 5.7529 | \n",
      "Epoch: 50 | train_loss: 5.4868 | test_loss: 5.4705 | \n",
      "Epoch: 60 | train_loss: 5.2148 | test_loss: 5.1619 | \n",
      "Epoch: 70 | train_loss: 4.9857 | test_loss: 4.9449 | \n",
      "Epoch: 80 | train_loss: 4.7819 | test_loss: 4.7583 | \n",
      "Epoch: 90 | train_loss: 4.6026 | test_loss: 4.5844 | \n",
      "Epoch: 100 | train_loss: 4.4396 | test_loss: 4.4019 | \n",
      "Epoch: 110 | train_loss: 4.2914 | test_loss: 4.2975 | \n",
      "Epoch: 120 | train_loss: 4.1532 | test_loss: 4.1277 | \n",
      "Epoch: 130 | train_loss: 4.0260 | test_loss: 4.0211 | \n",
      "Epoch: 140 | train_loss: 3.9066 | test_loss: 3.8986 | \n",
      "Epoch: 150 | train_loss: 3.7952 | test_loss: 3.7749 | \n",
      "Epoch: 160 | train_loss: 3.6901 | test_loss: 3.6880 | \n",
      "Epoch: 170 | train_loss: 3.5898 | test_loss: 3.5666 | \n",
      "Epoch: 180 | train_loss: 3.4962 | test_loss: 3.4839 | \n",
      "Epoch: 190 | train_loss: 3.4049 | test_loss: 3.4044 | \n",
      "Epoch: 200 | train_loss: 3.3183 | test_loss: 3.3229 | \n",
      "Epoch: 210 | train_loss: 3.2352 | test_loss: 3.2178 | \n",
      "Epoch: 220 | train_loss: 3.1556 | test_loss: 3.1522 | \n",
      "Epoch: 230 | train_loss: 3.0775 | test_loss: 3.0599 | \n",
      "Epoch: 240 | train_loss: 3.0043 | test_loss: 2.9924 | \n",
      "Epoch: 250 | train_loss: 2.9315 | test_loss: 2.8999 | \n",
      "Epoch: 260 | train_loss: 2.8617 | test_loss: 2.8554 | \n",
      "Epoch: 270 | train_loss: 2.7938 | test_loss: 2.7840 | \n",
      "Epoch: 280 | train_loss: 2.7281 | test_loss: 2.7280 | \n",
      "Epoch: 290 | train_loss: 2.6647 | test_loss: 2.6381 | \n",
      "Epoch: 300 | train_loss: 2.6024 | test_loss: 2.6034 | \n",
      "Epoch: 310 | train_loss: 2.5403 | test_loss: 2.5291 | \n",
      "Epoch: 320 | train_loss: 2.4832 | test_loss: 2.4444 | \n",
      "Epoch: 330 | train_loss: 2.4237 | test_loss: 2.4331 | \n",
      "Epoch: 340 | train_loss: 2.3654 | test_loss: 2.3528 | \n",
      "Epoch: 350 | train_loss: 2.3094 | test_loss: 2.2952 | \n",
      "Epoch: 360 | train_loss: 2.2561 | test_loss: 2.2399 | \n",
      "Epoch: 370 | train_loss: 2.2006 | test_loss: 2.1812 | \n",
      "Epoch: 380 | train_loss: 2.1480 | test_loss: 2.1417 | \n",
      "Epoch: 390 | train_loss: 2.0961 | test_loss: 2.0798 | \n",
      "Epoch: 400 | train_loss: 2.0451 | test_loss: 2.0329 | \n",
      "Epoch: 410 | train_loss: 1.9944 | test_loss: 1.9877 | \n",
      "Epoch: 420 | train_loss: 1.9454 | test_loss: 1.9246 | \n",
      "Epoch: 430 | train_loss: 1.8965 | test_loss: 1.9046 | \n",
      "Epoch: 440 | train_loss: 1.8475 | test_loss: 1.8371 | \n",
      "Epoch: 450 | train_loss: 1.8001 | test_loss: 1.7987 | \n",
      "Epoch: 460 | train_loss: 1.7539 | test_loss: 1.7431 | \n",
      "Epoch: 470 | train_loss: 1.7097 | test_loss: 1.6887 | \n",
      "Epoch: 480 | train_loss: 1.6641 | test_loss: 1.6481 | \n",
      "Epoch: 490 | train_loss: 1.6181 | test_loss: 1.6073 | \n",
      "Epoch: 500 | train_loss: 1.5745 | test_loss: 1.5706 | \n",
      "Epoch: 510 | train_loss: 1.5298 | test_loss: 1.5285 | \n",
      "Epoch: 520 | train_loss: 1.4862 | test_loss: 1.4761 | \n",
      "Epoch: 530 | train_loss: 1.4429 | test_loss: 1.4175 | \n",
      "Epoch: 540 | train_loss: 1.4017 | test_loss: 1.4439 | \n",
      "Epoch: 550 | train_loss: 1.3586 | test_loss: 1.3529 | \n",
      "Epoch: 560 | train_loss: 1.3169 | test_loss: 1.2998 | \n",
      "Epoch: 570 | train_loss: 1.2769 | test_loss: 1.2813 | \n",
      "Epoch: 580 | train_loss: 1.2358 | test_loss: 1.2050 | \n",
      "Epoch: 590 | train_loss: 1.1960 | test_loss: 1.2021 | \n",
      "Epoch: 600 | train_loss: 1.1558 | test_loss: 1.1493 | \n",
      "Epoch: 610 | train_loss: 1.1166 | test_loss: 1.0977 | \n",
      "Epoch: 620 | train_loss: 1.0780 | test_loss: 1.0953 | \n",
      "Epoch: 630 | train_loss: 1.0391 | test_loss: 1.0227 | \n",
      "Epoch: 640 | train_loss: 0.9997 | test_loss: 0.9839 | \n",
      "Epoch: 650 | train_loss: 0.9632 | test_loss: 0.9543 | \n",
      "Epoch: 660 | train_loss: 0.9250 | test_loss: 0.9327 | \n",
      "Epoch: 670 | train_loss: 0.8882 | test_loss: 0.8986 | \n",
      "Epoch: 680 | train_loss: 0.8506 | test_loss: 0.8533 | \n",
      "Epoch: 690 | train_loss: 0.8150 | test_loss: 0.8215 | \n",
      "Epoch: 700 | train_loss: 0.7778 | test_loss: 0.7720 | \n",
      "Epoch: 710 | train_loss: 0.7442 | test_loss: 0.7446 | \n",
      "Epoch: 720 | train_loss: 0.7069 | test_loss: 0.7149 | \n",
      "Epoch: 730 | train_loss: 0.6738 | test_loss: 0.6941 | \n",
      "Epoch: 740 | train_loss: 0.6382 | test_loss: 0.6429 | \n",
      "Epoch: 750 | train_loss: 0.6020 | test_loss: 0.5979 | \n",
      "Epoch: 760 | train_loss: 0.5671 | test_loss: 0.5782 | \n",
      "Epoch: 770 | train_loss: 0.5326 | test_loss: 0.5307 | \n",
      "Epoch: 780 | train_loss: 0.4988 | test_loss: 0.5122 | \n",
      "Epoch: 790 | train_loss: 0.4654 | test_loss: 0.4709 | \n",
      "Epoch: 800 | train_loss: 0.4321 | test_loss: 0.4384 | \n",
      "Epoch: 810 | train_loss: 0.4000 | test_loss: 0.4101 | \n",
      "Epoch: 820 | train_loss: 0.3688 | test_loss: 0.3697 | \n",
      "Epoch: 830 | train_loss: 0.3394 | test_loss: 0.3469 | \n",
      "Epoch: 840 | train_loss: 0.3088 | test_loss: 0.3312 | \n",
      "Epoch: 850 | train_loss: 0.2761 | test_loss: 0.3083 | \n",
      "Epoch: 860 | train_loss: 0.2475 | test_loss: 0.2877 | \n",
      "Epoch: 870 | train_loss: 0.2183 | test_loss: 0.2597 | \n",
      "Epoch: 880 | train_loss: 0.1878 | test_loss: 0.2279 | \n",
      "Epoch: 890 | train_loss: 0.1646 | test_loss: 0.1928 | \n",
      "Epoch: 900 | train_loss: 0.1371 | test_loss: 0.1913 | \n",
      "Epoch: 910 | train_loss: 0.1132 | test_loss: 0.1684 | \n",
      "Epoch: 920 | train_loss: 0.1000 | test_loss: 0.1529 | \n",
      "Epoch: 930 | train_loss: 0.0757 | test_loss: 0.1476 | \n",
      "Epoch: 940 | train_loss: 0.0563 | test_loss: 0.1458 | \n",
      "Epoch: 950 | train_loss: 0.0572 | test_loss: 0.1337 | \n",
      "Epoch: 960 | train_loss: 0.0471 | test_loss: 0.1408 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8684 | test_loss: 10.1705 | \n",
      "Epoch: 10 | train_loss: 7.7436 | test_loss: 7.6619 | \n",
      "Epoch: 20 | train_loss: 6.8550 | test_loss: 6.7991 | \n",
      "Epoch: 30 | train_loss: 6.2777 | test_loss: 6.2213 | \n",
      "Epoch: 40 | train_loss: 5.8592 | test_loss: 5.8052 | \n",
      "Epoch: 50 | train_loss: 5.5273 | test_loss: 5.4940 | \n",
      "Epoch: 60 | train_loss: 5.2563 | test_loss: 5.2255 | \n",
      "Epoch: 70 | train_loss: 5.0245 | test_loss: 5.0009 | \n",
      "Epoch: 80 | train_loss: 4.8199 | test_loss: 4.7822 | \n",
      "Epoch: 90 | train_loss: 4.6368 | test_loss: 4.6175 | \n",
      "Epoch: 100 | train_loss: 4.4767 | test_loss: 4.4487 | \n",
      "Epoch: 110 | train_loss: 4.3240 | test_loss: 4.2979 | \n",
      "Epoch: 120 | train_loss: 4.1889 | test_loss: 4.1733 | \n",
      "Epoch: 130 | train_loss: 4.0609 | test_loss: 4.0469 | \n",
      "Epoch: 140 | train_loss: 3.9441 | test_loss: 3.9273 | \n",
      "Epoch: 150 | train_loss: 3.8332 | test_loss: 3.8086 | \n",
      "Epoch: 160 | train_loss: 3.7225 | test_loss: 3.7014 | \n",
      "Epoch: 170 | train_loss: 3.6268 | test_loss: 3.6018 | \n",
      "Epoch: 180 | train_loss: 3.5281 | test_loss: 3.5070 | \n",
      "Epoch: 190 | train_loss: 3.4421 | test_loss: 3.4170 | \n",
      "Epoch: 200 | train_loss: 3.3551 | test_loss: 3.3290 | \n",
      "Epoch: 210 | train_loss: 3.2691 | test_loss: 3.2420 | \n",
      "Epoch: 220 | train_loss: 3.1893 | test_loss: 3.1652 | \n",
      "Epoch: 230 | train_loss: 3.1155 | test_loss: 3.0890 | \n",
      "Epoch: 240 | train_loss: 3.0403 | test_loss: 3.0148 | \n",
      "Epoch: 250 | train_loss: 2.9642 | test_loss: 2.9461 | \n",
      "Epoch: 260 | train_loss: 2.8921 | test_loss: 2.8744 | \n",
      "Epoch: 270 | train_loss: 2.8290 | test_loss: 2.8094 | \n",
      "Epoch: 280 | train_loss: 2.7632 | test_loss: 2.7446 | \n",
      "Epoch: 290 | train_loss: 2.7004 | test_loss: 2.6796 | \n",
      "Epoch: 300 | train_loss: 2.6334 | test_loss: 2.6170 | \n",
      "Epoch: 310 | train_loss: 2.5751 | test_loss: 2.5501 | \n",
      "Epoch: 320 | train_loss: 2.5113 | test_loss: 2.4945 | \n",
      "Epoch: 330 | train_loss: 2.4502 | test_loss: 2.4370 | \n",
      "Epoch: 340 | train_loss: 2.3942 | test_loss: 2.3761 | \n",
      "Epoch: 350 | train_loss: 2.3405 | test_loss: 2.3159 | \n",
      "Epoch: 360 | train_loss: 2.2856 | test_loss: 2.2687 | \n",
      "Epoch: 370 | train_loss: 2.2336 | test_loss: 2.2123 | \n",
      "Epoch: 380 | train_loss: 2.1775 | test_loss: 2.1588 | \n",
      "Epoch: 390 | train_loss: 2.1274 | test_loss: 2.1144 | \n",
      "Epoch: 400 | train_loss: 2.0741 | test_loss: 2.0572 | \n",
      "Epoch: 410 | train_loss: 2.0255 | test_loss: 2.0018 | \n",
      "Epoch: 420 | train_loss: 1.9727 | test_loss: 1.9507 | \n",
      "Epoch: 430 | train_loss: 1.9280 | test_loss: 1.9070 | \n",
      "Epoch: 440 | train_loss: 1.8791 | test_loss: 1.8645 | \n",
      "Epoch: 450 | train_loss: 1.8313 | test_loss: 1.8132 | \n",
      "Epoch: 460 | train_loss: 1.7860 | test_loss: 1.7689 | \n",
      "Epoch: 470 | train_loss: 1.7337 | test_loss: 1.7223 | \n",
      "Epoch: 480 | train_loss: 1.6948 | test_loss: 1.6727 | \n",
      "Epoch: 490 | train_loss: 1.6479 | test_loss: 1.6285 | \n",
      "Epoch: 500 | train_loss: 1.5969 | test_loss: 1.5886 | \n",
      "Epoch: 510 | train_loss: 1.5588 | test_loss: 1.5468 | \n",
      "Epoch: 520 | train_loss: 1.5177 | test_loss: 1.4970 | \n",
      "Epoch: 530 | train_loss: 1.4767 | test_loss: 1.4517 | \n",
      "Epoch: 540 | train_loss: 1.4303 | test_loss: 1.4173 | \n",
      "Epoch: 550 | train_loss: 1.3907 | test_loss: 1.3737 | \n",
      "Epoch: 560 | train_loss: 1.3455 | test_loss: 1.3263 | \n",
      "Epoch: 570 | train_loss: 1.3080 | test_loss: 1.2906 | \n",
      "Epoch: 580 | train_loss: 1.2661 | test_loss: 1.2490 | \n",
      "Epoch: 590 | train_loss: 1.2240 | test_loss: 1.2103 | \n",
      "Epoch: 600 | train_loss: 1.1859 | test_loss: 1.1677 | \n",
      "Epoch: 610 | train_loss: 1.1459 | test_loss: 1.1337 | \n",
      "Epoch: 620 | train_loss: 1.1075 | test_loss: 1.0925 | \n",
      "Epoch: 630 | train_loss: 1.0727 | test_loss: 1.0554 | \n",
      "Epoch: 640 | train_loss: 1.0294 | test_loss: 1.0170 | \n",
      "Epoch: 650 | train_loss: 0.9987 | test_loss: 0.9825 | \n",
      "Epoch: 660 | train_loss: 0.9589 | test_loss: 0.9403 | \n",
      "Epoch: 670 | train_loss: 0.9201 | test_loss: 0.9042 | \n",
      "Epoch: 680 | train_loss: 0.8850 | test_loss: 0.8655 | \n",
      "Epoch: 690 | train_loss: 0.8495 | test_loss: 0.8335 | \n",
      "Epoch: 700 | train_loss: 0.8099 | test_loss: 0.7904 | \n",
      "Epoch: 710 | train_loss: 0.7779 | test_loss: 0.7541 | \n",
      "Epoch: 720 | train_loss: 0.7400 | test_loss: 0.7264 | \n",
      "Epoch: 730 | train_loss: 0.7046 | test_loss: 0.6898 | \n",
      "Epoch: 740 | train_loss: 0.6710 | test_loss: 0.6572 | \n",
      "Epoch: 750 | train_loss: 0.6361 | test_loss: 0.6192 | \n",
      "Epoch: 760 | train_loss: 0.6139 | test_loss: 0.5923 | \n",
      "Epoch: 770 | train_loss: 0.5723 | test_loss: 0.5594 | \n",
      "Epoch: 780 | train_loss: 0.5393 | test_loss: 0.5190 | \n",
      "Epoch: 790 | train_loss: 0.5115 | test_loss: 0.4946 | \n",
      "Epoch: 800 | train_loss: 0.4766 | test_loss: 0.4686 | \n",
      "Epoch: 810 | train_loss: 0.4424 | test_loss: 0.4346 | \n",
      "Epoch: 820 | train_loss: 0.4142 | test_loss: 0.4013 | \n",
      "Epoch: 830 | train_loss: 0.3857 | test_loss: 0.3706 | \n",
      "Epoch: 840 | train_loss: 0.3543 | test_loss: 0.3496 | \n",
      "Epoch: 850 | train_loss: 0.3253 | test_loss: 0.3158 | \n",
      "Epoch: 860 | train_loss: 0.3053 | test_loss: 0.2952 | \n",
      "Epoch: 870 | train_loss: 0.2791 | test_loss: 0.2682 | \n",
      "Epoch: 880 | train_loss: 0.2481 | test_loss: 0.2452 | \n",
      "Epoch: 890 | train_loss: 0.2295 | test_loss: 0.2310 | \n",
      "Epoch: 900 | train_loss: 0.2026 | test_loss: 0.2069 | \n",
      "Epoch: 910 | train_loss: 0.1887 | test_loss: 0.1846 | \n",
      "Epoch: 920 | train_loss: 0.1755 | test_loss: 0.1797 | \n",
      "Epoch: 930 | train_loss: 0.1573 | test_loss: 0.1636 | \n",
      "Epoch: 940 | train_loss: 0.1465 | test_loss: 0.1592 | \n",
      "Epoch: 950 | train_loss: 0.1378 | test_loss: 0.1487 | \n",
      "Epoch: 960 | train_loss: 0.1285 | test_loss: 0.1412 | \n",
      "Epoch: 970 | train_loss: 0.1221 | test_loss: 0.1420 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8946 | test_loss: 9.5509 | \n",
      "Epoch: 10 | train_loss: 7.7729 | test_loss: 7.6884 | \n",
      "Epoch: 20 | train_loss: 6.8762 | test_loss: 6.8169 | \n",
      "Epoch: 30 | train_loss: 6.2956 | test_loss: 6.2316 | \n",
      "Epoch: 40 | train_loss: 5.8797 | test_loss: 5.8251 | \n",
      "Epoch: 50 | train_loss: 5.5434 | test_loss: 5.5039 | \n",
      "Epoch: 60 | train_loss: 5.2706 | test_loss: 5.2340 | \n",
      "Epoch: 70 | train_loss: 5.0424 | test_loss: 5.0091 | \n",
      "Epoch: 80 | train_loss: 4.8334 | test_loss: 4.8118 | \n",
      "Epoch: 90 | train_loss: 4.6529 | test_loss: 4.6272 | \n",
      "Epoch: 100 | train_loss: 4.4890 | test_loss: 4.4691 | \n",
      "Epoch: 110 | train_loss: 4.3392 | test_loss: 4.3210 | \n",
      "Epoch: 120 | train_loss: 4.2039 | test_loss: 4.1862 | \n",
      "Epoch: 130 | train_loss: 4.0804 | test_loss: 4.0596 | \n",
      "Epoch: 140 | train_loss: 3.9569 | test_loss: 3.9396 | \n",
      "Epoch: 150 | train_loss: 3.8457 | test_loss: 3.8256 | \n",
      "Epoch: 160 | train_loss: 3.7364 | test_loss: 3.7251 | \n",
      "Epoch: 170 | train_loss: 3.6396 | test_loss: 3.6249 | \n",
      "Epoch: 180 | train_loss: 3.5487 | test_loss: 3.5230 | \n",
      "Epoch: 190 | train_loss: 3.4558 | test_loss: 3.4352 | \n",
      "Epoch: 200 | train_loss: 3.3594 | test_loss: 3.3545 | \n",
      "Epoch: 210 | train_loss: 3.2813 | test_loss: 3.2695 | \n",
      "Epoch: 220 | train_loss: 3.2012 | test_loss: 3.1933 | \n",
      "Epoch: 230 | train_loss: 3.1269 | test_loss: 3.1071 | \n",
      "Epoch: 240 | train_loss: 3.0534 | test_loss: 3.0383 | \n",
      "Epoch: 250 | train_loss: 2.9803 | test_loss: 2.9685 | \n",
      "Epoch: 260 | train_loss: 2.9073 | test_loss: 2.8943 | \n",
      "Epoch: 270 | train_loss: 2.8438 | test_loss: 2.8270 | \n",
      "Epoch: 280 | train_loss: 2.7768 | test_loss: 2.7586 | \n",
      "Epoch: 290 | train_loss: 2.7096 | test_loss: 2.6947 | \n",
      "Epoch: 300 | train_loss: 2.6482 | test_loss: 2.6331 | \n",
      "Epoch: 310 | train_loss: 2.5876 | test_loss: 2.5670 | \n",
      "Epoch: 320 | train_loss: 2.5270 | test_loss: 2.5115 | \n",
      "Epoch: 330 | train_loss: 2.4705 | test_loss: 2.4514 | \n",
      "Epoch: 340 | train_loss: 2.4120 | test_loss: 2.3986 | \n",
      "Epoch: 350 | train_loss: 2.3565 | test_loss: 2.3440 | \n",
      "Epoch: 360 | train_loss: 2.3051 | test_loss: 2.2837 | \n",
      "Epoch: 370 | train_loss: 2.2448 | test_loss: 2.2330 | \n",
      "Epoch: 380 | train_loss: 2.1965 | test_loss: 2.1782 | \n",
      "Epoch: 390 | train_loss: 2.1418 | test_loss: 2.1272 | \n",
      "Epoch: 400 | train_loss: 2.0858 | test_loss: 2.0761 | \n",
      "Epoch: 410 | train_loss: 2.0366 | test_loss: 2.0264 | \n",
      "Epoch: 420 | train_loss: 1.9932 | test_loss: 1.9770 | \n",
      "Epoch: 430 | train_loss: 1.9447 | test_loss: 1.9232 | \n",
      "Epoch: 440 | train_loss: 1.8960 | test_loss: 1.8815 | \n",
      "Epoch: 450 | train_loss: 1.8462 | test_loss: 1.8291 | \n",
      "Epoch: 460 | train_loss: 1.8008 | test_loss: 1.7834 | \n",
      "Epoch: 470 | train_loss: 1.7541 | test_loss: 1.7397 | \n",
      "Epoch: 480 | train_loss: 1.7072 | test_loss: 1.6983 | \n",
      "Epoch: 490 | train_loss: 1.6632 | test_loss: 1.6498 | \n",
      "Epoch: 500 | train_loss: 1.6186 | test_loss: 1.6088 | \n",
      "Epoch: 510 | train_loss: 1.5782 | test_loss: 1.5594 | \n",
      "Epoch: 520 | train_loss: 1.5368 | test_loss: 1.5211 | \n",
      "Epoch: 530 | train_loss: 1.4931 | test_loss: 1.4820 | \n",
      "Epoch: 540 | train_loss: 1.4468 | test_loss: 1.4312 | \n",
      "Epoch: 550 | train_loss: 1.4026 | test_loss: 1.3956 | \n",
      "Epoch: 560 | train_loss: 1.3661 | test_loss: 1.3543 | \n",
      "Epoch: 570 | train_loss: 1.3224 | test_loss: 1.3063 | \n",
      "Epoch: 580 | train_loss: 1.2789 | test_loss: 1.2760 | \n",
      "Epoch: 590 | train_loss: 1.2419 | test_loss: 1.2296 | \n",
      "Epoch: 600 | train_loss: 1.2035 | test_loss: 1.1920 | \n",
      "Epoch: 610 | train_loss: 1.1651 | test_loss: 1.1506 | \n",
      "Epoch: 620 | train_loss: 1.1223 | test_loss: 1.1246 | \n",
      "Epoch: 630 | train_loss: 1.0860 | test_loss: 1.0708 | \n",
      "Epoch: 640 | train_loss: 1.0476 | test_loss: 1.0329 | \n",
      "Epoch: 650 | train_loss: 1.0127 | test_loss: 0.9962 | \n",
      "Epoch: 660 | train_loss: 0.9762 | test_loss: 0.9667 | \n",
      "Epoch: 670 | train_loss: 0.9339 | test_loss: 0.9259 | \n",
      "Epoch: 680 | train_loss: 0.8969 | test_loss: 0.8934 | \n",
      "Epoch: 690 | train_loss: 0.8666 | test_loss: 0.8522 | \n",
      "Epoch: 700 | train_loss: 0.8288 | test_loss: 0.8235 | \n",
      "Epoch: 710 | train_loss: 0.7931 | test_loss: 0.7832 | \n",
      "Epoch: 720 | train_loss: 0.7587 | test_loss: 0.7587 | \n",
      "Epoch: 730 | train_loss: 0.7193 | test_loss: 0.7140 | \n",
      "Epoch: 740 | train_loss: 0.6881 | test_loss: 0.6746 | \n",
      "Epoch: 750 | train_loss: 0.6531 | test_loss: 0.6479 | \n",
      "Epoch: 760 | train_loss: 0.6207 | test_loss: 0.6165 | \n",
      "Epoch: 770 | train_loss: 0.5866 | test_loss: 0.5803 | \n",
      "Epoch: 780 | train_loss: 0.5537 | test_loss: 0.5463 | \n",
      "Epoch: 790 | train_loss: 0.5203 | test_loss: 0.5235 | \n",
      "Epoch: 800 | train_loss: 0.4933 | test_loss: 0.4842 | \n",
      "Epoch: 810 | train_loss: 0.4583 | test_loss: 0.4592 | \n",
      "Epoch: 820 | train_loss: 0.4267 | test_loss: 0.4228 | \n",
      "Epoch: 830 | train_loss: 0.4001 | test_loss: 0.3973 | \n",
      "Epoch: 840 | train_loss: 0.3673 | test_loss: 0.3696 | \n",
      "Epoch: 850 | train_loss: 0.3446 | test_loss: 0.3405 | \n",
      "Epoch: 860 | train_loss: 0.3145 | test_loss: 0.3139 | \n",
      "Epoch: 870 | train_loss: 0.2832 | test_loss: 0.2923 | \n",
      "Epoch: 880 | train_loss: 0.2625 | test_loss: 0.2597 | \n",
      "Epoch: 890 | train_loss: 0.2405 | test_loss: 0.2403 | \n",
      "Epoch: 900 | train_loss: 0.2176 | test_loss: 0.2143 | \n",
      "Epoch: 910 | train_loss: 0.1914 | test_loss: 0.2053 | \n",
      "Epoch: 920 | train_loss: 0.1743 | test_loss: 0.1733 | \n",
      "Epoch: 930 | train_loss: 0.1585 | test_loss: 0.1768 | \n",
      "Epoch: 940 | train_loss: 0.1448 | test_loss: 0.1643 | \n",
      "Epoch: 950 | train_loss: 0.1311 | test_loss: 0.1489 | \n",
      "Epoch: 960 | train_loss: 0.1262 | test_loss: 0.1476 | \n",
      "Epoch: 970 | train_loss: 0.1179 | test_loss: 0.1403 | \n",
      "Epoch: 980 | train_loss: 0.1189 | test_loss: 0.1362 | \n",
      "Epoch: 990 | train_loss: 0.1141 | test_loss: 0.1323 | \n",
      "Epoch: 1000 | train_loss: 0.1111 | test_loss: 0.1354 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 6.1120 | test_loss: 2.6297 | \n",
      "Epoch: 10 | train_loss: 0.1680 | test_loss: 0.1607 | \n",
      "Epoch: 20 | train_loss: 0.1456 | test_loss: 0.1481 | \n",
      "Epoch: 30 | train_loss: 0.1351 | test_loss: 0.1472 | \n",
      "Epoch: 40 | train_loss: 0.1281 | test_loss: 0.1399 | \n",
      "Epoch: 50 | train_loss: 0.1208 | test_loss: 0.1372 | \n",
      "Epoch: 60 | train_loss: 0.1105 | test_loss: 0.1350 | \n",
      "Epoch: 70 | train_loss: 0.1049 | test_loss: 0.1387 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.3802 | test_loss: 0.3029 | \n",
      "Epoch: 10 | train_loss: 0.1420 | test_loss: 0.1414 | \n",
      "Epoch: 20 | train_loss: 0.1251 | test_loss: 0.1350 | \n",
      "Epoch: 30 | train_loss: 0.1087 | test_loss: 0.1391 | \n",
      "Epoch: 40 | train_loss: 0.1039 | test_loss: 0.1367 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 2.0539 | test_loss: 0.5051 | \n",
      "Epoch: 10 | train_loss: 0.1254 | test_loss: 0.1413 | \n",
      "Epoch: 20 | train_loss: 0.1402 | test_loss: 0.1590 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.5957 | test_loss: 8.5924 | \n",
      "Epoch: 10 | train_loss: 5.8895 | test_loss: 5.8222 | \n",
      "Epoch: 20 | train_loss: 4.8294 | test_loss: 4.8194 | \n",
      "Epoch: 30 | train_loss: 4.1874 | test_loss: 4.1647 | \n",
      "Epoch: 40 | train_loss: 3.7226 | test_loss: 3.6741 | \n",
      "Epoch: 50 | train_loss: 3.3463 | test_loss: 3.3447 | \n",
      "Epoch: 60 | train_loss: 3.0274 | test_loss: 3.0141 | \n",
      "Epoch: 70 | train_loss: 2.7504 | test_loss: 2.7434 | \n",
      "Epoch: 80 | train_loss: 2.5042 | test_loss: 2.4772 | \n",
      "Epoch: 90 | train_loss: 2.2763 | test_loss: 2.2596 | \n",
      "Epoch: 100 | train_loss: 2.0655 | test_loss: 2.0522 | \n",
      "Epoch: 110 | train_loss: 1.8669 | test_loss: 1.8327 | \n",
      "Epoch: 120 | train_loss: 1.6806 | test_loss: 1.6641 | \n",
      "Epoch: 130 | train_loss: 1.5031 | test_loss: 1.5001 | \n",
      "Epoch: 140 | train_loss: 1.3387 | test_loss: 1.3291 | \n",
      "Epoch: 150 | train_loss: 1.1809 | test_loss: 1.1640 | \n",
      "Epoch: 160 | train_loss: 1.0233 | test_loss: 1.0140 | \n",
      "Epoch: 170 | train_loss: 0.8765 | test_loss: 0.8641 | \n",
      "Epoch: 180 | train_loss: 0.7290 | test_loss: 0.7145 | \n",
      "Epoch: 190 | train_loss: 0.5913 | test_loss: 0.5862 | \n",
      "Epoch: 200 | train_loss: 0.4583 | test_loss: 0.4604 | \n",
      "Epoch: 210 | train_loss: 0.3362 | test_loss: 0.3504 | \n",
      "Epoch: 220 | train_loss: 0.2372 | test_loss: 0.2463 | \n",
      "Epoch: 230 | train_loss: 0.1593 | test_loss: 0.1991 | \n",
      "Epoch: 240 | train_loss: 0.1090 | test_loss: 0.1646 | \n",
      "Epoch: 250 | train_loss: 0.1014 | test_loss: 0.1455 | \n",
      "Epoch: 260 | train_loss: 0.0913 | test_loss: 0.1420 | \n",
      "Epoch: 270 | train_loss: 0.0957 | test_loss: 0.1564 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6218 | test_loss: 8.6535 | \n",
      "Epoch: 10 | train_loss: 5.8856 | test_loss: 5.7336 | \n",
      "Epoch: 20 | train_loss: 4.8268 | test_loss: 4.7425 | \n",
      "Epoch: 30 | train_loss: 4.1902 | test_loss: 4.1192 | \n",
      "Epoch: 40 | train_loss: 3.7280 | test_loss: 3.6760 | \n",
      "Epoch: 50 | train_loss: 3.3477 | test_loss: 3.3403 | \n",
      "Epoch: 60 | train_loss: 3.0284 | test_loss: 3.0004 | \n",
      "Epoch: 70 | train_loss: 2.7526 | test_loss: 2.6871 | \n",
      "Epoch: 80 | train_loss: 2.5011 | test_loss: 2.4874 | \n",
      "Epoch: 90 | train_loss: 2.2756 | test_loss: 2.2453 | \n",
      "Epoch: 100 | train_loss: 2.0642 | test_loss: 2.0351 | \n",
      "Epoch: 110 | train_loss: 1.8674 | test_loss: 1.8566 | \n",
      "Epoch: 120 | train_loss: 1.6814 | test_loss: 1.6918 | \n",
      "Epoch: 130 | train_loss: 1.5036 | test_loss: 1.4994 | \n",
      "Epoch: 140 | train_loss: 1.3349 | test_loss: 1.3291 | \n",
      "Epoch: 150 | train_loss: 1.1747 | test_loss: 1.1769 | \n",
      "Epoch: 160 | train_loss: 1.0185 | test_loss: 1.0015 | \n",
      "Epoch: 170 | train_loss: 0.8749 | test_loss: 0.8797 | \n",
      "Epoch: 180 | train_loss: 0.7288 | test_loss: 0.6951 | \n",
      "Epoch: 190 | train_loss: 0.5923 | test_loss: 0.6142 | \n",
      "Epoch: 200 | train_loss: 0.4582 | test_loss: 0.4567 | \n",
      "Epoch: 210 | train_loss: 0.3335 | test_loss: 0.3498 | \n",
      "Epoch: 220 | train_loss: 0.2206 | test_loss: 0.2362 | \n",
      "Epoch: 230 | train_loss: 0.1489 | test_loss: 0.1945 | \n",
      "Epoch: 240 | train_loss: 0.1088 | test_loss: 0.1616 | \n",
      "Epoch: 250 | train_loss: 0.0897 | test_loss: 0.1436 | \n",
      "Epoch: 260 | train_loss: 0.0928 | test_loss: 0.1442 | \n",
      "Epoch: 270 | train_loss: 0.0868 | test_loss: 0.1482 | \n",
      "Epoch: 280 | train_loss: 0.0860 | test_loss: 0.1396 | \n",
      "Epoch: 290 | train_loss: 0.0716 | test_loss: 0.1419 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.7071 | test_loss: 8.6261 | \n",
      "Epoch: 10 | train_loss: 5.9829 | test_loss: 5.8723 | \n",
      "Epoch: 20 | train_loss: 4.9064 | test_loss: 4.8358 | \n",
      "Epoch: 30 | train_loss: 4.2673 | test_loss: 4.2062 | \n",
      "Epoch: 40 | train_loss: 3.7957 | test_loss: 3.7624 | \n",
      "Epoch: 50 | train_loss: 3.4197 | test_loss: 3.3833 | \n",
      "Epoch: 60 | train_loss: 3.1031 | test_loss: 3.0686 | \n",
      "Epoch: 70 | train_loss: 2.8305 | test_loss: 2.7906 | \n",
      "Epoch: 80 | train_loss: 2.5767 | test_loss: 2.5516 | \n",
      "Epoch: 90 | train_loss: 2.3478 | test_loss: 2.3181 | \n",
      "Epoch: 100 | train_loss: 2.1404 | test_loss: 2.1142 | \n",
      "Epoch: 110 | train_loss: 1.9450 | test_loss: 1.9165 | \n",
      "Epoch: 120 | train_loss: 1.7532 | test_loss: 1.7240 | \n",
      "Epoch: 130 | train_loss: 1.5784 | test_loss: 1.5562 | \n",
      "Epoch: 140 | train_loss: 1.4070 | test_loss: 1.3815 | \n",
      "Epoch: 150 | train_loss: 1.2528 | test_loss: 1.2196 | \n",
      "Epoch: 160 | train_loss: 1.0947 | test_loss: 1.0698 | \n",
      "Epoch: 170 | train_loss: 0.9468 | test_loss: 0.9251 | \n",
      "Epoch: 180 | train_loss: 0.8092 | test_loss: 0.7917 | \n",
      "Epoch: 190 | train_loss: 0.6709 | test_loss: 0.6590 | \n",
      "Epoch: 200 | train_loss: 0.5442 | test_loss: 0.5256 | \n",
      "Epoch: 210 | train_loss: 0.4225 | test_loss: 0.4155 | \n",
      "Epoch: 220 | train_loss: 0.3199 | test_loss: 0.3104 | \n",
      "Epoch: 230 | train_loss: 0.2339 | test_loss: 0.2175 | \n",
      "Epoch: 240 | train_loss: 0.1940 | test_loss: 0.1829 | \n",
      "Epoch: 250 | train_loss: 0.1675 | test_loss: 0.1511 | \n",
      "Epoch: 260 | train_loss: 0.1606 | test_loss: 0.1472 | \n",
      "Epoch: 270 | train_loss: 0.1544 | test_loss: 0.1415 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6952 | test_loss: 8.6357 | \n",
      "Epoch: 10 | train_loss: 5.9719 | test_loss: 5.8581 | \n",
      "Epoch: 20 | train_loss: 4.8952 | test_loss: 4.8493 | \n",
      "Epoch: 30 | train_loss: 4.2593 | test_loss: 4.2006 | \n",
      "Epoch: 40 | train_loss: 3.7818 | test_loss: 3.7427 | \n",
      "Epoch: 50 | train_loss: 3.4092 | test_loss: 3.3738 | \n",
      "Epoch: 60 | train_loss: 3.0922 | test_loss: 3.0590 | \n",
      "Epoch: 70 | train_loss: 2.8155 | test_loss: 2.7847 | \n",
      "Epoch: 80 | train_loss: 2.5661 | test_loss: 2.5316 | \n",
      "Epoch: 90 | train_loss: 2.3425 | test_loss: 2.3129 | \n",
      "Epoch: 100 | train_loss: 2.1243 | test_loss: 2.1081 | \n",
      "Epoch: 110 | train_loss: 1.9371 | test_loss: 1.9082 | \n",
      "Epoch: 120 | train_loss: 1.7470 | test_loss: 1.7260 | \n",
      "Epoch: 130 | train_loss: 1.5713 | test_loss: 1.5495 | \n",
      "Epoch: 140 | train_loss: 1.4033 | test_loss: 1.3760 | \n",
      "Epoch: 150 | train_loss: 1.2401 | test_loss: 1.2106 | \n",
      "Epoch: 160 | train_loss: 1.0881 | test_loss: 1.0603 | \n",
      "Epoch: 170 | train_loss: 0.9396 | test_loss: 0.9216 | \n",
      "Epoch: 180 | train_loss: 0.7965 | test_loss: 0.7788 | \n",
      "Epoch: 190 | train_loss: 0.6657 | test_loss: 0.6304 | \n",
      "Epoch: 200 | train_loss: 0.5417 | test_loss: 0.5188 | \n",
      "Epoch: 210 | train_loss: 0.4219 | test_loss: 0.4160 | \n",
      "Epoch: 220 | train_loss: 0.3120 | test_loss: 0.2976 | \n",
      "Epoch: 230 | train_loss: 0.2391 | test_loss: 0.2310 | \n",
      "Epoch: 240 | train_loss: 0.1907 | test_loss: 0.1610 | \n",
      "Epoch: 250 | train_loss: 0.1640 | test_loss: 0.1575 | \n",
      "Epoch: 260 | train_loss: 0.1683 | test_loss: 0.1369 | \n",
      "Epoch: 270 | train_loss: 0.1532 | test_loss: 0.1400 | \n",
      "Epoch: 280 | train_loss: 0.1394 | test_loss: 0.1387 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.3368 | test_loss: 4.7758 | \n",
      "Epoch: 10 | train_loss: 0.1922 | test_loss: 0.1759 | \n",
      "Epoch: 20 | train_loss: 0.1626 | test_loss: 0.1570 | \n",
      "Epoch: 30 | train_loss: 0.1484 | test_loss: 0.1514 | \n",
      "Epoch: 40 | train_loss: 0.1441 | test_loss: 0.1476 | \n",
      "Epoch: 50 | train_loss: 0.1368 | test_loss: 0.1448 | \n",
      "Epoch: 60 | train_loss: 0.1324 | test_loss: 0.1421 | \n",
      "Epoch: 70 | train_loss: 0.1279 | test_loss: 0.1393 | \n",
      "Epoch: 80 | train_loss: 0.1253 | test_loss: 0.1382 | \n",
      "Epoch: 90 | train_loss: 0.1189 | test_loss: 0.1374 | \n",
      "Epoch: 100 | train_loss: 0.1135 | test_loss: 0.1388 | \n",
      "Epoch: 110 | train_loss: 0.1081 | test_loss: 0.1360 | \n",
      "Epoch: 120 | train_loss: 0.1054 | test_loss: 0.1369 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.7046 | test_loss: 1.8802 | \n",
      "Epoch: 10 | train_loss: 0.1609 | test_loss: 0.1531 | \n",
      "Epoch: 20 | train_loss: 0.1344 | test_loss: 0.1420 | \n",
      "Epoch: 30 | train_loss: 0.1225 | test_loss: 0.1378 | \n",
      "Epoch: 40 | train_loss: 0.1076 | test_loss: 0.1386 | \n",
      "Epoch: 50 | train_loss: 0.0921 | test_loss: 0.1377 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.2050 | test_loss: 1.6930 | \n",
      "Epoch: 10 | train_loss: 0.1373 | test_loss: 0.1492 | \n",
      "Epoch: 20 | train_loss: 0.1120 | test_loss: 0.1601 | \n",
      "Epoch: 30 | train_loss: 0.0979 | test_loss: 0.1475 | \n",
      "Epoch: 40 | train_loss: 0.0900 | test_loss: 0.1614 | \n",
      "Epoch: 50 | train_loss: 0.0691 | test_loss: 0.1567 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2331 | test_loss: 9.2183 | \n",
      "Epoch: 10 | train_loss: 6.8593 | test_loss: 6.7679 | \n",
      "Epoch: 20 | train_loss: 5.8539 | test_loss: 5.7935 | \n",
      "Epoch: 30 | train_loss: 5.2484 | test_loss: 5.1915 | \n",
      "Epoch: 40 | train_loss: 4.8057 | test_loss: 4.7580 | \n",
      "Epoch: 50 | train_loss: 4.4637 | test_loss: 4.4255 | \n",
      "Epoch: 60 | train_loss: 4.1735 | test_loss: 4.1389 | \n",
      "Epoch: 70 | train_loss: 3.9271 | test_loss: 3.8939 | \n",
      "Epoch: 80 | train_loss: 3.7113 | test_loss: 3.7002 | \n",
      "Epoch: 90 | train_loss: 3.5169 | test_loss: 3.4764 | \n",
      "Epoch: 100 | train_loss: 3.3374 | test_loss: 3.3166 | \n",
      "Epoch: 110 | train_loss: 3.1747 | test_loss: 3.1381 | \n",
      "Epoch: 120 | train_loss: 3.0220 | test_loss: 2.9954 | \n",
      "Epoch: 130 | train_loss: 2.8822 | test_loss: 2.8520 | \n",
      "Epoch: 140 | train_loss: 2.7462 | test_loss: 2.7207 | \n",
      "Epoch: 150 | train_loss: 2.6197 | test_loss: 2.5696 | \n",
      "Epoch: 160 | train_loss: 2.5009 | test_loss: 2.5004 | \n",
      "Epoch: 170 | train_loss: 2.3839 | test_loss: 2.3471 | \n",
      "Epoch: 180 | train_loss: 2.2705 | test_loss: 2.2561 | \n",
      "Epoch: 190 | train_loss: 2.1652 | test_loss: 2.1543 | \n",
      "Epoch: 200 | train_loss: 2.0616 | test_loss: 2.0482 | \n",
      "Epoch: 210 | train_loss: 1.9618 | test_loss: 1.9716 | \n",
      "Epoch: 220 | train_loss: 1.8642 | test_loss: 1.8573 | \n",
      "Epoch: 230 | train_loss: 1.7693 | test_loss: 1.7578 | \n",
      "Epoch: 240 | train_loss: 1.6774 | test_loss: 1.6608 | \n",
      "Epoch: 250 | train_loss: 1.5906 | test_loss: 1.5692 | \n",
      "Epoch: 260 | train_loss: 1.5204 | test_loss: 1.5361 | \n",
      "Epoch: 270 | train_loss: 1.4228 | test_loss: 1.4051 | \n",
      "Epoch: 280 | train_loss: 1.3350 | test_loss: 1.3252 | \n",
      "Epoch: 290 | train_loss: 1.2518 | test_loss: 1.2391 | \n",
      "Epoch: 300 | train_loss: 1.1730 | test_loss: 1.1800 | \n",
      "Epoch: 310 | train_loss: 1.0921 | test_loss: 1.0801 | \n",
      "Epoch: 320 | train_loss: 1.0163 | test_loss: 1.0277 | \n",
      "Epoch: 330 | train_loss: 0.9437 | test_loss: 0.9251 | \n",
      "Epoch: 340 | train_loss: 0.8665 | test_loss: 0.8698 | \n",
      "Epoch: 350 | train_loss: 0.7932 | test_loss: 0.7869 | \n",
      "Epoch: 360 | train_loss: 0.7221 | test_loss: 0.7246 | \n",
      "Epoch: 370 | train_loss: 0.6522 | test_loss: 0.6622 | \n",
      "Epoch: 380 | train_loss: 0.5820 | test_loss: 0.5960 | \n",
      "Epoch: 390 | train_loss: 0.5172 | test_loss: 0.5256 | \n",
      "Epoch: 400 | train_loss: 0.4502 | test_loss: 0.4556 | \n",
      "Epoch: 410 | train_loss: 0.3865 | test_loss: 0.3921 | \n",
      "Epoch: 420 | train_loss: 0.3242 | test_loss: 0.3446 | \n",
      "Epoch: 430 | train_loss: 0.2643 | test_loss: 0.2910 | \n",
      "Epoch: 440 | train_loss: 0.2071 | test_loss: 0.2614 | \n",
      "Epoch: 450 | train_loss: 0.1597 | test_loss: 0.2010 | \n",
      "Epoch: 460 | train_loss: 0.1099 | test_loss: 0.1838 | \n",
      "Epoch: 470 | train_loss: 0.0934 | test_loss: 0.1569 | \n",
      "Epoch: 480 | train_loss: 0.0736 | test_loss: 0.1571 | \n",
      "Epoch: 490 | train_loss: 0.0677 | test_loss: 0.1421 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2321 | test_loss: 9.1143 | \n",
      "Epoch: 10 | train_loss: 6.8638 | test_loss: 6.7857 | \n",
      "Epoch: 20 | train_loss: 5.8386 | test_loss: 5.7874 | \n",
      "Epoch: 30 | train_loss: 5.2312 | test_loss: 5.1762 | \n",
      "Epoch: 40 | train_loss: 4.7947 | test_loss: 4.7605 | \n",
      "Epoch: 50 | train_loss: 4.4481 | test_loss: 4.4165 | \n",
      "Epoch: 60 | train_loss: 4.1636 | test_loss: 4.1615 | \n",
      "Epoch: 70 | train_loss: 3.9150 | test_loss: 3.8702 | \n",
      "Epoch: 80 | train_loss: 3.6981 | test_loss: 3.6703 | \n",
      "Epoch: 90 | train_loss: 3.5028 | test_loss: 3.4871 | \n",
      "Epoch: 100 | train_loss: 3.3257 | test_loss: 3.3310 | \n",
      "Epoch: 110 | train_loss: 3.1624 | test_loss: 3.0985 | \n",
      "Epoch: 120 | train_loss: 3.0110 | test_loss: 2.9951 | \n",
      "Epoch: 130 | train_loss: 2.8672 | test_loss: 2.8561 | \n",
      "Epoch: 140 | train_loss: 2.7323 | test_loss: 2.7306 | \n",
      "Epoch: 150 | train_loss: 2.6075 | test_loss: 2.6062 | \n",
      "Epoch: 160 | train_loss: 2.4872 | test_loss: 2.5101 | \n",
      "Epoch: 170 | train_loss: 2.3704 | test_loss: 2.3546 | \n",
      "Epoch: 180 | train_loss: 2.2602 | test_loss: 2.2404 | \n",
      "Epoch: 190 | train_loss: 2.1519 | test_loss: 2.1384 | \n",
      "Epoch: 200 | train_loss: 2.0507 | test_loss: 2.0596 | \n",
      "Epoch: 210 | train_loss: 1.9475 | test_loss: 1.9273 | \n",
      "Epoch: 220 | train_loss: 1.8496 | test_loss: 1.8343 | \n",
      "Epoch: 230 | train_loss: 1.7551 | test_loss: 1.7611 | \n",
      "Epoch: 240 | train_loss: 1.6654 | test_loss: 1.6637 | \n",
      "Epoch: 250 | train_loss: 1.5992 | test_loss: 1.5800 | \n",
      "Epoch: 260 | train_loss: 1.4931 | test_loss: 1.4871 | \n",
      "Epoch: 270 | train_loss: 1.4068 | test_loss: 1.4008 | \n",
      "Epoch: 280 | train_loss: 1.3219 | test_loss: 1.3179 | \n",
      "Epoch: 290 | train_loss: 1.2383 | test_loss: 1.2276 | \n",
      "Epoch: 300 | train_loss: 1.1559 | test_loss: 1.1522 | \n",
      "Epoch: 310 | train_loss: 1.0797 | test_loss: 1.0649 | \n",
      "Epoch: 320 | train_loss: 1.0030 | test_loss: 1.0087 | \n",
      "Epoch: 330 | train_loss: 0.9310 | test_loss: 0.9325 | \n",
      "Epoch: 340 | train_loss: 0.8548 | test_loss: 0.8579 | \n",
      "Epoch: 350 | train_loss: 0.7799 | test_loss: 0.7741 | \n",
      "Epoch: 360 | train_loss: 0.7081 | test_loss: 0.7124 | \n",
      "Epoch: 370 | train_loss: 0.6378 | test_loss: 0.6237 | \n",
      "Epoch: 380 | train_loss: 0.5693 | test_loss: 0.5716 | \n",
      "Epoch: 390 | train_loss: 0.5027 | test_loss: 0.4993 | \n",
      "Epoch: 400 | train_loss: 0.4369 | test_loss: 0.4307 | \n",
      "Epoch: 410 | train_loss: 0.3737 | test_loss: 0.3966 | \n",
      "Epoch: 420 | train_loss: 0.3143 | test_loss: 0.3195 | \n",
      "Epoch: 430 | train_loss: 0.2559 | test_loss: 0.3166 | \n",
      "Epoch: 440 | train_loss: 0.2018 | test_loss: 0.2355 | \n",
      "Epoch: 450 | train_loss: 0.1534 | test_loss: 0.1875 | \n",
      "Epoch: 460 | train_loss: 0.1162 | test_loss: 0.1748 | \n",
      "Epoch: 470 | train_loss: 0.0909 | test_loss: 0.1447 | \n",
      "Epoch: 480 | train_loss: 0.0690 | test_loss: 0.1494 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2980 | test_loss: 9.0889 | \n",
      "Epoch: 10 | train_loss: 6.9017 | test_loss: 6.8101 | \n",
      "Epoch: 20 | train_loss: 5.8937 | test_loss: 5.8338 | \n",
      "Epoch: 30 | train_loss: 5.2871 | test_loss: 5.2294 | \n",
      "Epoch: 40 | train_loss: 4.8483 | test_loss: 4.7999 | \n",
      "Epoch: 50 | train_loss: 4.4970 | test_loss: 4.4593 | \n",
      "Epoch: 60 | train_loss: 4.2170 | test_loss: 4.1781 | \n",
      "Epoch: 70 | train_loss: 3.9620 | test_loss: 3.9366 | \n",
      "Epoch: 80 | train_loss: 3.7440 | test_loss: 3.7161 | \n",
      "Epoch: 90 | train_loss: 3.5534 | test_loss: 3.5208 | \n",
      "Epoch: 100 | train_loss: 3.3718 | test_loss: 3.3431 | \n",
      "Epoch: 110 | train_loss: 3.2036 | test_loss: 3.1870 | \n",
      "Epoch: 120 | train_loss: 3.0527 | test_loss: 3.0294 | \n",
      "Epoch: 130 | train_loss: 2.9176 | test_loss: 2.8896 | \n",
      "Epoch: 140 | train_loss: 2.7761 | test_loss: 2.7533 | \n",
      "Epoch: 150 | train_loss: 2.6510 | test_loss: 2.6290 | \n",
      "Epoch: 160 | train_loss: 2.5330 | test_loss: 2.5080 | \n",
      "Epoch: 170 | train_loss: 2.4174 | test_loss: 2.3915 | \n",
      "Epoch: 180 | train_loss: 2.3049 | test_loss: 2.2803 | \n",
      "Epoch: 190 | train_loss: 2.1980 | test_loss: 2.1738 | \n",
      "Epoch: 200 | train_loss: 2.0982 | test_loss: 2.0730 | \n",
      "Epoch: 210 | train_loss: 1.9909 | test_loss: 1.9695 | \n",
      "Epoch: 220 | train_loss: 1.8980 | test_loss: 1.8755 | \n",
      "Epoch: 230 | train_loss: 1.8008 | test_loss: 1.7899 | \n",
      "Epoch: 240 | train_loss: 1.7121 | test_loss: 1.6941 | \n",
      "Epoch: 250 | train_loss: 1.6240 | test_loss: 1.6051 | \n",
      "Epoch: 260 | train_loss: 1.5347 | test_loss: 1.5157 | \n",
      "Epoch: 270 | train_loss: 1.4512 | test_loss: 1.4330 | \n",
      "Epoch: 280 | train_loss: 1.3658 | test_loss: 1.3451 | \n",
      "Epoch: 290 | train_loss: 1.2904 | test_loss: 1.2675 | \n",
      "Epoch: 300 | train_loss: 1.2074 | test_loss: 1.1890 | \n",
      "Epoch: 310 | train_loss: 1.1312 | test_loss: 1.1138 | \n",
      "Epoch: 320 | train_loss: 1.0559 | test_loss: 1.0348 | \n",
      "Epoch: 330 | train_loss: 0.9772 | test_loss: 0.9668 | \n",
      "Epoch: 340 | train_loss: 0.9074 | test_loss: 0.8870 | \n",
      "Epoch: 350 | train_loss: 0.8348 | test_loss: 0.8102 | \n",
      "Epoch: 360 | train_loss: 0.7625 | test_loss: 0.7426 | \n",
      "Epoch: 370 | train_loss: 0.6920 | test_loss: 0.6850 | \n",
      "Epoch: 380 | train_loss: 0.6324 | test_loss: 0.6080 | \n",
      "Epoch: 390 | train_loss: 0.5694 | test_loss: 0.5479 | \n",
      "Epoch: 400 | train_loss: 0.5013 | test_loss: 0.4793 | \n",
      "Epoch: 410 | train_loss: 0.4382 | test_loss: 0.4232 | \n",
      "Epoch: 420 | train_loss: 0.3839 | test_loss: 0.3713 | \n",
      "Epoch: 430 | train_loss: 0.3310 | test_loss: 0.3188 | \n",
      "Epoch: 440 | train_loss: 0.2775 | test_loss: 0.2745 | \n",
      "Epoch: 450 | train_loss: 0.2358 | test_loss: 0.2386 | \n",
      "Epoch: 460 | train_loss: 0.1965 | test_loss: 0.1967 | \n",
      "Epoch: 470 | train_loss: 0.1725 | test_loss: 0.1754 | \n",
      "Epoch: 480 | train_loss: 0.1475 | test_loss: 0.1433 | \n",
      "Epoch: 490 | train_loss: 0.1344 | test_loss: 0.1430 | \n",
      "Epoch: 500 | train_loss: 0.1280 | test_loss: 0.1364 | \n",
      "Epoch: 510 | train_loss: 0.1323 | test_loss: 0.1381 | \n",
      "Epoch: 520 | train_loss: 0.1283 | test_loss: 0.1381 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3847 | test_loss: 9.1107 | \n",
      "Epoch: 10 | train_loss: 6.9981 | test_loss: 6.8992 | \n",
      "Epoch: 20 | train_loss: 5.9815 | test_loss: 5.9072 | \n",
      "Epoch: 30 | train_loss: 5.3699 | test_loss: 5.3082 | \n",
      "Epoch: 40 | train_loss: 4.9248 | test_loss: 4.8803 | \n",
      "Epoch: 50 | train_loss: 4.5761 | test_loss: 4.5292 | \n",
      "Epoch: 60 | train_loss: 4.2833 | test_loss: 4.2450 | \n",
      "Epoch: 70 | train_loss: 4.0402 | test_loss: 3.9987 | \n",
      "Epoch: 80 | train_loss: 3.8228 | test_loss: 3.7834 | \n",
      "Epoch: 90 | train_loss: 3.6259 | test_loss: 3.5928 | \n",
      "Epoch: 100 | train_loss: 3.4473 | test_loss: 3.4151 | \n",
      "Epoch: 110 | train_loss: 3.2881 | test_loss: 3.2504 | \n",
      "Epoch: 120 | train_loss: 3.1268 | test_loss: 3.1023 | \n",
      "Epoch: 130 | train_loss: 2.9857 | test_loss: 2.9581 | \n",
      "Epoch: 140 | train_loss: 2.8513 | test_loss: 2.8274 | \n",
      "Epoch: 150 | train_loss: 2.7181 | test_loss: 2.7007 | \n",
      "Epoch: 160 | train_loss: 2.6009 | test_loss: 2.5785 | \n",
      "Epoch: 170 | train_loss: 2.4867 | test_loss: 2.4675 | \n",
      "Epoch: 180 | train_loss: 2.3740 | test_loss: 2.3524 | \n",
      "Epoch: 190 | train_loss: 2.2643 | test_loss: 2.2484 | \n",
      "Epoch: 200 | train_loss: 2.1591 | test_loss: 2.1447 | \n",
      "Epoch: 210 | train_loss: 2.0595 | test_loss: 2.0484 | \n",
      "Epoch: 220 | train_loss: 1.9634 | test_loss: 1.9465 | \n",
      "Epoch: 230 | train_loss: 1.8662 | test_loss: 1.8556 | \n",
      "Epoch: 240 | train_loss: 1.7777 | test_loss: 1.7641 | \n",
      "Epoch: 250 | train_loss: 1.6868 | test_loss: 1.6772 | \n",
      "Epoch: 260 | train_loss: 1.5994 | test_loss: 1.5812 | \n",
      "Epoch: 270 | train_loss: 1.5162 | test_loss: 1.5023 | \n",
      "Epoch: 280 | train_loss: 1.4310 | test_loss: 1.4119 | \n",
      "Epoch: 290 | train_loss: 1.3527 | test_loss: 1.3351 | \n",
      "Epoch: 300 | train_loss: 1.2749 | test_loss: 1.2565 | \n",
      "Epoch: 310 | train_loss: 1.1924 | test_loss: 1.1746 | \n",
      "Epoch: 320 | train_loss: 1.1136 | test_loss: 1.0981 | \n",
      "Epoch: 330 | train_loss: 1.0452 | test_loss: 1.0245 | \n",
      "Epoch: 340 | train_loss: 0.9605 | test_loss: 0.9521 | \n",
      "Epoch: 350 | train_loss: 0.8899 | test_loss: 0.8804 | \n",
      "Epoch: 360 | train_loss: 0.8194 | test_loss: 0.8120 | \n",
      "Epoch: 370 | train_loss: 0.7526 | test_loss: 0.7352 | \n",
      "Epoch: 380 | train_loss: 0.6824 | test_loss: 0.6687 | \n",
      "Epoch: 390 | train_loss: 0.6220 | test_loss: 0.6038 | \n",
      "Epoch: 400 | train_loss: 0.5505 | test_loss: 0.5430 | \n",
      "Epoch: 410 | train_loss: 0.4895 | test_loss: 0.4807 | \n",
      "Epoch: 420 | train_loss: 0.4230 | test_loss: 0.4156 | \n",
      "Epoch: 430 | train_loss: 0.3727 | test_loss: 0.3679 | \n",
      "Epoch: 440 | train_loss: 0.3171 | test_loss: 0.3174 | \n",
      "Epoch: 450 | train_loss: 0.2702 | test_loss: 0.2606 | \n",
      "Epoch: 460 | train_loss: 0.2208 | test_loss: 0.2224 | \n",
      "Epoch: 470 | train_loss: 0.1897 | test_loss: 0.1810 | \n",
      "Epoch: 480 | train_loss: 0.1600 | test_loss: 0.1615 | \n",
      "Epoch: 490 | train_loss: 0.1510 | test_loss: 0.1520 | \n",
      "Epoch: 500 | train_loss: 0.1380 | test_loss: 0.1454 | \n",
      "Epoch: 510 | train_loss: 0.1330 | test_loss: 0.1375 | \n",
      "Epoch: 520 | train_loss: 0.1202 | test_loss: 0.1387 | \n",
      "Epoch: 530 | train_loss: 0.1239 | test_loss: 0.1352 | \n",
      "Epoch: 540 | train_loss: 0.1342 | test_loss: 0.1389 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3566 | test_loss: 7.3519 | \n",
      "Epoch: 10 | train_loss: 0.2903 | test_loss: 0.2371 | \n",
      "Epoch: 20 | train_loss: 0.1883 | test_loss: 0.1760 | \n",
      "Epoch: 30 | train_loss: 0.1696 | test_loss: 0.1620 | \n",
      "Epoch: 40 | train_loss: 0.1605 | test_loss: 0.1560 | \n",
      "Epoch: 50 | train_loss: 0.1539 | test_loss: 0.1530 | \n",
      "Epoch: 60 | train_loss: 0.1472 | test_loss: 0.1499 | \n",
      "Epoch: 70 | train_loss: 0.1457 | test_loss: 0.1475 | \n",
      "Epoch: 80 | train_loss: 0.1422 | test_loss: 0.1469 | \n",
      "Epoch: 90 | train_loss: 0.1388 | test_loss: 0.1441 | \n",
      "Epoch: 100 | train_loss: 0.1364 | test_loss: 0.1432 | \n",
      "Epoch: 110 | train_loss: 0.1318 | test_loss: 0.1417 | \n",
      "Epoch: 120 | train_loss: 0.1304 | test_loss: 0.1406 | \n",
      "Epoch: 130 | train_loss: 0.1288 | test_loss: 0.1400 | \n",
      "Epoch: 140 | train_loss: 0.1259 | test_loss: 0.1387 | \n",
      "Epoch: 150 | train_loss: 0.1236 | test_loss: 0.1379 | \n",
      "Epoch: 160 | train_loss: 0.1206 | test_loss: 0.1374 | \n",
      "Epoch: 170 | train_loss: 0.1180 | test_loss: 0.1381 | \n",
      "Epoch: 180 | train_loss: 0.1147 | test_loss: 0.1384 | \n",
      "Epoch: 190 | train_loss: 0.1127 | test_loss: 0.1370 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.3364 | test_loss: 4.4855 | \n",
      "Epoch: 10 | train_loss: 0.2056 | test_loss: 0.1866 | \n",
      "Epoch: 20 | train_loss: 0.1610 | test_loss: 0.1554 | \n",
      "Epoch: 30 | train_loss: 0.1451 | test_loss: 0.1477 | \n",
      "Epoch: 40 | train_loss: 0.1350 | test_loss: 0.1444 | \n",
      "Epoch: 50 | train_loss: 0.1251 | test_loss: 0.1402 | \n",
      "Epoch: 60 | train_loss: 0.1169 | test_loss: 0.1386 | \n",
      "Epoch: 70 | train_loss: 0.1091 | test_loss: 0.1393 | \n",
      "Epoch: 80 | train_loss: 0.0971 | test_loss: 0.1386 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.0161 | test_loss: 0.4059 | \n",
      "Epoch: 10 | train_loss: 0.1612 | test_loss: 0.1530 | \n",
      "Epoch: 20 | train_loss: 0.1280 | test_loss: 0.1443 | \n",
      "Epoch: 30 | train_loss: 0.1302 | test_loss: 0.1478 | \n",
      "Epoch: 40 | train_loss: 0.0817 | test_loss: 0.1420 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8863 | test_loss: 9.7456 | \n",
      "Epoch: 10 | train_loss: 7.7610 | test_loss: 7.6963 | \n",
      "Epoch: 20 | train_loss: 6.8655 | test_loss: 6.8192 | \n",
      "Epoch: 30 | train_loss: 6.2842 | test_loss: 6.2533 | \n",
      "Epoch: 40 | train_loss: 5.8657 | test_loss: 5.8413 | \n",
      "Epoch: 50 | train_loss: 5.5391 | test_loss: 5.5052 | \n",
      "Epoch: 60 | train_loss: 5.2674 | test_loss: 5.2334 | \n",
      "Epoch: 70 | train_loss: 5.0352 | test_loss: 4.9925 | \n",
      "Epoch: 80 | train_loss: 4.8288 | test_loss: 4.8134 | \n",
      "Epoch: 90 | train_loss: 4.6472 | test_loss: 4.6310 | \n",
      "Epoch: 100 | train_loss: 4.4847 | test_loss: 4.4560 | \n",
      "Epoch: 110 | train_loss: 4.3348 | test_loss: 4.3225 | \n",
      "Epoch: 120 | train_loss: 4.1973 | test_loss: 4.1755 | \n",
      "Epoch: 130 | train_loss: 4.0704 | test_loss: 4.0471 | \n",
      "Epoch: 140 | train_loss: 3.9507 | test_loss: 3.9329 | \n",
      "Epoch: 150 | train_loss: 3.8386 | test_loss: 3.8214 | \n",
      "Epoch: 160 | train_loss: 3.7342 | test_loss: 3.7152 | \n",
      "Epoch: 170 | train_loss: 3.6341 | test_loss: 3.6168 | \n",
      "Epoch: 180 | train_loss: 3.5394 | test_loss: 3.5365 | \n",
      "Epoch: 190 | train_loss: 3.4479 | test_loss: 3.4241 | \n",
      "Epoch: 200 | train_loss: 3.3608 | test_loss: 3.3495 | \n",
      "Epoch: 210 | train_loss: 3.2778 | test_loss: 3.2680 | \n",
      "Epoch: 220 | train_loss: 3.1975 | test_loss: 3.1796 | \n",
      "Epoch: 230 | train_loss: 3.1208 | test_loss: 3.1114 | \n",
      "Epoch: 240 | train_loss: 3.0452 | test_loss: 3.0318 | \n",
      "Epoch: 250 | train_loss: 2.9749 | test_loss: 2.9647 | \n",
      "Epoch: 260 | train_loss: 2.9034 | test_loss: 2.8933 | \n",
      "Epoch: 270 | train_loss: 2.8351 | test_loss: 2.8178 | \n",
      "Epoch: 280 | train_loss: 2.7700 | test_loss: 2.7560 | \n",
      "Epoch: 290 | train_loss: 2.7049 | test_loss: 2.6968 | \n",
      "Epoch: 300 | train_loss: 2.6420 | test_loss: 2.6240 | \n",
      "Epoch: 310 | train_loss: 2.5803 | test_loss: 2.5552 | \n",
      "Epoch: 320 | train_loss: 2.5209 | test_loss: 2.5082 | \n",
      "Epoch: 330 | train_loss: 2.4627 | test_loss: 2.4657 | \n",
      "Epoch: 340 | train_loss: 2.4046 | test_loss: 2.3935 | \n",
      "Epoch: 350 | train_loss: 2.3494 | test_loss: 2.3550 | \n",
      "Epoch: 360 | train_loss: 2.2949 | test_loss: 2.2908 | \n",
      "Epoch: 370 | train_loss: 2.2392 | test_loss: 2.2362 | \n",
      "Epoch: 380 | train_loss: 2.1866 | test_loss: 2.1698 | \n",
      "Epoch: 390 | train_loss: 2.1348 | test_loss: 2.1128 | \n",
      "Epoch: 400 | train_loss: 2.0843 | test_loss: 2.0728 | \n",
      "Epoch: 410 | train_loss: 2.0325 | test_loss: 2.0167 | \n",
      "Epoch: 420 | train_loss: 1.9849 | test_loss: 1.9850 | \n",
      "Epoch: 430 | train_loss: 1.9354 | test_loss: 1.9223 | \n",
      "Epoch: 440 | train_loss: 1.8868 | test_loss: 1.8804 | \n",
      "Epoch: 450 | train_loss: 1.8389 | test_loss: 1.8329 | \n",
      "Epoch: 460 | train_loss: 1.7913 | test_loss: 1.7815 | \n",
      "Epoch: 470 | train_loss: 1.7469 | test_loss: 1.7396 | \n",
      "Epoch: 480 | train_loss: 1.7004 | test_loss: 1.7077 | \n",
      "Epoch: 490 | train_loss: 1.6553 | test_loss: 1.6460 | \n",
      "Epoch: 500 | train_loss: 1.6108 | test_loss: 1.6172 | \n",
      "Epoch: 510 | train_loss: 1.5681 | test_loss: 1.5603 | \n",
      "Epoch: 520 | train_loss: 1.5237 | test_loss: 1.5229 | \n",
      "Epoch: 530 | train_loss: 1.4814 | test_loss: 1.4754 | \n",
      "Epoch: 540 | train_loss: 1.4377 | test_loss: 1.4431 | \n",
      "Epoch: 550 | train_loss: 1.3962 | test_loss: 1.3961 | \n",
      "Epoch: 560 | train_loss: 1.3543 | test_loss: 1.3678 | \n",
      "Epoch: 570 | train_loss: 1.3136 | test_loss: 1.2986 | \n",
      "Epoch: 580 | train_loss: 1.2748 | test_loss: 1.2778 | \n",
      "Epoch: 590 | train_loss: 1.2331 | test_loss: 1.2225 | \n",
      "Epoch: 600 | train_loss: 1.1922 | test_loss: 1.1899 | \n",
      "Epoch: 610 | train_loss: 1.1526 | test_loss: 1.1542 | \n",
      "Epoch: 620 | train_loss: 1.1127 | test_loss: 1.1132 | \n",
      "Epoch: 630 | train_loss: 1.0747 | test_loss: 1.0499 | \n",
      "Epoch: 640 | train_loss: 1.0365 | test_loss: 1.0258 | \n",
      "Epoch: 650 | train_loss: 0.9984 | test_loss: 0.9903 | \n",
      "Epoch: 660 | train_loss: 0.9612 | test_loss: 0.9626 | \n",
      "Epoch: 670 | train_loss: 0.9228 | test_loss: 0.9218 | \n",
      "Epoch: 680 | train_loss: 0.8878 | test_loss: 0.8871 | \n",
      "Epoch: 690 | train_loss: 0.8501 | test_loss: 0.8339 | \n",
      "Epoch: 700 | train_loss: 0.8137 | test_loss: 0.8149 | \n",
      "Epoch: 710 | train_loss: 0.7773 | test_loss: 0.7817 | \n",
      "Epoch: 720 | train_loss: 0.7418 | test_loss: 0.7450 | \n",
      "Epoch: 730 | train_loss: 0.7062 | test_loss: 0.7131 | \n",
      "Epoch: 740 | train_loss: 0.6726 | test_loss: 0.6833 | \n",
      "Epoch: 750 | train_loss: 0.6366 | test_loss: 0.6387 | \n",
      "Epoch: 760 | train_loss: 0.6028 | test_loss: 0.6115 | \n",
      "Epoch: 770 | train_loss: 0.5690 | test_loss: 0.5716 | \n",
      "Epoch: 780 | train_loss: 0.5349 | test_loss: 0.5505 | \n",
      "Epoch: 790 | train_loss: 0.5012 | test_loss: 0.5105 | \n",
      "Epoch: 800 | train_loss: 0.4690 | test_loss: 0.4871 | \n",
      "Epoch: 810 | train_loss: 0.4360 | test_loss: 0.4334 | \n",
      "Epoch: 820 | train_loss: 0.4050 | test_loss: 0.4180 | \n",
      "Epoch: 830 | train_loss: 0.3725 | test_loss: 0.3827 | \n",
      "Epoch: 840 | train_loss: 0.3414 | test_loss: 0.3443 | \n",
      "Epoch: 850 | train_loss: 0.3130 | test_loss: 0.3291 | \n",
      "Epoch: 860 | train_loss: 0.2838 | test_loss: 0.3082 | \n",
      "Epoch: 870 | train_loss: 0.2511 | test_loss: 0.2650 | \n",
      "Epoch: 880 | train_loss: 0.2216 | test_loss: 0.2552 | \n",
      "Epoch: 890 | train_loss: 0.1932 | test_loss: 0.2340 | \n",
      "Epoch: 900 | train_loss: 0.1695 | test_loss: 0.2037 | \n",
      "Epoch: 910 | train_loss: 0.1421 | test_loss: 0.1906 | \n",
      "Epoch: 920 | train_loss: 0.1176 | test_loss: 0.1570 | \n",
      "Epoch: 930 | train_loss: 0.0943 | test_loss: 0.1516 | \n",
      "Epoch: 940 | train_loss: 0.0772 | test_loss: 0.1552 | \n",
      "Epoch: 950 | train_loss: 0.0649 | test_loss: 0.1541 | \n",
      "Epoch: 960 | train_loss: 0.0571 | test_loss: 0.1420 | \n",
      "Epoch: 970 | train_loss: 0.0432 | test_loss: 0.1379 | \n",
      "Epoch: 980 | train_loss: 0.0538 | test_loss: 0.1402 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8238 | test_loss: 9.3286 | \n",
      "Epoch: 10 | train_loss: 7.7085 | test_loss: 7.6358 | \n",
      "Epoch: 20 | train_loss: 6.8111 | test_loss: 6.8028 | \n",
      "Epoch: 30 | train_loss: 6.2364 | test_loss: 6.2036 | \n",
      "Epoch: 40 | train_loss: 5.8148 | test_loss: 5.7896 | \n",
      "Epoch: 50 | train_loss: 5.4843 | test_loss: 5.4133 | \n",
      "Epoch: 60 | train_loss: 5.2107 | test_loss: 5.2018 | \n",
      "Epoch: 70 | train_loss: 4.9778 | test_loss: 4.9531 | \n",
      "Epoch: 80 | train_loss: 4.7744 | test_loss: 4.7282 | \n",
      "Epoch: 90 | train_loss: 4.5934 | test_loss: 4.5689 | \n",
      "Epoch: 100 | train_loss: 4.4317 | test_loss: 4.4382 | \n",
      "Epoch: 110 | train_loss: 4.2823 | test_loss: 4.2651 | \n",
      "Epoch: 120 | train_loss: 4.1448 | test_loss: 4.1056 | \n",
      "Epoch: 130 | train_loss: 4.0168 | test_loss: 3.9770 | \n",
      "Epoch: 140 | train_loss: 3.9005 | test_loss: 3.8948 | \n",
      "Epoch: 150 | train_loss: 3.7864 | test_loss: 3.7383 | \n",
      "Epoch: 160 | train_loss: 3.6816 | test_loss: 3.6979 | \n",
      "Epoch: 170 | train_loss: 3.5807 | test_loss: 3.5534 | \n",
      "Epoch: 180 | train_loss: 3.4867 | test_loss: 3.4691 | \n",
      "Epoch: 190 | train_loss: 3.3959 | test_loss: 3.3929 | \n",
      "Epoch: 200 | train_loss: 3.3091 | test_loss: 3.3009 | \n",
      "Epoch: 210 | train_loss: 3.2277 | test_loss: 3.2111 | \n",
      "Epoch: 220 | train_loss: 3.1459 | test_loss: 3.1297 | \n",
      "Epoch: 230 | train_loss: 3.0694 | test_loss: 3.0399 | \n",
      "Epoch: 240 | train_loss: 2.9944 | test_loss: 2.9776 | \n",
      "Epoch: 250 | train_loss: 2.9239 | test_loss: 2.9121 | \n",
      "Epoch: 260 | train_loss: 2.8534 | test_loss: 2.8315 | \n",
      "Epoch: 270 | train_loss: 2.7846 | test_loss: 2.7383 | \n",
      "Epoch: 280 | train_loss: 2.7188 | test_loss: 2.7032 | \n",
      "Epoch: 290 | train_loss: 2.6544 | test_loss: 2.6257 | \n",
      "Epoch: 300 | train_loss: 2.5931 | test_loss: 2.5867 | \n",
      "Epoch: 310 | train_loss: 2.5309 | test_loss: 2.5260 | \n",
      "Epoch: 320 | train_loss: 2.4706 | test_loss: 2.4714 | \n",
      "Epoch: 330 | train_loss: 2.4122 | test_loss: 2.3881 | \n",
      "Epoch: 340 | train_loss: 2.3558 | test_loss: 2.3694 | \n",
      "Epoch: 350 | train_loss: 2.2990 | test_loss: 2.2507 | \n",
      "Epoch: 360 | train_loss: 2.2451 | test_loss: 2.2229 | \n",
      "Epoch: 370 | train_loss: 2.1904 | test_loss: 2.1530 | \n",
      "Epoch: 380 | train_loss: 2.1371 | test_loss: 2.1427 | \n",
      "Epoch: 390 | train_loss: 2.0850 | test_loss: 2.0710 | \n",
      "Epoch: 400 | train_loss: 2.0343 | test_loss: 1.9938 | \n",
      "Epoch: 410 | train_loss: 1.9843 | test_loss: 2.0075 | \n",
      "Epoch: 420 | train_loss: 1.9341 | test_loss: 1.9577 | \n",
      "Epoch: 430 | train_loss: 1.8858 | test_loss: 1.8989 | \n",
      "Epoch: 440 | train_loss: 1.8385 | test_loss: 1.8150 | \n",
      "Epoch: 450 | train_loss: 1.7913 | test_loss: 1.7834 | \n",
      "Epoch: 460 | train_loss: 1.7432 | test_loss: 1.7450 | \n",
      "Epoch: 470 | train_loss: 1.6973 | test_loss: 1.6892 | \n",
      "Epoch: 480 | train_loss: 1.6522 | test_loss: 1.6512 | \n",
      "Epoch: 490 | train_loss: 1.6078 | test_loss: 1.5859 | \n",
      "Epoch: 500 | train_loss: 1.5652 | test_loss: 1.5625 | \n",
      "Epoch: 510 | train_loss: 1.5184 | test_loss: 1.5049 | \n",
      "Epoch: 520 | train_loss: 1.4765 | test_loss: 1.4700 | \n",
      "Epoch: 530 | train_loss: 1.4335 | test_loss: 1.4046 | \n",
      "Epoch: 540 | train_loss: 1.3907 | test_loss: 1.4068 | \n",
      "Epoch: 550 | train_loss: 1.3488 | test_loss: 1.3388 | \n",
      "Epoch: 560 | train_loss: 1.3069 | test_loss: 1.2913 | \n",
      "Epoch: 570 | train_loss: 1.2665 | test_loss: 1.2400 | \n",
      "Epoch: 580 | train_loss: 1.2259 | test_loss: 1.2484 | \n",
      "Epoch: 590 | train_loss: 1.1857 | test_loss: 1.2014 | \n",
      "Epoch: 600 | train_loss: 1.1449 | test_loss: 1.1286 | \n",
      "Epoch: 610 | train_loss: 1.1066 | test_loss: 1.1105 | \n",
      "Epoch: 620 | train_loss: 1.0665 | test_loss: 1.0881 | \n",
      "Epoch: 630 | train_loss: 1.0275 | test_loss: 1.0391 | \n",
      "Epoch: 640 | train_loss: 0.9893 | test_loss: 0.9659 | \n",
      "Epoch: 650 | train_loss: 0.9519 | test_loss: 0.9427 | \n",
      "Epoch: 660 | train_loss: 0.9136 | test_loss: 0.9062 | \n",
      "Epoch: 670 | train_loss: 0.8769 | test_loss: 0.8515 | \n",
      "Epoch: 680 | train_loss: 0.8406 | test_loss: 0.8011 | \n",
      "Epoch: 690 | train_loss: 0.8045 | test_loss: 0.8070 | \n",
      "Epoch: 700 | train_loss: 0.7680 | test_loss: 0.7883 | \n",
      "Epoch: 710 | train_loss: 0.7326 | test_loss: 0.7187 | \n",
      "Epoch: 720 | train_loss: 0.6964 | test_loss: 0.7271 | \n",
      "Epoch: 730 | train_loss: 0.6611 | test_loss: 0.6306 | \n",
      "Epoch: 740 | train_loss: 0.6263 | test_loss: 0.6262 | \n",
      "Epoch: 750 | train_loss: 0.5919 | test_loss: 0.5897 | \n",
      "Epoch: 760 | train_loss: 0.5581 | test_loss: 0.5407 | \n",
      "Epoch: 770 | train_loss: 0.5244 | test_loss: 0.5047 | \n",
      "Epoch: 780 | train_loss: 0.4908 | test_loss: 0.4851 | \n",
      "Epoch: 790 | train_loss: 0.4593 | test_loss: 0.4649 | \n",
      "Epoch: 800 | train_loss: 0.4278 | test_loss: 0.4308 | \n",
      "Epoch: 810 | train_loss: 0.3933 | test_loss: 0.4063 | \n",
      "Epoch: 820 | train_loss: 0.3625 | test_loss: 0.3745 | \n",
      "Epoch: 830 | train_loss: 0.3319 | test_loss: 0.3531 | \n",
      "Epoch: 840 | train_loss: 0.3083 | test_loss: 0.3368 | \n",
      "Epoch: 850 | train_loss: 0.2712 | test_loss: 0.2897 | \n",
      "Epoch: 860 | train_loss: 0.2429 | test_loss: 0.2626 | \n",
      "Epoch: 870 | train_loss: 0.2144 | test_loss: 0.2395 | \n",
      "Epoch: 880 | train_loss: 0.1859 | test_loss: 0.2275 | \n",
      "Epoch: 890 | train_loss: 0.1569 | test_loss: 0.2041 | \n",
      "Epoch: 900 | train_loss: 0.1360 | test_loss: 0.1680 | \n",
      "Epoch: 910 | train_loss: 0.1066 | test_loss: 0.1604 | \n",
      "Epoch: 920 | train_loss: 0.0869 | test_loss: 0.1504 | \n",
      "Epoch: 930 | train_loss: 0.0680 | test_loss: 0.1398 | \n",
      "Epoch: 940 | train_loss: 0.0614 | test_loss: 0.1436 | \n",
      "Epoch: 950 | train_loss: 0.0515 | test_loss: 0.1460 | \n",
      "Epoch: 960 | train_loss: 0.0481 | test_loss: 0.1483 | \n",
      "Epoch: 970 | train_loss: 0.0453 | test_loss: 0.1384 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.9345 | test_loss: 10.0798 | \n",
      "Epoch: 10 | train_loss: 7.7988 | test_loss: 7.7146 | \n",
      "Epoch: 20 | train_loss: 6.9089 | test_loss: 6.8590 | \n",
      "Epoch: 30 | train_loss: 6.3322 | test_loss: 6.2915 | \n",
      "Epoch: 40 | train_loss: 5.9159 | test_loss: 5.8482 | \n",
      "Epoch: 50 | train_loss: 5.5792 | test_loss: 5.5460 | \n",
      "Epoch: 60 | train_loss: 5.3068 | test_loss: 5.2642 | \n",
      "Epoch: 70 | train_loss: 5.0841 | test_loss: 5.0453 | \n",
      "Epoch: 80 | train_loss: 4.8736 | test_loss: 4.8427 | \n",
      "Epoch: 90 | train_loss: 4.6896 | test_loss: 4.6591 | \n",
      "Epoch: 100 | train_loss: 4.5272 | test_loss: 4.4951 | \n",
      "Epoch: 110 | train_loss: 4.3755 | test_loss: 4.3503 | \n",
      "Epoch: 120 | train_loss: 4.2376 | test_loss: 4.2100 | \n",
      "Epoch: 130 | train_loss: 4.1088 | test_loss: 4.0768 | \n",
      "Epoch: 140 | train_loss: 3.9948 | test_loss: 3.9637 | \n",
      "Epoch: 150 | train_loss: 3.8774 | test_loss: 3.8528 | \n",
      "Epoch: 160 | train_loss: 3.7746 | test_loss: 3.7486 | \n",
      "Epoch: 170 | train_loss: 3.6726 | test_loss: 3.6483 | \n",
      "Epoch: 180 | train_loss: 3.5789 | test_loss: 3.5556 | \n",
      "Epoch: 190 | train_loss: 3.4866 | test_loss: 3.4623 | \n",
      "Epoch: 200 | train_loss: 3.3978 | test_loss: 3.3755 | \n",
      "Epoch: 210 | train_loss: 3.3141 | test_loss: 3.2936 | \n",
      "Epoch: 220 | train_loss: 3.2335 | test_loss: 3.2131 | \n",
      "Epoch: 230 | train_loss: 3.1513 | test_loss: 3.1323 | \n",
      "Epoch: 240 | train_loss: 3.0837 | test_loss: 3.0624 | \n",
      "Epoch: 250 | train_loss: 3.0128 | test_loss: 2.9876 | \n",
      "Epoch: 260 | train_loss: 2.9415 | test_loss: 2.9199 | \n",
      "Epoch: 270 | train_loss: 2.8707 | test_loss: 2.8526 | \n",
      "Epoch: 280 | train_loss: 2.8043 | test_loss: 2.7848 | \n",
      "Epoch: 290 | train_loss: 2.7423 | test_loss: 2.7187 | \n",
      "Epoch: 300 | train_loss: 2.6782 | test_loss: 2.6601 | \n",
      "Epoch: 310 | train_loss: 2.6202 | test_loss: 2.5995 | \n",
      "Epoch: 320 | train_loss: 2.5595 | test_loss: 2.5414 | \n",
      "Epoch: 330 | train_loss: 2.4970 | test_loss: 2.4757 | \n",
      "Epoch: 340 | train_loss: 2.4407 | test_loss: 2.4197 | \n",
      "Epoch: 350 | train_loss: 2.3866 | test_loss: 2.3599 | \n",
      "Epoch: 360 | train_loss: 2.3290 | test_loss: 2.3095 | \n",
      "Epoch: 370 | train_loss: 2.2718 | test_loss: 2.2562 | \n",
      "Epoch: 380 | train_loss: 2.2271 | test_loss: 2.2026 | \n",
      "Epoch: 390 | train_loss: 2.1729 | test_loss: 2.1518 | \n",
      "Epoch: 400 | train_loss: 2.1196 | test_loss: 2.1001 | \n",
      "Epoch: 410 | train_loss: 2.0677 | test_loss: 2.0497 | \n",
      "Epoch: 420 | train_loss: 2.0179 | test_loss: 2.0019 | \n",
      "Epoch: 430 | train_loss: 1.9699 | test_loss: 1.9533 | \n",
      "Epoch: 440 | train_loss: 1.9270 | test_loss: 1.9039 | \n",
      "Epoch: 450 | train_loss: 1.8771 | test_loss: 1.8507 | \n",
      "Epoch: 460 | train_loss: 1.8253 | test_loss: 1.8074 | \n",
      "Epoch: 470 | train_loss: 1.7777 | test_loss: 1.7660 | \n",
      "Epoch: 480 | train_loss: 1.7335 | test_loss: 1.7147 | \n",
      "Epoch: 490 | train_loss: 1.6903 | test_loss: 1.6716 | \n",
      "Epoch: 500 | train_loss: 1.6491 | test_loss: 1.6286 | \n",
      "Epoch: 510 | train_loss: 1.6031 | test_loss: 1.5802 | \n",
      "Epoch: 520 | train_loss: 1.5597 | test_loss: 1.5402 | \n",
      "Epoch: 530 | train_loss: 1.5171 | test_loss: 1.5030 | \n",
      "Epoch: 540 | train_loss: 1.4722 | test_loss: 1.4613 | \n",
      "Epoch: 550 | train_loss: 1.4328 | test_loss: 1.4136 | \n",
      "Epoch: 560 | train_loss: 1.3908 | test_loss: 1.3722 | \n",
      "Epoch: 570 | train_loss: 1.3487 | test_loss: 1.3306 | \n",
      "Epoch: 580 | train_loss: 1.3041 | test_loss: 1.2984 | \n",
      "Epoch: 590 | train_loss: 1.2651 | test_loss: 1.2445 | \n",
      "Epoch: 600 | train_loss: 1.2294 | test_loss: 1.2173 | \n",
      "Epoch: 610 | train_loss: 1.1888 | test_loss: 1.1737 | \n",
      "Epoch: 620 | train_loss: 1.1506 | test_loss: 1.1382 | \n",
      "Epoch: 630 | train_loss: 1.1103 | test_loss: 1.0961 | \n",
      "Epoch: 640 | train_loss: 1.0716 | test_loss: 1.0616 | \n",
      "Epoch: 650 | train_loss: 1.0348 | test_loss: 1.0194 | \n",
      "Epoch: 660 | train_loss: 0.9907 | test_loss: 0.9792 | \n",
      "Epoch: 670 | train_loss: 0.9600 | test_loss: 0.9454 | \n",
      "Epoch: 680 | train_loss: 0.9253 | test_loss: 0.9057 | \n",
      "Epoch: 690 | train_loss: 0.8831 | test_loss: 0.8721 | \n",
      "Epoch: 700 | train_loss: 0.8473 | test_loss: 0.8366 | \n",
      "Epoch: 710 | train_loss: 0.8167 | test_loss: 0.8029 | \n",
      "Epoch: 720 | train_loss: 0.7796 | test_loss: 0.7821 | \n",
      "Epoch: 730 | train_loss: 0.7430 | test_loss: 0.7301 | \n",
      "Epoch: 740 | train_loss: 0.7075 | test_loss: 0.6932 | \n",
      "Epoch: 750 | train_loss: 0.6777 | test_loss: 0.6633 | \n",
      "Epoch: 760 | train_loss: 0.6409 | test_loss: 0.6264 | \n",
      "Epoch: 770 | train_loss: 0.6071 | test_loss: 0.5958 | \n",
      "Epoch: 780 | train_loss: 0.5752 | test_loss: 0.5644 | \n",
      "Epoch: 790 | train_loss: 0.5395 | test_loss: 0.5224 | \n",
      "Epoch: 800 | train_loss: 0.5070 | test_loss: 0.4996 | \n",
      "Epoch: 810 | train_loss: 0.4829 | test_loss: 0.4675 | \n",
      "Epoch: 820 | train_loss: 0.4497 | test_loss: 0.4401 | \n",
      "Epoch: 830 | train_loss: 0.4191 | test_loss: 0.4094 | \n",
      "Epoch: 840 | train_loss: 0.3920 | test_loss: 0.3827 | \n",
      "Epoch: 850 | train_loss: 0.3590 | test_loss: 0.3499 | \n",
      "Epoch: 860 | train_loss: 0.3291 | test_loss: 0.3204 | \n",
      "Epoch: 870 | train_loss: 0.3019 | test_loss: 0.2939 | \n",
      "Epoch: 880 | train_loss: 0.2760 | test_loss: 0.2790 | \n",
      "Epoch: 890 | train_loss: 0.2542 | test_loss: 0.2466 | \n",
      "Epoch: 900 | train_loss: 0.2263 | test_loss: 0.2268 | \n",
      "Epoch: 910 | train_loss: 0.2115 | test_loss: 0.2132 | \n",
      "Epoch: 920 | train_loss: 0.1887 | test_loss: 0.1936 | \n",
      "Epoch: 930 | train_loss: 0.1689 | test_loss: 0.1763 | \n",
      "Epoch: 940 | train_loss: 0.1633 | test_loss: 0.1550 | \n",
      "Epoch: 950 | train_loss: 0.1436 | test_loss: 0.1531 | \n",
      "Epoch: 960 | train_loss: 0.1306 | test_loss: 0.1544 | \n",
      "Epoch: 970 | train_loss: 0.1304 | test_loss: 0.1508 | \n",
      "Epoch: 980 | train_loss: 0.1177 | test_loss: 0.1428 | \n",
      "Epoch: 990 | train_loss: 0.1216 | test_loss: 0.1417 | \n",
      "Epoch: 1000 | train_loss: 0.1172 | test_loss: 0.1426 | \n",
      "Epoch: 1010 | train_loss: 0.1135 | test_loss: 0.1363 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8738 | test_loss: 9.6914 | \n",
      "Epoch: 10 | train_loss: 7.7454 | test_loss: 7.6572 | \n",
      "Epoch: 20 | train_loss: 6.8551 | test_loss: 6.7946 | \n",
      "Epoch: 30 | train_loss: 6.2829 | test_loss: 6.2279 | \n",
      "Epoch: 40 | train_loss: 5.8503 | test_loss: 5.8104 | \n",
      "Epoch: 50 | train_loss: 5.5297 | test_loss: 5.4875 | \n",
      "Epoch: 60 | train_loss: 5.2523 | test_loss: 5.2192 | \n",
      "Epoch: 70 | train_loss: 5.0175 | test_loss: 4.9890 | \n",
      "Epoch: 80 | train_loss: 4.8169 | test_loss: 4.7871 | \n",
      "Epoch: 90 | train_loss: 4.6377 | test_loss: 4.6023 | \n",
      "Epoch: 100 | train_loss: 4.4706 | test_loss: 4.4483 | \n",
      "Epoch: 110 | train_loss: 4.3261 | test_loss: 4.3034 | \n",
      "Epoch: 120 | train_loss: 4.1872 | test_loss: 4.1644 | \n",
      "Epoch: 130 | train_loss: 4.0605 | test_loss: 4.0393 | \n",
      "Epoch: 140 | train_loss: 3.9384 | test_loss: 3.9140 | \n",
      "Epoch: 150 | train_loss: 3.8254 | test_loss: 3.8036 | \n",
      "Epoch: 160 | train_loss: 3.7155 | test_loss: 3.6995 | \n",
      "Epoch: 170 | train_loss: 3.6153 | test_loss: 3.5929 | \n",
      "Epoch: 180 | train_loss: 3.5241 | test_loss: 3.5062 | \n",
      "Epoch: 190 | train_loss: 3.4333 | test_loss: 3.4147 | \n",
      "Epoch: 200 | train_loss: 3.3476 | test_loss: 3.3263 | \n",
      "Epoch: 210 | train_loss: 3.2603 | test_loss: 3.2403 | \n",
      "Epoch: 220 | train_loss: 3.1764 | test_loss: 3.1665 | \n",
      "Epoch: 230 | train_loss: 3.1051 | test_loss: 3.0846 | \n",
      "Epoch: 240 | train_loss: 3.0311 | test_loss: 3.0126 | \n",
      "Epoch: 250 | train_loss: 2.9572 | test_loss: 2.9403 | \n",
      "Epoch: 260 | train_loss: 2.8881 | test_loss: 2.8739 | \n",
      "Epoch: 270 | train_loss: 2.8191 | test_loss: 2.8044 | \n",
      "Epoch: 280 | train_loss: 2.7528 | test_loss: 2.7364 | \n",
      "Epoch: 290 | train_loss: 2.6847 | test_loss: 2.6717 | \n",
      "Epoch: 300 | train_loss: 2.6262 | test_loss: 2.6091 | \n",
      "Epoch: 310 | train_loss: 2.5685 | test_loss: 2.5580 | \n",
      "Epoch: 320 | train_loss: 2.5076 | test_loss: 2.4897 | \n",
      "Epoch: 330 | train_loss: 2.4541 | test_loss: 2.4277 | \n",
      "Epoch: 340 | train_loss: 2.3917 | test_loss: 2.3727 | \n",
      "Epoch: 350 | train_loss: 2.3378 | test_loss: 2.3203 | \n",
      "Epoch: 360 | train_loss: 2.2779 | test_loss: 2.2628 | \n",
      "Epoch: 370 | train_loss: 2.2278 | test_loss: 2.2043 | \n",
      "Epoch: 380 | train_loss: 2.1758 | test_loss: 2.1634 | \n",
      "Epoch: 390 | train_loss: 2.1184 | test_loss: 2.1056 | \n",
      "Epoch: 400 | train_loss: 2.0726 | test_loss: 2.0485 | \n",
      "Epoch: 410 | train_loss: 2.0143 | test_loss: 2.0047 | \n",
      "Epoch: 420 | train_loss: 1.9723 | test_loss: 1.9561 | \n",
      "Epoch: 430 | train_loss: 1.9277 | test_loss: 1.9077 | \n",
      "Epoch: 440 | train_loss: 1.8712 | test_loss: 1.8579 | \n",
      "Epoch: 450 | train_loss: 1.8264 | test_loss: 1.8097 | \n",
      "Epoch: 460 | train_loss: 1.7866 | test_loss: 1.7624 | \n",
      "Epoch: 470 | train_loss: 1.7315 | test_loss: 1.7164 | \n",
      "Epoch: 480 | train_loss: 1.6900 | test_loss: 1.6662 | \n",
      "Epoch: 490 | train_loss: 1.6387 | test_loss: 1.6234 | \n",
      "Epoch: 500 | train_loss: 1.6022 | test_loss: 1.5819 | \n",
      "Epoch: 510 | train_loss: 1.5542 | test_loss: 1.5375 | \n",
      "Epoch: 520 | train_loss: 1.5099 | test_loss: 1.4904 | \n",
      "Epoch: 530 | train_loss: 1.4697 | test_loss: 1.4529 | \n",
      "Epoch: 540 | train_loss: 1.4217 | test_loss: 1.4052 | \n",
      "Epoch: 550 | train_loss: 1.3868 | test_loss: 1.3680 | \n",
      "Epoch: 560 | train_loss: 1.3407 | test_loss: 1.3268 | \n",
      "Epoch: 570 | train_loss: 1.3007 | test_loss: 1.2825 | \n",
      "Epoch: 580 | train_loss: 1.2563 | test_loss: 1.2463 | \n",
      "Epoch: 590 | train_loss: 1.2179 | test_loss: 1.2098 | \n",
      "Epoch: 600 | train_loss: 1.1820 | test_loss: 1.1714 | \n",
      "Epoch: 610 | train_loss: 1.1413 | test_loss: 1.1306 | \n",
      "Epoch: 620 | train_loss: 1.0960 | test_loss: 1.0904 | \n",
      "Epoch: 630 | train_loss: 1.0667 | test_loss: 1.0498 | \n",
      "Epoch: 640 | train_loss: 1.0283 | test_loss: 1.0157 | \n",
      "Epoch: 650 | train_loss: 0.9922 | test_loss: 0.9717 | \n",
      "Epoch: 660 | train_loss: 0.9507 | test_loss: 0.9414 | \n",
      "Epoch: 670 | train_loss: 0.9126 | test_loss: 0.8956 | \n",
      "Epoch: 680 | train_loss: 0.8749 | test_loss: 0.8677 | \n",
      "Epoch: 690 | train_loss: 0.8438 | test_loss: 0.8232 | \n",
      "Epoch: 700 | train_loss: 0.8086 | test_loss: 0.7959 | \n",
      "Epoch: 710 | train_loss: 0.7716 | test_loss: 0.7639 | \n",
      "Epoch: 720 | train_loss: 0.7340 | test_loss: 0.7216 | \n",
      "Epoch: 730 | train_loss: 0.7032 | test_loss: 0.6841 | \n",
      "Epoch: 740 | train_loss: 0.6671 | test_loss: 0.6529 | \n",
      "Epoch: 750 | train_loss: 0.6309 | test_loss: 0.6229 | \n",
      "Epoch: 760 | train_loss: 0.5991 | test_loss: 0.5907 | \n",
      "Epoch: 770 | train_loss: 0.5623 | test_loss: 0.5623 | \n",
      "Epoch: 780 | train_loss: 0.5354 | test_loss: 0.5254 | \n",
      "Epoch: 790 | train_loss: 0.5012 | test_loss: 0.4899 | \n",
      "Epoch: 800 | train_loss: 0.4700 | test_loss: 0.4582 | \n",
      "Epoch: 810 | train_loss: 0.4480 | test_loss: 0.4362 | \n",
      "Epoch: 820 | train_loss: 0.4124 | test_loss: 0.4060 | \n",
      "Epoch: 830 | train_loss: 0.3811 | test_loss: 0.3794 | \n",
      "Epoch: 840 | train_loss: 0.3586 | test_loss: 0.3498 | \n",
      "Epoch: 850 | train_loss: 0.3251 | test_loss: 0.3231 | \n",
      "Epoch: 860 | train_loss: 0.2949 | test_loss: 0.3016 | \n",
      "Epoch: 870 | train_loss: 0.2707 | test_loss: 0.2759 | \n",
      "Epoch: 880 | train_loss: 0.2514 | test_loss: 0.2560 | \n",
      "Epoch: 890 | train_loss: 0.2246 | test_loss: 0.2350 | \n",
      "Epoch: 900 | train_loss: 0.2014 | test_loss: 0.2120 | \n",
      "Epoch: 910 | train_loss: 0.1822 | test_loss: 0.1878 | \n",
      "Epoch: 920 | train_loss: 0.1655 | test_loss: 0.1867 | \n",
      "Epoch: 930 | train_loss: 0.1507 | test_loss: 0.1705 | \n",
      "Epoch: 940 | train_loss: 0.1379 | test_loss: 0.1657 | \n",
      "Epoch: 950 | train_loss: 0.1301 | test_loss: 0.1553 | \n",
      "Epoch: 960 | train_loss: 0.1236 | test_loss: 0.1483 | \n",
      "Epoch: 970 | train_loss: 0.1243 | test_loss: 0.1429 | \n",
      "Epoch: 980 | train_loss: 0.1094 | test_loss: 0.1440 | \n",
      "Epoch: 990 | train_loss: 0.1126 | test_loss: 0.1403 | \n",
      "Epoch: 1000 | train_loss: 0.1086 | test_loss: 0.1394 | \n",
      "Epoch: 1010 | train_loss: 0.1114 | test_loss: 0.1395 | \n",
      "Epoch: 1020 | train_loss: 0.1106 | test_loss: 0.1408 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 6.1197 | test_loss: 2.6301 | \n",
      "Epoch: 10 | train_loss: 0.1627 | test_loss: 0.1574 | \n",
      "Epoch: 20 | train_loss: 0.1441 | test_loss: 0.1507 | \n",
      "Epoch: 30 | train_loss: 0.1345 | test_loss: 0.1465 | \n",
      "Epoch: 40 | train_loss: 0.1275 | test_loss: 0.1444 | \n",
      "Epoch: 50 | train_loss: 0.1218 | test_loss: 0.1410 | \n",
      "Epoch: 60 | train_loss: 0.1133 | test_loss: 0.1384 | \n",
      "Epoch: 70 | train_loss: 0.1066 | test_loss: 0.1382 | \n",
      "Epoch: 80 | train_loss: 0.1014 | test_loss: 0.1361 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.3625 | test_loss: 0.2995 | \n",
      "Epoch: 10 | train_loss: 0.1401 | test_loss: 0.1438 | \n",
      "Epoch: 20 | train_loss: 0.1220 | test_loss: 0.1362 | \n",
      "Epoch: 30 | train_loss: 0.1096 | test_loss: 0.1390 | \n",
      "Epoch: 40 | train_loss: 0.0988 | test_loss: 0.1389 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 2.0885 | test_loss: 0.5959 | \n",
      "Epoch: 10 | train_loss: 0.1375 | test_loss: 0.1527 | \n",
      "Epoch: 20 | train_loss: 0.1104 | test_loss: 0.1522 | \n",
      "Epoch: 30 | train_loss: 0.0924 | test_loss: 0.1526 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6195 | test_loss: 8.6166 | \n",
      "Epoch: 10 | train_loss: 5.9134 | test_loss: 5.8723 | \n",
      "Epoch: 20 | train_loss: 4.8548 | test_loss: 4.7875 | \n",
      "Epoch: 30 | train_loss: 4.2115 | test_loss: 4.1881 | \n",
      "Epoch: 40 | train_loss: 3.7455 | test_loss: 3.7015 | \n",
      "Epoch: 50 | train_loss: 3.3716 | test_loss: 3.3452 | \n",
      "Epoch: 60 | train_loss: 3.0542 | test_loss: 3.0461 | \n",
      "Epoch: 70 | train_loss: 2.7759 | test_loss: 2.7607 | \n",
      "Epoch: 80 | train_loss: 2.5280 | test_loss: 2.5031 | \n",
      "Epoch: 90 | train_loss: 2.3029 | test_loss: 2.2849 | \n",
      "Epoch: 100 | train_loss: 2.0929 | test_loss: 2.0791 | \n",
      "Epoch: 110 | train_loss: 1.8947 | test_loss: 1.8896 | \n",
      "Epoch: 120 | train_loss: 1.7159 | test_loss: 1.6911 | \n",
      "Epoch: 130 | train_loss: 1.5353 | test_loss: 1.5199 | \n",
      "Epoch: 140 | train_loss: 1.3644 | test_loss: 1.3548 | \n",
      "Epoch: 150 | train_loss: 1.2063 | test_loss: 1.1816 | \n",
      "Epoch: 160 | train_loss: 1.0496 | test_loss: 1.0354 | \n",
      "Epoch: 170 | train_loss: 0.9024 | test_loss: 0.8847 | \n",
      "Epoch: 180 | train_loss: 0.7605 | test_loss: 0.7531 | \n",
      "Epoch: 190 | train_loss: 0.6196 | test_loss: 0.6099 | \n",
      "Epoch: 200 | train_loss: 0.4864 | test_loss: 0.4925 | \n",
      "Epoch: 210 | train_loss: 0.3602 | test_loss: 0.3667 | \n",
      "Epoch: 220 | train_loss: 0.2559 | test_loss: 0.2665 | \n",
      "Epoch: 230 | train_loss: 0.1565 | test_loss: 0.1957 | \n",
      "Epoch: 240 | train_loss: 0.1111 | test_loss: 0.1450 | \n",
      "Epoch: 250 | train_loss: 0.1050 | test_loss: 0.1580 | \n",
      "Epoch: 260 | train_loss: 0.0947 | test_loss: 0.1449 | \n",
      "Epoch: 270 | train_loss: 0.0806 | test_loss: 0.1434 | \n",
      "Epoch: 280 | train_loss: 0.0706 | test_loss: 0.1493 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6083 | test_loss: 8.6441 | \n",
      "Epoch: 10 | train_loss: 5.8995 | test_loss: 5.8561 | \n",
      "Epoch: 20 | train_loss: 4.8366 | test_loss: 4.7875 | \n",
      "Epoch: 30 | train_loss: 4.1960 | test_loss: 4.1419 | \n",
      "Epoch: 40 | train_loss: 3.7281 | test_loss: 3.6833 | \n",
      "Epoch: 50 | train_loss: 3.3553 | test_loss: 3.3092 | \n",
      "Epoch: 60 | train_loss: 3.0389 | test_loss: 3.0009 | \n",
      "Epoch: 70 | train_loss: 2.7575 | test_loss: 2.7255 | \n",
      "Epoch: 80 | train_loss: 2.5097 | test_loss: 2.5236 | \n",
      "Epoch: 90 | train_loss: 2.2818 | test_loss: 2.2690 | \n",
      "Epoch: 100 | train_loss: 2.0751 | test_loss: 2.0583 | \n",
      "Epoch: 110 | train_loss: 1.8717 | test_loss: 1.8686 | \n",
      "Epoch: 120 | train_loss: 1.6868 | test_loss: 1.6466 | \n",
      "Epoch: 130 | train_loss: 1.5078 | test_loss: 1.4913 | \n",
      "Epoch: 140 | train_loss: 1.3385 | test_loss: 1.3362 | \n",
      "Epoch: 150 | train_loss: 1.1849 | test_loss: 1.1875 | \n",
      "Epoch: 160 | train_loss: 1.0273 | test_loss: 1.0224 | \n",
      "Epoch: 170 | train_loss: 0.8775 | test_loss: 0.8672 | \n",
      "Epoch: 180 | train_loss: 0.7349 | test_loss: 0.7432 | \n",
      "Epoch: 190 | train_loss: 0.5979 | test_loss: 0.6175 | \n",
      "Epoch: 200 | train_loss: 0.4661 | test_loss: 0.4768 | \n",
      "Epoch: 210 | train_loss: 0.3408 | test_loss: 0.3658 | \n",
      "Epoch: 220 | train_loss: 0.2324 | test_loss: 0.2599 | \n",
      "Epoch: 230 | train_loss: 0.1594 | test_loss: 0.2089 | \n",
      "Epoch: 240 | train_loss: 0.1006 | test_loss: 0.1581 | \n",
      "Epoch: 250 | train_loss: 0.0917 | test_loss: 0.1438 | \n",
      "Epoch: 260 | train_loss: 0.0818 | test_loss: 0.1550 | \n",
      "Epoch: 270 | train_loss: 0.0797 | test_loss: 0.1440 | \n",
      "Epoch: 280 | train_loss: 0.0759 | test_loss: 0.1448 | \n",
      "Epoch: 290 | train_loss: 0.0885 | test_loss: 0.1412 | \n",
      "Epoch: 300 | train_loss: 0.0798 | test_loss: 0.1456 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.7029 | test_loss: 8.6248 | \n",
      "Epoch: 10 | train_loss: 5.9690 | test_loss: 5.8580 | \n",
      "Epoch: 20 | train_loss: 4.8984 | test_loss: 4.8494 | \n",
      "Epoch: 30 | train_loss: 4.2657 | test_loss: 4.2242 | \n",
      "Epoch: 40 | train_loss: 3.7918 | test_loss: 3.7657 | \n",
      "Epoch: 50 | train_loss: 3.4177 | test_loss: 3.3770 | \n",
      "Epoch: 60 | train_loss: 3.0987 | test_loss: 3.0611 | \n",
      "Epoch: 70 | train_loss: 2.8225 | test_loss: 2.8055 | \n",
      "Epoch: 80 | train_loss: 2.5715 | test_loss: 2.5429 | \n",
      "Epoch: 90 | train_loss: 2.3458 | test_loss: 2.3156 | \n",
      "Epoch: 100 | train_loss: 2.1300 | test_loss: 2.1087 | \n",
      "Epoch: 110 | train_loss: 1.9378 | test_loss: 1.9022 | \n",
      "Epoch: 120 | train_loss: 1.7511 | test_loss: 1.7261 | \n",
      "Epoch: 130 | train_loss: 1.5680 | test_loss: 1.5469 | \n",
      "Epoch: 140 | train_loss: 1.3978 | test_loss: 1.3934 | \n",
      "Epoch: 150 | train_loss: 1.2414 | test_loss: 1.2256 | \n",
      "Epoch: 160 | train_loss: 1.0882 | test_loss: 1.0650 | \n",
      "Epoch: 170 | train_loss: 0.9371 | test_loss: 0.9169 | \n",
      "Epoch: 180 | train_loss: 0.7940 | test_loss: 0.7737 | \n",
      "Epoch: 190 | train_loss: 0.6581 | test_loss: 0.6478 | \n",
      "Epoch: 200 | train_loss: 0.5420 | test_loss: 0.5283 | \n",
      "Epoch: 210 | train_loss: 0.4204 | test_loss: 0.4030 | \n",
      "Epoch: 220 | train_loss: 0.3095 | test_loss: 0.2930 | \n",
      "Epoch: 230 | train_loss: 0.2351 | test_loss: 0.2123 | \n",
      "Epoch: 240 | train_loss: 0.1930 | test_loss: 0.1769 | \n",
      "Epoch: 250 | train_loss: 0.1614 | test_loss: 0.1568 | \n",
      "Epoch: 260 | train_loss: 0.1565 | test_loss: 0.1446 | \n",
      "Epoch: 270 | train_loss: 0.1544 | test_loss: 0.1358 | \n",
      "Epoch: 280 | train_loss: 0.1528 | test_loss: 0.1385 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.7199 | test_loss: 8.6416 | \n",
      "Epoch: 10 | train_loss: 5.9641 | test_loss: 5.8677 | \n",
      "Epoch: 20 | train_loss: 4.8963 | test_loss: 4.8415 | \n",
      "Epoch: 30 | train_loss: 4.2559 | test_loss: 4.2009 | \n",
      "Epoch: 40 | train_loss: 3.7872 | test_loss: 3.7424 | \n",
      "Epoch: 50 | train_loss: 3.4086 | test_loss: 3.3704 | \n",
      "Epoch: 60 | train_loss: 3.0889 | test_loss: 3.0567 | \n",
      "Epoch: 70 | train_loss: 2.8124 | test_loss: 2.7890 | \n",
      "Epoch: 80 | train_loss: 2.5647 | test_loss: 2.5369 | \n",
      "Epoch: 90 | train_loss: 2.3341 | test_loss: 2.2971 | \n",
      "Epoch: 100 | train_loss: 2.1217 | test_loss: 2.1004 | \n",
      "Epoch: 110 | train_loss: 1.9258 | test_loss: 1.9002 | \n",
      "Epoch: 120 | train_loss: 1.7416 | test_loss: 1.7224 | \n",
      "Epoch: 130 | train_loss: 1.5640 | test_loss: 1.5469 | \n",
      "Epoch: 140 | train_loss: 1.3989 | test_loss: 1.3756 | \n",
      "Epoch: 150 | train_loss: 1.2364 | test_loss: 1.2109 | \n",
      "Epoch: 160 | train_loss: 1.0754 | test_loss: 1.0604 | \n",
      "Epoch: 170 | train_loss: 0.9305 | test_loss: 0.9180 | \n",
      "Epoch: 180 | train_loss: 0.7871 | test_loss: 0.7702 | \n",
      "Epoch: 190 | train_loss: 0.6613 | test_loss: 0.6439 | \n",
      "Epoch: 200 | train_loss: 0.5281 | test_loss: 0.5134 | \n",
      "Epoch: 210 | train_loss: 0.4104 | test_loss: 0.3878 | \n",
      "Epoch: 220 | train_loss: 0.3073 | test_loss: 0.2973 | \n",
      "Epoch: 230 | train_loss: 0.2244 | test_loss: 0.2131 | \n",
      "Epoch: 240 | train_loss: 0.1916 | test_loss: 0.1794 | \n",
      "Epoch: 250 | train_loss: 0.1686 | test_loss: 0.1539 | \n",
      "Epoch: 260 | train_loss: 0.1618 | test_loss: 0.1435 | \n",
      "Epoch: 270 | train_loss: 0.1475 | test_loss: 0.1415 | \n",
      "Epoch: 280 | train_loss: 0.1520 | test_loss: 0.1368 | \n",
      "Epoch: 290 | train_loss: 0.1437 | test_loss: 0.1400 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.2830 | test_loss: 4.6864 | \n",
      "Epoch: 10 | train_loss: 0.1867 | test_loss: 0.1724 | \n",
      "Epoch: 20 | train_loss: 0.1583 | test_loss: 0.1550 | \n",
      "Epoch: 30 | train_loss: 0.1479 | test_loss: 0.1503 | \n",
      "Epoch: 40 | train_loss: 0.1390 | test_loss: 0.1478 | \n",
      "Epoch: 50 | train_loss: 0.1327 | test_loss: 0.1446 | \n",
      "Epoch: 60 | train_loss: 0.1280 | test_loss: 0.1448 | \n",
      "Epoch: 70 | train_loss: 0.1261 | test_loss: 0.1414 | \n",
      "Epoch: 80 | train_loss: 0.1194 | test_loss: 0.1402 | \n",
      "Epoch: 90 | train_loss: 0.1152 | test_loss: 0.1381 | \n",
      "Epoch: 100 | train_loss: 0.1113 | test_loss: 0.1391 | \n",
      "Epoch: 110 | train_loss: 0.1078 | test_loss: 0.1391 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.7623 | test_loss: 1.9122 | \n",
      "Epoch: 10 | train_loss: 0.1585 | test_loss: 0.1537 | \n",
      "Epoch: 20 | train_loss: 0.1367 | test_loss: 0.1479 | \n",
      "Epoch: 30 | train_loss: 0.1226 | test_loss: 0.1389 | \n",
      "Epoch: 40 | train_loss: 0.1114 | test_loss: 0.1375 | \n",
      "Epoch: 50 | train_loss: 0.1015 | test_loss: 0.1407 | \n",
      "Epoch: 60 | train_loss: 0.0978 | test_loss: 0.1421 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.1624 | test_loss: 1.6119 | \n",
      "Epoch: 10 | train_loss: 0.1359 | test_loss: 0.1525 | \n",
      "Epoch: 20 | train_loss: 0.1130 | test_loss: 0.1459 | \n",
      "Epoch: 30 | train_loss: 0.1082 | test_loss: 0.1501 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2802 | test_loss: 9.1401 | \n",
      "Epoch: 10 | train_loss: 6.8829 | test_loss: 6.8157 | \n",
      "Epoch: 20 | train_loss: 5.8768 | test_loss: 5.8018 | \n",
      "Epoch: 30 | train_loss: 5.2707 | test_loss: 5.2080 | \n",
      "Epoch: 40 | train_loss: 4.8285 | test_loss: 4.8154 | \n",
      "Epoch: 50 | train_loss: 4.4801 | test_loss: 4.4651 | \n",
      "Epoch: 60 | train_loss: 4.1929 | test_loss: 4.1670 | \n",
      "Epoch: 70 | train_loss: 3.9491 | test_loss: 3.9390 | \n",
      "Epoch: 80 | train_loss: 3.7293 | test_loss: 3.6982 | \n",
      "Epoch: 90 | train_loss: 3.5355 | test_loss: 3.5014 | \n",
      "Epoch: 100 | train_loss: 3.3582 | test_loss: 3.3344 | \n",
      "Epoch: 110 | train_loss: 3.1932 | test_loss: 3.1913 | \n",
      "Epoch: 120 | train_loss: 3.0466 | test_loss: 3.0264 | \n",
      "Epoch: 130 | train_loss: 2.9013 | test_loss: 2.8904 | \n",
      "Epoch: 140 | train_loss: 2.7672 | test_loss: 2.7553 | \n",
      "Epoch: 150 | train_loss: 2.6397 | test_loss: 2.6347 | \n",
      "Epoch: 160 | train_loss: 2.5186 | test_loss: 2.5035 | \n",
      "Epoch: 170 | train_loss: 2.4029 | test_loss: 2.4003 | \n",
      "Epoch: 180 | train_loss: 2.2915 | test_loss: 2.2755 | \n",
      "Epoch: 190 | train_loss: 2.1841 | test_loss: 2.1605 | \n",
      "Epoch: 200 | train_loss: 2.0802 | test_loss: 2.0704 | \n",
      "Epoch: 210 | train_loss: 1.9955 | test_loss: 2.0053 | \n",
      "Epoch: 220 | train_loss: 1.8861 | test_loss: 1.8828 | \n",
      "Epoch: 230 | train_loss: 1.7935 | test_loss: 1.7782 | \n",
      "Epoch: 240 | train_loss: 1.6978 | test_loss: 1.6822 | \n",
      "Epoch: 250 | train_loss: 1.6078 | test_loss: 1.5975 | \n",
      "Epoch: 260 | train_loss: 1.5220 | test_loss: 1.5119 | \n",
      "Epoch: 270 | train_loss: 1.4365 | test_loss: 1.4297 | \n",
      "Epoch: 280 | train_loss: 1.3512 | test_loss: 1.3374 | \n",
      "Epoch: 290 | train_loss: 1.2709 | test_loss: 1.2603 | \n",
      "Epoch: 300 | train_loss: 1.1914 | test_loss: 1.1883 | \n",
      "Epoch: 310 | train_loss: 1.1109 | test_loss: 1.1038 | \n",
      "Epoch: 320 | train_loss: 1.0346 | test_loss: 1.0334 | \n",
      "Epoch: 330 | train_loss: 0.9603 | test_loss: 0.9502 | \n",
      "Epoch: 340 | train_loss: 0.8843 | test_loss: 0.8932 | \n",
      "Epoch: 350 | train_loss: 0.8116 | test_loss: 0.7913 | \n",
      "Epoch: 360 | train_loss: 0.7395 | test_loss: 0.7355 | \n",
      "Epoch: 370 | train_loss: 0.6682 | test_loss: 0.6618 | \n",
      "Epoch: 380 | train_loss: 0.5999 | test_loss: 0.5963 | \n",
      "Epoch: 390 | train_loss: 0.5326 | test_loss: 0.5303 | \n",
      "Epoch: 400 | train_loss: 0.4657 | test_loss: 0.4707 | \n",
      "Epoch: 410 | train_loss: 0.4023 | test_loss: 0.4235 | \n",
      "Epoch: 420 | train_loss: 0.3424 | test_loss: 0.3621 | \n",
      "Epoch: 430 | train_loss: 0.2796 | test_loss: 0.3159 | \n",
      "Epoch: 440 | train_loss: 0.2241 | test_loss: 0.2575 | \n",
      "Epoch: 450 | train_loss: 0.1695 | test_loss: 0.2135 | \n",
      "Epoch: 460 | train_loss: 0.1360 | test_loss: 0.1985 | \n",
      "Epoch: 470 | train_loss: 0.0937 | test_loss: 0.1566 | \n",
      "Epoch: 480 | train_loss: 0.0761 | test_loss: 0.1457 | \n",
      "Epoch: 490 | train_loss: 0.0604 | test_loss: 0.1453 | \n",
      "Epoch: 500 | train_loss: 0.0665 | test_loss: 0.1387 | \n",
      "Epoch: 510 | train_loss: 0.0581 | test_loss: 0.1406 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2566 | test_loss: 9.3091 | \n",
      "Epoch: 10 | train_loss: 6.8829 | test_loss: 6.8062 | \n",
      "Epoch: 20 | train_loss: 5.8709 | test_loss: 5.7927 | \n",
      "Epoch: 30 | train_loss: 5.2651 | test_loss: 5.2280 | \n",
      "Epoch: 40 | train_loss: 4.8297 | test_loss: 4.8146 | \n",
      "Epoch: 50 | train_loss: 4.4826 | test_loss: 4.4541 | \n",
      "Epoch: 60 | train_loss: 4.1959 | test_loss: 4.1881 | \n",
      "Epoch: 70 | train_loss: 3.9489 | test_loss: 3.9192 | \n",
      "Epoch: 80 | train_loss: 3.7300 | test_loss: 3.7201 | \n",
      "Epoch: 90 | train_loss: 3.5346 | test_loss: 3.5152 | \n",
      "Epoch: 100 | train_loss: 3.3565 | test_loss: 3.3433 | \n",
      "Epoch: 110 | train_loss: 3.1943 | test_loss: 3.1668 | \n",
      "Epoch: 120 | train_loss: 3.0418 | test_loss: 3.0248 | \n",
      "Epoch: 130 | train_loss: 2.9009 | test_loss: 2.8996 | \n",
      "Epoch: 140 | train_loss: 2.7652 | test_loss: 2.7636 | \n",
      "Epoch: 150 | train_loss: 2.6370 | test_loss: 2.6245 | \n",
      "Epoch: 160 | train_loss: 2.5167 | test_loss: 2.4941 | \n",
      "Epoch: 170 | train_loss: 2.4024 | test_loss: 2.3905 | \n",
      "Epoch: 180 | train_loss: 2.2901 | test_loss: 2.2958 | \n",
      "Epoch: 190 | train_loss: 2.1801 | test_loss: 2.1360 | \n",
      "Epoch: 200 | train_loss: 2.0790 | test_loss: 2.0420 | \n",
      "Epoch: 210 | train_loss: 1.9781 | test_loss: 1.9603 | \n",
      "Epoch: 220 | train_loss: 1.8820 | test_loss: 1.8552 | \n",
      "Epoch: 230 | train_loss: 1.7867 | test_loss: 1.7478 | \n",
      "Epoch: 240 | train_loss: 1.6958 | test_loss: 1.6754 | \n",
      "Epoch: 250 | train_loss: 1.6053 | test_loss: 1.5970 | \n",
      "Epoch: 260 | train_loss: 1.5172 | test_loss: 1.5084 | \n",
      "Epoch: 270 | train_loss: 1.4324 | test_loss: 1.4126 | \n",
      "Epoch: 280 | train_loss: 1.3477 | test_loss: 1.3277 | \n",
      "Epoch: 290 | train_loss: 1.2664 | test_loss: 1.2462 | \n",
      "Epoch: 300 | train_loss: 1.1877 | test_loss: 1.1802 | \n",
      "Epoch: 310 | train_loss: 1.1074 | test_loss: 1.0688 | \n",
      "Epoch: 320 | train_loss: 1.0320 | test_loss: 1.0110 | \n",
      "Epoch: 330 | train_loss: 0.9546 | test_loss: 0.9521 | \n",
      "Epoch: 340 | train_loss: 0.8862 | test_loss: 0.8635 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2769 | test_loss: 9.1100 | \n",
      "Epoch: 10 | train_loss: 6.8663 | test_loss: 6.7753 | \n",
      "Epoch: 20 | train_loss: 5.8600 | test_loss: 5.7909 | \n",
      "Epoch: 30 | train_loss: 5.2490 | test_loss: 5.1994 | \n",
      "Epoch: 40 | train_loss: 4.8126 | test_loss: 4.7621 | \n",
      "Epoch: 50 | train_loss: 4.4635 | test_loss: 4.4259 | \n",
      "Epoch: 60 | train_loss: 4.1781 | test_loss: 4.1459 | \n",
      "Epoch: 70 | train_loss: 3.9343 | test_loss: 3.8961 | \n",
      "Epoch: 80 | train_loss: 3.7143 | test_loss: 3.6863 | \n",
      "Epoch: 90 | train_loss: 3.5203 | test_loss: 3.4921 | \n",
      "Epoch: 100 | train_loss: 3.3317 | test_loss: 3.3114 | \n",
      "Epoch: 110 | train_loss: 3.1712 | test_loss: 3.1486 | \n",
      "Epoch: 120 | train_loss: 3.0202 | test_loss: 2.9991 | \n",
      "Epoch: 130 | train_loss: 2.8820 | test_loss: 2.8562 | \n",
      "Epoch: 140 | train_loss: 2.7452 | test_loss: 2.7194 | \n",
      "Epoch: 150 | train_loss: 2.6190 | test_loss: 2.5976 | \n",
      "Epoch: 160 | train_loss: 2.4982 | test_loss: 2.4781 | \n",
      "Epoch: 170 | train_loss: 2.3847 | test_loss: 2.3631 | \n",
      "Epoch: 180 | train_loss: 2.2663 | test_loss: 2.2500 | \n",
      "Epoch: 190 | train_loss: 2.1624 | test_loss: 2.1475 | \n",
      "Epoch: 200 | train_loss: 2.0624 | test_loss: 2.0420 | \n",
      "Epoch: 210 | train_loss: 1.9629 | test_loss: 1.9425 | \n",
      "Epoch: 220 | train_loss: 1.8606 | test_loss: 1.8438 | \n",
      "Epoch: 230 | train_loss: 1.7727 | test_loss: 1.7530 | \n",
      "Epoch: 240 | train_loss: 1.6729 | test_loss: 1.6660 | \n",
      "Epoch: 250 | train_loss: 1.5898 | test_loss: 1.5728 | \n",
      "Epoch: 260 | train_loss: 1.5024 | test_loss: 1.4859 | \n",
      "Epoch: 270 | train_loss: 1.4165 | test_loss: 1.3959 | \n",
      "Epoch: 280 | train_loss: 1.3373 | test_loss: 1.3239 | \n",
      "Epoch: 290 | train_loss: 1.2574 | test_loss: 1.2407 | \n",
      "Epoch: 300 | train_loss: 1.1720 | test_loss: 1.1595 | \n",
      "Epoch: 310 | train_loss: 1.0941 | test_loss: 1.0830 | \n",
      "Epoch: 320 | train_loss: 1.0211 | test_loss: 1.0075 | \n",
      "Epoch: 330 | train_loss: 0.9573 | test_loss: 0.9449 | \n",
      "Epoch: 340 | train_loss: 0.8798 | test_loss: 0.8685 | \n",
      "Epoch: 350 | train_loss: 0.8085 | test_loss: 0.7911 | \n",
      "Epoch: 360 | train_loss: 0.7371 | test_loss: 0.7175 | \n",
      "Epoch: 370 | train_loss: 0.6719 | test_loss: 0.6547 | \n",
      "Epoch: 380 | train_loss: 0.6020 | test_loss: 0.5872 | \n",
      "Epoch: 390 | train_loss: 0.5346 | test_loss: 0.5240 | \n",
      "Epoch: 400 | train_loss: 0.4746 | test_loss: 0.4529 | \n",
      "Epoch: 410 | train_loss: 0.4159 | test_loss: 0.3966 | \n",
      "Epoch: 420 | train_loss: 0.3544 | test_loss: 0.3422 | \n",
      "Epoch: 430 | train_loss: 0.3010 | test_loss: 0.2837 | \n",
      "Epoch: 440 | train_loss: 0.2568 | test_loss: 0.2449 | \n",
      "Epoch: 450 | train_loss: 0.2144 | test_loss: 0.1956 | \n",
      "Epoch: 460 | train_loss: 0.1839 | test_loss: 0.1838 | \n",
      "Epoch: 470 | train_loss: 0.1587 | test_loss: 0.1635 | \n",
      "Epoch: 480 | train_loss: 0.1551 | test_loss: 0.1469 | \n",
      "Epoch: 490 | train_loss: 0.1349 | test_loss: 0.1434 | \n",
      "Epoch: 500 | train_loss: 0.1307 | test_loss: 0.1418 | \n",
      "Epoch: 510 | train_loss: 0.1280 | test_loss: 0.1390 | \n",
      "Epoch: 520 | train_loss: 0.1323 | test_loss: 0.1364 | \n",
      "Epoch: 530 | train_loss: 0.1306 | test_loss: 0.1436 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2834 | test_loss: 9.0007 | \n",
      "Epoch: 10 | train_loss: 6.8973 | test_loss: 6.7926 | \n",
      "Epoch: 20 | train_loss: 5.8837 | test_loss: 5.8142 | \n",
      "Epoch: 30 | train_loss: 5.2708 | test_loss: 5.2143 | \n",
      "Epoch: 40 | train_loss: 4.8374 | test_loss: 4.7839 | \n",
      "Epoch: 50 | train_loss: 4.4902 | test_loss: 4.4496 | \n",
      "Epoch: 60 | train_loss: 4.1992 | test_loss: 4.1704 | \n",
      "Epoch: 70 | train_loss: 3.9535 | test_loss: 3.9257 | \n",
      "Epoch: 80 | train_loss: 3.7364 | test_loss: 3.7142 | \n",
      "Epoch: 90 | train_loss: 3.5407 | test_loss: 3.5151 | \n",
      "Epoch: 100 | train_loss: 3.3637 | test_loss: 3.3324 | \n",
      "Epoch: 110 | train_loss: 3.1937 | test_loss: 3.1706 | \n",
      "Epoch: 120 | train_loss: 3.0541 | test_loss: 3.0190 | \n",
      "Epoch: 130 | train_loss: 2.8998 | test_loss: 2.8774 | \n",
      "Epoch: 140 | train_loss: 2.7740 | test_loss: 2.7484 | \n",
      "Epoch: 150 | train_loss: 2.6426 | test_loss: 2.6235 | \n",
      "Epoch: 160 | train_loss: 2.5235 | test_loss: 2.5022 | \n",
      "Epoch: 170 | train_loss: 2.4062 | test_loss: 2.3885 | \n",
      "Epoch: 180 | train_loss: 2.2974 | test_loss: 2.2730 | \n",
      "Epoch: 190 | train_loss: 2.1827 | test_loss: 2.1686 | \n",
      "Epoch: 200 | train_loss: 2.0841 | test_loss: 2.0676 | \n",
      "Epoch: 210 | train_loss: 1.9793 | test_loss: 1.9615 | \n",
      "Epoch: 220 | train_loss: 1.8870 | test_loss: 1.8727 | \n",
      "Epoch: 230 | train_loss: 1.7940 | test_loss: 1.7784 | \n",
      "Epoch: 240 | train_loss: 1.7006 | test_loss: 1.6840 | \n",
      "Epoch: 250 | train_loss: 1.6168 | test_loss: 1.5946 | \n",
      "Epoch: 260 | train_loss: 1.5243 | test_loss: 1.5074 | \n",
      "Epoch: 270 | train_loss: 1.4421 | test_loss: 1.4312 | \n",
      "Epoch: 280 | train_loss: 1.3592 | test_loss: 1.3431 | \n",
      "Epoch: 290 | train_loss: 1.2760 | test_loss: 1.2638 | \n",
      "Epoch: 300 | train_loss: 1.1953 | test_loss: 1.1816 | \n",
      "Epoch: 310 | train_loss: 1.1195 | test_loss: 1.0969 | \n",
      "Epoch: 320 | train_loss: 1.0476 | test_loss: 1.0393 | \n",
      "Epoch: 330 | train_loss: 0.9706 | test_loss: 0.9567 | \n",
      "Epoch: 340 | train_loss: 0.8943 | test_loss: 0.8818 | \n",
      "Epoch: 350 | train_loss: 0.8245 | test_loss: 0.8093 | \n",
      "Epoch: 360 | train_loss: 0.7552 | test_loss: 0.7356 | \n",
      "Epoch: 370 | train_loss: 0.6881 | test_loss: 0.6696 | \n",
      "Epoch: 380 | train_loss: 0.6166 | test_loss: 0.6016 | \n",
      "Epoch: 390 | train_loss: 0.5559 | test_loss: 0.5427 | \n",
      "Epoch: 400 | train_loss: 0.4973 | test_loss: 0.4866 | \n",
      "Epoch: 410 | train_loss: 0.4400 | test_loss: 0.4336 | \n",
      "Epoch: 420 | train_loss: 0.3725 | test_loss: 0.3785 | \n",
      "Epoch: 430 | train_loss: 0.3159 | test_loss: 0.3021 | \n",
      "Epoch: 440 | train_loss: 0.2697 | test_loss: 0.2636 | \n",
      "Epoch: 450 | train_loss: 0.2318 | test_loss: 0.2322 | \n",
      "Epoch: 460 | train_loss: 0.1911 | test_loss: 0.1929 | \n",
      "Epoch: 470 | train_loss: 0.1711 | test_loss: 0.1609 | \n",
      "Epoch: 480 | train_loss: 0.1476 | test_loss: 0.1519 | \n",
      "Epoch: 490 | train_loss: 0.1363 | test_loss: 0.1449 | \n",
      "Epoch: 500 | train_loss: 0.1308 | test_loss: 0.1422 | \n",
      "Epoch: 510 | train_loss: 0.1252 | test_loss: 0.1400 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.5346 | test_loss: 7.6803 | \n",
      "Epoch: 10 | train_loss: 0.4192 | test_loss: 0.3187 | \n",
      "Epoch: 20 | train_loss: 0.1871 | test_loss: 0.1738 | \n",
      "Epoch: 30 | train_loss: 0.1700 | test_loss: 0.1613 | \n",
      "Epoch: 40 | train_loss: 0.1593 | test_loss: 0.1555 | \n",
      "Epoch: 50 | train_loss: 0.1526 | test_loss: 0.1535 | \n",
      "Epoch: 60 | train_loss: 0.1480 | test_loss: 0.1502 | \n",
      "Epoch: 70 | train_loss: 0.1444 | test_loss: 0.1490 | \n",
      "Epoch: 80 | train_loss: 0.1397 | test_loss: 0.1478 | \n",
      "Epoch: 90 | train_loss: 0.1386 | test_loss: 0.1469 | \n",
      "Epoch: 100 | train_loss: 0.1352 | test_loss: 0.1453 | \n",
      "Epoch: 110 | train_loss: 0.1324 | test_loss: 0.1448 | \n",
      "Epoch: 120 | train_loss: 0.1303 | test_loss: 0.1437 | \n",
      "Epoch: 130 | train_loss: 0.1274 | test_loss: 0.1425 | \n",
      "Epoch: 140 | train_loss: 0.1235 | test_loss: 0.1412 | \n",
      "Epoch: 150 | train_loss: 0.1207 | test_loss: 0.1390 | \n",
      "Epoch: 160 | train_loss: 0.1186 | test_loss: 0.1387 | \n",
      "Epoch: 170 | train_loss: 0.1164 | test_loss: 0.1382 | \n",
      "Epoch: 180 | train_loss: 0.1157 | test_loss: 0.1373 | \n",
      "Epoch: 190 | train_loss: 0.1130 | test_loss: 0.1367 | \n",
      "Epoch: 200 | train_loss: 0.1103 | test_loss: 0.1366 | \n",
      "Epoch: 210 | train_loss: 0.1064 | test_loss: 0.1355 | \n",
      "Epoch: 220 | train_loss: 0.1048 | test_loss: 0.1364 | \n",
      "Epoch: 230 | train_loss: 0.1025 | test_loss: 0.1353 | \n",
      "Epoch: 240 | train_loss: 0.0998 | test_loss: 0.1353 | \n",
      "Epoch: 250 | train_loss: 0.0998 | test_loss: 0.1342 | \n",
      "Epoch: 260 | train_loss: 0.0997 | test_loss: 0.1367 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.1332 | test_loss: 4.2487 | \n",
      "Epoch: 10 | train_loss: 0.1918 | test_loss: 0.1785 | \n",
      "Epoch: 20 | train_loss: 0.1546 | test_loss: 0.1515 | \n",
      "Epoch: 30 | train_loss: 0.1433 | test_loss: 0.1481 | \n",
      "Epoch: 40 | train_loss: 0.1307 | test_loss: 0.1441 | \n",
      "Epoch: 50 | train_loss: 0.1218 | test_loss: 0.1400 | \n",
      "Epoch: 60 | train_loss: 0.1175 | test_loss: 0.1381 | \n",
      "Epoch: 70 | train_loss: 0.1107 | test_loss: 0.1386 | \n",
      "Epoch: 80 | train_loss: 0.1100 | test_loss: 0.1391 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 4.8898 | test_loss: 0.4969 | \n",
      "Epoch: 10 | train_loss: 0.1595 | test_loss: 0.1496 | \n",
      "Epoch: 20 | train_loss: 0.1268 | test_loss: 0.1440 | \n",
      "Epoch: 30 | train_loss: 0.1041 | test_loss: 0.1415 | \n",
      "Epoch: 40 | train_loss: 0.0760 | test_loss: 0.1460 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8143 | test_loss: 9.4667 | \n",
      "Epoch: 10 | train_loss: 7.7140 | test_loss: 7.6527 | \n",
      "Epoch: 20 | train_loss: 6.8077 | test_loss: 6.7542 | \n",
      "Epoch: 30 | train_loss: 6.2288 | test_loss: 6.1876 | \n",
      "Epoch: 40 | train_loss: 5.8100 | test_loss: 5.7751 | \n",
      "Epoch: 50 | train_loss: 5.4840 | test_loss: 5.4311 | \n",
      "Epoch: 60 | train_loss: 5.2106 | test_loss: 5.1557 | \n",
      "Epoch: 70 | train_loss: 4.9799 | test_loss: 4.9811 | \n",
      "Epoch: 80 | train_loss: 4.7761 | test_loss: 4.7608 | \n",
      "Epoch: 90 | train_loss: 4.5944 | test_loss: 4.5768 | \n",
      "Epoch: 100 | train_loss: 4.4327 | test_loss: 4.4035 | \n",
      "Epoch: 110 | train_loss: 4.2856 | test_loss: 4.2404 | \n",
      "Epoch: 120 | train_loss: 4.1471 | test_loss: 4.1037 | \n",
      "Epoch: 130 | train_loss: 4.0211 | test_loss: 4.0290 | \n",
      "Epoch: 140 | train_loss: 3.9027 | test_loss: 3.8830 | \n",
      "Epoch: 150 | train_loss: 3.7918 | test_loss: 3.7816 | \n",
      "Epoch: 160 | train_loss: 3.6862 | test_loss: 3.6679 | \n",
      "Epoch: 170 | train_loss: 3.5871 | test_loss: 3.5589 | \n",
      "Epoch: 180 | train_loss: 3.4924 | test_loss: 3.4887 | \n",
      "Epoch: 190 | train_loss: 3.4022 | test_loss: 3.3960 | \n",
      "Epoch: 200 | train_loss: 3.3144 | test_loss: 3.3039 | \n",
      "Epoch: 210 | train_loss: 3.2314 | test_loss: 3.2232 | \n",
      "Epoch: 220 | train_loss: 3.1517 | test_loss: 3.1607 | \n",
      "Epoch: 230 | train_loss: 3.0751 | test_loss: 3.0852 | \n",
      "Epoch: 240 | train_loss: 3.0005 | test_loss: 2.9767 | \n",
      "Epoch: 250 | train_loss: 2.9290 | test_loss: 2.9126 | \n",
      "Epoch: 260 | train_loss: 2.8586 | test_loss: 2.8186 | \n",
      "Epoch: 270 | train_loss: 2.7903 | test_loss: 2.8061 | \n",
      "Epoch: 280 | train_loss: 2.7249 | test_loss: 2.7112 | \n",
      "Epoch: 290 | train_loss: 2.6600 | test_loss: 2.6587 | \n",
      "Epoch: 300 | train_loss: 2.5971 | test_loss: 2.5990 | \n",
      "Epoch: 310 | train_loss: 2.5362 | test_loss: 2.5213 | \n",
      "Epoch: 320 | train_loss: 2.4788 | test_loss: 2.4670 | \n",
      "Epoch: 330 | train_loss: 2.4171 | test_loss: 2.4033 | \n",
      "Epoch: 340 | train_loss: 2.3614 | test_loss: 2.3421 | \n",
      "Epoch: 350 | train_loss: 2.3139 | test_loss: 2.3433 | \n",
      "Epoch: 360 | train_loss: 2.2560 | test_loss: 2.2613 | \n",
      "Epoch: 370 | train_loss: 2.1996 | test_loss: 2.1961 | \n",
      "Epoch: 380 | train_loss: 2.1456 | test_loss: 2.1388 | \n",
      "Epoch: 390 | train_loss: 2.0918 | test_loss: 2.0916 | \n",
      "Epoch: 400 | train_loss: 2.0418 | test_loss: 2.0420 | \n",
      "Epoch: 410 | train_loss: 1.9911 | test_loss: 1.9890 | \n",
      "Epoch: 420 | train_loss: 1.9413 | test_loss: 1.9391 | \n",
      "Epoch: 430 | train_loss: 1.8929 | test_loss: 1.8885 | \n",
      "Epoch: 440 | train_loss: 1.8441 | test_loss: 1.8405 | \n",
      "Epoch: 450 | train_loss: 1.7970 | test_loss: 1.7964 | \n",
      "Epoch: 460 | train_loss: 1.7512 | test_loss: 1.7488 | \n",
      "Epoch: 470 | train_loss: 1.7047 | test_loss: 1.6919 | \n",
      "Epoch: 480 | train_loss: 1.6595 | test_loss: 1.6529 | \n",
      "Epoch: 490 | train_loss: 1.6148 | test_loss: 1.6059 | \n",
      "Epoch: 500 | train_loss: 1.5703 | test_loss: 1.5670 | \n",
      "Epoch: 510 | train_loss: 1.5282 | test_loss: 1.5161 | \n",
      "Epoch: 520 | train_loss: 1.4835 | test_loss: 1.4745 | \n",
      "Epoch: 530 | train_loss: 1.4411 | test_loss: 1.4428 | \n",
      "Epoch: 540 | train_loss: 1.3975 | test_loss: 1.3977 | \n",
      "Epoch: 550 | train_loss: 1.3564 | test_loss: 1.3468 | \n",
      "Epoch: 560 | train_loss: 1.3159 | test_loss: 1.3181 | \n",
      "Epoch: 570 | train_loss: 1.2748 | test_loss: 1.2720 | \n",
      "Epoch: 580 | train_loss: 1.2334 | test_loss: 1.2350 | \n",
      "Epoch: 590 | train_loss: 1.1929 | test_loss: 1.1874 | \n",
      "Epoch: 600 | train_loss: 1.1542 | test_loss: 1.1540 | \n",
      "Epoch: 610 | train_loss: 1.1146 | test_loss: 1.1172 | \n",
      "Epoch: 620 | train_loss: 1.0763 | test_loss: 1.0777 | \n",
      "Epoch: 630 | train_loss: 1.0363 | test_loss: 1.0358 | \n",
      "Epoch: 640 | train_loss: 0.9985 | test_loss: 1.0007 | \n",
      "Epoch: 650 | train_loss: 0.9599 | test_loss: 0.9544 | \n",
      "Epoch: 660 | train_loss: 0.9236 | test_loss: 0.9179 | \n",
      "Epoch: 670 | train_loss: 0.8879 | test_loss: 0.8859 | \n",
      "Epoch: 680 | train_loss: 0.8500 | test_loss: 0.8458 | \n",
      "Epoch: 690 | train_loss: 0.8135 | test_loss: 0.8081 | \n",
      "Epoch: 700 | train_loss: 0.7776 | test_loss: 0.7772 | \n",
      "Epoch: 710 | train_loss: 0.7416 | test_loss: 0.7417 | \n",
      "Epoch: 720 | train_loss: 0.7067 | test_loss: 0.7090 | \n",
      "Epoch: 730 | train_loss: 0.6710 | test_loss: 0.6702 | \n",
      "Epoch: 740 | train_loss: 0.6372 | test_loss: 0.6348 | \n",
      "Epoch: 750 | train_loss: 0.6038 | test_loss: 0.6058 | \n",
      "Epoch: 760 | train_loss: 0.5698 | test_loss: 0.5798 | \n",
      "Epoch: 770 | train_loss: 0.5365 | test_loss: 0.5439 | \n",
      "Epoch: 780 | train_loss: 0.5033 | test_loss: 0.5134 | \n",
      "Epoch: 790 | train_loss: 0.4698 | test_loss: 0.4784 | \n",
      "Epoch: 800 | train_loss: 0.4380 | test_loss: 0.4645 | \n",
      "Epoch: 810 | train_loss: 0.4056 | test_loss: 0.4067 | \n",
      "Epoch: 820 | train_loss: 0.3749 | test_loss: 0.3872 | \n",
      "Epoch: 830 | train_loss: 0.3432 | test_loss: 0.3598 | \n",
      "Epoch: 840 | train_loss: 0.3134 | test_loss: 0.3504 | \n",
      "Epoch: 850 | train_loss: 0.2871 | test_loss: 0.3088 | \n",
      "Epoch: 860 | train_loss: 0.2537 | test_loss: 0.2829 | \n",
      "Epoch: 870 | train_loss: 0.2278 | test_loss: 0.2512 | \n",
      "Epoch: 880 | train_loss: 0.1964 | test_loss: 0.2438 | \n",
      "Epoch: 890 | train_loss: 0.1669 | test_loss: 0.2223 | \n",
      "Epoch: 900 | train_loss: 0.1416 | test_loss: 0.1985 | \n",
      "Epoch: 910 | train_loss: 0.1186 | test_loss: 0.1733 | \n",
      "Epoch: 920 | train_loss: 0.1039 | test_loss: 0.1697 | \n",
      "Epoch: 930 | train_loss: 0.0791 | test_loss: 0.1536 | \n",
      "Epoch: 940 | train_loss: 0.0701 | test_loss: 0.1429 | \n",
      "Epoch: 950 | train_loss: 0.0508 | test_loss: 0.1407 | \n",
      "Epoch: 960 | train_loss: 0.0449 | test_loss: 0.1429 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8148 | test_loss: 9.4206 | \n",
      "Epoch: 10 | train_loss: 7.7134 | test_loss: 7.6423 | \n",
      "Epoch: 20 | train_loss: 6.8153 | test_loss: 6.7743 | \n",
      "Epoch: 30 | train_loss: 6.2384 | test_loss: 6.2026 | \n",
      "Epoch: 40 | train_loss: 5.8174 | test_loss: 5.7636 | \n",
      "Epoch: 50 | train_loss: 5.4857 | test_loss: 5.4744 | \n",
      "Epoch: 60 | train_loss: 5.2134 | test_loss: 5.1846 | \n",
      "Epoch: 70 | train_loss: 4.9829 | test_loss: 4.9894 | \n",
      "Epoch: 80 | train_loss: 4.7797 | test_loss: 4.7680 | \n",
      "Epoch: 90 | train_loss: 4.6008 | test_loss: 4.5997 | \n",
      "Epoch: 100 | train_loss: 4.4334 | test_loss: 4.4084 | \n",
      "Epoch: 110 | train_loss: 4.2857 | test_loss: 4.2652 | \n",
      "Epoch: 120 | train_loss: 4.1475 | test_loss: 4.1324 | \n",
      "Epoch: 130 | train_loss: 4.0207 | test_loss: 4.0048 | \n",
      "Epoch: 140 | train_loss: 3.9045 | test_loss: 3.8838 | \n",
      "Epoch: 150 | train_loss: 3.7921 | test_loss: 3.7757 | \n",
      "Epoch: 160 | train_loss: 3.6864 | test_loss: 3.6779 | \n",
      "Epoch: 170 | train_loss: 3.5864 | test_loss: 3.5658 | \n",
      "Epoch: 180 | train_loss: 3.4927 | test_loss: 3.4669 | \n",
      "Epoch: 190 | train_loss: 3.4009 | test_loss: 3.3909 | \n",
      "Epoch: 200 | train_loss: 3.3143 | test_loss: 3.3178 | \n",
      "Epoch: 210 | train_loss: 3.2318 | test_loss: 3.2082 | \n",
      "Epoch: 220 | train_loss: 3.1533 | test_loss: 3.1393 | \n",
      "Epoch: 230 | train_loss: 3.0747 | test_loss: 3.0610 | \n",
      "Epoch: 240 | train_loss: 3.0003 | test_loss: 2.9872 | \n",
      "Epoch: 250 | train_loss: 2.9286 | test_loss: 2.9049 | \n",
      "Epoch: 260 | train_loss: 2.8581 | test_loss: 2.8608 | \n",
      "Epoch: 270 | train_loss: 2.7908 | test_loss: 2.7787 | \n",
      "Epoch: 280 | train_loss: 2.7259 | test_loss: 2.7156 | \n",
      "Epoch: 290 | train_loss: 2.6609 | test_loss: 2.6332 | \n",
      "Epoch: 300 | train_loss: 2.5985 | test_loss: 2.5785 | \n",
      "Epoch: 310 | train_loss: 2.5376 | test_loss: 2.5371 | \n",
      "Epoch: 320 | train_loss: 2.4770 | test_loss: 2.4687 | \n",
      "Epoch: 330 | train_loss: 2.4192 | test_loss: 2.3941 | \n",
      "Epoch: 340 | train_loss: 2.3627 | test_loss: 2.3568 | \n",
      "Epoch: 350 | train_loss: 2.3048 | test_loss: 2.2980 | \n",
      "Epoch: 360 | train_loss: 2.2502 | test_loss: 2.2319 | \n",
      "Epoch: 370 | train_loss: 2.1979 | test_loss: 2.1933 | \n",
      "Epoch: 380 | train_loss: 2.1438 | test_loss: 2.1456 | \n",
      "Epoch: 390 | train_loss: 2.0921 | test_loss: 2.0878 | \n",
      "Epoch: 400 | train_loss: 2.0411 | test_loss: 2.0257 | \n",
      "Epoch: 410 | train_loss: 1.9914 | test_loss: 1.9687 | \n",
      "Epoch: 420 | train_loss: 1.9405 | test_loss: 1.9388 | \n",
      "Epoch: 430 | train_loss: 1.8932 | test_loss: 1.8834 | \n",
      "Epoch: 440 | train_loss: 1.8453 | test_loss: 1.8266 | \n",
      "Epoch: 450 | train_loss: 1.7976 | test_loss: 1.7890 | \n",
      "Epoch: 460 | train_loss: 1.7507 | test_loss: 1.7373 | \n",
      "Epoch: 470 | train_loss: 1.7039 | test_loss: 1.6892 | \n",
      "Epoch: 480 | train_loss: 1.6582 | test_loss: 1.6506 | \n",
      "Epoch: 490 | train_loss: 1.6146 | test_loss: 1.6027 | \n",
      "Epoch: 500 | train_loss: 1.5694 | test_loss: 1.5656 | \n",
      "Epoch: 510 | train_loss: 1.5257 | test_loss: 1.5251 | \n",
      "Epoch: 520 | train_loss: 1.4832 | test_loss: 1.4913 | \n",
      "Epoch: 530 | train_loss: 1.4407 | test_loss: 1.4414 | \n",
      "Epoch: 540 | train_loss: 1.3976 | test_loss: 1.4030 | \n",
      "Epoch: 550 | train_loss: 1.3567 | test_loss: 1.3598 | \n",
      "Epoch: 560 | train_loss: 1.3129 | test_loss: 1.3002 | \n",
      "Epoch: 570 | train_loss: 1.2743 | test_loss: 1.2709 | \n",
      "Epoch: 580 | train_loss: 1.2327 | test_loss: 1.2230 | \n",
      "Epoch: 590 | train_loss: 1.1919 | test_loss: 1.1817 | \n",
      "Epoch: 600 | train_loss: 1.1527 | test_loss: 1.1518 | \n",
      "Epoch: 610 | train_loss: 1.1117 | test_loss: 1.1154 | \n",
      "Epoch: 620 | train_loss: 1.0734 | test_loss: 1.0790 | \n",
      "Epoch: 630 | train_loss: 1.0345 | test_loss: 1.0260 | \n",
      "Epoch: 640 | train_loss: 0.9956 | test_loss: 0.9957 | \n",
      "Epoch: 650 | train_loss: 0.9575 | test_loss: 0.9688 | \n",
      "Epoch: 660 | train_loss: 0.9202 | test_loss: 0.9228 | \n",
      "Epoch: 670 | train_loss: 0.8830 | test_loss: 0.8973 | \n",
      "Epoch: 680 | train_loss: 0.8470 | test_loss: 0.8391 | \n",
      "Epoch: 690 | train_loss: 0.8097 | test_loss: 0.8163 | \n",
      "Epoch: 700 | train_loss: 0.7750 | test_loss: 0.7793 | \n",
      "Epoch: 710 | train_loss: 0.7432 | test_loss: 0.7242 | \n",
      "Epoch: 720 | train_loss: 0.7036 | test_loss: 0.7299 | \n",
      "Epoch: 730 | train_loss: 0.6680 | test_loss: 0.6757 | \n",
      "Epoch: 740 | train_loss: 0.6325 | test_loss: 0.6447 | \n",
      "Epoch: 750 | train_loss: 0.5989 | test_loss: 0.6052 | \n",
      "Epoch: 760 | train_loss: 0.5633 | test_loss: 0.5720 | \n",
      "Epoch: 770 | train_loss: 0.5291 | test_loss: 0.5339 | \n",
      "Epoch: 780 | train_loss: 0.4967 | test_loss: 0.5119 | \n",
      "Epoch: 790 | train_loss: 0.4641 | test_loss: 0.4793 | \n",
      "Epoch: 800 | train_loss: 0.4306 | test_loss: 0.4341 | \n",
      "Epoch: 810 | train_loss: 0.3984 | test_loss: 0.4391 | \n",
      "Epoch: 820 | train_loss: 0.3697 | test_loss: 0.3932 | \n",
      "Epoch: 830 | train_loss: 0.3362 | test_loss: 0.3531 | \n",
      "Epoch: 840 | train_loss: 0.3061 | test_loss: 0.3325 | \n",
      "Epoch: 850 | train_loss: 0.2766 | test_loss: 0.2988 | \n",
      "Epoch: 860 | train_loss: 0.2464 | test_loss: 0.2759 | \n",
      "Epoch: 870 | train_loss: 0.2174 | test_loss: 0.2399 | \n",
      "Epoch: 880 | train_loss: 0.1892 | test_loss: 0.2333 | \n",
      "Epoch: 890 | train_loss: 0.1611 | test_loss: 0.1997 | \n",
      "Epoch: 900 | train_loss: 0.1349 | test_loss: 0.1809 | \n",
      "Epoch: 910 | train_loss: 0.1218 | test_loss: 0.1755 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.9023 | test_loss: 10.1552 | \n",
      "Epoch: 10 | train_loss: 7.7716 | test_loss: 7.6891 | \n",
      "Epoch: 20 | train_loss: 6.8834 | test_loss: 6.8309 | \n",
      "Epoch: 30 | train_loss: 6.3114 | test_loss: 6.2457 | \n",
      "Epoch: 40 | train_loss: 5.8813 | test_loss: 5.8286 | \n",
      "Epoch: 50 | train_loss: 5.5557 | test_loss: 5.5070 | \n",
      "Epoch: 60 | train_loss: 5.2810 | test_loss: 5.2379 | \n",
      "Epoch: 70 | train_loss: 5.0506 | test_loss: 5.0089 | \n",
      "Epoch: 80 | train_loss: 4.8495 | test_loss: 4.8158 | \n",
      "Epoch: 90 | train_loss: 4.6653 | test_loss: 4.6325 | \n",
      "Epoch: 100 | train_loss: 4.4966 | test_loss: 4.4691 | \n",
      "Epoch: 110 | train_loss: 4.3508 | test_loss: 4.3228 | \n",
      "Epoch: 120 | train_loss: 4.2155 | test_loss: 4.1863 | \n",
      "Epoch: 130 | train_loss: 4.0839 | test_loss: 4.0631 | \n",
      "Epoch: 140 | train_loss: 3.9716 | test_loss: 3.9430 | \n",
      "Epoch: 150 | train_loss: 3.8510 | test_loss: 3.8370 | \n",
      "Epoch: 160 | train_loss: 3.7505 | test_loss: 3.7298 | \n",
      "Epoch: 170 | train_loss: 3.6493 | test_loss: 3.6298 | \n",
      "Epoch: 180 | train_loss: 3.5556 | test_loss: 3.5300 | \n",
      "Epoch: 190 | train_loss: 3.4651 | test_loss: 3.4439 | \n",
      "Epoch: 200 | train_loss: 3.3723 | test_loss: 3.3609 | \n",
      "Epoch: 210 | train_loss: 3.2930 | test_loss: 3.2752 | \n",
      "Epoch: 220 | train_loss: 3.2093 | test_loss: 3.1948 | \n",
      "Epoch: 230 | train_loss: 3.1382 | test_loss: 3.1172 | \n",
      "Epoch: 240 | train_loss: 3.0588 | test_loss: 3.0428 | \n",
      "Epoch: 250 | train_loss: 2.9860 | test_loss: 2.9724 | \n",
      "Epoch: 260 | train_loss: 2.9181 | test_loss: 2.9007 | \n",
      "Epoch: 270 | train_loss: 2.8502 | test_loss: 2.8351 | \n",
      "Epoch: 280 | train_loss: 2.7876 | test_loss: 2.7645 | \n",
      "Epoch: 290 | train_loss: 2.7157 | test_loss: 2.7012 | \n",
      "Epoch: 300 | train_loss: 2.6590 | test_loss: 2.6387 | \n",
      "Epoch: 310 | train_loss: 2.5985 | test_loss: 2.5770 | \n",
      "Epoch: 320 | train_loss: 2.5369 | test_loss: 2.5220 | \n",
      "Epoch: 330 | train_loss: 2.4782 | test_loss: 2.4609 | \n",
      "Epoch: 340 | train_loss: 2.4211 | test_loss: 2.4048 | \n",
      "Epoch: 350 | train_loss: 2.3629 | test_loss: 2.3496 | \n",
      "Epoch: 360 | train_loss: 2.3083 | test_loss: 2.2970 | \n",
      "Epoch: 370 | train_loss: 2.2544 | test_loss: 2.2312 | \n",
      "Epoch: 380 | train_loss: 2.2010 | test_loss: 2.1798 | \n",
      "Epoch: 390 | train_loss: 2.1518 | test_loss: 2.1295 | \n",
      "Epoch: 400 | train_loss: 2.1013 | test_loss: 2.0794 | \n",
      "Epoch: 410 | train_loss: 2.0432 | test_loss: 2.0320 | \n",
      "Epoch: 420 | train_loss: 1.9964 | test_loss: 1.9772 | \n",
      "Epoch: 430 | train_loss: 1.9476 | test_loss: 1.9302 | \n",
      "Epoch: 440 | train_loss: 1.9011 | test_loss: 1.8775 | \n",
      "Epoch: 450 | train_loss: 1.8505 | test_loss: 1.8362 | \n",
      "Epoch: 460 | train_loss: 1.8049 | test_loss: 1.7890 | \n",
      "Epoch: 470 | train_loss: 1.7602 | test_loss: 1.7421 | \n",
      "Epoch: 480 | train_loss: 1.7166 | test_loss: 1.7001 | \n",
      "Epoch: 490 | train_loss: 1.6679 | test_loss: 1.6497 | \n",
      "Epoch: 500 | train_loss: 1.6208 | test_loss: 1.6054 | \n",
      "Epoch: 510 | train_loss: 1.5809 | test_loss: 1.5664 | \n",
      "Epoch: 520 | train_loss: 1.5354 | test_loss: 1.5229 | \n",
      "Epoch: 530 | train_loss: 1.4959 | test_loss: 1.4774 | \n",
      "Epoch: 540 | train_loss: 1.4500 | test_loss: 1.4345 | \n",
      "Epoch: 550 | train_loss: 1.4089 | test_loss: 1.3980 | \n",
      "Epoch: 560 | train_loss: 1.3702 | test_loss: 1.3509 | \n",
      "Epoch: 570 | train_loss: 1.3282 | test_loss: 1.3128 | \n",
      "Epoch: 580 | train_loss: 1.2839 | test_loss: 1.2701 | \n",
      "Epoch: 590 | train_loss: 1.2463 | test_loss: 1.2356 | \n",
      "Epoch: 600 | train_loss: 1.2064 | test_loss: 1.1916 | \n",
      "Epoch: 610 | train_loss: 1.1654 | test_loss: 1.1505 | \n",
      "Epoch: 620 | train_loss: 1.1322 | test_loss: 1.1193 | \n",
      "Epoch: 630 | train_loss: 1.0839 | test_loss: 1.0767 | \n",
      "Epoch: 640 | train_loss: 1.0518 | test_loss: 1.0457 | \n",
      "Epoch: 650 | train_loss: 1.0126 | test_loss: 1.0027 | \n",
      "Epoch: 660 | train_loss: 0.9788 | test_loss: 0.9686 | \n",
      "Epoch: 670 | train_loss: 0.9396 | test_loss: 0.9280 | \n",
      "Epoch: 680 | train_loss: 0.9027 | test_loss: 0.8953 | \n",
      "Epoch: 690 | train_loss: 0.8668 | test_loss: 0.8587 | \n",
      "Epoch: 700 | train_loss: 0.8309 | test_loss: 0.8182 | \n",
      "Epoch: 710 | train_loss: 0.7945 | test_loss: 0.7900 | \n",
      "Epoch: 720 | train_loss: 0.7547 | test_loss: 0.7504 | \n",
      "Epoch: 730 | train_loss: 0.7181 | test_loss: 0.7134 | \n",
      "Epoch: 740 | train_loss: 0.6882 | test_loss: 0.6803 | \n",
      "Epoch: 750 | train_loss: 0.6550 | test_loss: 0.6536 | \n",
      "Epoch: 760 | train_loss: 0.6205 | test_loss: 0.6174 | \n",
      "Epoch: 770 | train_loss: 0.5912 | test_loss: 0.5842 | \n",
      "Epoch: 780 | train_loss: 0.5595 | test_loss: 0.5488 | \n",
      "Epoch: 790 | train_loss: 0.5255 | test_loss: 0.5132 | \n",
      "Epoch: 800 | train_loss: 0.4918 | test_loss: 0.4847 | \n",
      "Epoch: 810 | train_loss: 0.4605 | test_loss: 0.4507 | \n",
      "Epoch: 820 | train_loss: 0.4328 | test_loss: 0.4209 | \n",
      "Epoch: 830 | train_loss: 0.3980 | test_loss: 0.4010 | \n",
      "Epoch: 840 | train_loss: 0.3707 | test_loss: 0.3717 | \n",
      "Epoch: 850 | train_loss: 0.3444 | test_loss: 0.3437 | \n",
      "Epoch: 860 | train_loss: 0.3212 | test_loss: 0.3109 | \n",
      "Epoch: 870 | train_loss: 0.2906 | test_loss: 0.2990 | \n",
      "Epoch: 880 | train_loss: 0.2672 | test_loss: 0.2770 | \n",
      "Epoch: 890 | train_loss: 0.2394 | test_loss: 0.2466 | \n",
      "Epoch: 900 | train_loss: 0.2153 | test_loss: 0.2171 | \n",
      "Epoch: 910 | train_loss: 0.1938 | test_loss: 0.2086 | \n",
      "Epoch: 920 | train_loss: 0.1839 | test_loss: 0.1921 | \n",
      "Epoch: 930 | train_loss: 0.1651 | test_loss: 0.1753 | \n",
      "Epoch: 940 | train_loss: 0.1500 | test_loss: 0.1570 | \n",
      "Epoch: 950 | train_loss: 0.1388 | test_loss: 0.1544 | \n",
      "Epoch: 960 | train_loss: 0.1343 | test_loss: 0.1540 | \n",
      "Epoch: 970 | train_loss: 0.1240 | test_loss: 0.1459 | \n",
      "Epoch: 980 | train_loss: 0.1270 | test_loss: 0.1417 | \n",
      "Epoch: 990 | train_loss: 0.1133 | test_loss: 0.1397 | \n",
      "Epoch: 1000 | train_loss: 0.1156 | test_loss: 0.1397 | \n",
      "Epoch: 1010 | train_loss: 0.1160 | test_loss: 0.1425 | \n",
      "Epoch: 1020 | train_loss: 0.1076 | test_loss: 0.1435 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: nan | test_loss: nan | \n",
      "Epoch: 10 | train_loss: nan | test_loss: nan | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.8396 | test_loss: 2.3306 | \n",
      "Epoch: 10 | train_loss: 0.1521 | test_loss: 0.1533 | \n",
      "Epoch: 20 | train_loss: 0.1373 | test_loss: 0.1464 | \n",
      "Epoch: 30 | train_loss: 0.1256 | test_loss: 0.1416 | \n",
      "Epoch: 40 | train_loss: 0.1156 | test_loss: 0.1407 | \n",
      "Epoch: 50 | train_loss: 0.1122 | test_loss: 0.1379 | \n",
      "Epoch: 60 | train_loss: 0.1036 | test_loss: 0.1400 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.2496 | test_loss: 0.3661 | \n",
      "Epoch: 10 | train_loss: 0.1336 | test_loss: 0.1404 | \n",
      "Epoch: 20 | train_loss: 0.1167 | test_loss: 0.1450 | \n",
      "Epoch: 30 | train_loss: 0.1056 | test_loss: 0.1337 | \n",
      "Epoch: 40 | train_loss: 0.0915 | test_loss: 0.1379 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 2.1506 | test_loss: 0.6016 | \n",
      "Epoch: 10 | train_loss: 0.1605 | test_loss: 0.1783 | \n",
      "Epoch: 20 | train_loss: 0.1114 | test_loss: 0.1466 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6465 | test_loss: 8.6391 | \n",
      "Epoch: 10 | train_loss: 5.9273 | test_loss: 5.7981 | \n",
      "Epoch: 20 | train_loss: 4.8615 | test_loss: 4.8381 | \n",
      "Epoch: 30 | train_loss: 4.2234 | test_loss: 4.1881 | \n",
      "Epoch: 40 | train_loss: 3.7613 | test_loss: 3.7222 | \n",
      "Epoch: 50 | train_loss: 3.3790 | test_loss: 3.3535 | \n",
      "Epoch: 60 | train_loss: 3.0623 | test_loss: 3.0206 | \n",
      "Epoch: 70 | train_loss: 2.7853 | test_loss: 2.7460 | \n",
      "Epoch: 80 | train_loss: 2.5360 | test_loss: 2.5113 | \n",
      "Epoch: 90 | train_loss: 2.3066 | test_loss: 2.3019 | \n",
      "Epoch: 100 | train_loss: 2.1040 | test_loss: 2.1174 | \n",
      "Epoch: 110 | train_loss: 1.9011 | test_loss: 1.8783 | \n",
      "Epoch: 120 | train_loss: 1.7367 | test_loss: 1.7290 | \n",
      "Epoch: 130 | train_loss: 1.5416 | test_loss: 1.5319 | \n",
      "Epoch: 140 | train_loss: 1.3796 | test_loss: 1.3667 | \n",
      "Epoch: 150 | train_loss: 1.2111 | test_loss: 1.1989 | \n",
      "Epoch: 160 | train_loss: 1.0559 | test_loss: 1.0500 | \n",
      "Epoch: 170 | train_loss: 0.9095 | test_loss: 0.8966 | \n",
      "Epoch: 180 | train_loss: 0.7638 | test_loss: 0.7642 | \n",
      "Epoch: 190 | train_loss: 0.6306 | test_loss: 0.6227 | \n",
      "Epoch: 200 | train_loss: 0.4934 | test_loss: 0.4851 | \n",
      "Epoch: 210 | train_loss: 0.3732 | test_loss: 0.3735 | \n",
      "Epoch: 220 | train_loss: 0.2582 | test_loss: 0.2827 | \n",
      "Epoch: 230 | train_loss: 0.1720 | test_loss: 0.2123 | \n",
      "Epoch: 240 | train_loss: 0.1137 | test_loss: 0.1607 | \n",
      "Epoch: 250 | train_loss: 0.0931 | test_loss: 0.1417 | \n",
      "Epoch: 260 | train_loss: 0.0968 | test_loss: 0.1457 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.5962 | test_loss: 8.6149 | \n",
      "Epoch: 10 | train_loss: 5.8932 | test_loss: 5.7988 | \n",
      "Epoch: 20 | train_loss: 4.8356 | test_loss: 4.7741 | \n",
      "Epoch: 30 | train_loss: 4.1943 | test_loss: 4.1599 | \n",
      "Epoch: 40 | train_loss: 3.7257 | test_loss: 3.6291 | \n",
      "Epoch: 50 | train_loss: 3.3524 | test_loss: 3.3303 | \n",
      "Epoch: 60 | train_loss: 3.0372 | test_loss: 3.0203 | \n",
      "Epoch: 70 | train_loss: 2.7583 | test_loss: 2.7542 | \n",
      "Epoch: 80 | train_loss: 2.5095 | test_loss: 2.4909 | \n",
      "Epoch: 90 | train_loss: 2.2819 | test_loss: 2.2701 | \n",
      "Epoch: 100 | train_loss: 2.0697 | test_loss: 2.0630 | \n",
      "Epoch: 110 | train_loss: 1.8715 | test_loss: 1.8668 | \n",
      "Epoch: 120 | train_loss: 1.6848 | test_loss: 1.6626 | \n",
      "Epoch: 130 | train_loss: 1.5079 | test_loss: 1.4977 | \n",
      "Epoch: 140 | train_loss: 1.3402 | test_loss: 1.3258 | \n",
      "Epoch: 150 | train_loss: 1.1753 | test_loss: 1.1726 | \n",
      "Epoch: 160 | train_loss: 1.0196 | test_loss: 1.0024 | \n",
      "Epoch: 170 | train_loss: 0.8693 | test_loss: 0.8760 | \n",
      "Epoch: 180 | train_loss: 0.7259 | test_loss: 0.7254 | \n",
      "Epoch: 190 | train_loss: 0.5908 | test_loss: 0.5816 | \n",
      "Epoch: 200 | train_loss: 0.4535 | test_loss: 0.4846 | \n",
      "Epoch: 210 | train_loss: 0.3318 | test_loss: 0.3645 | \n",
      "Epoch: 220 | train_loss: 0.2217 | test_loss: 0.2418 | \n",
      "Epoch: 230 | train_loss: 0.1403 | test_loss: 0.2170 | \n",
      "Epoch: 240 | train_loss: 0.1030 | test_loss: 0.1547 | \n",
      "Epoch: 250 | train_loss: 0.0879 | test_loss: 0.1486 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6773 | test_loss: 8.6228 | \n",
      "Epoch: 10 | train_loss: 5.9519 | test_loss: 5.8522 | \n",
      "Epoch: 20 | train_loss: 4.8899 | test_loss: 4.8156 | \n",
      "Epoch: 30 | train_loss: 4.2422 | test_loss: 4.1849 | \n",
      "Epoch: 40 | train_loss: 3.7807 | test_loss: 3.7390 | \n",
      "Epoch: 50 | train_loss: 3.3985 | test_loss: 3.3644 | \n",
      "Epoch: 60 | train_loss: 3.0781 | test_loss: 3.0438 | \n",
      "Epoch: 70 | train_loss: 2.8040 | test_loss: 2.7714 | \n",
      "Epoch: 80 | train_loss: 2.5499 | test_loss: 2.5213 | \n",
      "Epoch: 90 | train_loss: 2.3192 | test_loss: 2.3010 | \n",
      "Epoch: 100 | train_loss: 2.1084 | test_loss: 2.0814 | \n",
      "Epoch: 110 | train_loss: 1.9103 | test_loss: 1.8899 | \n",
      "Epoch: 120 | train_loss: 1.7260 | test_loss: 1.7064 | \n",
      "Epoch: 130 | train_loss: 1.5544 | test_loss: 1.5316 | \n",
      "Epoch: 140 | train_loss: 1.3832 | test_loss: 1.3567 | \n",
      "Epoch: 150 | train_loss: 1.2222 | test_loss: 1.2015 | \n",
      "Epoch: 160 | train_loss: 1.0695 | test_loss: 1.0408 | \n",
      "Epoch: 170 | train_loss: 0.9236 | test_loss: 0.9049 | \n",
      "Epoch: 180 | train_loss: 0.7812 | test_loss: 0.7631 | \n",
      "Epoch: 190 | train_loss: 0.6489 | test_loss: 0.6234 | \n",
      "Epoch: 200 | train_loss: 0.5188 | test_loss: 0.5016 | \n",
      "Epoch: 210 | train_loss: 0.4049 | test_loss: 0.3903 | \n",
      "Epoch: 220 | train_loss: 0.3018 | test_loss: 0.2858 | \n",
      "Epoch: 230 | train_loss: 0.2261 | test_loss: 0.2137 | \n",
      "Epoch: 240 | train_loss: 0.1807 | test_loss: 0.1590 | \n",
      "Epoch: 250 | train_loss: 0.1584 | test_loss: 0.1440 | \n",
      "Epoch: 260 | train_loss: 0.1461 | test_loss: 0.1424 | \n",
      "Epoch: 270 | train_loss: 0.1497 | test_loss: 0.1388 | \n",
      "Epoch: 280 | train_loss: 0.1512 | test_loss: 0.1340 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.7036 | test_loss: 8.6004 | \n",
      "Epoch: 10 | train_loss: 5.9734 | test_loss: 5.8716 | \n",
      "Epoch: 20 | train_loss: 4.9001 | test_loss: 4.8363 | \n",
      "Epoch: 30 | train_loss: 4.2594 | test_loss: 4.2263 | \n",
      "Epoch: 40 | train_loss: 3.7895 | test_loss: 3.7410 | \n",
      "Epoch: 50 | train_loss: 3.4124 | test_loss: 3.3818 | \n",
      "Epoch: 60 | train_loss: 3.0943 | test_loss: 3.0672 | \n",
      "Epoch: 70 | train_loss: 2.8146 | test_loss: 2.7871 | \n",
      "Epoch: 80 | train_loss: 2.5689 | test_loss: 2.5354 | \n",
      "Epoch: 90 | train_loss: 2.3415 | test_loss: 2.3134 | \n",
      "Epoch: 100 | train_loss: 2.1269 | test_loss: 2.1029 | \n",
      "Epoch: 110 | train_loss: 1.9347 | test_loss: 1.9002 | \n",
      "Epoch: 120 | train_loss: 1.7470 | test_loss: 1.7167 | \n",
      "Epoch: 130 | train_loss: 1.5672 | test_loss: 1.5459 | \n",
      "Epoch: 140 | train_loss: 1.4020 | test_loss: 1.3802 | \n",
      "Epoch: 150 | train_loss: 1.2412 | test_loss: 1.2123 | \n",
      "Epoch: 160 | train_loss: 1.0880 | test_loss: 1.0630 | \n",
      "Epoch: 170 | train_loss: 0.9439 | test_loss: 0.9203 | \n",
      "Epoch: 180 | train_loss: 0.7959 | test_loss: 0.7802 | \n",
      "Epoch: 190 | train_loss: 0.6619 | test_loss: 0.6375 | \n",
      "Epoch: 200 | train_loss: 0.5332 | test_loss: 0.5141 | \n",
      "Epoch: 210 | train_loss: 0.4191 | test_loss: 0.4110 | \n",
      "Epoch: 220 | train_loss: 0.3185 | test_loss: 0.3154 | \n",
      "Epoch: 230 | train_loss: 0.2268 | test_loss: 0.2130 | \n",
      "Epoch: 240 | train_loss: 0.1853 | test_loss: 0.1729 | \n",
      "Epoch: 250 | train_loss: 0.1649 | test_loss: 0.1515 | \n",
      "Epoch: 260 | train_loss: 0.1483 | test_loss: 0.1464 | \n",
      "Epoch: 270 | train_loss: 0.1414 | test_loss: 0.1376 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.2676 | test_loss: 4.6678 | \n",
      "Epoch: 10 | train_loss: 0.1801 | test_loss: 0.1675 | \n",
      "Epoch: 20 | train_loss: 0.1546 | test_loss: 0.1535 | \n",
      "Epoch: 30 | train_loss: 0.1412 | test_loss: 0.1486 | \n",
      "Epoch: 40 | train_loss: 0.1365 | test_loss: 0.1466 | \n",
      "Epoch: 50 | train_loss: 0.1290 | test_loss: 0.1452 | \n",
      "Epoch: 60 | train_loss: 0.1256 | test_loss: 0.1435 | \n",
      "Epoch: 70 | train_loss: 0.1219 | test_loss: 0.1408 | \n",
      "Epoch: 80 | train_loss: 0.1153 | test_loss: 0.1395 | \n",
      "Epoch: 90 | train_loss: 0.1140 | test_loss: 0.1381 | \n",
      "Epoch: 100 | train_loss: 0.1082 | test_loss: 0.1387 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.9378 | test_loss: 2.0719 | \n",
      "Epoch: 10 | train_loss: 0.1540 | test_loss: 0.1507 | \n",
      "Epoch: 20 | train_loss: 0.1341 | test_loss: 0.1469 | \n",
      "Epoch: 30 | train_loss: 0.1215 | test_loss: 0.1397 | \n",
      "Epoch: 40 | train_loss: 0.1133 | test_loss: 0.1411 | \n",
      "Epoch: 50 | train_loss: 0.1048 | test_loss: 0.1365 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.1443 | test_loss: 1.5817 | \n",
      "Epoch: 10 | train_loss: 0.1348 | test_loss: 0.1451 | \n",
      "Epoch: 20 | train_loss: 0.1066 | test_loss: 0.1445 | \n",
      "Epoch: 30 | train_loss: 0.0943 | test_loss: 0.1427 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2382 | test_loss: 9.0752 | \n",
      "Epoch: 10 | train_loss: 6.8563 | test_loss: 6.8073 | \n",
      "Epoch: 20 | train_loss: 5.8474 | test_loss: 5.8042 | \n",
      "Epoch: 30 | train_loss: 5.2433 | test_loss: 5.1982 | \n",
      "Epoch: 40 | train_loss: 4.8041 | test_loss: 4.7731 | \n",
      "Epoch: 50 | train_loss: 4.4608 | test_loss: 4.4187 | \n",
      "Epoch: 60 | train_loss: 4.1727 | test_loss: 4.1652 | \n",
      "Epoch: 70 | train_loss: 3.9242 | test_loss: 3.9005 | \n",
      "Epoch: 80 | train_loss: 3.7066 | test_loss: 3.6693 | \n",
      "Epoch: 90 | train_loss: 3.5124 | test_loss: 3.5269 | \n",
      "Epoch: 100 | train_loss: 3.3318 | test_loss: 3.3180 | \n",
      "Epoch: 110 | train_loss: 3.1691 | test_loss: 3.1706 | \n",
      "Epoch: 120 | train_loss: 3.0158 | test_loss: 2.9815 | \n",
      "Epoch: 130 | train_loss: 2.8733 | test_loss: 2.8336 | \n",
      "Epoch: 140 | train_loss: 2.7395 | test_loss: 2.7237 | \n",
      "Epoch: 150 | train_loss: 2.6106 | test_loss: 2.5833 | \n",
      "Epoch: 160 | train_loss: 2.4908 | test_loss: 2.4530 | \n",
      "Epoch: 170 | train_loss: 2.3749 | test_loss: 2.3558 | \n",
      "Epoch: 180 | train_loss: 2.2637 | test_loss: 2.2602 | \n",
      "Epoch: 190 | train_loss: 2.1547 | test_loss: 2.1468 | \n",
      "Epoch: 200 | train_loss: 2.0520 | test_loss: 2.0585 | \n",
      "Epoch: 210 | train_loss: 1.9523 | test_loss: 1.9171 | \n",
      "Epoch: 220 | train_loss: 1.8558 | test_loss: 1.8345 | \n",
      "Epoch: 230 | train_loss: 1.7598 | test_loss: 1.7656 | \n",
      "Epoch: 240 | train_loss: 1.6700 | test_loss: 1.6473 | \n",
      "Epoch: 250 | train_loss: 1.5783 | test_loss: 1.5680 | \n",
      "Epoch: 260 | train_loss: 1.4937 | test_loss: 1.4923 | \n",
      "Epoch: 270 | train_loss: 1.4073 | test_loss: 1.4003 | \n",
      "Epoch: 280 | train_loss: 1.3242 | test_loss: 1.3328 | \n",
      "Epoch: 290 | train_loss: 1.2405 | test_loss: 1.2293 | \n",
      "Epoch: 300 | train_loss: 1.1616 | test_loss: 1.1936 | \n",
      "Epoch: 310 | train_loss: 1.0820 | test_loss: 1.0805 | \n",
      "Epoch: 320 | train_loss: 1.0048 | test_loss: 0.9986 | \n",
      "Epoch: 330 | train_loss: 0.9307 | test_loss: 0.9213 | \n",
      "Epoch: 340 | train_loss: 0.8567 | test_loss: 0.8439 | \n",
      "Epoch: 350 | train_loss: 0.7839 | test_loss: 0.7881 | \n",
      "Epoch: 360 | train_loss: 0.7111 | test_loss: 0.7226 | \n",
      "Epoch: 370 | train_loss: 0.6418 | test_loss: 0.6729 | \n",
      "Epoch: 380 | train_loss: 0.5728 | test_loss: 0.5772 | \n",
      "Epoch: 390 | train_loss: 0.5087 | test_loss: 0.4925 | \n",
      "Epoch: 400 | train_loss: 0.4429 | test_loss: 0.4532 | \n",
      "Epoch: 410 | train_loss: 0.3769 | test_loss: 0.4165 | \n",
      "Epoch: 420 | train_loss: 0.3158 | test_loss: 0.3530 | \n",
      "Epoch: 430 | train_loss: 0.2575 | test_loss: 0.2625 | \n",
      "Epoch: 440 | train_loss: 0.2030 | test_loss: 0.2276 | \n",
      "Epoch: 450 | train_loss: 0.1489 | test_loss: 0.2147 | \n",
      "Epoch: 460 | train_loss: 0.1138 | test_loss: 0.1609 | \n",
      "Epoch: 470 | train_loss: 0.0905 | test_loss: 0.1576 | \n",
      "Epoch: 480 | train_loss: 0.0720 | test_loss: 0.1431 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2305 | test_loss: 9.1749 | \n",
      "Epoch: 10 | train_loss: 6.8643 | test_loss: 6.7921 | \n",
      "Epoch: 20 | train_loss: 5.8467 | test_loss: 5.7692 | \n",
      "Epoch: 30 | train_loss: 5.2398 | test_loss: 5.2095 | \n",
      "Epoch: 40 | train_loss: 4.8000 | test_loss: 4.7801 | \n",
      "Epoch: 50 | train_loss: 4.4554 | test_loss: 4.4319 | \n",
      "Epoch: 60 | train_loss: 4.1704 | test_loss: 4.1682 | \n",
      "Epoch: 70 | train_loss: 3.9212 | test_loss: 3.9056 | \n",
      "Epoch: 80 | train_loss: 3.7050 | test_loss: 3.6934 | \n",
      "Epoch: 90 | train_loss: 3.5085 | test_loss: 3.5041 | \n",
      "Epoch: 100 | train_loss: 3.3317 | test_loss: 3.3145 | \n",
      "Epoch: 110 | train_loss: 3.1688 | test_loss: 3.1411 | \n",
      "Epoch: 120 | train_loss: 3.0160 | test_loss: 3.0223 | \n",
      "Epoch: 130 | train_loss: 2.8729 | test_loss: 2.8458 | \n",
      "Epoch: 140 | train_loss: 2.7404 | test_loss: 2.7178 | \n",
      "Epoch: 150 | train_loss: 2.6267 | test_loss: 2.5314 | \n",
      "Epoch: 160 | train_loss: 2.4915 | test_loss: 2.4641 | \n",
      "Epoch: 170 | train_loss: 2.3753 | test_loss: 2.3623 | \n",
      "Epoch: 180 | train_loss: 2.2636 | test_loss: 2.2386 | \n",
      "Epoch: 190 | train_loss: 2.1565 | test_loss: 2.1449 | \n",
      "Epoch: 200 | train_loss: 2.0525 | test_loss: 2.0380 | \n",
      "Epoch: 210 | train_loss: 1.9526 | test_loss: 1.9391 | \n",
      "Epoch: 220 | train_loss: 1.8564 | test_loss: 1.8452 | \n",
      "Epoch: 230 | train_loss: 1.7608 | test_loss: 1.7555 | \n",
      "Epoch: 240 | train_loss: 1.6687 | test_loss: 1.6738 | \n",
      "Epoch: 250 | train_loss: 1.5792 | test_loss: 1.5730 | \n",
      "Epoch: 260 | train_loss: 1.4923 | test_loss: 1.4794 | \n",
      "Epoch: 270 | train_loss: 1.4074 | test_loss: 1.3979 | \n",
      "Epoch: 280 | train_loss: 1.3246 | test_loss: 1.3144 | \n",
      "Epoch: 290 | train_loss: 1.2422 | test_loss: 1.2329 | \n",
      "Epoch: 300 | train_loss: 1.1653 | test_loss: 1.1606 | \n",
      "Epoch: 310 | train_loss: 1.0839 | test_loss: 1.0783 | \n",
      "Epoch: 320 | train_loss: 1.0086 | test_loss: 0.9851 | \n",
      "Epoch: 330 | train_loss: 0.9298 | test_loss: 0.9321 | \n",
      "Epoch: 340 | train_loss: 0.8561 | test_loss: 0.8631 | \n",
      "Epoch: 350 | train_loss: 0.7830 | test_loss: 0.8086 | \n",
      "Epoch: 360 | train_loss: 0.7116 | test_loss: 0.6883 | \n",
      "Epoch: 370 | train_loss: 0.6419 | test_loss: 0.6577 | \n",
      "Epoch: 380 | train_loss: 0.5729 | test_loss: 0.5778 | \n",
      "Epoch: 390 | train_loss: 0.5070 | test_loss: 0.5124 | \n",
      "Epoch: 400 | train_loss: 0.4411 | test_loss: 0.4627 | \n",
      "Epoch: 410 | train_loss: 0.3791 | test_loss: 0.3895 | \n",
      "Epoch: 420 | train_loss: 0.3157 | test_loss: 0.3346 | \n",
      "Epoch: 430 | train_loss: 0.2588 | test_loss: 0.2724 | \n",
      "Epoch: 440 | train_loss: 0.2212 | test_loss: 0.2057 | \n",
      "Epoch: 450 | train_loss: 0.1552 | test_loss: 0.2013 | \n",
      "Epoch: 460 | train_loss: 0.1109 | test_loss: 0.1611 | \n",
      "Epoch: 470 | train_loss: 0.0843 | test_loss: 0.1538 | \n",
      "Epoch: 480 | train_loss: 0.0719 | test_loss: 0.1390 | \n",
      "Epoch: 490 | train_loss: 0.0602 | test_loss: 0.1370 | \n",
      "Epoch: 500 | train_loss: 0.0579 | test_loss: 0.1338 | \n",
      "Epoch: 510 | train_loss: 0.0568 | test_loss: 0.1340 | \n",
      "Epoch: 520 | train_loss: 0.0542 | test_loss: 0.1359 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3382 | test_loss: 9.1915 | \n",
      "Epoch: 10 | train_loss: 6.9125 | test_loss: 6.8180 | \n",
      "Epoch: 20 | train_loss: 5.9083 | test_loss: 5.8504 | \n",
      "Epoch: 30 | train_loss: 5.2946 | test_loss: 5.2462 | \n",
      "Epoch: 40 | train_loss: 4.8562 | test_loss: 4.8229 | \n",
      "Epoch: 50 | train_loss: 4.5071 | test_loss: 4.4757 | \n",
      "Epoch: 60 | train_loss: 4.2253 | test_loss: 4.1870 | \n",
      "Epoch: 70 | train_loss: 3.9739 | test_loss: 3.9500 | \n",
      "Epoch: 80 | train_loss: 3.7577 | test_loss: 3.7311 | \n",
      "Epoch: 90 | train_loss: 3.5598 | test_loss: 3.5332 | \n",
      "Epoch: 100 | train_loss: 3.3873 | test_loss: 3.3515 | \n",
      "Epoch: 110 | train_loss: 3.2187 | test_loss: 3.1915 | \n",
      "Epoch: 120 | train_loss: 3.0613 | test_loss: 3.0394 | \n",
      "Epoch: 130 | train_loss: 2.9225 | test_loss: 2.8985 | \n",
      "Epoch: 140 | train_loss: 2.7885 | test_loss: 2.7675 | \n",
      "Epoch: 150 | train_loss: 2.6648 | test_loss: 2.6439 | \n",
      "Epoch: 160 | train_loss: 2.5423 | test_loss: 2.5170 | \n",
      "Epoch: 170 | train_loss: 2.4262 | test_loss: 2.4069 | \n",
      "Epoch: 180 | train_loss: 2.3161 | test_loss: 2.2966 | \n",
      "Epoch: 190 | train_loss: 2.2058 | test_loss: 2.1849 | \n",
      "Epoch: 200 | train_loss: 2.1037 | test_loss: 2.0874 | \n",
      "Epoch: 210 | train_loss: 2.0019 | test_loss: 1.9836 | \n",
      "Epoch: 220 | train_loss: 1.9060 | test_loss: 1.8860 | \n",
      "Epoch: 230 | train_loss: 1.8128 | test_loss: 1.7949 | \n",
      "Epoch: 240 | train_loss: 1.7225 | test_loss: 1.7046 | \n",
      "Epoch: 250 | train_loss: 1.6307 | test_loss: 1.6169 | \n",
      "Epoch: 260 | train_loss: 1.5462 | test_loss: 1.5256 | \n",
      "Epoch: 270 | train_loss: 1.4572 | test_loss: 1.4355 | \n",
      "Epoch: 280 | train_loss: 1.3764 | test_loss: 1.3532 | \n",
      "Epoch: 290 | train_loss: 1.2904 | test_loss: 1.2743 | \n",
      "Epoch: 300 | train_loss: 1.2141 | test_loss: 1.1995 | \n",
      "Epoch: 310 | train_loss: 1.1361 | test_loss: 1.1262 | \n",
      "Epoch: 320 | train_loss: 1.0593 | test_loss: 1.0518 | \n",
      "Epoch: 330 | train_loss: 0.9841 | test_loss: 0.9676 | \n",
      "Epoch: 340 | train_loss: 0.9103 | test_loss: 0.8967 | \n",
      "Epoch: 350 | train_loss: 0.8413 | test_loss: 0.8219 | \n",
      "Epoch: 360 | train_loss: 0.7670 | test_loss: 0.7581 | \n",
      "Epoch: 370 | train_loss: 0.6912 | test_loss: 0.6860 | \n",
      "Epoch: 380 | train_loss: 0.6325 | test_loss: 0.6227 | \n",
      "Epoch: 390 | train_loss: 0.5654 | test_loss: 0.5494 | \n",
      "Epoch: 400 | train_loss: 0.5001 | test_loss: 0.4888 | \n",
      "Epoch: 410 | train_loss: 0.4395 | test_loss: 0.4309 | \n",
      "Epoch: 420 | train_loss: 0.3793 | test_loss: 0.3646 | \n",
      "Epoch: 430 | train_loss: 0.3286 | test_loss: 0.3074 | \n",
      "Epoch: 440 | train_loss: 0.2775 | test_loss: 0.2732 | \n",
      "Epoch: 450 | train_loss: 0.2334 | test_loss: 0.2291 | \n",
      "Epoch: 460 | train_loss: 0.2001 | test_loss: 0.2000 | \n",
      "Epoch: 470 | train_loss: 0.1848 | test_loss: 0.1842 | \n",
      "Epoch: 480 | train_loss: 0.1499 | test_loss: 0.1662 | \n",
      "Epoch: 490 | train_loss: 0.1402 | test_loss: 0.1433 | \n",
      "Epoch: 500 | train_loss: 0.1322 | test_loss: 0.1411 | \n",
      "Epoch: 510 | train_loss: 0.1279 | test_loss: 0.1386 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3871 | test_loss: 9.0966 | \n",
      "Epoch: 10 | train_loss: 6.9813 | test_loss: 6.8878 | \n",
      "Epoch: 20 | train_loss: 5.9707 | test_loss: 5.9007 | \n",
      "Epoch: 30 | train_loss: 5.3547 | test_loss: 5.2883 | \n",
      "Epoch: 40 | train_loss: 4.9083 | test_loss: 4.8594 | \n",
      "Epoch: 50 | train_loss: 4.5712 | test_loss: 4.5183 | \n",
      "Epoch: 60 | train_loss: 4.2770 | test_loss: 4.2365 | \n",
      "Epoch: 70 | train_loss: 4.0270 | test_loss: 3.9857 | \n",
      "Epoch: 80 | train_loss: 3.8046 | test_loss: 3.7645 | \n",
      "Epoch: 90 | train_loss: 3.6094 | test_loss: 3.5739 | \n",
      "Epoch: 100 | train_loss: 3.4293 | test_loss: 3.3946 | \n",
      "Epoch: 110 | train_loss: 3.2669 | test_loss: 3.2379 | \n",
      "Epoch: 120 | train_loss: 3.1105 | test_loss: 3.0857 | \n",
      "Epoch: 130 | train_loss: 2.9724 | test_loss: 2.9424 | \n",
      "Epoch: 140 | train_loss: 2.8395 | test_loss: 2.8166 | \n",
      "Epoch: 150 | train_loss: 2.7059 | test_loss: 2.6812 | \n",
      "Epoch: 160 | train_loss: 2.5897 | test_loss: 2.5658 | \n",
      "Epoch: 170 | train_loss: 2.4737 | test_loss: 2.4459 | \n",
      "Epoch: 180 | train_loss: 2.3572 | test_loss: 2.3430 | \n",
      "Epoch: 190 | train_loss: 2.2562 | test_loss: 2.2299 | \n",
      "Epoch: 200 | train_loss: 2.1526 | test_loss: 2.1333 | \n",
      "Epoch: 210 | train_loss: 2.0517 | test_loss: 2.0286 | \n",
      "Epoch: 220 | train_loss: 1.9553 | test_loss: 1.9274 | \n",
      "Epoch: 230 | train_loss: 1.8560 | test_loss: 1.8355 | \n",
      "Epoch: 240 | train_loss: 1.7646 | test_loss: 1.7473 | \n",
      "Epoch: 250 | train_loss: 1.6761 | test_loss: 1.6542 | \n",
      "Epoch: 260 | train_loss: 1.5892 | test_loss: 1.5743 | \n",
      "Epoch: 270 | train_loss: 1.5019 | test_loss: 1.4899 | \n",
      "Epoch: 280 | train_loss: 1.4229 | test_loss: 1.4047 | \n",
      "Epoch: 290 | train_loss: 1.3432 | test_loss: 1.3250 | \n",
      "Epoch: 300 | train_loss: 1.2606 | test_loss: 1.2404 | \n",
      "Epoch: 310 | train_loss: 1.1757 | test_loss: 1.1608 | \n",
      "Epoch: 320 | train_loss: 1.1048 | test_loss: 1.0849 | \n",
      "Epoch: 330 | train_loss: 1.0253 | test_loss: 1.0079 | \n",
      "Epoch: 340 | train_loss: 0.9530 | test_loss: 0.9360 | \n",
      "Epoch: 350 | train_loss: 0.8814 | test_loss: 0.8662 | \n",
      "Epoch: 360 | train_loss: 0.8160 | test_loss: 0.7943 | \n",
      "Epoch: 370 | train_loss: 0.7414 | test_loss: 0.7302 | \n",
      "Epoch: 380 | train_loss: 0.6717 | test_loss: 0.6598 | \n",
      "Epoch: 390 | train_loss: 0.6073 | test_loss: 0.6003 | \n",
      "Epoch: 400 | train_loss: 0.5425 | test_loss: 0.5295 | \n",
      "Epoch: 410 | train_loss: 0.4804 | test_loss: 0.4596 | \n",
      "Epoch: 420 | train_loss: 0.4158 | test_loss: 0.4165 | \n",
      "Epoch: 430 | train_loss: 0.3594 | test_loss: 0.3581 | \n",
      "Epoch: 440 | train_loss: 0.3063 | test_loss: 0.3056 | \n",
      "Epoch: 450 | train_loss: 0.2625 | test_loss: 0.2519 | \n",
      "Epoch: 460 | train_loss: 0.2161 | test_loss: 0.2149 | \n",
      "Epoch: 470 | train_loss: 0.1830 | test_loss: 0.1855 | \n",
      "Epoch: 480 | train_loss: 0.1565 | test_loss: 0.1658 | \n",
      "Epoch: 490 | train_loss: 0.1492 | test_loss: 0.1540 | \n",
      "Epoch: 500 | train_loss: 0.1310 | test_loss: 0.1343 | \n",
      "Epoch: 510 | train_loss: 0.1331 | test_loss: 0.1409 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.7493 | test_loss: 8.0376 | \n",
      "Epoch: 10 | train_loss: 0.6209 | test_loss: 0.4952 | \n",
      "Epoch: 20 | train_loss: 0.1852 | test_loss: 0.1749 | \n",
      "Epoch: 30 | train_loss: 0.1663 | test_loss: 0.1622 | \n",
      "Epoch: 40 | train_loss: 0.1566 | test_loss: 0.1569 | \n",
      "Epoch: 50 | train_loss: 0.1492 | test_loss: 0.1532 | \n",
      "Epoch: 60 | train_loss: 0.1443 | test_loss: 0.1522 | \n",
      "Epoch: 70 | train_loss: 0.1398 | test_loss: 0.1489 | \n",
      "Epoch: 80 | train_loss: 0.1375 | test_loss: 0.1485 | \n",
      "Epoch: 90 | train_loss: 0.1352 | test_loss: 0.1481 | \n",
      "Epoch: 100 | train_loss: 0.1331 | test_loss: 0.1465 | \n",
      "Epoch: 110 | train_loss: 0.1313 | test_loss: 0.1456 | \n",
      "Epoch: 120 | train_loss: 0.1281 | test_loss: 0.1449 | \n",
      "Epoch: 130 | train_loss: 0.1263 | test_loss: 0.1442 | \n",
      "Epoch: 140 | train_loss: 0.1250 | test_loss: 0.1431 | \n",
      "Epoch: 150 | train_loss: 0.1236 | test_loss: 0.1431 | \n",
      "Epoch: 160 | train_loss: 0.1214 | test_loss: 0.1424 | \n",
      "Epoch: 170 | train_loss: 0.1194 | test_loss: 0.1418 | \n",
      "Epoch: 180 | train_loss: 0.1163 | test_loss: 0.1411 | \n",
      "Epoch: 190 | train_loss: 0.1160 | test_loss: 0.1396 | \n",
      "Epoch: 200 | train_loss: 0.1144 | test_loss: 0.1399 | \n",
      "Epoch: 210 | train_loss: 0.1127 | test_loss: 0.1393 | \n",
      "Epoch: 220 | train_loss: 0.1093 | test_loss: 0.1391 | \n",
      "Epoch: 230 | train_loss: 0.1058 | test_loss: 0.1384 | \n",
      "Epoch: 240 | train_loss: 0.1044 | test_loss: 0.1377 | \n",
      "Epoch: 250 | train_loss: 0.1020 | test_loss: 0.1368 | \n",
      "Epoch: 260 | train_loss: 0.0989 | test_loss: 0.1380 | \n",
      "Epoch: 270 | train_loss: 0.0965 | test_loss: 0.1372 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.2485 | test_loss: 4.3959 | \n",
      "Epoch: 10 | train_loss: 0.1890 | test_loss: 0.1769 | \n",
      "Epoch: 20 | train_loss: 0.1496 | test_loss: 0.1496 | \n",
      "Epoch: 30 | train_loss: 0.1379 | test_loss: 0.1457 | \n",
      "Epoch: 40 | train_loss: 0.1307 | test_loss: 0.1438 | \n",
      "Epoch: 50 | train_loss: 0.1231 | test_loss: 0.1415 | \n",
      "Epoch: 60 | train_loss: 0.1184 | test_loss: 0.1441 | \n",
      "Epoch: 70 | train_loss: 0.1109 | test_loss: 0.1390 | \n",
      "Epoch: 80 | train_loss: 0.1045 | test_loss: 0.1387 | \n",
      "Epoch: 90 | train_loss: 0.1012 | test_loss: 0.1389 | \n",
      "Epoch: 100 | train_loss: 0.0945 | test_loss: 0.1383 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 4.7372 | test_loss: 0.5705 | \n",
      "Epoch: 10 | train_loss: 0.1561 | test_loss: 0.1560 | \n",
      "Epoch: 20 | train_loss: 0.1366 | test_loss: 0.1644 | \n",
      "Epoch: 30 | train_loss: 0.1162 | test_loss: 0.1466 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8847 | test_loss: 9.2700 | \n",
      "Epoch: 10 | train_loss: 7.7374 | test_loss: 7.6821 | \n",
      "Epoch: 20 | train_loss: 6.8265 | test_loss: 6.7663 | \n",
      "Epoch: 30 | train_loss: 6.2500 | test_loss: 6.1870 | \n",
      "Epoch: 40 | train_loss: 5.8345 | test_loss: 5.8234 | \n",
      "Epoch: 50 | train_loss: 5.5083 | test_loss: 5.4759 | \n",
      "Epoch: 60 | train_loss: 5.2369 | test_loss: 5.1957 | \n",
      "Epoch: 70 | train_loss: 5.0048 | test_loss: 4.9674 | \n",
      "Epoch: 80 | train_loss: 4.8027 | test_loss: 4.7921 | \n",
      "Epoch: 90 | train_loss: 4.6208 | test_loss: 4.6047 | \n",
      "Epoch: 100 | train_loss: 4.4573 | test_loss: 4.4528 | \n",
      "Epoch: 110 | train_loss: 4.3094 | test_loss: 4.2881 | \n",
      "Epoch: 120 | train_loss: 4.1716 | test_loss: 4.1525 | \n",
      "Epoch: 130 | train_loss: 4.0438 | test_loss: 4.0260 | \n",
      "Epoch: 140 | train_loss: 3.9263 | test_loss: 3.9038 | \n",
      "Epoch: 150 | train_loss: 3.8151 | test_loss: 3.8056 | \n",
      "Epoch: 160 | train_loss: 3.7109 | test_loss: 3.6959 | \n",
      "Epoch: 170 | train_loss: 3.6100 | test_loss: 3.6032 | \n",
      "Epoch: 180 | train_loss: 3.5157 | test_loss: 3.4914 | \n",
      "Epoch: 190 | train_loss: 3.4247 | test_loss: 3.4066 | \n",
      "Epoch: 200 | train_loss: 3.3378 | test_loss: 3.3240 | \n",
      "Epoch: 210 | train_loss: 3.2569 | test_loss: 3.2423 | \n",
      "Epoch: 220 | train_loss: 3.1748 | test_loss: 3.1558 | \n",
      "Epoch: 230 | train_loss: 3.0976 | test_loss: 3.0776 | \n",
      "Epoch: 240 | train_loss: 3.0232 | test_loss: 2.9980 | \n",
      "Epoch: 250 | train_loss: 2.9513 | test_loss: 2.9412 | \n",
      "Epoch: 260 | train_loss: 2.8831 | test_loss: 2.8616 | \n",
      "Epoch: 270 | train_loss: 2.8137 | test_loss: 2.7946 | \n",
      "Epoch: 280 | train_loss: 2.7488 | test_loss: 2.7338 | \n",
      "Epoch: 290 | train_loss: 2.6840 | test_loss: 2.6778 | \n",
      "Epoch: 300 | train_loss: 2.6222 | test_loss: 2.6126 | \n",
      "Epoch: 310 | train_loss: 2.5596 | test_loss: 2.5536 | \n",
      "Epoch: 320 | train_loss: 2.5011 | test_loss: 2.5038 | \n",
      "Epoch: 330 | train_loss: 2.4422 | test_loss: 2.4287 | \n",
      "Epoch: 340 | train_loss: 2.3849 | test_loss: 2.3679 | \n",
      "Epoch: 350 | train_loss: 2.3275 | test_loss: 2.3219 | \n",
      "Epoch: 360 | train_loss: 2.2747 | test_loss: 2.2657 | \n",
      "Epoch: 370 | train_loss: 2.2192 | test_loss: 2.2035 | \n",
      "Epoch: 380 | train_loss: 2.1687 | test_loss: 2.1598 | \n",
      "Epoch: 390 | train_loss: 2.1176 | test_loss: 2.0913 | \n",
      "Epoch: 400 | train_loss: 2.0640 | test_loss: 2.0599 | \n",
      "Epoch: 410 | train_loss: 2.0121 | test_loss: 1.9949 | \n",
      "Epoch: 420 | train_loss: 1.9616 | test_loss: 1.9598 | \n",
      "Epoch: 430 | train_loss: 1.9139 | test_loss: 1.9002 | \n",
      "Epoch: 440 | train_loss: 1.8651 | test_loss: 1.8561 | \n",
      "Epoch: 450 | train_loss: 1.8175 | test_loss: 1.8053 | \n",
      "Epoch: 460 | train_loss: 1.7713 | test_loss: 1.7607 | \n",
      "Epoch: 470 | train_loss: 1.7282 | test_loss: 1.7307 | \n",
      "Epoch: 480 | train_loss: 1.6810 | test_loss: 1.6684 | \n",
      "Epoch: 490 | train_loss: 1.6344 | test_loss: 1.6222 | \n",
      "Epoch: 500 | train_loss: 1.5893 | test_loss: 1.5851 | \n",
      "Epoch: 510 | train_loss: 1.5440 | test_loss: 1.5461 | \n",
      "Epoch: 520 | train_loss: 1.5022 | test_loss: 1.4941 | \n",
      "Epoch: 530 | train_loss: 1.4583 | test_loss: 1.4499 | \n",
      "Epoch: 540 | train_loss: 1.4155 | test_loss: 1.4187 | \n",
      "Epoch: 550 | train_loss: 1.3726 | test_loss: 1.3641 | \n",
      "Epoch: 560 | train_loss: 1.3322 | test_loss: 1.3326 | \n",
      "Epoch: 570 | train_loss: 1.2912 | test_loss: 1.2702 | \n",
      "Epoch: 580 | train_loss: 1.2495 | test_loss: 1.2526 | \n",
      "Epoch: 590 | train_loss: 1.2089 | test_loss: 1.2181 | \n",
      "Epoch: 600 | train_loss: 1.1716 | test_loss: 1.1987 | \n",
      "Epoch: 610 | train_loss: 1.1299 | test_loss: 1.1241 | \n",
      "Epoch: 620 | train_loss: 1.0909 | test_loss: 1.0993 | \n",
      "Epoch: 630 | train_loss: 1.0518 | test_loss: 1.0510 | \n",
      "Epoch: 640 | train_loss: 1.0128 | test_loss: 1.0061 | \n",
      "Epoch: 650 | train_loss: 0.9749 | test_loss: 0.9818 | \n",
      "Epoch: 660 | train_loss: 0.9373 | test_loss: 0.9426 | \n",
      "Epoch: 670 | train_loss: 0.9008 | test_loss: 0.8945 | \n",
      "Epoch: 680 | train_loss: 0.8635 | test_loss: 0.8626 | \n",
      "Epoch: 690 | train_loss: 0.8268 | test_loss: 0.8237 | \n",
      "Epoch: 700 | train_loss: 0.7899 | test_loss: 0.8068 | \n",
      "Epoch: 710 | train_loss: 0.7542 | test_loss: 0.7661 | \n",
      "Epoch: 720 | train_loss: 0.7196 | test_loss: 0.7279 | \n",
      "Epoch: 730 | train_loss: 0.6826 | test_loss: 0.6850 | \n",
      "Epoch: 740 | train_loss: 0.6498 | test_loss: 0.6722 | \n",
      "Epoch: 750 | train_loss: 0.6140 | test_loss: 0.6068 | \n",
      "Epoch: 760 | train_loss: 0.5811 | test_loss: 0.5838 | \n",
      "Epoch: 770 | train_loss: 0.5454 | test_loss: 0.5585 | \n",
      "Epoch: 780 | train_loss: 0.5118 | test_loss: 0.5103 | \n",
      "Epoch: 790 | train_loss: 0.4794 | test_loss: 0.4848 | \n",
      "Epoch: 800 | train_loss: 0.4448 | test_loss: 0.4578 | \n",
      "Epoch: 810 | train_loss: 0.4135 | test_loss: 0.4465 | \n",
      "Epoch: 820 | train_loss: 0.3832 | test_loss: 0.4034 | \n",
      "Epoch: 830 | train_loss: 0.3492 | test_loss: 0.3734 | \n",
      "Epoch: 840 | train_loss: 0.3190 | test_loss: 0.3387 | \n",
      "Epoch: 850 | train_loss: 0.2907 | test_loss: 0.3237 | \n",
      "Epoch: 860 | train_loss: 0.2605 | test_loss: 0.2842 | \n",
      "Epoch: 870 | train_loss: 0.2298 | test_loss: 0.2548 | \n",
      "Epoch: 880 | train_loss: 0.2001 | test_loss: 0.2221 | \n",
      "Epoch: 890 | train_loss: 0.1739 | test_loss: 0.2219 | \n",
      "Epoch: 900 | train_loss: 0.1511 | test_loss: 0.2107 | \n",
      "Epoch: 910 | train_loss: 0.1226 | test_loss: 0.1785 | \n",
      "Epoch: 920 | train_loss: 0.0995 | test_loss: 0.1736 | \n",
      "Epoch: 930 | train_loss: 0.0873 | test_loss: 0.1529 | \n",
      "Epoch: 940 | train_loss: 0.0677 | test_loss: 0.1560 | \n",
      "Epoch: 950 | train_loss: 0.0479 | test_loss: 0.1472 | \n",
      "Epoch: 960 | train_loss: 0.0490 | test_loss: 0.1383 | \n",
      "Epoch: 970 | train_loss: 0.0442 | test_loss: 0.1423 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8322 | test_loss: 9.1330 | \n",
      "Epoch: 10 | train_loss: 7.6723 | test_loss: 7.6119 | \n",
      "Epoch: 20 | train_loss: 6.7827 | test_loss: 6.7743 | \n",
      "Epoch: 30 | train_loss: 6.1998 | test_loss: 6.1412 | \n",
      "Epoch: 40 | train_loss: 5.7833 | test_loss: 5.7167 | \n",
      "Epoch: 50 | train_loss: 5.4527 | test_loss: 5.4343 | \n",
      "Epoch: 60 | train_loss: 5.1818 | test_loss: 5.1496 | \n",
      "Epoch: 70 | train_loss: 4.9503 | test_loss: 4.9256 | \n",
      "Epoch: 80 | train_loss: 4.7479 | test_loss: 4.7265 | \n",
      "Epoch: 90 | train_loss: 4.5654 | test_loss: 4.5490 | \n",
      "Epoch: 100 | train_loss: 4.4035 | test_loss: 4.3842 | \n",
      "Epoch: 110 | train_loss: 4.2552 | test_loss: 4.2430 | \n",
      "Epoch: 120 | train_loss: 4.1169 | test_loss: 4.1015 | \n",
      "Epoch: 130 | train_loss: 3.9904 | test_loss: 3.9643 | \n",
      "Epoch: 140 | train_loss: 3.8730 | test_loss: 3.8330 | \n",
      "Epoch: 150 | train_loss: 3.7591 | test_loss: 3.7386 | \n",
      "Epoch: 160 | train_loss: 3.6536 | test_loss: 3.6004 | \n",
      "Epoch: 170 | train_loss: 3.5526 | test_loss: 3.5283 | \n",
      "Epoch: 180 | train_loss: 3.4574 | test_loss: 3.4351 | \n",
      "Epoch: 190 | train_loss: 3.3680 | test_loss: 3.3477 | \n",
      "Epoch: 200 | train_loss: 3.2817 | test_loss: 3.2503 | \n",
      "Epoch: 210 | train_loss: 3.1978 | test_loss: 3.1689 | \n",
      "Epoch: 220 | train_loss: 3.1184 | test_loss: 3.1056 | \n",
      "Epoch: 230 | train_loss: 3.0412 | test_loss: 3.0122 | \n",
      "Epoch: 240 | train_loss: 2.9657 | test_loss: 2.9323 | \n",
      "Epoch: 250 | train_loss: 2.8952 | test_loss: 2.8835 | \n",
      "Epoch: 260 | train_loss: 2.8241 | test_loss: 2.8129 | \n",
      "Epoch: 270 | train_loss: 2.7558 | test_loss: 2.7457 | \n",
      "Epoch: 280 | train_loss: 2.6988 | test_loss: 2.6588 | \n",
      "Epoch: 290 | train_loss: 2.6238 | test_loss: 2.6120 | \n",
      "Epoch: 300 | train_loss: 2.5619 | test_loss: 2.5426 | \n",
      "Epoch: 310 | train_loss: 2.5005 | test_loss: 2.5018 | \n",
      "Epoch: 320 | train_loss: 2.4416 | test_loss: 2.4265 | \n",
      "Epoch: 330 | train_loss: 2.3832 | test_loss: 2.3558 | \n",
      "Epoch: 340 | train_loss: 2.3261 | test_loss: 2.3109 | \n",
      "Epoch: 350 | train_loss: 2.2685 | test_loss: 2.2672 | \n",
      "Epoch: 360 | train_loss: 2.2141 | test_loss: 2.2089 | \n",
      "Epoch: 370 | train_loss: 2.1602 | test_loss: 2.1582 | \n",
      "Epoch: 380 | train_loss: 2.1067 | test_loss: 2.1077 | \n",
      "Epoch: 390 | train_loss: 2.0554 | test_loss: 2.0497 | \n",
      "Epoch: 400 | train_loss: 2.0041 | test_loss: 1.9889 | \n",
      "Epoch: 410 | train_loss: 1.9546 | test_loss: 1.9272 | \n",
      "Epoch: 420 | train_loss: 1.9042 | test_loss: 1.8984 | \n",
      "Epoch: 430 | train_loss: 1.8546 | test_loss: 1.8523 | \n",
      "Epoch: 440 | train_loss: 1.8080 | test_loss: 1.7922 | \n",
      "Epoch: 450 | train_loss: 1.7612 | test_loss: 1.7448 | \n",
      "Epoch: 460 | train_loss: 1.7151 | test_loss: 1.6891 | \n",
      "Epoch: 470 | train_loss: 1.6688 | test_loss: 1.6694 | \n",
      "Epoch: 480 | train_loss: 1.6226 | test_loss: 1.6138 | \n",
      "Epoch: 490 | train_loss: 1.5787 | test_loss: 1.5834 | \n",
      "Epoch: 500 | train_loss: 1.5324 | test_loss: 1.5346 | \n",
      "Epoch: 510 | train_loss: 1.4898 | test_loss: 1.4931 | \n",
      "Epoch: 520 | train_loss: 1.4460 | test_loss: 1.4306 | \n",
      "Epoch: 530 | train_loss: 1.4031 | test_loss: 1.3733 | \n",
      "Epoch: 540 | train_loss: 1.3621 | test_loss: 1.3738 | \n",
      "Epoch: 550 | train_loss: 1.3196 | test_loss: 1.3318 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.9484 | test_loss: 10.0933 | \n",
      "Epoch: 10 | train_loss: 7.8128 | test_loss: 7.7255 | \n",
      "Epoch: 20 | train_loss: 6.9300 | test_loss: 6.8696 | \n",
      "Epoch: 30 | train_loss: 6.3478 | test_loss: 6.2933 | \n",
      "Epoch: 40 | train_loss: 5.9310 | test_loss: 5.8742 | \n",
      "Epoch: 50 | train_loss: 5.5956 | test_loss: 5.5533 | \n",
      "Epoch: 60 | train_loss: 5.3192 | test_loss: 5.2905 | \n",
      "Epoch: 70 | train_loss: 5.0886 | test_loss: 5.0542 | \n",
      "Epoch: 80 | train_loss: 4.8831 | test_loss: 4.8468 | \n",
      "Epoch: 90 | train_loss: 4.7012 | test_loss: 4.6673 | \n",
      "Epoch: 100 | train_loss: 4.5419 | test_loss: 4.5060 | \n",
      "Epoch: 110 | train_loss: 4.3899 | test_loss: 4.3513 | \n",
      "Epoch: 120 | train_loss: 4.2438 | test_loss: 4.2164 | \n",
      "Epoch: 130 | train_loss: 4.1211 | test_loss: 4.0900 | \n",
      "Epoch: 140 | train_loss: 3.9995 | test_loss: 3.9698 | \n",
      "Epoch: 150 | train_loss: 3.8873 | test_loss: 3.8587 | \n",
      "Epoch: 160 | train_loss: 3.7870 | test_loss: 3.7554 | \n",
      "Epoch: 170 | train_loss: 3.6830 | test_loss: 3.6554 | \n",
      "Epoch: 180 | train_loss: 3.5822 | test_loss: 3.5571 | \n",
      "Epoch: 190 | train_loss: 3.4990 | test_loss: 3.4708 | \n",
      "Epoch: 200 | train_loss: 3.4095 | test_loss: 3.3844 | \n",
      "Epoch: 210 | train_loss: 3.3243 | test_loss: 3.3000 | \n",
      "Epoch: 220 | train_loss: 3.2452 | test_loss: 3.2222 | \n",
      "Epoch: 230 | train_loss: 3.1734 | test_loss: 3.1507 | \n",
      "Epoch: 240 | train_loss: 3.0921 | test_loss: 3.0666 | \n",
      "Epoch: 250 | train_loss: 3.0172 | test_loss: 2.9953 | \n",
      "Epoch: 260 | train_loss: 2.9485 | test_loss: 2.9249 | \n",
      "Epoch: 270 | train_loss: 2.8813 | test_loss: 2.8564 | \n",
      "Epoch: 280 | train_loss: 2.8153 | test_loss: 2.7947 | \n",
      "Epoch: 290 | train_loss: 2.7548 | test_loss: 2.7295 | \n",
      "Epoch: 300 | train_loss: 2.6903 | test_loss: 2.6676 | \n",
      "Epoch: 310 | train_loss: 2.6280 | test_loss: 2.6087 | \n",
      "Epoch: 320 | train_loss: 2.5710 | test_loss: 2.5494 | \n",
      "Epoch: 330 | train_loss: 2.5064 | test_loss: 2.4892 | \n",
      "Epoch: 340 | train_loss: 2.4491 | test_loss: 2.4351 | \n",
      "Epoch: 350 | train_loss: 2.3936 | test_loss: 2.3778 | \n",
      "Epoch: 360 | train_loss: 2.3412 | test_loss: 2.3212 | \n",
      "Epoch: 370 | train_loss: 2.2864 | test_loss: 2.2661 | \n",
      "Epoch: 380 | train_loss: 2.2364 | test_loss: 2.2133 | \n",
      "Epoch: 390 | train_loss: 2.1843 | test_loss: 2.1608 | \n",
      "Epoch: 400 | train_loss: 2.1314 | test_loss: 2.1088 | \n",
      "Epoch: 410 | train_loss: 2.0787 | test_loss: 2.0588 | \n",
      "Epoch: 420 | train_loss: 2.0325 | test_loss: 2.0095 | \n",
      "Epoch: 430 | train_loss: 1.9877 | test_loss: 1.9608 | \n",
      "Epoch: 440 | train_loss: 1.9309 | test_loss: 1.9126 | \n",
      "Epoch: 450 | train_loss: 1.8872 | test_loss: 1.8641 | \n",
      "Epoch: 460 | train_loss: 1.8384 | test_loss: 1.8211 | \n",
      "Epoch: 470 | train_loss: 1.7919 | test_loss: 1.7709 | \n",
      "Epoch: 480 | train_loss: 1.7502 | test_loss: 1.7267 | \n",
      "Epoch: 490 | train_loss: 1.7083 | test_loss: 1.6851 | \n",
      "Epoch: 500 | train_loss: 1.6555 | test_loss: 1.6326 | \n",
      "Epoch: 510 | train_loss: 1.6110 | test_loss: 1.5944 | \n",
      "Epoch: 520 | train_loss: 1.5733 | test_loss: 1.5503 | \n",
      "Epoch: 530 | train_loss: 1.5229 | test_loss: 1.5038 | \n",
      "Epoch: 540 | train_loss: 1.4857 | test_loss: 1.4653 | \n",
      "Epoch: 550 | train_loss: 1.4433 | test_loss: 1.4215 | \n",
      "Epoch: 560 | train_loss: 1.4016 | test_loss: 1.3826 | \n",
      "Epoch: 570 | train_loss: 1.3591 | test_loss: 1.3357 | \n",
      "Epoch: 580 | train_loss: 1.3135 | test_loss: 1.3026 | \n",
      "Epoch: 590 | train_loss: 1.2751 | test_loss: 1.2619 | \n",
      "Epoch: 600 | train_loss: 1.2446 | test_loss: 1.2229 | \n",
      "Epoch: 610 | train_loss: 1.2039 | test_loss: 1.1801 | \n",
      "Epoch: 620 | train_loss: 1.1597 | test_loss: 1.1397 | \n",
      "Epoch: 630 | train_loss: 1.1208 | test_loss: 1.1099 | \n",
      "Epoch: 640 | train_loss: 1.0829 | test_loss: 1.0666 | \n",
      "Epoch: 650 | train_loss: 1.0426 | test_loss: 1.0243 | \n",
      "Epoch: 660 | train_loss: 1.0064 | test_loss: 0.9870 | \n",
      "Epoch: 670 | train_loss: 0.9700 | test_loss: 0.9585 | \n",
      "Epoch: 680 | train_loss: 0.9358 | test_loss: 0.9130 | \n",
      "Epoch: 690 | train_loss: 0.8981 | test_loss: 0.8911 | \n",
      "Epoch: 700 | train_loss: 0.8626 | test_loss: 0.8439 | \n",
      "Epoch: 710 | train_loss: 0.8259 | test_loss: 0.8101 | \n",
      "Epoch: 720 | train_loss: 0.7885 | test_loss: 0.7779 | \n",
      "Epoch: 730 | train_loss: 0.7527 | test_loss: 0.7404 | \n",
      "Epoch: 740 | train_loss: 0.7175 | test_loss: 0.6976 | \n",
      "Epoch: 750 | train_loss: 0.6903 | test_loss: 0.6769 | \n",
      "Epoch: 760 | train_loss: 0.6525 | test_loss: 0.6438 | \n",
      "Epoch: 770 | train_loss: 0.6185 | test_loss: 0.6076 | \n",
      "Epoch: 780 | train_loss: 0.5875 | test_loss: 0.5705 | \n",
      "Epoch: 790 | train_loss: 0.5514 | test_loss: 0.5406 | \n",
      "Epoch: 800 | train_loss: 0.5172 | test_loss: 0.5197 | \n",
      "Epoch: 810 | train_loss: 0.4836 | test_loss: 0.4760 | \n",
      "Epoch: 820 | train_loss: 0.4579 | test_loss: 0.4433 | \n",
      "Epoch: 830 | train_loss: 0.4243 | test_loss: 0.4196 | \n",
      "Epoch: 840 | train_loss: 0.3967 | test_loss: 0.3916 | \n",
      "Epoch: 850 | train_loss: 0.3626 | test_loss: 0.3601 | \n",
      "Epoch: 860 | train_loss: 0.3359 | test_loss: 0.3389 | \n",
      "Epoch: 870 | train_loss: 0.3113 | test_loss: 0.3072 | \n",
      "Epoch: 880 | train_loss: 0.2841 | test_loss: 0.2727 | \n",
      "Epoch: 890 | train_loss: 0.2601 | test_loss: 0.2583 | \n",
      "Epoch: 900 | train_loss: 0.2358 | test_loss: 0.2374 | \n",
      "Epoch: 910 | train_loss: 0.2170 | test_loss: 0.2145 | \n",
      "Epoch: 920 | train_loss: 0.1980 | test_loss: 0.2066 | \n",
      "Epoch: 930 | train_loss: 0.1749 | test_loss: 0.1802 | \n",
      "Epoch: 940 | train_loss: 0.1549 | test_loss: 0.1682 | \n",
      "Epoch: 950 | train_loss: 0.1493 | test_loss: 0.1521 | \n",
      "Epoch: 960 | train_loss: 0.1344 | test_loss: 0.1525 | \n",
      "Epoch: 970 | train_loss: 0.1310 | test_loss: 0.1394 | \n",
      "Epoch: 980 | train_loss: 0.1197 | test_loss: 0.1376 | \n",
      "Epoch: 990 | train_loss: 0.1267 | test_loss: 0.1389 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8995 | test_loss: 9.6626 | \n",
      "Epoch: 10 | train_loss: 7.7743 | test_loss: 7.6856 | \n",
      "Epoch: 20 | train_loss: 6.8827 | test_loss: 6.8198 | \n",
      "Epoch: 30 | train_loss: 6.3125 | test_loss: 6.2588 | \n",
      "Epoch: 40 | train_loss: 5.8845 | test_loss: 5.8226 | \n",
      "Epoch: 50 | train_loss: 5.5567 | test_loss: 5.5093 | \n",
      "Epoch: 60 | train_loss: 5.2772 | test_loss: 5.2426 | \n",
      "Epoch: 70 | train_loss: 5.0409 | test_loss: 5.0143 | \n",
      "Epoch: 80 | train_loss: 4.8426 | test_loss: 4.8158 | \n",
      "Epoch: 90 | train_loss: 4.6603 | test_loss: 4.6275 | \n",
      "Epoch: 100 | train_loss: 4.4924 | test_loss: 4.4688 | \n",
      "Epoch: 110 | train_loss: 4.3436 | test_loss: 4.3146 | \n",
      "Epoch: 120 | train_loss: 4.2092 | test_loss: 4.1761 | \n",
      "Epoch: 130 | train_loss: 4.0781 | test_loss: 4.0586 | \n",
      "Epoch: 140 | train_loss: 3.9572 | test_loss: 3.9386 | \n",
      "Epoch: 150 | train_loss: 3.8493 | test_loss: 3.8268 | \n",
      "Epoch: 160 | train_loss: 3.7378 | test_loss: 3.7154 | \n",
      "Epoch: 170 | train_loss: 3.6389 | test_loss: 3.6171 | \n",
      "Epoch: 180 | train_loss: 3.5499 | test_loss: 3.5241 | \n",
      "Epoch: 190 | train_loss: 3.4573 | test_loss: 3.4269 | \n",
      "Epoch: 200 | train_loss: 3.3657 | test_loss: 3.3444 | \n",
      "Epoch: 210 | train_loss: 3.2818 | test_loss: 3.2644 | \n",
      "Epoch: 220 | train_loss: 3.1978 | test_loss: 3.1826 | \n",
      "Epoch: 230 | train_loss: 3.1249 | test_loss: 3.1034 | \n",
      "Epoch: 240 | train_loss: 3.0522 | test_loss: 3.0312 | \n",
      "Epoch: 250 | train_loss: 2.9770 | test_loss: 2.9595 | \n",
      "Epoch: 260 | train_loss: 2.9123 | test_loss: 2.8873 | \n",
      "Epoch: 270 | train_loss: 2.8339 | test_loss: 2.8214 | \n",
      "Epoch: 280 | train_loss: 2.7759 | test_loss: 2.7512 | \n",
      "Epoch: 290 | train_loss: 2.7090 | test_loss: 2.6877 | \n",
      "Epoch: 300 | train_loss: 2.6475 | test_loss: 2.6262 | \n",
      "Epoch: 310 | train_loss: 2.5850 | test_loss: 2.5683 | \n",
      "Epoch: 320 | train_loss: 2.5238 | test_loss: 2.5050 | \n",
      "Epoch: 330 | train_loss: 2.4715 | test_loss: 2.4473 | \n",
      "Epoch: 340 | train_loss: 2.4111 | test_loss: 2.3898 | \n",
      "Epoch: 350 | train_loss: 2.3529 | test_loss: 2.3362 | \n",
      "Epoch: 360 | train_loss: 2.3005 | test_loss: 2.2792 | \n",
      "Epoch: 370 | train_loss: 2.2479 | test_loss: 2.2307 | \n",
      "Epoch: 380 | train_loss: 2.1930 | test_loss: 2.1782 | \n",
      "Epoch: 390 | train_loss: 2.1367 | test_loss: 2.1265 | \n",
      "Epoch: 400 | train_loss: 2.0913 | test_loss: 2.0702 | \n",
      "Epoch: 410 | train_loss: 2.0415 | test_loss: 2.0270 | \n",
      "Epoch: 420 | train_loss: 1.9939 | test_loss: 1.9736 | \n",
      "Epoch: 430 | train_loss: 1.9371 | test_loss: 1.9252 | \n",
      "Epoch: 440 | train_loss: 1.8860 | test_loss: 1.8753 | \n",
      "Epoch: 450 | train_loss: 1.8484 | test_loss: 1.8340 | \n",
      "Epoch: 460 | train_loss: 1.7991 | test_loss: 1.7804 | \n",
      "Epoch: 470 | train_loss: 1.7513 | test_loss: 1.7337 | \n",
      "Epoch: 480 | train_loss: 1.7092 | test_loss: 1.6887 | \n",
      "Epoch: 490 | train_loss: 1.6642 | test_loss: 1.6390 | \n",
      "Epoch: 500 | train_loss: 1.6201 | test_loss: 1.6017 | \n",
      "Epoch: 510 | train_loss: 1.5723 | test_loss: 1.5602 | \n",
      "Epoch: 520 | train_loss: 1.5326 | test_loss: 1.5121 | \n",
      "Epoch: 530 | train_loss: 1.4926 | test_loss: 1.4686 | \n",
      "Epoch: 540 | train_loss: 1.4444 | test_loss: 1.4302 | \n",
      "Epoch: 550 | train_loss: 1.4067 | test_loss: 1.3835 | \n",
      "Epoch: 560 | train_loss: 1.3623 | test_loss: 1.3481 | \n",
      "Epoch: 570 | train_loss: 1.3261 | test_loss: 1.3057 | \n",
      "Epoch: 580 | train_loss: 1.2808 | test_loss: 1.2690 | \n",
      "Epoch: 590 | train_loss: 1.2415 | test_loss: 1.2257 | \n",
      "Epoch: 600 | train_loss: 1.2074 | test_loss: 1.1858 | \n",
      "Epoch: 610 | train_loss: 1.1633 | test_loss: 1.1434 | \n",
      "Epoch: 620 | train_loss: 1.1226 | test_loss: 1.1110 | \n",
      "Epoch: 630 | train_loss: 1.0882 | test_loss: 1.0695 | \n",
      "Epoch: 640 | train_loss: 1.0501 | test_loss: 1.0365 | \n",
      "Epoch: 650 | train_loss: 1.0122 | test_loss: 0.9966 | \n",
      "Epoch: 660 | train_loss: 0.9794 | test_loss: 0.9798 | \n",
      "Epoch: 670 | train_loss: 0.9367 | test_loss: 0.9242 | \n",
      "Epoch: 680 | train_loss: 0.8984 | test_loss: 0.8833 | \n",
      "Epoch: 690 | train_loss: 0.8661 | test_loss: 0.8465 | \n",
      "Epoch: 700 | train_loss: 0.8299 | test_loss: 0.8076 | \n",
      "Epoch: 710 | train_loss: 0.7935 | test_loss: 0.7772 | \n",
      "Epoch: 720 | train_loss: 0.7536 | test_loss: 0.7422 | \n",
      "Epoch: 730 | train_loss: 0.7251 | test_loss: 0.7090 | \n",
      "Epoch: 740 | train_loss: 0.6898 | test_loss: 0.6681 | \n",
      "Epoch: 750 | train_loss: 0.6558 | test_loss: 0.6446 | \n",
      "Epoch: 760 | train_loss: 0.6218 | test_loss: 0.6099 | \n",
      "Epoch: 770 | train_loss: 0.5851 | test_loss: 0.5776 | \n",
      "Epoch: 780 | train_loss: 0.5557 | test_loss: 0.5438 | \n",
      "Epoch: 790 | train_loss: 0.5213 | test_loss: 0.5106 | \n",
      "Epoch: 800 | train_loss: 0.4906 | test_loss: 0.4762 | \n",
      "Epoch: 810 | train_loss: 0.4544 | test_loss: 0.4491 | \n",
      "Epoch: 820 | train_loss: 0.4325 | test_loss: 0.4255 | \n",
      "Epoch: 830 | train_loss: 0.3999 | test_loss: 0.3908 | \n",
      "Epoch: 840 | train_loss: 0.3713 | test_loss: 0.3688 | \n",
      "Epoch: 850 | train_loss: 0.3427 | test_loss: 0.3407 | \n",
      "Epoch: 860 | train_loss: 0.3123 | test_loss: 0.3121 | \n",
      "Epoch: 870 | train_loss: 0.2917 | test_loss: 0.2874 | \n",
      "Epoch: 880 | train_loss: 0.2625 | test_loss: 0.2625 | \n",
      "Epoch: 890 | train_loss: 0.2420 | test_loss: 0.2340 | \n",
      "Epoch: 900 | train_loss: 0.2142 | test_loss: 0.2066 | \n",
      "Epoch: 910 | train_loss: 0.1921 | test_loss: 0.1964 | \n",
      "Epoch: 920 | train_loss: 0.1765 | test_loss: 0.1827 | \n",
      "Epoch: 930 | train_loss: 0.1598 | test_loss: 0.1695 | \n",
      "Epoch: 940 | train_loss: 0.1469 | test_loss: 0.1677 | \n",
      "Epoch: 950 | train_loss: 0.1329 | test_loss: 0.1572 | \n",
      "Epoch: 960 | train_loss: 0.1340 | test_loss: 0.1520 | \n",
      "Epoch: 970 | train_loss: 0.1169 | test_loss: 0.1392 | \n",
      "Epoch: 980 | train_loss: 0.1216 | test_loss: 0.1424 | \n",
      "Epoch: 990 | train_loss: 0.1194 | test_loss: 0.1375 | \n",
      "Epoch: 1000 | train_loss: 0.1103 | test_loss: 0.1353 | \n",
      "Epoch: 1010 | train_loss: 0.1089 | test_loss: 0.1380 | \n",
      "Epoch: 1020 | train_loss: 0.0993 | test_loss: 0.1363 | \n",
      "Epoch: 1030 | train_loss: 0.1028 | test_loss: 0.1354 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 6.1163 | test_loss: 2.6398 | \n",
      "Epoch: 10 | train_loss: 0.1580 | test_loss: 0.1557 | \n",
      "Epoch: 20 | train_loss: 0.1376 | test_loss: 0.1464 | \n",
      "Epoch: 30 | train_loss: 0.1267 | test_loss: 0.1467 | \n",
      "Epoch: 40 | train_loss: 0.1193 | test_loss: 0.1419 | \n",
      "Epoch: 50 | train_loss: 0.1118 | test_loss: 0.1490 | \n",
      "Epoch: 60 | train_loss: 0.1026 | test_loss: 0.1409 | \n",
      "Epoch: 70 | train_loss: 0.1000 | test_loss: 0.1406 | \n",
      "Epoch: 80 | train_loss: 0.0928 | test_loss: 0.1475 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.2181 | test_loss: 0.3389 | \n",
      "Epoch: 10 | train_loss: 0.1339 | test_loss: 0.1424 | \n",
      "Epoch: 20 | train_loss: 0.1097 | test_loss: 0.1383 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 2.1369 | test_loss: 0.5437 | \n",
      "Epoch: 10 | train_loss: 0.1218 | test_loss: 0.1452 | \n",
      "Epoch: 20 | train_loss: 0.1242 | test_loss: 0.1496 | \n",
      "Epoch: 30 | train_loss: 0.0822 | test_loss: 0.1678 | \n",
      "Epoch: 40 | train_loss: 0.0898 | test_loss: 0.1575 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6232 | test_loss: 8.6511 | \n",
      "Epoch: 10 | train_loss: 5.9050 | test_loss: 5.8176 | \n",
      "Epoch: 20 | train_loss: 4.8406 | test_loss: 4.7675 | \n",
      "Epoch: 30 | train_loss: 4.2031 | test_loss: 4.1728 | \n",
      "Epoch: 40 | train_loss: 3.7308 | test_loss: 3.7169 | \n",
      "Epoch: 50 | train_loss: 3.3547 | test_loss: 3.3626 | \n",
      "Epoch: 60 | train_loss: 3.0387 | test_loss: 3.0248 | \n",
      "Epoch: 70 | train_loss: 2.7596 | test_loss: 2.7302 | \n",
      "Epoch: 80 | train_loss: 2.5137 | test_loss: 2.4729 | \n",
      "Epoch: 90 | train_loss: 2.2852 | test_loss: 2.2757 | \n",
      "Epoch: 100 | train_loss: 2.0721 | test_loss: 2.0457 | \n",
      "Epoch: 110 | train_loss: 1.8756 | test_loss: 1.8542 | \n",
      "Epoch: 120 | train_loss: 1.6922 | test_loss: 1.6813 | \n",
      "Epoch: 130 | train_loss: 1.5111 | test_loss: 1.4887 | \n",
      "Epoch: 140 | train_loss: 1.3423 | test_loss: 1.3134 | \n",
      "Epoch: 150 | train_loss: 1.1788 | test_loss: 1.1627 | \n",
      "Epoch: 160 | train_loss: 1.0231 | test_loss: 1.0268 | \n",
      "Epoch: 170 | train_loss: 0.8731 | test_loss: 0.8723 | \n",
      "Epoch: 180 | train_loss: 0.7294 | test_loss: 0.7178 | \n",
      "Epoch: 190 | train_loss: 0.5940 | test_loss: 0.6082 | \n",
      "Epoch: 200 | train_loss: 0.4586 | test_loss: 0.4669 | \n",
      "Epoch: 210 | train_loss: 0.3360 | test_loss: 0.3365 | \n",
      "Epoch: 220 | train_loss: 0.2204 | test_loss: 0.2576 | \n",
      "Epoch: 230 | train_loss: 0.1383 | test_loss: 0.2088 | \n",
      "Epoch: 240 | train_loss: 0.0984 | test_loss: 0.1485 | \n",
      "Epoch: 250 | train_loss: 0.0885 | test_loss: 0.1623 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6412 | test_loss: 8.7043 | \n",
      "Epoch: 10 | train_loss: 5.9188 | test_loss: 5.8013 | \n",
      "Epoch: 20 | train_loss: 4.8569 | test_loss: 4.8077 | \n",
      "Epoch: 30 | train_loss: 4.2163 | test_loss: 4.1696 | \n",
      "Epoch: 40 | train_loss: 3.7479 | test_loss: 3.7132 | \n",
      "Epoch: 50 | train_loss: 3.3708 | test_loss: 3.3402 | \n",
      "Epoch: 60 | train_loss: 3.0561 | test_loss: 3.0592 | \n",
      "Epoch: 70 | train_loss: 2.7763 | test_loss: 2.7594 | \n",
      "Epoch: 80 | train_loss: 2.5299 | test_loss: 2.4966 | \n",
      "Epoch: 90 | train_loss: 2.2984 | test_loss: 2.2848 | \n",
      "Epoch: 100 | train_loss: 2.0876 | test_loss: 2.0762 | \n",
      "Epoch: 110 | train_loss: 1.8912 | test_loss: 1.8749 | \n",
      "Epoch: 120 | train_loss: 1.7025 | test_loss: 1.6836 | \n",
      "Epoch: 130 | train_loss: 1.5268 | test_loss: 1.4906 | \n",
      "Epoch: 140 | train_loss: 1.3579 | test_loss: 1.3668 | \n",
      "Epoch: 150 | train_loss: 1.1946 | test_loss: 1.1681 | \n",
      "Epoch: 160 | train_loss: 1.0380 | test_loss: 1.0338 | \n",
      "Epoch: 170 | train_loss: 0.8890 | test_loss: 0.8692 | \n",
      "Epoch: 180 | train_loss: 0.7441 | test_loss: 0.7203 | \n",
      "Epoch: 190 | train_loss: 0.6036 | test_loss: 0.5973 | \n",
      "Epoch: 200 | train_loss: 0.4763 | test_loss: 0.4816 | \n",
      "Epoch: 210 | train_loss: 0.3486 | test_loss: 0.3610 | \n",
      "Epoch: 220 | train_loss: 0.2344 | test_loss: 0.2362 | \n",
      "Epoch: 230 | train_loss: 0.1412 | test_loss: 0.1850 | \n",
      "Epoch: 240 | train_loss: 0.0965 | test_loss: 0.1495 | \n",
      "Epoch: 250 | train_loss: 0.0865 | test_loss: 0.1484 | \n",
      "Epoch: 260 | train_loss: 0.0781 | test_loss: 0.1503 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.7076 | test_loss: 8.6359 | \n",
      "Epoch: 10 | train_loss: 5.9858 | test_loss: 5.8558 | \n",
      "Epoch: 20 | train_loss: 4.9037 | test_loss: 4.8345 | \n",
      "Epoch: 30 | train_loss: 4.2683 | test_loss: 4.2146 | \n",
      "Epoch: 40 | train_loss: 3.7992 | test_loss: 3.7478 | \n",
      "Epoch: 50 | train_loss: 3.4223 | test_loss: 3.3758 | \n",
      "Epoch: 60 | train_loss: 3.1083 | test_loss: 3.0725 | \n",
      "Epoch: 70 | train_loss: 2.8284 | test_loss: 2.8006 | \n",
      "Epoch: 80 | train_loss: 2.5830 | test_loss: 2.5496 | \n",
      "Epoch: 90 | train_loss: 2.3541 | test_loss: 2.3166 | \n",
      "Epoch: 100 | train_loss: 2.1441 | test_loss: 2.1133 | \n",
      "Epoch: 110 | train_loss: 1.9427 | test_loss: 1.9068 | \n",
      "Epoch: 120 | train_loss: 1.7526 | test_loss: 1.7213 | \n",
      "Epoch: 130 | train_loss: 1.5812 | test_loss: 1.5575 | \n",
      "Epoch: 140 | train_loss: 1.4123 | test_loss: 1.3843 | \n",
      "Epoch: 150 | train_loss: 1.2520 | test_loss: 1.2254 | \n",
      "Epoch: 160 | train_loss: 1.0946 | test_loss: 1.0772 | \n",
      "Epoch: 170 | train_loss: 0.9454 | test_loss: 0.9321 | \n",
      "Epoch: 180 | train_loss: 0.8071 | test_loss: 0.7901 | \n",
      "Epoch: 190 | train_loss: 0.6689 | test_loss: 0.6520 | \n",
      "Epoch: 200 | train_loss: 0.5388 | test_loss: 0.5241 | \n",
      "Epoch: 210 | train_loss: 0.4207 | test_loss: 0.4063 | \n",
      "Epoch: 220 | train_loss: 0.3199 | test_loss: 0.3081 | \n",
      "Epoch: 230 | train_loss: 0.2414 | test_loss: 0.2112 | \n",
      "Epoch: 240 | train_loss: 0.1909 | test_loss: 0.1662 | \n",
      "Epoch: 250 | train_loss: 0.1547 | test_loss: 0.1559 | \n",
      "Epoch: 260 | train_loss: 0.1518 | test_loss: 0.1451 | \n",
      "Epoch: 270 | train_loss: 0.1419 | test_loss: 0.1422 | \n",
      "Epoch: 280 | train_loss: 0.1443 | test_loss: 0.1412 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.7661 | test_loss: 8.7175 | \n",
      "Epoch: 10 | train_loss: 6.0393 | test_loss: 5.9266 | \n",
      "Epoch: 20 | train_loss: 4.9684 | test_loss: 4.8998 | \n",
      "Epoch: 30 | train_loss: 4.3217 | test_loss: 4.2661 | \n",
      "Epoch: 40 | train_loss: 3.8565 | test_loss: 3.8029 | \n",
      "Epoch: 50 | train_loss: 3.4767 | test_loss: 3.4297 | \n",
      "Epoch: 60 | train_loss: 3.1615 | test_loss: 3.1226 | \n",
      "Epoch: 70 | train_loss: 2.8835 | test_loss: 2.8395 | \n",
      "Epoch: 80 | train_loss: 2.6304 | test_loss: 2.5946 | \n",
      "Epoch: 90 | train_loss: 2.4048 | test_loss: 2.3660 | \n",
      "Epoch: 100 | train_loss: 2.1922 | test_loss: 2.1582 | \n",
      "Epoch: 110 | train_loss: 1.9980 | test_loss: 1.9650 | \n",
      "Epoch: 120 | train_loss: 1.8064 | test_loss: 1.7812 | \n",
      "Epoch: 130 | train_loss: 1.6354 | test_loss: 1.6016 | \n",
      "Epoch: 140 | train_loss: 1.4676 | test_loss: 1.4335 | \n",
      "Epoch: 150 | train_loss: 1.2958 | test_loss: 1.2759 | \n",
      "Epoch: 160 | train_loss: 1.1393 | test_loss: 1.1295 | \n",
      "Epoch: 170 | train_loss: 0.9903 | test_loss: 0.9746 | \n",
      "Epoch: 180 | train_loss: 0.8487 | test_loss: 0.8307 | \n",
      "Epoch: 190 | train_loss: 0.7064 | test_loss: 0.6912 | \n",
      "Epoch: 200 | train_loss: 0.5824 | test_loss: 0.5609 | \n",
      "Epoch: 210 | train_loss: 0.4618 | test_loss: 0.4321 | \n",
      "Epoch: 220 | train_loss: 0.3477 | test_loss: 0.3384 | \n",
      "Epoch: 230 | train_loss: 0.2582 | test_loss: 0.2485 | \n",
      "Epoch: 240 | train_loss: 0.1987 | test_loss: 0.1826 | \n",
      "Epoch: 250 | train_loss: 0.1590 | test_loss: 0.1559 | \n",
      "Epoch: 260 | train_loss: 0.1570 | test_loss: 0.1488 | \n",
      "Epoch: 270 | train_loss: 0.1485 | test_loss: 0.1428 | \n",
      "Epoch: 280 | train_loss: 0.1413 | test_loss: 0.1522 | \n",
      "Epoch: 290 | train_loss: 0.1399 | test_loss: 0.1496 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.1529 | test_loss: 4.5695 | \n",
      "Epoch: 10 | train_loss: 0.1802 | test_loss: 0.1678 | \n",
      "Epoch: 20 | train_loss: 0.1543 | test_loss: 0.1560 | \n",
      "Epoch: 30 | train_loss: 0.1458 | test_loss: 0.1553 | \n",
      "Epoch: 40 | train_loss: 0.1340 | test_loss: 0.1495 | \n",
      "Epoch: 50 | train_loss: 0.1313 | test_loss: 0.1470 | \n",
      "Epoch: 60 | train_loss: 0.1260 | test_loss: 0.1467 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.7304 | test_loss: 1.9008 | \n",
      "Epoch: 10 | train_loss: 0.1532 | test_loss: 0.1524 | \n",
      "Epoch: 20 | train_loss: 0.1326 | test_loss: 0.1424 | \n",
      "Epoch: 30 | train_loss: 0.1236 | test_loss: 0.1412 | \n",
      "Epoch: 40 | train_loss: 0.1061 | test_loss: 0.1485 | \n",
      "Epoch: 50 | train_loss: 0.0956 | test_loss: 0.1429 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.1546 | test_loss: 1.6197 | \n",
      "Epoch: 10 | train_loss: 0.1371 | test_loss: 0.1440 | \n",
      "Epoch: 20 | train_loss: 0.1149 | test_loss: 0.1577 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2605 | test_loss: 9.1539 | \n",
      "Epoch: 10 | train_loss: 6.8662 | test_loss: 6.7939 | \n",
      "Epoch: 20 | train_loss: 5.8486 | test_loss: 5.7827 | \n",
      "Epoch: 30 | train_loss: 5.2461 | test_loss: 5.2050 | \n",
      "Epoch: 40 | train_loss: 4.8064 | test_loss: 4.7829 | \n",
      "Epoch: 50 | train_loss: 4.4601 | test_loss: 4.4548 | \n",
      "Epoch: 60 | train_loss: 4.1720 | test_loss: 4.1512 | \n",
      "Epoch: 70 | train_loss: 3.9254 | test_loss: 3.9104 | \n",
      "Epoch: 80 | train_loss: 3.7078 | test_loss: 3.6975 | \n",
      "Epoch: 90 | train_loss: 3.5123 | test_loss: 3.5023 | \n",
      "Epoch: 100 | train_loss: 3.3363 | test_loss: 3.3263 | \n",
      "Epoch: 110 | train_loss: 3.1711 | test_loss: 3.1614 | \n",
      "Epoch: 120 | train_loss: 3.0180 | test_loss: 3.0081 | \n",
      "Epoch: 130 | train_loss: 2.8791 | test_loss: 2.8849 | \n",
      "Epoch: 140 | train_loss: 2.7418 | test_loss: 2.7299 | \n",
      "Epoch: 150 | train_loss: 2.6152 | test_loss: 2.6085 | \n",
      "Epoch: 160 | train_loss: 2.4959 | test_loss: 2.4972 | \n",
      "Epoch: 170 | train_loss: 2.3799 | test_loss: 2.3584 | \n",
      "Epoch: 180 | train_loss: 2.2696 | test_loss: 2.2715 | \n",
      "Epoch: 190 | train_loss: 2.1610 | test_loss: 2.1486 | \n",
      "Epoch: 200 | train_loss: 2.0585 | test_loss: 2.0465 | \n",
      "Epoch: 210 | train_loss: 1.9594 | test_loss: 1.9519 | \n",
      "Epoch: 220 | train_loss: 1.8607 | test_loss: 1.8498 | \n",
      "Epoch: 230 | train_loss: 1.7671 | test_loss: 1.7500 | \n",
      "Epoch: 240 | train_loss: 1.6748 | test_loss: 1.6694 | \n",
      "Epoch: 250 | train_loss: 1.5850 | test_loss: 1.5606 | \n",
      "Epoch: 260 | train_loss: 1.4988 | test_loss: 1.4710 | \n",
      "Epoch: 270 | train_loss: 1.4126 | test_loss: 1.4116 | \n",
      "Epoch: 280 | train_loss: 1.3274 | test_loss: 1.3253 | \n",
      "Epoch: 290 | train_loss: 1.2477 | test_loss: 1.2426 | \n",
      "Epoch: 300 | train_loss: 1.1669 | test_loss: 1.1515 | \n",
      "Epoch: 310 | train_loss: 1.0877 | test_loss: 1.0811 | \n",
      "Epoch: 320 | train_loss: 1.0101 | test_loss: 1.0085 | \n",
      "Epoch: 330 | train_loss: 0.9346 | test_loss: 0.9357 | \n",
      "Epoch: 340 | train_loss: 0.8611 | test_loss: 0.8561 | \n",
      "Epoch: 350 | train_loss: 0.7880 | test_loss: 0.7926 | \n",
      "Epoch: 360 | train_loss: 0.7166 | test_loss: 0.7224 | \n",
      "Epoch: 370 | train_loss: 0.6477 | test_loss: 0.6481 | \n",
      "Epoch: 380 | train_loss: 0.5777 | test_loss: 0.5861 | \n",
      "Epoch: 390 | train_loss: 0.5109 | test_loss: 0.5392 | \n",
      "Epoch: 400 | train_loss: 0.4456 | test_loss: 0.4332 | \n",
      "Epoch: 410 | train_loss: 0.3801 | test_loss: 0.3925 | \n",
      "Epoch: 420 | train_loss: 0.3198 | test_loss: 0.3654 | \n",
      "Epoch: 430 | train_loss: 0.2581 | test_loss: 0.2918 | \n",
      "Epoch: 440 | train_loss: 0.2022 | test_loss: 0.2395 | \n",
      "Epoch: 450 | train_loss: 0.1500 | test_loss: 0.2191 | \n",
      "Epoch: 460 | train_loss: 0.1112 | test_loss: 0.1702 | \n",
      "Epoch: 470 | train_loss: 0.0823 | test_loss: 0.1669 | \n",
      "Epoch: 480 | train_loss: 0.0685 | test_loss: 0.1453 | \n",
      "Epoch: 490 | train_loss: 0.0529 | test_loss: 0.1439 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2243 | test_loss: 9.0931 | \n",
      "Epoch: 10 | train_loss: 6.8444 | test_loss: 6.7592 | \n",
      "Epoch: 20 | train_loss: 5.8382 | test_loss: 5.8055 | \n",
      "Epoch: 30 | train_loss: 5.2337 | test_loss: 5.2085 | \n",
      "Epoch: 40 | train_loss: 4.7938 | test_loss: 4.7484 | \n",
      "Epoch: 50 | train_loss: 4.4467 | test_loss: 4.3944 | \n",
      "Epoch: 60 | train_loss: 4.1619 | test_loss: 4.1433 | \n",
      "Epoch: 70 | train_loss: 3.9130 | test_loss: 3.8860 | \n",
      "Epoch: 80 | train_loss: 3.6935 | test_loss: 3.6715 | \n",
      "Epoch: 90 | train_loss: 3.5005 | test_loss: 3.4905 | \n",
      "Epoch: 100 | train_loss: 3.3230 | test_loss: 3.2982 | \n",
      "Epoch: 110 | train_loss: 3.1596 | test_loss: 3.1230 | \n",
      "Epoch: 120 | train_loss: 3.0067 | test_loss: 2.9895 | \n",
      "Epoch: 130 | train_loss: 2.8655 | test_loss: 2.8366 | \n",
      "Epoch: 140 | train_loss: 2.7317 | test_loss: 2.7102 | \n",
      "Epoch: 150 | train_loss: 2.6028 | test_loss: 2.5879 | \n",
      "Epoch: 160 | train_loss: 2.4834 | test_loss: 2.4759 | \n",
      "Epoch: 170 | train_loss: 2.3676 | test_loss: 2.3773 | \n",
      "Epoch: 180 | train_loss: 2.2576 | test_loss: 2.2306 | \n",
      "Epoch: 190 | train_loss: 2.1500 | test_loss: 2.1562 | \n",
      "Epoch: 200 | train_loss: 2.0478 | test_loss: 2.0330 | \n",
      "Epoch: 210 | train_loss: 1.9494 | test_loss: 1.9226 | \n",
      "Epoch: 220 | train_loss: 1.8527 | test_loss: 1.8230 | \n",
      "Epoch: 230 | train_loss: 1.7554 | test_loss: 1.7534 | \n",
      "Epoch: 240 | train_loss: 1.6632 | test_loss: 1.6822 | \n",
      "Epoch: 250 | train_loss: 1.5741 | test_loss: 1.5549 | \n",
      "Epoch: 260 | train_loss: 1.4860 | test_loss: 1.4870 | \n",
      "Epoch: 270 | train_loss: 1.4006 | test_loss: 1.3941 | \n",
      "Epoch: 280 | train_loss: 1.3172 | test_loss: 1.3135 | \n",
      "Epoch: 290 | train_loss: 1.2346 | test_loss: 1.2231 | \n",
      "Epoch: 300 | train_loss: 1.1552 | test_loss: 1.1438 | \n",
      "Epoch: 310 | train_loss: 1.0770 | test_loss: 1.0659 | \n",
      "Epoch: 320 | train_loss: 0.9997 | test_loss: 0.9807 | \n",
      "Epoch: 330 | train_loss: 0.9254 | test_loss: 0.9212 | \n",
      "Epoch: 340 | train_loss: 0.8522 | test_loss: 0.8828 | \n",
      "Epoch: 350 | train_loss: 0.7781 | test_loss: 0.7774 | \n",
      "Epoch: 360 | train_loss: 0.7138 | test_loss: 0.6974 | \n",
      "Epoch: 370 | train_loss: 0.6405 | test_loss: 0.6461 | \n",
      "Epoch: 380 | train_loss: 0.5745 | test_loss: 0.5706 | \n",
      "Epoch: 390 | train_loss: 0.5050 | test_loss: 0.5026 | \n",
      "Epoch: 400 | train_loss: 0.4409 | test_loss: 0.4479 | \n",
      "Epoch: 410 | train_loss: 0.3757 | test_loss: 0.3779 | \n",
      "Epoch: 420 | train_loss: 0.3151 | test_loss: 0.3288 | \n",
      "Epoch: 430 | train_loss: 0.2576 | test_loss: 0.2953 | \n",
      "Epoch: 440 | train_loss: 0.2006 | test_loss: 0.2356 | \n",
      "Epoch: 450 | train_loss: 0.1546 | test_loss: 0.2270 | \n",
      "Epoch: 460 | train_loss: 0.1100 | test_loss: 0.1760 | \n",
      "Epoch: 470 | train_loss: 0.0820 | test_loss: 0.1527 | \n",
      "Epoch: 480 | train_loss: 0.0647 | test_loss: 0.1410 | \n",
      "Epoch: 490 | train_loss: 0.0656 | test_loss: 0.1468 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3482 | test_loss: 9.2581 | \n",
      "Epoch: 10 | train_loss: 6.9323 | test_loss: 6.8469 | \n",
      "Epoch: 20 | train_loss: 5.9353 | test_loss: 5.8641 | \n",
      "Epoch: 30 | train_loss: 5.3231 | test_loss: 5.2640 | \n",
      "Epoch: 40 | train_loss: 4.8894 | test_loss: 4.8319 | \n",
      "Epoch: 50 | train_loss: 4.5366 | test_loss: 4.5042 | \n",
      "Epoch: 60 | train_loss: 4.2473 | test_loss: 4.2041 | \n",
      "Epoch: 70 | train_loss: 4.0023 | test_loss: 3.9687 | \n",
      "Epoch: 80 | train_loss: 3.7838 | test_loss: 3.7568 | \n",
      "Epoch: 90 | train_loss: 3.5864 | test_loss: 3.5580 | \n",
      "Epoch: 100 | train_loss: 3.4089 | test_loss: 3.3811 | \n",
      "Epoch: 110 | train_loss: 3.2373 | test_loss: 3.2251 | \n",
      "Epoch: 120 | train_loss: 3.0930 | test_loss: 3.0606 | \n",
      "Epoch: 130 | train_loss: 2.9481 | test_loss: 2.9307 | \n",
      "Epoch: 140 | train_loss: 2.8085 | test_loss: 2.7885 | \n",
      "Epoch: 150 | train_loss: 2.6829 | test_loss: 2.6553 | \n",
      "Epoch: 160 | train_loss: 2.5589 | test_loss: 2.5379 | \n",
      "Epoch: 170 | train_loss: 2.4470 | test_loss: 2.4235 | \n",
      "Epoch: 180 | train_loss: 2.3318 | test_loss: 2.3025 | \n",
      "Epoch: 190 | train_loss: 2.2227 | test_loss: 2.1972 | \n",
      "Epoch: 200 | train_loss: 2.1287 | test_loss: 2.0969 | \n",
      "Epoch: 210 | train_loss: 2.0240 | test_loss: 1.9958 | \n",
      "Epoch: 220 | train_loss: 1.9229 | test_loss: 1.9008 | \n",
      "Epoch: 230 | train_loss: 1.8282 | test_loss: 1.8016 | \n",
      "Epoch: 240 | train_loss: 1.7393 | test_loss: 1.7190 | \n",
      "Epoch: 250 | train_loss: 1.6488 | test_loss: 1.6232 | \n",
      "Epoch: 260 | train_loss: 1.5583 | test_loss: 1.5387 | \n",
      "Epoch: 270 | train_loss: 1.4785 | test_loss: 1.4518 | \n",
      "Epoch: 280 | train_loss: 1.3911 | test_loss: 1.3674 | \n",
      "Epoch: 290 | train_loss: 1.3108 | test_loss: 1.2912 | \n",
      "Epoch: 300 | train_loss: 1.2299 | test_loss: 1.2068 | \n",
      "Epoch: 310 | train_loss: 1.1547 | test_loss: 1.1313 | \n",
      "Epoch: 320 | train_loss: 1.0779 | test_loss: 1.0529 | \n",
      "Epoch: 330 | train_loss: 0.9983 | test_loss: 0.9826 | \n",
      "Epoch: 340 | train_loss: 0.9246 | test_loss: 0.9060 | \n",
      "Epoch: 350 | train_loss: 0.8522 | test_loss: 0.8315 | \n",
      "Epoch: 360 | train_loss: 0.7849 | test_loss: 0.7626 | \n",
      "Epoch: 370 | train_loss: 0.7110 | test_loss: 0.6942 | \n",
      "Epoch: 380 | train_loss: 0.6439 | test_loss: 0.6259 | \n",
      "Epoch: 390 | train_loss: 0.5754 | test_loss: 0.5676 | \n",
      "Epoch: 400 | train_loss: 0.5140 | test_loss: 0.5065 | \n",
      "Epoch: 410 | train_loss: 0.4533 | test_loss: 0.4451 | \n",
      "Epoch: 420 | train_loss: 0.3906 | test_loss: 0.3839 | \n",
      "Epoch: 430 | train_loss: 0.3380 | test_loss: 0.3272 | \n",
      "Epoch: 440 | train_loss: 0.2857 | test_loss: 0.2879 | \n",
      "Epoch: 450 | train_loss: 0.2423 | test_loss: 0.2443 | \n",
      "Epoch: 460 | train_loss: 0.2027 | test_loss: 0.2100 | \n",
      "Epoch: 470 | train_loss: 0.1699 | test_loss: 0.1707 | \n",
      "Epoch: 480 | train_loss: 0.1534 | test_loss: 0.1602 | \n",
      "Epoch: 490 | train_loss: 0.1341 | test_loss: 0.1423 | \n",
      "Epoch: 500 | train_loss: 0.1307 | test_loss: 0.1432 | \n",
      "Epoch: 510 | train_loss: 0.1250 | test_loss: 0.1375 | \n",
      "Epoch: 520 | train_loss: 0.1297 | test_loss: 0.1313 | \n",
      "Epoch: 530 | train_loss: 0.1235 | test_loss: 0.1364 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3328 | test_loss: 9.1172 | \n",
      "Epoch: 10 | train_loss: 6.9491 | test_loss: 6.8528 | \n",
      "Epoch: 20 | train_loss: 5.9487 | test_loss: 5.8732 | \n",
      "Epoch: 30 | train_loss: 5.3240 | test_loss: 5.2681 | \n",
      "Epoch: 40 | train_loss: 4.8814 | test_loss: 4.8404 | \n",
      "Epoch: 50 | train_loss: 4.5397 | test_loss: 4.4997 | \n",
      "Epoch: 60 | train_loss: 4.2483 | test_loss: 4.2131 | \n",
      "Epoch: 70 | train_loss: 4.0026 | test_loss: 3.9677 | \n",
      "Epoch: 80 | train_loss: 3.7802 | test_loss: 3.7473 | \n",
      "Epoch: 90 | train_loss: 3.5860 | test_loss: 3.5509 | \n",
      "Epoch: 100 | train_loss: 3.4136 | test_loss: 3.3847 | \n",
      "Epoch: 110 | train_loss: 3.2401 | test_loss: 3.2138 | \n",
      "Epoch: 120 | train_loss: 3.0888 | test_loss: 3.0626 | \n",
      "Epoch: 130 | train_loss: 2.9492 | test_loss: 2.9165 | \n",
      "Epoch: 140 | train_loss: 2.8155 | test_loss: 2.7876 | \n",
      "Epoch: 150 | train_loss: 2.6953 | test_loss: 2.6665 | \n",
      "Epoch: 160 | train_loss: 2.5625 | test_loss: 2.5402 | \n",
      "Epoch: 170 | train_loss: 2.4535 | test_loss: 2.4227 | \n",
      "Epoch: 180 | train_loss: 2.3404 | test_loss: 2.3140 | \n",
      "Epoch: 190 | train_loss: 2.2277 | test_loss: 2.2055 | \n",
      "Epoch: 200 | train_loss: 2.1295 | test_loss: 2.0995 | \n",
      "Epoch: 210 | train_loss: 2.0280 | test_loss: 1.9982 | \n",
      "Epoch: 220 | train_loss: 1.9303 | test_loss: 1.9029 | \n",
      "Epoch: 230 | train_loss: 1.8391 | test_loss: 1.8129 | \n",
      "Epoch: 240 | train_loss: 1.7445 | test_loss: 1.7237 | \n",
      "Epoch: 250 | train_loss: 1.6584 | test_loss: 1.6270 | \n",
      "Epoch: 260 | train_loss: 1.5672 | test_loss: 1.5409 | \n",
      "Epoch: 270 | train_loss: 1.4850 | test_loss: 1.4578 | \n",
      "Epoch: 280 | train_loss: 1.4021 | test_loss: 1.3834 | \n",
      "Epoch: 290 | train_loss: 1.3150 | test_loss: 1.3001 | \n",
      "Epoch: 300 | train_loss: 1.2310 | test_loss: 1.2123 | \n",
      "Epoch: 310 | train_loss: 1.1549 | test_loss: 1.1354 | \n",
      "Epoch: 320 | train_loss: 1.0840 | test_loss: 1.0647 | \n",
      "Epoch: 330 | train_loss: 1.0035 | test_loss: 0.9880 | \n",
      "Epoch: 340 | train_loss: 0.9283 | test_loss: 0.9114 | \n",
      "Epoch: 350 | train_loss: 0.8575 | test_loss: 0.8422 | \n",
      "Epoch: 360 | train_loss: 0.7863 | test_loss: 0.7718 | \n",
      "Epoch: 370 | train_loss: 0.7118 | test_loss: 0.7076 | \n",
      "Epoch: 380 | train_loss: 0.6501 | test_loss: 0.6290 | \n",
      "Epoch: 390 | train_loss: 0.5803 | test_loss: 0.5716 | \n",
      "Epoch: 400 | train_loss: 0.5168 | test_loss: 0.4998 | \n",
      "Epoch: 410 | train_loss: 0.4590 | test_loss: 0.4427 | \n",
      "Epoch: 420 | train_loss: 0.4005 | test_loss: 0.3914 | \n",
      "Epoch: 430 | train_loss: 0.3387 | test_loss: 0.3311 | \n",
      "Epoch: 440 | train_loss: 0.2810 | test_loss: 0.2727 | \n",
      "Epoch: 450 | train_loss: 0.2457 | test_loss: 0.2374 | \n",
      "Epoch: 460 | train_loss: 0.1992 | test_loss: 0.2101 | \n",
      "Epoch: 470 | train_loss: 0.1743 | test_loss: 0.1802 | \n",
      "Epoch: 480 | train_loss: 0.1461 | test_loss: 0.1661 | \n",
      "Epoch: 490 | train_loss: 0.1354 | test_loss: 0.1470 | \n",
      "Epoch: 500 | train_loss: 0.1275 | test_loss: 0.1402 | \n",
      "Epoch: 510 | train_loss: 0.1223 | test_loss: 0.1392 | \n",
      "Epoch: 520 | train_loss: 0.1223 | test_loss: 0.1380 | \n",
      "Epoch: 530 | train_loss: 0.1190 | test_loss: 0.1348 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2464 | test_loss: 7.1527 | \n",
      "Epoch: 10 | train_loss: 0.2373 | test_loss: 0.2140 | \n",
      "Epoch: 20 | train_loss: 0.1764 | test_loss: 0.1682 | \n",
      "Epoch: 30 | train_loss: 0.1599 | test_loss: 0.1576 | \n",
      "Epoch: 40 | train_loss: 0.1506 | test_loss: 0.1540 | \n",
      "Epoch: 50 | train_loss: 0.1451 | test_loss: 0.1521 | \n",
      "Epoch: 60 | train_loss: 0.1392 | test_loss: 0.1518 | \n",
      "Epoch: 70 | train_loss: 0.1353 | test_loss: 0.1491 | \n",
      "Epoch: 80 | train_loss: 0.1330 | test_loss: 0.1491 | \n",
      "Epoch: 90 | train_loss: 0.1306 | test_loss: 0.1479 | \n",
      "Epoch: 100 | train_loss: 0.1273 | test_loss: 0.1483 | \n",
      "Epoch: 110 | train_loss: 0.1245 | test_loss: 0.1482 | \n",
      "Epoch: 120 | train_loss: 0.1240 | test_loss: 0.1475 | \n",
      "Epoch: 130 | train_loss: 0.1199 | test_loss: 0.1464 | \n",
      "Epoch: 140 | train_loss: 0.1172 | test_loss: 0.1466 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.1886 | test_loss: 4.2799 | \n",
      "Epoch: 10 | train_loss: 0.1870 | test_loss: 0.1774 | \n",
      "Epoch: 20 | train_loss: 0.1499 | test_loss: 0.1509 | \n",
      "Epoch: 30 | train_loss: 0.1370 | test_loss: 0.1461 | \n",
      "Epoch: 40 | train_loss: 0.1276 | test_loss: 0.1427 | \n",
      "Epoch: 50 | train_loss: 0.1203 | test_loss: 0.1463 | \n",
      "Epoch: 60 | train_loss: 0.1111 | test_loss: 0.1424 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.1997 | test_loss: 0.3751 | \n",
      "Epoch: 10 | train_loss: 0.1652 | test_loss: 0.1775 | \n",
      "Epoch: 20 | train_loss: 0.1209 | test_loss: 0.1407 | \n",
      "Epoch: 30 | train_loss: 0.0879 | test_loss: 0.1422 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.9573 | test_loss: 9.5384 | \n",
      "Epoch: 10 | train_loss: 7.7371 | test_loss: 7.6858 | \n",
      "Epoch: 20 | train_loss: 6.8389 | test_loss: 6.7959 | \n",
      "Epoch: 30 | train_loss: 6.2654 | test_loss: 6.1955 | \n",
      "Epoch: 40 | train_loss: 5.8457 | test_loss: 5.8181 | \n",
      "Epoch: 50 | train_loss: 5.5152 | test_loss: 5.4914 | \n",
      "Epoch: 60 | train_loss: 5.2432 | test_loss: 5.2143 | \n",
      "Epoch: 70 | train_loss: 5.0128 | test_loss: 4.9738 | \n",
      "Epoch: 80 | train_loss: 4.8084 | test_loss: 4.7870 | \n",
      "Epoch: 90 | train_loss: 4.6276 | test_loss: 4.6057 | \n",
      "Epoch: 100 | train_loss: 4.4649 | test_loss: 4.4378 | \n",
      "Epoch: 110 | train_loss: 4.3159 | test_loss: 4.2932 | \n",
      "Epoch: 120 | train_loss: 4.1788 | test_loss: 4.1511 | \n",
      "Epoch: 130 | train_loss: 4.0514 | test_loss: 4.0296 | \n",
      "Epoch: 140 | train_loss: 3.9322 | test_loss: 3.9141 | \n",
      "Epoch: 150 | train_loss: 3.8210 | test_loss: 3.7903 | \n",
      "Epoch: 160 | train_loss: 3.7160 | test_loss: 3.6903 | \n",
      "Epoch: 170 | train_loss: 3.6157 | test_loss: 3.6013 | \n",
      "Epoch: 180 | train_loss: 3.5205 | test_loss: 3.5049 | \n",
      "Epoch: 190 | train_loss: 3.4297 | test_loss: 3.4059 | \n",
      "Epoch: 200 | train_loss: 3.3417 | test_loss: 3.3223 | \n",
      "Epoch: 210 | train_loss: 3.2606 | test_loss: 3.2459 | \n",
      "Epoch: 220 | train_loss: 3.1787 | test_loss: 3.1659 | \n",
      "Epoch: 230 | train_loss: 3.1030 | test_loss: 3.0891 | \n",
      "Epoch: 240 | train_loss: 3.0275 | test_loss: 3.0168 | \n",
      "Epoch: 250 | train_loss: 2.9544 | test_loss: 2.9461 | \n",
      "Epoch: 260 | train_loss: 2.8838 | test_loss: 2.8697 | \n",
      "Epoch: 270 | train_loss: 2.8169 | test_loss: 2.8013 | \n",
      "Epoch: 280 | train_loss: 2.7503 | test_loss: 2.7401 | \n",
      "Epoch: 290 | train_loss: 2.6855 | test_loss: 2.6804 | \n",
      "Epoch: 300 | train_loss: 2.6241 | test_loss: 2.6153 | \n",
      "Epoch: 310 | train_loss: 2.5620 | test_loss: 2.5491 | \n",
      "Epoch: 320 | train_loss: 2.5021 | test_loss: 2.4914 | \n",
      "Epoch: 330 | train_loss: 2.4434 | test_loss: 2.4225 | \n",
      "Epoch: 340 | train_loss: 2.3857 | test_loss: 2.3742 | \n",
      "Epoch: 350 | train_loss: 2.3297 | test_loss: 2.3205 | \n",
      "Epoch: 360 | train_loss: 2.2755 | test_loss: 2.2728 | \n",
      "Epoch: 370 | train_loss: 2.2205 | test_loss: 2.2113 | \n",
      "Epoch: 380 | train_loss: 2.1666 | test_loss: 2.1530 | \n",
      "Epoch: 390 | train_loss: 2.1162 | test_loss: 2.1120 | \n",
      "Epoch: 400 | train_loss: 2.0648 | test_loss: 2.0456 | \n",
      "Epoch: 410 | train_loss: 2.0138 | test_loss: 1.9975 | \n",
      "Epoch: 420 | train_loss: 1.9645 | test_loss: 1.9599 | \n",
      "Epoch: 430 | train_loss: 1.9137 | test_loss: 1.9099 | \n",
      "Epoch: 440 | train_loss: 1.8668 | test_loss: 1.8556 | \n",
      "Epoch: 450 | train_loss: 1.8180 | test_loss: 1.8184 | \n",
      "Epoch: 460 | train_loss: 1.7719 | test_loss: 1.7636 | \n",
      "Epoch: 470 | train_loss: 1.7265 | test_loss: 1.7170 | \n",
      "Epoch: 480 | train_loss: 1.6788 | test_loss: 1.6643 | \n",
      "Epoch: 490 | train_loss: 1.6345 | test_loss: 1.6081 | \n",
      "Epoch: 500 | train_loss: 1.5910 | test_loss: 1.5855 | \n",
      "Epoch: 510 | train_loss: 1.5462 | test_loss: 1.5483 | \n",
      "Epoch: 520 | train_loss: 1.5024 | test_loss: 1.4858 | \n",
      "Epoch: 530 | train_loss: 1.4593 | test_loss: 1.4574 | \n",
      "Epoch: 540 | train_loss: 1.4171 | test_loss: 1.4172 | \n",
      "Epoch: 550 | train_loss: 1.3755 | test_loss: 1.3627 | \n",
      "Epoch: 560 | train_loss: 1.3331 | test_loss: 1.3143 | \n",
      "Epoch: 570 | train_loss: 1.2916 | test_loss: 1.2920 | \n",
      "Epoch: 580 | train_loss: 1.2513 | test_loss: 1.2457 | \n",
      "Epoch: 590 | train_loss: 1.2110 | test_loss: 1.1960 | \n",
      "Epoch: 600 | train_loss: 1.1704 | test_loss: 1.1721 | \n",
      "Epoch: 610 | train_loss: 1.1311 | test_loss: 1.1363 | \n",
      "Epoch: 620 | train_loss: 1.0916 | test_loss: 1.0764 | \n",
      "Epoch: 630 | train_loss: 1.0528 | test_loss: 1.0399 | \n",
      "Epoch: 640 | train_loss: 1.0141 | test_loss: 1.0204 | \n",
      "Epoch: 650 | train_loss: 0.9768 | test_loss: 0.9769 | \n",
      "Epoch: 660 | train_loss: 0.9394 | test_loss: 0.9452 | \n",
      "Epoch: 670 | train_loss: 0.9015 | test_loss: 0.9072 | \n",
      "Epoch: 680 | train_loss: 0.8640 | test_loss: 0.8609 | \n",
      "Epoch: 690 | train_loss: 0.8281 | test_loss: 0.8295 | \n",
      "Epoch: 700 | train_loss: 0.7903 | test_loss: 0.7975 | \n",
      "Epoch: 710 | train_loss: 0.7543 | test_loss: 0.7633 | \n",
      "Epoch: 720 | train_loss: 0.7190 | test_loss: 0.7247 | \n",
      "Epoch: 730 | train_loss: 0.6844 | test_loss: 0.6996 | \n",
      "Epoch: 740 | train_loss: 0.6483 | test_loss: 0.6518 | \n",
      "Epoch: 750 | train_loss: 0.6131 | test_loss: 0.6293 | \n",
      "Epoch: 760 | train_loss: 0.5798 | test_loss: 0.5889 | \n",
      "Epoch: 770 | train_loss: 0.5454 | test_loss: 0.5508 | \n",
      "Epoch: 780 | train_loss: 0.5119 | test_loss: 0.5163 | \n",
      "Epoch: 790 | train_loss: 0.4789 | test_loss: 0.4911 | \n",
      "Epoch: 800 | train_loss: 0.4472 | test_loss: 0.4720 | \n",
      "Epoch: 810 | train_loss: 0.4137 | test_loss: 0.4253 | \n",
      "Epoch: 820 | train_loss: 0.3829 | test_loss: 0.4029 | \n",
      "Epoch: 830 | train_loss: 0.3509 | test_loss: 0.3786 | \n",
      "Epoch: 840 | train_loss: 0.3180 | test_loss: 0.3469 | \n",
      "Epoch: 850 | train_loss: 0.2884 | test_loss: 0.3348 | \n",
      "Epoch: 860 | train_loss: 0.2588 | test_loss: 0.2800 | \n",
      "Epoch: 870 | train_loss: 0.2308 | test_loss: 0.2726 | \n",
      "Epoch: 880 | train_loss: 0.2017 | test_loss: 0.2419 | \n",
      "Epoch: 890 | train_loss: 0.1732 | test_loss: 0.2110 | \n",
      "Epoch: 900 | train_loss: 0.1463 | test_loss: 0.2041 | \n",
      "Epoch: 910 | train_loss: 0.1262 | test_loss: 0.1852 | \n",
      "Epoch: 920 | train_loss: 0.1004 | test_loss: 0.1702 | \n",
      "Epoch: 930 | train_loss: 0.0842 | test_loss: 0.1658 | \n",
      "Epoch: 940 | train_loss: 0.0663 | test_loss: 0.1525 | \n",
      "Epoch: 950 | train_loss: 0.0577 | test_loss: 0.1521 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8739 | test_loss: 9.2058 | \n",
      "Epoch: 10 | train_loss: 7.7375 | test_loss: 7.6697 | \n",
      "Epoch: 20 | train_loss: 6.8458 | test_loss: 6.8271 | \n",
      "Epoch: 30 | train_loss: 6.2579 | test_loss: 6.2107 | \n",
      "Epoch: 40 | train_loss: 5.8365 | test_loss: 5.7745 | \n",
      "Epoch: 50 | train_loss: 5.5060 | test_loss: 5.5020 | \n",
      "Epoch: 60 | train_loss: 5.2357 | test_loss: 5.2169 | \n",
      "Epoch: 70 | train_loss: 5.0055 | test_loss: 4.9918 | \n",
      "Epoch: 80 | train_loss: 4.8011 | test_loss: 4.7618 | \n",
      "Epoch: 90 | train_loss: 4.6198 | test_loss: 4.5890 | \n",
      "Epoch: 100 | train_loss: 4.4564 | test_loss: 4.4269 | \n",
      "Epoch: 110 | train_loss: 4.3059 | test_loss: 4.2821 | \n",
      "Epoch: 120 | train_loss: 4.1681 | test_loss: 4.1703 | \n",
      "Epoch: 130 | train_loss: 4.0406 | test_loss: 4.0364 | \n",
      "Epoch: 140 | train_loss: 3.9214 | test_loss: 3.8845 | \n",
      "Epoch: 150 | train_loss: 3.8094 | test_loss: 3.7808 | \n",
      "Epoch: 160 | train_loss: 3.7058 | test_loss: 3.7097 | \n",
      "Epoch: 170 | train_loss: 3.6048 | test_loss: 3.5736 | \n",
      "Epoch: 180 | train_loss: 3.5099 | test_loss: 3.5035 | \n",
      "Epoch: 190 | train_loss: 3.4189 | test_loss: 3.4032 | \n",
      "Epoch: 200 | train_loss: 3.3315 | test_loss: 3.3074 | \n",
      "Epoch: 210 | train_loss: 3.2493 | test_loss: 3.2301 | \n",
      "Epoch: 220 | train_loss: 3.1683 | test_loss: 3.1453 | \n",
      "Epoch: 230 | train_loss: 3.0925 | test_loss: 3.0743 | \n",
      "Epoch: 240 | train_loss: 3.0179 | test_loss: 3.0155 | \n",
      "Epoch: 250 | train_loss: 2.9446 | test_loss: 2.9198 | \n",
      "Epoch: 260 | train_loss: 2.8783 | test_loss: 2.8662 | \n",
      "Epoch: 270 | train_loss: 2.8065 | test_loss: 2.7966 | \n",
      "Epoch: 280 | train_loss: 2.7405 | test_loss: 2.7172 | \n",
      "Epoch: 290 | train_loss: 2.6767 | test_loss: 2.6653 | \n",
      "Epoch: 300 | train_loss: 2.6141 | test_loss: 2.5961 | \n",
      "Epoch: 310 | train_loss: 2.5521 | test_loss: 2.5416 | \n",
      "Epoch: 320 | train_loss: 2.4937 | test_loss: 2.4888 | \n",
      "Epoch: 330 | train_loss: 2.4346 | test_loss: 2.4268 | \n",
      "Epoch: 340 | train_loss: 2.3770 | test_loss: 2.3707 | \n",
      "Epoch: 350 | train_loss: 2.3233 | test_loss: 2.3010 | \n",
      "Epoch: 360 | train_loss: 2.2675 | test_loss: 2.2108 | \n",
      "Epoch: 370 | train_loss: 2.2128 | test_loss: 2.2105 | \n",
      "Epoch: 380 | train_loss: 2.1590 | test_loss: 2.1556 | \n",
      "Epoch: 390 | train_loss: 2.1070 | test_loss: 2.1029 | \n",
      "Epoch: 400 | train_loss: 2.0563 | test_loss: 2.0560 | \n",
      "Epoch: 410 | train_loss: 2.0067 | test_loss: 1.9909 | \n",
      "Epoch: 420 | train_loss: 1.9564 | test_loss: 1.9404 | \n",
      "Epoch: 430 | train_loss: 1.9081 | test_loss: 1.8968 | \n",
      "Epoch: 440 | train_loss: 1.8607 | test_loss: 1.8461 | \n",
      "Epoch: 450 | train_loss: 1.8133 | test_loss: 1.7889 | \n",
      "Epoch: 460 | train_loss: 1.7657 | test_loss: 1.7709 | \n",
      "Epoch: 470 | train_loss: 1.7200 | test_loss: 1.7167 | \n",
      "Epoch: 480 | train_loss: 1.6746 | test_loss: 1.6696 | \n",
      "Epoch: 490 | train_loss: 1.6295 | test_loss: 1.6237 | \n",
      "Epoch: 500 | train_loss: 1.5850 | test_loss: 1.5760 | \n",
      "Epoch: 510 | train_loss: 1.5409 | test_loss: 1.5415 | \n",
      "Epoch: 520 | train_loss: 1.4979 | test_loss: 1.4930 | \n",
      "Epoch: 530 | train_loss: 1.4560 | test_loss: 1.4416 | \n",
      "Epoch: 540 | train_loss: 1.4107 | test_loss: 1.4084 | \n",
      "Epoch: 550 | train_loss: 1.3706 | test_loss: 1.3897 | \n",
      "Epoch: 560 | train_loss: 1.3291 | test_loss: 1.3220 | \n",
      "Epoch: 570 | train_loss: 1.2880 | test_loss: 1.2699 | \n",
      "Epoch: 580 | train_loss: 1.2460 | test_loss: 1.2350 | \n",
      "Epoch: 590 | train_loss: 1.2074 | test_loss: 1.1994 | \n",
      "Epoch: 600 | train_loss: 1.1657 | test_loss: 1.1586 | \n",
      "Epoch: 610 | train_loss: 1.1275 | test_loss: 1.1121 | \n",
      "Epoch: 620 | train_loss: 1.0881 | test_loss: 1.0903 | \n",
      "Epoch: 630 | train_loss: 1.0490 | test_loss: 1.0512 | \n",
      "Epoch: 640 | train_loss: 1.0108 | test_loss: 1.0123 | \n",
      "Epoch: 650 | train_loss: 0.9722 | test_loss: 0.9723 | \n",
      "Epoch: 660 | train_loss: 0.9348 | test_loss: 0.9347 | \n",
      "Epoch: 670 | train_loss: 0.8978 | test_loss: 0.8972 | \n",
      "Epoch: 680 | train_loss: 0.8609 | test_loss: 0.8558 | \n",
      "Epoch: 690 | train_loss: 0.8248 | test_loss: 0.8188 | \n",
      "Epoch: 700 | train_loss: 0.7867 | test_loss: 0.7881 | \n",
      "Epoch: 710 | train_loss: 0.7516 | test_loss: 0.7492 | \n",
      "Epoch: 720 | train_loss: 0.7160 | test_loss: 0.7158 | \n",
      "Epoch: 730 | train_loss: 0.6809 | test_loss: 0.6933 | \n",
      "Epoch: 740 | train_loss: 0.6464 | test_loss: 0.6554 | \n",
      "Epoch: 750 | train_loss: 0.6132 | test_loss: 0.6324 | \n",
      "Epoch: 760 | train_loss: 0.5792 | test_loss: 0.5767 | \n",
      "Epoch: 770 | train_loss: 0.5437 | test_loss: 0.5460 | \n",
      "Epoch: 780 | train_loss: 0.5104 | test_loss: 0.5144 | \n",
      "Epoch: 790 | train_loss: 0.4774 | test_loss: 0.4849 | \n",
      "Epoch: 800 | train_loss: 0.4448 | test_loss: 0.4646 | \n",
      "Epoch: 810 | train_loss: 0.4127 | test_loss: 0.4168 | \n",
      "Epoch: 820 | train_loss: 0.3816 | test_loss: 0.4039 | \n",
      "Epoch: 830 | train_loss: 0.3488 | test_loss: 0.3853 | \n",
      "Epoch: 840 | train_loss: 0.3189 | test_loss: 0.3451 | \n",
      "Epoch: 850 | train_loss: 0.2885 | test_loss: 0.3144 | \n",
      "Epoch: 860 | train_loss: 0.2586 | test_loss: 0.2814 | \n",
      "Epoch: 870 | train_loss: 0.2285 | test_loss: 0.2569 | \n",
      "Epoch: 880 | train_loss: 0.2013 | test_loss: 0.2231 | \n",
      "Epoch: 890 | train_loss: 0.1766 | test_loss: 0.2168 | \n",
      "Epoch: 900 | train_loss: 0.1494 | test_loss: 0.1922 | \n",
      "Epoch: 910 | train_loss: 0.1223 | test_loss: 0.1917 | \n",
      "Epoch: 920 | train_loss: 0.0985 | test_loss: 0.1675 | \n",
      "Epoch: 930 | train_loss: 0.0797 | test_loss: 0.1563 | \n",
      "Epoch: 940 | train_loss: 0.0706 | test_loss: 0.1530 | \n",
      "Epoch: 950 | train_loss: 0.0562 | test_loss: 0.1489 | \n",
      "Epoch: 960 | train_loss: 0.0557 | test_loss: 0.1427 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8917 | test_loss: 9.9842 | \n",
      "Epoch: 10 | train_loss: 7.7484 | test_loss: 7.6685 | \n",
      "Epoch: 20 | train_loss: 6.8703 | test_loss: 6.8180 | \n",
      "Epoch: 30 | train_loss: 6.2858 | test_loss: 6.2363 | \n",
      "Epoch: 40 | train_loss: 5.8564 | test_loss: 5.8121 | \n",
      "Epoch: 50 | train_loss: 5.5409 | test_loss: 5.4956 | \n",
      "Epoch: 60 | train_loss: 5.2663 | test_loss: 5.2309 | \n",
      "Epoch: 70 | train_loss: 5.0344 | test_loss: 5.0016 | \n",
      "Epoch: 80 | train_loss: 4.8276 | test_loss: 4.7922 | \n",
      "Epoch: 90 | train_loss: 4.6485 | test_loss: 4.6155 | \n",
      "Epoch: 100 | train_loss: 4.4820 | test_loss: 4.4485 | \n",
      "Epoch: 110 | train_loss: 4.3312 | test_loss: 4.3035 | \n",
      "Epoch: 120 | train_loss: 4.1992 | test_loss: 4.1684 | \n",
      "Epoch: 130 | train_loss: 4.0635 | test_loss: 4.0487 | \n",
      "Epoch: 140 | train_loss: 3.9527 | test_loss: 3.9202 | \n",
      "Epoch: 150 | train_loss: 3.8369 | test_loss: 3.8123 | \n",
      "Epoch: 160 | train_loss: 3.7275 | test_loss: 3.7095 | \n",
      "Epoch: 170 | train_loss: 3.6314 | test_loss: 3.6052 | \n",
      "Epoch: 180 | train_loss: 3.5277 | test_loss: 3.5131 | \n",
      "Epoch: 190 | train_loss: 3.4443 | test_loss: 3.4185 | \n",
      "Epoch: 200 | train_loss: 3.3579 | test_loss: 3.3346 | \n",
      "Epoch: 210 | train_loss: 3.2755 | test_loss: 3.2552 | \n",
      "Epoch: 220 | train_loss: 3.1947 | test_loss: 3.1734 | \n",
      "Epoch: 230 | train_loss: 3.1178 | test_loss: 3.0955 | \n",
      "Epoch: 240 | train_loss: 3.0418 | test_loss: 3.0229 | \n",
      "Epoch: 250 | train_loss: 2.9712 | test_loss: 2.9489 | \n",
      "Epoch: 260 | train_loss: 2.8967 | test_loss: 2.8772 | \n",
      "Epoch: 270 | train_loss: 2.8295 | test_loss: 2.8129 | \n",
      "Epoch: 280 | train_loss: 2.7744 | test_loss: 2.7525 | \n",
      "Epoch: 290 | train_loss: 2.7009 | test_loss: 2.6747 | \n",
      "Epoch: 300 | train_loss: 2.6380 | test_loss: 2.6167 | \n",
      "Epoch: 310 | train_loss: 2.5748 | test_loss: 2.5591 | \n",
      "Epoch: 320 | train_loss: 2.5165 | test_loss: 2.4917 | \n",
      "Epoch: 330 | train_loss: 2.4588 | test_loss: 2.4323 | \n",
      "Epoch: 340 | train_loss: 2.4050 | test_loss: 2.3892 | \n",
      "Epoch: 350 | train_loss: 2.3436 | test_loss: 2.3258 | \n",
      "Epoch: 360 | train_loss: 2.2903 | test_loss: 2.2711 | \n",
      "Epoch: 370 | train_loss: 2.2414 | test_loss: 2.2164 | \n",
      "Epoch: 380 | train_loss: 2.1808 | test_loss: 2.1627 | \n",
      "Epoch: 390 | train_loss: 2.1303 | test_loss: 2.1142 | \n",
      "Epoch: 400 | train_loss: 2.0774 | test_loss: 2.0643 | \n",
      "Epoch: 410 | train_loss: 2.0285 | test_loss: 2.0125 | \n",
      "Epoch: 420 | train_loss: 1.9810 | test_loss: 1.9597 | \n",
      "Epoch: 430 | train_loss: 1.9333 | test_loss: 1.9118 | \n",
      "Epoch: 440 | train_loss: 1.8805 | test_loss: 1.8645 | \n",
      "Epoch: 450 | train_loss: 1.8330 | test_loss: 1.8177 | \n",
      "Epoch: 460 | train_loss: 1.7912 | test_loss: 1.7704 | \n",
      "Epoch: 470 | train_loss: 1.7427 | test_loss: 1.7244 | \n",
      "Epoch: 480 | train_loss: 1.6932 | test_loss: 1.6773 | \n",
      "Epoch: 490 | train_loss: 1.6511 | test_loss: 1.6335 | \n",
      "Epoch: 500 | train_loss: 1.6075 | test_loss: 1.5885 | \n",
      "Epoch: 510 | train_loss: 1.5620 | test_loss: 1.5478 | \n",
      "Epoch: 520 | train_loss: 1.5216 | test_loss: 1.5050 | \n",
      "Epoch: 530 | train_loss: 1.4773 | test_loss: 1.4606 | \n",
      "Epoch: 540 | train_loss: 1.4350 | test_loss: 1.4204 | \n",
      "Epoch: 550 | train_loss: 1.3989 | test_loss: 1.3808 | \n",
      "Epoch: 560 | train_loss: 1.3463 | test_loss: 1.3371 | \n",
      "Epoch: 570 | train_loss: 1.3122 | test_loss: 1.3005 | \n",
      "Epoch: 580 | train_loss: 1.2678 | test_loss: 1.2491 | \n",
      "Epoch: 590 | train_loss: 1.2301 | test_loss: 1.2165 | \n",
      "Epoch: 600 | train_loss: 1.1918 | test_loss: 1.1738 | \n",
      "Epoch: 610 | train_loss: 1.1481 | test_loss: 1.1430 | \n",
      "Epoch: 620 | train_loss: 1.1081 | test_loss: 1.0982 | \n",
      "Epoch: 630 | train_loss: 1.0743 | test_loss: 1.0603 | \n",
      "Epoch: 640 | train_loss: 1.0333 | test_loss: 1.0205 | \n",
      "Epoch: 650 | train_loss: 0.9960 | test_loss: 0.9868 | \n",
      "Epoch: 660 | train_loss: 0.9579 | test_loss: 0.9480 | \n",
      "Epoch: 670 | train_loss: 0.9217 | test_loss: 0.9128 | \n",
      "Epoch: 680 | train_loss: 0.8901 | test_loss: 0.8687 | \n",
      "Epoch: 690 | train_loss: 0.8543 | test_loss: 0.8393 | \n",
      "Epoch: 700 | train_loss: 0.8187 | test_loss: 0.8024 | \n",
      "Epoch: 710 | train_loss: 0.7827 | test_loss: 0.7763 | \n",
      "Epoch: 720 | train_loss: 0.7445 | test_loss: 0.7386 | \n",
      "Epoch: 730 | train_loss: 0.7105 | test_loss: 0.6942 | \n",
      "Epoch: 740 | train_loss: 0.6774 | test_loss: 0.6601 | \n",
      "Epoch: 750 | train_loss: 0.6381 | test_loss: 0.6282 | \n",
      "Epoch: 760 | train_loss: 0.6073 | test_loss: 0.6025 | \n",
      "Epoch: 770 | train_loss: 0.5698 | test_loss: 0.5642 | \n",
      "Epoch: 780 | train_loss: 0.5393 | test_loss: 0.5337 | \n",
      "Epoch: 790 | train_loss: 0.5044 | test_loss: 0.5025 | \n",
      "Epoch: 800 | train_loss: 0.4799 | test_loss: 0.4760 | \n",
      "Epoch: 810 | train_loss: 0.4474 | test_loss: 0.4426 | \n",
      "Epoch: 820 | train_loss: 0.4236 | test_loss: 0.4190 | \n",
      "Epoch: 830 | train_loss: 0.3895 | test_loss: 0.3825 | \n",
      "Epoch: 840 | train_loss: 0.3557 | test_loss: 0.3610 | \n",
      "Epoch: 850 | train_loss: 0.3344 | test_loss: 0.3265 | \n",
      "Epoch: 860 | train_loss: 0.3036 | test_loss: 0.3070 | \n",
      "Epoch: 870 | train_loss: 0.2735 | test_loss: 0.2833 | \n",
      "Epoch: 880 | train_loss: 0.2538 | test_loss: 0.2686 | \n",
      "Epoch: 890 | train_loss: 0.2288 | test_loss: 0.2335 | \n",
      "Epoch: 900 | train_loss: 0.2019 | test_loss: 0.2148 | \n",
      "Epoch: 910 | train_loss: 0.1873 | test_loss: 0.2045 | \n",
      "Epoch: 920 | train_loss: 0.1760 | test_loss: 0.1869 | \n",
      "Epoch: 930 | train_loss: 0.1625 | test_loss: 0.1650 | \n",
      "Epoch: 940 | train_loss: 0.1459 | test_loss: 0.1520 | \n",
      "Epoch: 950 | train_loss: 0.1398 | test_loss: 0.1498 | \n",
      "Epoch: 960 | train_loss: 0.1282 | test_loss: 0.1481 | \n",
      "Epoch: 970 | train_loss: 0.1183 | test_loss: 0.1466 | \n",
      "Epoch: 980 | train_loss: 0.1181 | test_loss: 0.1408 | \n",
      "Epoch: 990 | train_loss: 0.1147 | test_loss: 0.1402 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8584 | test_loss: 9.6100 | \n",
      "Epoch: 10 | train_loss: 7.7357 | test_loss: 7.6491 | \n",
      "Epoch: 20 | train_loss: 6.8407 | test_loss: 6.7869 | \n",
      "Epoch: 30 | train_loss: 6.2730 | test_loss: 6.2141 | \n",
      "Epoch: 40 | train_loss: 5.8519 | test_loss: 5.8012 | \n",
      "Epoch: 50 | train_loss: 5.5191 | test_loss: 5.4806 | \n",
      "Epoch: 60 | train_loss: 5.2446 | test_loss: 5.2053 | \n",
      "Epoch: 70 | train_loss: 5.0082 | test_loss: 4.9801 | \n",
      "Epoch: 80 | train_loss: 4.8080 | test_loss: 4.7775 | \n",
      "Epoch: 90 | train_loss: 4.6235 | test_loss: 4.5931 | \n",
      "Epoch: 100 | train_loss: 4.4592 | test_loss: 4.4259 | \n",
      "Epoch: 110 | train_loss: 4.3156 | test_loss: 4.2863 | \n",
      "Epoch: 120 | train_loss: 4.1727 | test_loss: 4.1474 | \n",
      "Epoch: 130 | train_loss: 4.0471 | test_loss: 4.0196 | \n",
      "Epoch: 140 | train_loss: 3.9259 | test_loss: 3.9052 | \n",
      "Epoch: 150 | train_loss: 3.8210 | test_loss: 3.7924 | \n",
      "Epoch: 160 | train_loss: 3.7117 | test_loss: 3.6875 | \n",
      "Epoch: 170 | train_loss: 3.6051 | test_loss: 3.5922 | \n",
      "Epoch: 180 | train_loss: 3.5095 | test_loss: 3.4931 | \n",
      "Epoch: 190 | train_loss: 3.4234 | test_loss: 3.4044 | \n",
      "Epoch: 200 | train_loss: 3.3340 | test_loss: 3.3191 | \n",
      "Epoch: 210 | train_loss: 3.2520 | test_loss: 3.2339 | \n",
      "Epoch: 220 | train_loss: 3.1781 | test_loss: 3.1593 | \n",
      "Epoch: 230 | train_loss: 3.1002 | test_loss: 3.0784 | \n",
      "Epoch: 240 | train_loss: 3.0187 | test_loss: 3.0076 | \n",
      "Epoch: 250 | train_loss: 2.9476 | test_loss: 2.9386 | \n",
      "Epoch: 260 | train_loss: 2.8809 | test_loss: 2.8665 | \n",
      "Epoch: 270 | train_loss: 2.8120 | test_loss: 2.7993 | \n",
      "Epoch: 280 | train_loss: 2.7489 | test_loss: 2.7343 | \n",
      "Epoch: 290 | train_loss: 2.6795 | test_loss: 2.6688 | \n",
      "Epoch: 300 | train_loss: 2.6164 | test_loss: 2.6108 | \n",
      "Epoch: 310 | train_loss: 2.5585 | test_loss: 2.5448 | \n",
      "Epoch: 320 | train_loss: 2.4995 | test_loss: 2.4841 | \n",
      "Epoch: 330 | train_loss: 2.4421 | test_loss: 2.4319 | \n",
      "Epoch: 340 | train_loss: 2.3818 | test_loss: 2.3690 | \n",
      "Epoch: 350 | train_loss: 2.3253 | test_loss: 2.3126 | \n",
      "Epoch: 360 | train_loss: 2.2707 | test_loss: 2.2632 | \n",
      "Epoch: 370 | train_loss: 2.2149 | test_loss: 2.2058 | \n",
      "Epoch: 380 | train_loss: 2.1635 | test_loss: 2.1566 | \n",
      "Epoch: 390 | train_loss: 2.1124 | test_loss: 2.1040 | \n",
      "Epoch: 400 | train_loss: 2.0570 | test_loss: 2.0516 | \n",
      "Epoch: 410 | train_loss: 2.0122 | test_loss: 1.9979 | \n",
      "Epoch: 420 | train_loss: 1.9593 | test_loss: 1.9444 | \n",
      "Epoch: 430 | train_loss: 1.9128 | test_loss: 1.9042 | \n",
      "Epoch: 440 | train_loss: 1.8598 | test_loss: 1.8509 | \n",
      "Epoch: 450 | train_loss: 1.8181 | test_loss: 1.8071 | \n",
      "Epoch: 460 | train_loss: 1.7686 | test_loss: 1.7576 | \n",
      "Epoch: 470 | train_loss: 1.7216 | test_loss: 1.7129 | \n",
      "Epoch: 480 | train_loss: 1.6734 | test_loss: 1.6644 | \n",
      "Epoch: 490 | train_loss: 1.6312 | test_loss: 1.6172 | \n",
      "Epoch: 500 | train_loss: 1.5882 | test_loss: 1.5799 | \n",
      "Epoch: 510 | train_loss: 1.5449 | test_loss: 1.5376 | \n",
      "Epoch: 520 | train_loss: 1.5019 | test_loss: 1.4893 | \n",
      "Epoch: 530 | train_loss: 1.4584 | test_loss: 1.4493 | \n",
      "Epoch: 540 | train_loss: 1.4162 | test_loss: 1.4071 | \n",
      "Epoch: 550 | train_loss: 1.3714 | test_loss: 1.3632 | \n",
      "Epoch: 560 | train_loss: 1.3373 | test_loss: 1.3194 | \n",
      "Epoch: 570 | train_loss: 1.2961 | test_loss: 1.2807 | \n",
      "Epoch: 580 | train_loss: 1.2540 | test_loss: 1.2437 | \n",
      "Epoch: 590 | train_loss: 1.2145 | test_loss: 1.2012 | \n",
      "Epoch: 600 | train_loss: 1.1787 | test_loss: 1.1615 | \n",
      "Epoch: 610 | train_loss: 1.1328 | test_loss: 1.1228 | \n",
      "Epoch: 620 | train_loss: 1.0970 | test_loss: 1.0839 | \n",
      "Epoch: 630 | train_loss: 1.0545 | test_loss: 1.0466 | \n",
      "Epoch: 640 | train_loss: 1.0227 | test_loss: 1.0044 | \n",
      "Epoch: 650 | train_loss: 0.9814 | test_loss: 0.9606 | \n",
      "Epoch: 660 | train_loss: 0.9423 | test_loss: 0.9333 | \n",
      "Epoch: 670 | train_loss: 0.9087 | test_loss: 0.8969 | \n",
      "Epoch: 680 | train_loss: 0.8708 | test_loss: 0.8595 | \n",
      "Epoch: 690 | train_loss: 0.8374 | test_loss: 0.8244 | \n",
      "Epoch: 700 | train_loss: 0.7955 | test_loss: 0.7964 | \n",
      "Epoch: 710 | train_loss: 0.7671 | test_loss: 0.7496 | \n",
      "Epoch: 720 | train_loss: 0.7310 | test_loss: 0.7180 | \n",
      "Epoch: 730 | train_loss: 0.6979 | test_loss: 0.6875 | \n",
      "Epoch: 740 | train_loss: 0.6659 | test_loss: 0.6541 | \n",
      "Epoch: 750 | train_loss: 0.6244 | test_loss: 0.6235 | \n",
      "Epoch: 760 | train_loss: 0.5936 | test_loss: 0.5854 | \n",
      "Epoch: 770 | train_loss: 0.5551 | test_loss: 0.5500 | \n",
      "Epoch: 780 | train_loss: 0.5270 | test_loss: 0.5176 | \n",
      "Epoch: 790 | train_loss: 0.4973 | test_loss: 0.4837 | \n",
      "Epoch: 800 | train_loss: 0.4648 | test_loss: 0.4514 | \n",
      "Epoch: 810 | train_loss: 0.4327 | test_loss: 0.4274 | \n",
      "Epoch: 820 | train_loss: 0.4075 | test_loss: 0.4022 | \n",
      "Epoch: 830 | train_loss: 0.3729 | test_loss: 0.3662 | \n",
      "Epoch: 840 | train_loss: 0.3483 | test_loss: 0.3430 | \n",
      "Epoch: 850 | train_loss: 0.3158 | test_loss: 0.3161 | \n",
      "Epoch: 860 | train_loss: 0.2853 | test_loss: 0.2915 | \n",
      "Epoch: 870 | train_loss: 0.2636 | test_loss: 0.2619 | \n",
      "Epoch: 880 | train_loss: 0.2378 | test_loss: 0.2424 | \n",
      "Epoch: 890 | train_loss: 0.2119 | test_loss: 0.2171 | \n",
      "Epoch: 900 | train_loss: 0.1930 | test_loss: 0.1976 | \n",
      "Epoch: 910 | train_loss: 0.1713 | test_loss: 0.1861 | \n",
      "Epoch: 920 | train_loss: 0.1627 | test_loss: 0.1670 | \n",
      "Epoch: 930 | train_loss: 0.1452 | test_loss: 0.1602 | \n",
      "Epoch: 940 | train_loss: 0.1380 | test_loss: 0.1515 | \n",
      "Epoch: 950 | train_loss: 0.1216 | test_loss: 0.1483 | \n",
      "Epoch: 960 | train_loss: 0.1172 | test_loss: 0.1445 | \n",
      "Epoch: 970 | train_loss: 0.1171 | test_loss: 0.1464 | \n",
      "Epoch: 980 | train_loss: 0.1131 | test_loss: 0.1391 | \n",
      "Epoch: 990 | train_loss: 0.1098 | test_loss: 0.1409 | \n",
      "Epoch: 1000 | train_loss: 0.1172 | test_loss: 0.1431 | \n",
      "Epoch: 1010 | train_loss: 0.1095 | test_loss: 0.1356 | \n",
      "Epoch: 1020 | train_loss: 0.1107 | test_loss: 0.1378 | \n",
      "Epoch: 1030 | train_loss: 0.1075 | test_loss: 0.1381 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.8643 | test_loss: 2.3865 | \n",
      "Epoch: 10 | train_loss: 0.1533 | test_loss: 0.1538 | \n",
      "Epoch: 20 | train_loss: 0.1318 | test_loss: 0.1551 | \n",
      "Epoch: 30 | train_loss: 0.1237 | test_loss: 0.1499 | \n",
      "Epoch: 40 | train_loss: 0.1172 | test_loss: 0.1473 | \n",
      "Epoch: 50 | train_loss: 0.1099 | test_loss: 0.1477 | \n",
      "Epoch: 60 | train_loss: 0.1035 | test_loss: 0.1448 | \n",
      "Epoch: 70 | train_loss: 0.0975 | test_loss: 0.1431 | \n",
      "Epoch: 80 | train_loss: 0.0901 | test_loss: 0.1439 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.2898 | test_loss: 0.3968 | \n",
      "Epoch: 10 | train_loss: 0.1329 | test_loss: 0.1451 | \n",
      "Epoch: 20 | train_loss: 0.1156 | test_loss: 0.1456 | \n",
      "Epoch: 30 | train_loss: 0.1050 | test_loss: 0.1462 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 2.0478 | test_loss: 0.3968 | \n",
      "Epoch: 10 | train_loss: 0.1338 | test_loss: 0.1451 | \n",
      "Epoch: 20 | train_loss: 0.1063 | test_loss: 0.1457 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6314 | test_loss: 8.6317 | \n",
      "Epoch: 10 | train_loss: 5.9143 | test_loss: 5.8095 | \n",
      "Epoch: 20 | train_loss: 4.8470 | test_loss: 4.8087 | \n",
      "Epoch: 30 | train_loss: 4.2141 | test_loss: 4.1724 | \n",
      "Epoch: 40 | train_loss: 3.7369 | test_loss: 3.6909 | \n",
      "Epoch: 50 | train_loss: 3.3609 | test_loss: 3.3442 | \n",
      "Epoch: 60 | train_loss: 3.0432 | test_loss: 3.0311 | \n",
      "Epoch: 70 | train_loss: 2.7666 | test_loss: 2.7434 | \n",
      "Epoch: 80 | train_loss: 2.5147 | test_loss: 2.4988 | \n",
      "Epoch: 90 | train_loss: 2.2879 | test_loss: 2.2644 | \n",
      "Epoch: 100 | train_loss: 2.0776 | test_loss: 2.0352 | \n",
      "Epoch: 110 | train_loss: 1.8805 | test_loss: 1.8695 | \n",
      "Epoch: 120 | train_loss: 1.7059 | test_loss: 1.6927 | \n",
      "Epoch: 130 | train_loss: 1.5231 | test_loss: 1.5085 | \n",
      "Epoch: 140 | train_loss: 1.3521 | test_loss: 1.3420 | \n",
      "Epoch: 150 | train_loss: 1.1871 | test_loss: 1.1680 | \n",
      "Epoch: 160 | train_loss: 1.0306 | test_loss: 1.0239 | \n",
      "Epoch: 170 | train_loss: 0.8857 | test_loss: 0.8742 | \n",
      "Epoch: 180 | train_loss: 0.7387 | test_loss: 0.7203 | \n",
      "Epoch: 190 | train_loss: 0.6002 | test_loss: 0.6323 | \n",
      "Epoch: 200 | train_loss: 0.4746 | test_loss: 0.4498 | \n",
      "Epoch: 210 | train_loss: 0.3464 | test_loss: 0.3621 | \n",
      "Epoch: 220 | train_loss: 0.2379 | test_loss: 0.2622 | \n",
      "Epoch: 230 | train_loss: 0.1601 | test_loss: 0.1974 | \n",
      "Epoch: 240 | train_loss: 0.1059 | test_loss: 0.1670 | \n",
      "Epoch: 250 | train_loss: 0.0858 | test_loss: 0.1519 | \n",
      "Epoch: 260 | train_loss: 0.0853 | test_loss: 0.1481 | \n",
      "Epoch: 270 | train_loss: 0.0832 | test_loss: 0.1493 | \n",
      "Epoch: 280 | train_loss: 0.0820 | test_loss: 0.1494 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6250 | test_loss: 8.5785 | \n",
      "Epoch: 10 | train_loss: 5.9017 | test_loss: 5.8336 | \n",
      "Epoch: 20 | train_loss: 4.8419 | test_loss: 4.7984 | \n",
      "Epoch: 30 | train_loss: 4.2016 | test_loss: 4.1754 | \n",
      "Epoch: 40 | train_loss: 3.7376 | test_loss: 3.7218 | \n",
      "Epoch: 50 | train_loss: 3.3601 | test_loss: 3.3420 | \n",
      "Epoch: 60 | train_loss: 3.0407 | test_loss: 3.0194 | \n",
      "Epoch: 70 | train_loss: 2.7622 | test_loss: 2.7401 | \n",
      "Epoch: 80 | train_loss: 2.5131 | test_loss: 2.4959 | \n",
      "Epoch: 90 | train_loss: 2.2854 | test_loss: 2.2604 | \n",
      "Epoch: 100 | train_loss: 2.0748 | test_loss: 2.0473 | \n",
      "Epoch: 110 | train_loss: 1.8766 | test_loss: 1.8529 | \n",
      "Epoch: 120 | train_loss: 1.6934 | test_loss: 1.6782 | \n",
      "Epoch: 130 | train_loss: 1.5121 | test_loss: 1.4946 | \n",
      "Epoch: 140 | train_loss: 1.3442 | test_loss: 1.3307 | \n",
      "Epoch: 150 | train_loss: 1.1823 | test_loss: 1.1732 | \n",
      "Epoch: 160 | train_loss: 1.0277 | test_loss: 1.0206 | \n",
      "Epoch: 170 | train_loss: 0.8755 | test_loss: 0.8786 | \n",
      "Epoch: 180 | train_loss: 0.7319 | test_loss: 0.7369 | \n",
      "Epoch: 190 | train_loss: 0.5928 | test_loss: 0.5989 | \n",
      "Epoch: 200 | train_loss: 0.4582 | test_loss: 0.4724 | \n",
      "Epoch: 210 | train_loss: 0.3375 | test_loss: 0.3563 | \n",
      "Epoch: 220 | train_loss: 0.2236 | test_loss: 0.2628 | \n",
      "Epoch: 230 | train_loss: 0.1459 | test_loss: 0.1882 | \n",
      "Epoch: 240 | train_loss: 0.1024 | test_loss: 0.1573 | \n",
      "Epoch: 250 | train_loss: 0.0854 | test_loss: 0.1489 | \n",
      "Epoch: 260 | train_loss: 0.0794 | test_loss: 0.1494 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.7231 | test_loss: 8.6329 | \n",
      "Epoch: 10 | train_loss: 6.0001 | test_loss: 5.8911 | \n",
      "Epoch: 20 | train_loss: 4.9307 | test_loss: 4.8782 | \n",
      "Epoch: 30 | train_loss: 4.2905 | test_loss: 4.2453 | \n",
      "Epoch: 40 | train_loss: 3.8224 | test_loss: 3.7811 | \n",
      "Epoch: 50 | train_loss: 3.4429 | test_loss: 3.4178 | \n",
      "Epoch: 60 | train_loss: 3.1282 | test_loss: 3.0906 | \n",
      "Epoch: 70 | train_loss: 2.8474 | test_loss: 2.8208 | \n",
      "Epoch: 80 | train_loss: 2.5976 | test_loss: 2.5732 | \n",
      "Epoch: 90 | train_loss: 2.3698 | test_loss: 2.3485 | \n",
      "Epoch: 100 | train_loss: 2.1571 | test_loss: 2.1226 | \n",
      "Epoch: 110 | train_loss: 1.9534 | test_loss: 1.9330 | \n",
      "Epoch: 120 | train_loss: 1.7710 | test_loss: 1.7392 | \n",
      "Epoch: 130 | train_loss: 1.5924 | test_loss: 1.5635 | \n",
      "Epoch: 140 | train_loss: 1.4233 | test_loss: 1.3962 | \n",
      "Epoch: 150 | train_loss: 1.2645 | test_loss: 1.2404 | \n",
      "Epoch: 160 | train_loss: 1.1076 | test_loss: 1.0889 | \n",
      "Epoch: 170 | train_loss: 0.9573 | test_loss: 0.9335 | \n",
      "Epoch: 180 | train_loss: 0.8185 | test_loss: 0.8001 | \n",
      "Epoch: 190 | train_loss: 0.6842 | test_loss: 0.6610 | \n",
      "Epoch: 200 | train_loss: 0.5573 | test_loss: 0.5302 | \n",
      "Epoch: 210 | train_loss: 0.4382 | test_loss: 0.4301 | \n",
      "Epoch: 220 | train_loss: 0.3289 | test_loss: 0.3202 | \n",
      "Epoch: 230 | train_loss: 0.2422 | test_loss: 0.2441 | \n",
      "Epoch: 240 | train_loss: 0.1905 | test_loss: 0.1872 | \n",
      "Epoch: 250 | train_loss: 0.1611 | test_loss: 0.1567 | \n",
      "Epoch: 260 | train_loss: 0.1579 | test_loss: 0.1542 | \n",
      "Epoch: 270 | train_loss: 0.1487 | test_loss: 0.1438 | \n",
      "Epoch: 280 | train_loss: 0.1425 | test_loss: 0.1487 | \n",
      "Epoch: 290 | train_loss: 0.1379 | test_loss: 0.1423 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6761 | test_loss: 8.6160 | \n",
      "Epoch: 10 | train_loss: 5.9461 | test_loss: 5.8431 | \n",
      "Epoch: 20 | train_loss: 4.8837 | test_loss: 4.8090 | \n",
      "Epoch: 30 | train_loss: 4.2382 | test_loss: 4.1851 | \n",
      "Epoch: 40 | train_loss: 3.7684 | test_loss: 3.7293 | \n",
      "Epoch: 50 | train_loss: 3.3905 | test_loss: 3.3634 | \n",
      "Epoch: 60 | train_loss: 3.0761 | test_loss: 3.0435 | \n",
      "Epoch: 70 | train_loss: 2.7955 | test_loss: 2.7637 | \n",
      "Epoch: 80 | train_loss: 2.5445 | test_loss: 2.5100 | \n",
      "Epoch: 90 | train_loss: 2.3221 | test_loss: 2.2973 | \n",
      "Epoch: 100 | train_loss: 2.1098 | test_loss: 2.0768 | \n",
      "Epoch: 110 | train_loss: 1.9140 | test_loss: 1.8862 | \n",
      "Epoch: 120 | train_loss: 1.7272 | test_loss: 1.7000 | \n",
      "Epoch: 130 | train_loss: 1.5531 | test_loss: 1.5191 | \n",
      "Epoch: 140 | train_loss: 1.3854 | test_loss: 1.3511 | \n",
      "Epoch: 150 | train_loss: 1.2223 | test_loss: 1.1986 | \n",
      "Epoch: 160 | train_loss: 1.0621 | test_loss: 1.0451 | \n",
      "Epoch: 170 | train_loss: 0.9171 | test_loss: 0.8939 | \n",
      "Epoch: 180 | train_loss: 0.7790 | test_loss: 0.7484 | \n",
      "Epoch: 190 | train_loss: 0.6403 | test_loss: 0.6040 | \n",
      "Epoch: 200 | train_loss: 0.5134 | test_loss: 0.5036 | \n",
      "Epoch: 210 | train_loss: 0.3961 | test_loss: 0.3835 | \n",
      "Epoch: 220 | train_loss: 0.3001 | test_loss: 0.2746 | \n",
      "Epoch: 230 | train_loss: 0.2140 | test_loss: 0.1973 | \n",
      "Epoch: 240 | train_loss: 0.1711 | test_loss: 0.1669 | \n",
      "Epoch: 250 | train_loss: 0.1492 | test_loss: 0.1421 | \n",
      "Epoch: 260 | train_loss: 0.1441 | test_loss: 0.1386 | \n",
      "Epoch: 270 | train_loss: 0.1430 | test_loss: 0.1439 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.4549 | test_loss: 4.8587 | \n",
      "Epoch: 10 | train_loss: 0.1791 | test_loss: 0.1696 | \n",
      "Epoch: 20 | train_loss: 0.1518 | test_loss: 0.1565 | \n",
      "Epoch: 30 | train_loss: 0.1413 | test_loss: 0.1557 | \n",
      "Epoch: 40 | train_loss: 0.1329 | test_loss: 0.1530 | \n",
      "Epoch: 50 | train_loss: 0.1283 | test_loss: 0.1548 | \n",
      "Epoch: 60 | train_loss: 0.1241 | test_loss: 0.1524 | \n",
      "Epoch: 70 | train_loss: 0.1203 | test_loss: 0.1496 | \n",
      "Epoch: 80 | train_loss: 0.1190 | test_loss: 0.1504 | \n",
      "Epoch: 90 | train_loss: 0.1147 | test_loss: 0.1492 | \n",
      "Epoch: 100 | train_loss: 0.1109 | test_loss: 0.1497 | \n",
      "Epoch: 110 | train_loss: 0.1078 | test_loss: 0.1487 | \n",
      "Epoch: 120 | train_loss: 0.1033 | test_loss: 0.1463 | \n",
      "Epoch: 130 | train_loss: 0.0997 | test_loss: 0.1500 | \n",
      "Epoch: 140 | train_loss: 0.1006 | test_loss: 0.1492 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.7750 | test_loss: 1.9226 | \n",
      "Epoch: 10 | train_loss: 0.1474 | test_loss: 0.1586 | \n",
      "Epoch: 20 | train_loss: 0.1280 | test_loss: 0.1522 | \n",
      "Epoch: 30 | train_loss: 0.1201 | test_loss: 0.1472 | \n",
      "Epoch: 40 | train_loss: 0.1112 | test_loss: 0.1449 | \n",
      "Epoch: 50 | train_loss: 0.1013 | test_loss: 0.1486 | \n",
      "Epoch: 60 | train_loss: 0.0928 | test_loss: 0.1469 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.1149 | test_loss: 1.6074 | \n",
      "Epoch: 10 | train_loss: 0.1325 | test_loss: 0.1453 | \n",
      "Epoch: 20 | train_loss: 0.1137 | test_loss: 0.1646 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2688 | test_loss: 9.1395 | \n",
      "Epoch: 10 | train_loss: 6.9118 | test_loss: 6.8511 | \n",
      "Epoch: 20 | train_loss: 5.8945 | test_loss: 5.8520 | \n",
      "Epoch: 30 | train_loss: 5.2892 | test_loss: 5.2190 | \n",
      "Epoch: 40 | train_loss: 4.8462 | test_loss: 4.7881 | \n",
      "Epoch: 50 | train_loss: 4.5014 | test_loss: 4.4657 | \n",
      "Epoch: 60 | train_loss: 4.2140 | test_loss: 4.1836 | \n",
      "Epoch: 70 | train_loss: 3.9645 | test_loss: 3.9558 | \n",
      "Epoch: 80 | train_loss: 3.7486 | test_loss: 3.7098 | \n",
      "Epoch: 90 | train_loss: 3.5510 | test_loss: 3.5519 | \n",
      "Epoch: 100 | train_loss: 3.3743 | test_loss: 3.3624 | \n",
      "Epoch: 110 | train_loss: 3.2089 | test_loss: 3.1918 | \n",
      "Epoch: 120 | train_loss: 3.0590 | test_loss: 3.0685 | \n",
      "Epoch: 130 | train_loss: 2.9169 | test_loss: 2.8951 | \n",
      "Epoch: 140 | train_loss: 2.7821 | test_loss: 2.7732 | \n",
      "Epoch: 150 | train_loss: 2.6534 | test_loss: 2.6270 | \n",
      "Epoch: 160 | train_loss: 2.5312 | test_loss: 2.5049 | \n",
      "Epoch: 170 | train_loss: 2.4183 | test_loss: 2.4305 | \n",
      "Epoch: 180 | train_loss: 2.3064 | test_loss: 2.3143 | \n",
      "Epoch: 190 | train_loss: 2.1991 | test_loss: 2.1667 | \n",
      "Epoch: 200 | train_loss: 2.0967 | test_loss: 2.0863 | \n",
      "Epoch: 210 | train_loss: 1.9960 | test_loss: 1.9472 | \n",
      "Epoch: 220 | train_loss: 1.8985 | test_loss: 1.8737 | \n",
      "Epoch: 230 | train_loss: 1.8045 | test_loss: 1.7885 | \n",
      "Epoch: 240 | train_loss: 1.7150 | test_loss: 1.7180 | \n",
      "Epoch: 250 | train_loss: 1.6235 | test_loss: 1.5875 | \n",
      "Epoch: 260 | train_loss: 1.5364 | test_loss: 1.5653 | \n",
      "Epoch: 270 | train_loss: 1.4503 | test_loss: 1.4282 | \n",
      "Epoch: 280 | train_loss: 1.3663 | test_loss: 1.3392 | \n",
      "Epoch: 290 | train_loss: 1.2839 | test_loss: 1.2652 | \n",
      "Epoch: 300 | train_loss: 1.2033 | test_loss: 1.1988 | \n",
      "Epoch: 310 | train_loss: 1.1237 | test_loss: 1.1166 | \n",
      "Epoch: 320 | train_loss: 1.0478 | test_loss: 1.0307 | \n",
      "Epoch: 330 | train_loss: 0.9738 | test_loss: 0.9704 | \n",
      "Epoch: 340 | train_loss: 0.8954 | test_loss: 0.8961 | \n",
      "Epoch: 350 | train_loss: 0.8219 | test_loss: 0.8130 | \n",
      "Epoch: 360 | train_loss: 0.7501 | test_loss: 0.7633 | \n",
      "Epoch: 370 | train_loss: 0.6810 | test_loss: 0.6573 | \n",
      "Epoch: 380 | train_loss: 0.6094 | test_loss: 0.6244 | \n",
      "Epoch: 390 | train_loss: 0.5431 | test_loss: 0.5462 | \n",
      "Epoch: 400 | train_loss: 0.4772 | test_loss: 0.4760 | \n",
      "Epoch: 410 | train_loss: 0.4137 | test_loss: 0.4408 | \n",
      "Epoch: 420 | train_loss: 0.3504 | test_loss: 0.3616 | \n",
      "Epoch: 430 | train_loss: 0.2938 | test_loss: 0.3223 | \n",
      "Epoch: 440 | train_loss: 0.2398 | test_loss: 0.2649 | \n",
      "Epoch: 450 | train_loss: 0.1793 | test_loss: 0.2168 | \n",
      "Epoch: 460 | train_loss: 0.1351 | test_loss: 0.1630 | \n",
      "Epoch: 470 | train_loss: 0.0986 | test_loss: 0.1698 | \n",
      "Epoch: 480 | train_loss: 0.0724 | test_loss: 0.1453 | \n",
      "Epoch: 490 | train_loss: 0.0699 | test_loss: 0.1484 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2493 | test_loss: 9.0862 | \n",
      "Epoch: 10 | train_loss: 6.8638 | test_loss: 6.7943 | \n",
      "Epoch: 20 | train_loss: 5.8513 | test_loss: 5.7837 | \n",
      "Epoch: 30 | train_loss: 5.2462 | test_loss: 5.2030 | \n",
      "Epoch: 40 | train_loss: 4.8089 | test_loss: 4.7867 | \n",
      "Epoch: 50 | train_loss: 4.4634 | test_loss: 4.4279 | \n",
      "Epoch: 60 | train_loss: 4.1721 | test_loss: 4.1489 | \n",
      "Epoch: 70 | train_loss: 3.9232 | test_loss: 3.9572 | \n",
      "Epoch: 80 | train_loss: 3.7050 | test_loss: 3.6700 | \n",
      "Epoch: 90 | train_loss: 3.5106 | test_loss: 3.5002 | \n",
      "Epoch: 100 | train_loss: 3.3341 | test_loss: 3.3339 | \n",
      "Epoch: 110 | train_loss: 3.1713 | test_loss: 3.1807 | \n",
      "Epoch: 120 | train_loss: 3.0180 | test_loss: 3.0011 | \n",
      "Epoch: 130 | train_loss: 2.8758 | test_loss: 2.8408 | \n",
      "Epoch: 140 | train_loss: 2.7417 | test_loss: 2.7142 | \n",
      "Epoch: 150 | train_loss: 2.6150 | test_loss: 2.5985 | \n",
      "Epoch: 160 | train_loss: 2.4964 | test_loss: 2.4729 | \n",
      "Epoch: 170 | train_loss: 2.3789 | test_loss: 2.3461 | \n",
      "Epoch: 180 | train_loss: 2.2675 | test_loss: 2.2803 | \n",
      "Epoch: 190 | train_loss: 2.1593 | test_loss: 2.1441 | \n",
      "Epoch: 200 | train_loss: 2.0575 | test_loss: 2.0572 | \n",
      "Epoch: 210 | train_loss: 1.9565 | test_loss: 1.9278 | \n",
      "Epoch: 220 | train_loss: 1.8594 | test_loss: 1.8486 | \n",
      "Epoch: 230 | train_loss: 1.7648 | test_loss: 1.7656 | \n",
      "Epoch: 240 | train_loss: 1.6736 | test_loss: 1.6718 | \n",
      "Epoch: 250 | train_loss: 1.5849 | test_loss: 1.5578 | \n",
      "Epoch: 260 | train_loss: 1.4974 | test_loss: 1.5062 | \n",
      "Epoch: 270 | train_loss: 1.4120 | test_loss: 1.4050 | \n",
      "Epoch: 280 | train_loss: 1.3324 | test_loss: 1.3132 | \n",
      "Epoch: 290 | train_loss: 1.2475 | test_loss: 1.2336 | \n",
      "Epoch: 300 | train_loss: 1.1656 | test_loss: 1.1770 | \n",
      "Epoch: 310 | train_loss: 1.0860 | test_loss: 1.1052 | \n",
      "Epoch: 320 | train_loss: 1.0092 | test_loss: 1.0045 | \n",
      "Epoch: 330 | train_loss: 0.9330 | test_loss: 0.9392 | \n",
      "Epoch: 340 | train_loss: 0.8604 | test_loss: 0.8947 | \n",
      "Epoch: 350 | train_loss: 0.7873 | test_loss: 0.7888 | \n",
      "Epoch: 360 | train_loss: 0.7151 | test_loss: 0.7399 | \n",
      "Epoch: 370 | train_loss: 0.6461 | test_loss: 0.6492 | \n",
      "Epoch: 380 | train_loss: 0.5771 | test_loss: 0.5890 | \n",
      "Epoch: 390 | train_loss: 0.5083 | test_loss: 0.5084 | \n",
      "Epoch: 400 | train_loss: 0.4445 | test_loss: 0.4429 | \n",
      "Epoch: 410 | train_loss: 0.3794 | test_loss: 0.3821 | \n",
      "Epoch: 420 | train_loss: 0.3183 | test_loss: 0.3208 | \n",
      "Epoch: 430 | train_loss: 0.2611 | test_loss: 0.2970 | \n",
      "Epoch: 440 | train_loss: 0.2034 | test_loss: 0.2354 | \n",
      "Epoch: 450 | train_loss: 0.1544 | test_loss: 0.2276 | \n",
      "Epoch: 460 | train_loss: 0.1112 | test_loss: 0.1644 | \n",
      "Epoch: 470 | train_loss: 0.0801 | test_loss: 0.1455 | \n",
      "Epoch: 480 | train_loss: 0.0677 | test_loss: 0.1564 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2779 | test_loss: 9.1116 | \n",
      "Epoch: 10 | train_loss: 6.8908 | test_loss: 6.8049 | \n",
      "Epoch: 20 | train_loss: 5.8838 | test_loss: 5.8052 | \n",
      "Epoch: 30 | train_loss: 5.2706 | test_loss: 5.2104 | \n",
      "Epoch: 40 | train_loss: 4.8249 | test_loss: 4.7806 | \n",
      "Epoch: 50 | train_loss: 4.4796 | test_loss: 4.4391 | \n",
      "Epoch: 60 | train_loss: 4.1961 | test_loss: 4.1581 | \n",
      "Epoch: 70 | train_loss: 3.9471 | test_loss: 3.9165 | \n",
      "Epoch: 80 | train_loss: 3.7208 | test_loss: 3.6971 | \n",
      "Epoch: 90 | train_loss: 3.5283 | test_loss: 3.5064 | \n",
      "Epoch: 100 | train_loss: 3.3504 | test_loss: 3.3208 | \n",
      "Epoch: 110 | train_loss: 3.1904 | test_loss: 3.1680 | \n",
      "Epoch: 120 | train_loss: 3.0405 | test_loss: 3.0145 | \n",
      "Epoch: 130 | train_loss: 2.8975 | test_loss: 2.8717 | \n",
      "Epoch: 140 | train_loss: 2.7655 | test_loss: 2.7354 | \n",
      "Epoch: 150 | train_loss: 2.6339 | test_loss: 2.6136 | \n",
      "Epoch: 160 | train_loss: 2.5143 | test_loss: 2.4936 | \n",
      "Epoch: 170 | train_loss: 2.3906 | test_loss: 2.3809 | \n",
      "Epoch: 180 | train_loss: 2.2834 | test_loss: 2.2632 | \n",
      "Epoch: 190 | train_loss: 2.1744 | test_loss: 2.1624 | \n",
      "Epoch: 200 | train_loss: 2.0734 | test_loss: 2.0554 | \n",
      "Epoch: 210 | train_loss: 1.9736 | test_loss: 1.9554 | \n",
      "Epoch: 220 | train_loss: 1.8758 | test_loss: 1.8618 | \n",
      "Epoch: 230 | train_loss: 1.7829 | test_loss: 1.7654 | \n",
      "Epoch: 240 | train_loss: 1.6941 | test_loss: 1.6790 | \n",
      "Epoch: 250 | train_loss: 1.6065 | test_loss: 1.5950 | \n",
      "Epoch: 260 | train_loss: 1.5219 | test_loss: 1.4994 | \n",
      "Epoch: 270 | train_loss: 1.4332 | test_loss: 1.4120 | \n",
      "Epoch: 280 | train_loss: 1.3494 | test_loss: 1.3328 | \n",
      "Epoch: 290 | train_loss: 1.2713 | test_loss: 1.2476 | \n",
      "Epoch: 300 | train_loss: 1.1906 | test_loss: 1.1709 | \n",
      "Epoch: 310 | train_loss: 1.1093 | test_loss: 1.0893 | \n",
      "Epoch: 320 | train_loss: 1.0366 | test_loss: 1.0174 | \n",
      "Epoch: 330 | train_loss: 0.9623 | test_loss: 0.9390 | \n",
      "Epoch: 340 | train_loss: 0.8830 | test_loss: 0.8636 | \n",
      "Epoch: 350 | train_loss: 0.8070 | test_loss: 0.7941 | \n",
      "Epoch: 360 | train_loss: 0.7459 | test_loss: 0.7298 | \n",
      "Epoch: 370 | train_loss: 0.6728 | test_loss: 0.6598 | \n",
      "Epoch: 380 | train_loss: 0.6062 | test_loss: 0.6021 | \n",
      "Epoch: 390 | train_loss: 0.5428 | test_loss: 0.5339 | \n",
      "Epoch: 400 | train_loss: 0.4950 | test_loss: 0.4736 | \n",
      "Epoch: 410 | train_loss: 0.4216 | test_loss: 0.4039 | \n",
      "Epoch: 420 | train_loss: 0.3640 | test_loss: 0.3545 | \n",
      "Epoch: 430 | train_loss: 0.3134 | test_loss: 0.2918 | \n",
      "Epoch: 440 | train_loss: 0.2624 | test_loss: 0.2680 | \n",
      "Epoch: 450 | train_loss: 0.2188 | test_loss: 0.2063 | \n",
      "Epoch: 460 | train_loss: 0.1853 | test_loss: 0.1828 | \n",
      "Epoch: 470 | train_loss: 0.1623 | test_loss: 0.1610 | \n",
      "Epoch: 480 | train_loss: 0.1467 | test_loss: 0.1478 | \n",
      "Epoch: 490 | train_loss: 0.1372 | test_loss: 0.1513 | \n",
      "Epoch: 500 | train_loss: 0.1240 | test_loss: 0.1424 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2925 | test_loss: 9.0135 | \n",
      "Epoch: 10 | train_loss: 6.8764 | test_loss: 6.7946 | \n",
      "Epoch: 20 | train_loss: 5.8760 | test_loss: 5.8204 | \n",
      "Epoch: 30 | train_loss: 5.2624 | test_loss: 5.2062 | \n",
      "Epoch: 40 | train_loss: 4.8209 | test_loss: 4.7877 | \n",
      "Epoch: 50 | train_loss: 4.4722 | test_loss: 4.4333 | \n",
      "Epoch: 60 | train_loss: 4.1836 | test_loss: 4.1623 | \n",
      "Epoch: 70 | train_loss: 3.9418 | test_loss: 3.9111 | \n",
      "Epoch: 80 | train_loss: 3.7260 | test_loss: 3.7009 | \n",
      "Epoch: 90 | train_loss: 3.5298 | test_loss: 3.5034 | \n",
      "Epoch: 100 | train_loss: 3.3483 | test_loss: 3.3255 | \n",
      "Epoch: 110 | train_loss: 3.1894 | test_loss: 3.1622 | \n",
      "Epoch: 120 | train_loss: 3.0358 | test_loss: 3.0184 | \n",
      "Epoch: 130 | train_loss: 2.8880 | test_loss: 2.8751 | \n",
      "Epoch: 140 | train_loss: 2.7583 | test_loss: 2.7382 | \n",
      "Epoch: 150 | train_loss: 2.6330 | test_loss: 2.6178 | \n",
      "Epoch: 160 | train_loss: 2.5109 | test_loss: 2.4901 | \n",
      "Epoch: 170 | train_loss: 2.3943 | test_loss: 2.3758 | \n",
      "Epoch: 180 | train_loss: 2.2814 | test_loss: 2.2666 | \n",
      "Epoch: 190 | train_loss: 2.1775 | test_loss: 2.1553 | \n",
      "Epoch: 200 | train_loss: 2.0739 | test_loss: 2.0497 | \n",
      "Epoch: 210 | train_loss: 1.9709 | test_loss: 1.9554 | \n",
      "Epoch: 220 | train_loss: 1.8795 | test_loss: 1.8544 | \n",
      "Epoch: 230 | train_loss: 1.7833 | test_loss: 1.7623 | \n",
      "Epoch: 240 | train_loss: 1.6902 | test_loss: 1.6728 | \n",
      "Epoch: 250 | train_loss: 1.6038 | test_loss: 1.5872 | \n",
      "Epoch: 260 | train_loss: 1.5150 | test_loss: 1.4951 | \n",
      "Epoch: 270 | train_loss: 1.4327 | test_loss: 1.4191 | \n",
      "Epoch: 280 | train_loss: 1.3488 | test_loss: 1.3291 | \n",
      "Epoch: 290 | train_loss: 1.2746 | test_loss: 1.2489 | \n",
      "Epoch: 300 | train_loss: 1.1870 | test_loss: 1.1670 | \n",
      "Epoch: 310 | train_loss: 1.1103 | test_loss: 1.0958 | \n",
      "Epoch: 320 | train_loss: 1.0370 | test_loss: 1.0130 | \n",
      "Epoch: 330 | train_loss: 0.9580 | test_loss: 0.9485 | \n",
      "Epoch: 340 | train_loss: 0.8841 | test_loss: 0.8693 | \n",
      "Epoch: 350 | train_loss: 0.8134 | test_loss: 0.7968 | \n",
      "Epoch: 360 | train_loss: 0.7417 | test_loss: 0.7358 | \n",
      "Epoch: 370 | train_loss: 0.6767 | test_loss: 0.6615 | \n",
      "Epoch: 380 | train_loss: 0.6019 | test_loss: 0.5931 | \n",
      "Epoch: 390 | train_loss: 0.5396 | test_loss: 0.5312 | \n",
      "Epoch: 400 | train_loss: 0.4788 | test_loss: 0.4609 | \n",
      "Epoch: 410 | train_loss: 0.4157 | test_loss: 0.4058 | \n",
      "Epoch: 420 | train_loss: 0.3622 | test_loss: 0.3640 | \n",
      "Epoch: 430 | train_loss: 0.3023 | test_loss: 0.3007 | \n",
      "Epoch: 440 | train_loss: 0.2608 | test_loss: 0.2438 | \n",
      "Epoch: 450 | train_loss: 0.2142 | test_loss: 0.2111 | \n",
      "Epoch: 460 | train_loss: 0.1799 | test_loss: 0.1920 | \n",
      "Epoch: 470 | train_loss: 0.1620 | test_loss: 0.1562 | \n",
      "Epoch: 480 | train_loss: 0.1378 | test_loss: 0.1561 | \n",
      "Epoch: 490 | train_loss: 0.1289 | test_loss: 0.1440 | \n",
      "Epoch: 500 | train_loss: 0.1247 | test_loss: 0.1406 | \n",
      "Epoch: 510 | train_loss: 0.1223 | test_loss: 0.1446 | \n",
      "Epoch: 520 | train_loss: 0.1162 | test_loss: 0.1346 | \n",
      "Epoch: 530 | train_loss: 0.1170 | test_loss: 0.1462 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2939 | test_loss: 7.2321 | \n",
      "Epoch: 10 | train_loss: 0.2350 | test_loss: 0.2153 | \n",
      "Epoch: 20 | train_loss: 0.1735 | test_loss: 0.1667 | \n",
      "Epoch: 30 | train_loss: 0.1558 | test_loss: 0.1578 | \n",
      "Epoch: 40 | train_loss: 0.1452 | test_loss: 0.1549 | \n",
      "Epoch: 50 | train_loss: 0.1401 | test_loss: 0.1539 | \n",
      "Epoch: 60 | train_loss: 0.1350 | test_loss: 0.1533 | \n",
      "Epoch: 70 | train_loss: 0.1314 | test_loss: 0.1528 | \n",
      "Epoch: 80 | train_loss: 0.1297 | test_loss: 0.1521 | \n",
      "Epoch: 90 | train_loss: 0.1246 | test_loss: 0.1510 | \n",
      "Epoch: 100 | train_loss: 0.1232 | test_loss: 0.1511 | \n",
      "Epoch: 110 | train_loss: 0.1212 | test_loss: 0.1498 | \n",
      "Epoch: 120 | train_loss: 0.1184 | test_loss: 0.1496 | \n",
      "Epoch: 130 | train_loss: 0.1158 | test_loss: 0.1483 | \n",
      "Epoch: 140 | train_loss: 0.1136 | test_loss: 0.1484 | \n",
      "Epoch: 150 | train_loss: 0.1122 | test_loss: 0.1476 | \n",
      "Epoch: 160 | train_loss: 0.1071 | test_loss: 0.1467 | \n",
      "Epoch: 170 | train_loss: 0.1103 | test_loss: 0.1478 | \n",
      "Epoch: 180 | train_loss: 0.1060 | test_loss: 0.1464 | \n",
      "Epoch: 190 | train_loss: 0.1025 | test_loss: 0.1453 | \n",
      "Epoch: 200 | train_loss: 0.1003 | test_loss: 0.1455 | \n",
      "Epoch: 210 | train_loss: 0.1000 | test_loss: 0.1458 | \n",
      "Epoch: 220 | train_loss: 0.0942 | test_loss: 0.1451 | \n",
      "Epoch: 230 | train_loss: 0.0916 | test_loss: 0.1452 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.2910 | test_loss: 4.4064 | \n",
      "Epoch: 10 | train_loss: 0.1871 | test_loss: 0.1771 | \n",
      "Epoch: 20 | train_loss: 0.1476 | test_loss: 0.1550 | \n",
      "Epoch: 30 | train_loss: 0.1363 | test_loss: 0.1519 | \n",
      "Epoch: 40 | train_loss: 0.1282 | test_loss: 0.1512 | \n",
      "Epoch: 50 | train_loss: 0.1231 | test_loss: 0.1503 | \n",
      "Epoch: 60 | train_loss: 0.1166 | test_loss: 0.1481 | \n",
      "Epoch: 70 | train_loss: 0.1117 | test_loss: 0.1485 | \n",
      "Epoch: 80 | train_loss: 0.1044 | test_loss: 0.1473 | \n",
      "Epoch: 90 | train_loss: 0.0994 | test_loss: 0.1446 | \n",
      "Epoch: 100 | train_loss: 0.0953 | test_loss: 0.1460 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.0160 | test_loss: 0.4230 | \n",
      "Epoch: 10 | train_loss: 0.1552 | test_loss: 0.1519 | \n",
      "Epoch: 20 | train_loss: 0.1198 | test_loss: 0.1502 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8771 | test_loss: 9.3766 | \n",
      "Epoch: 10 | train_loss: 7.7589 | test_loss: 7.7060 | \n",
      "Epoch: 20 | train_loss: 6.8540 | test_loss: 6.8112 | \n",
      "Epoch: 30 | train_loss: 6.2754 | test_loss: 6.2435 | \n",
      "Epoch: 40 | train_loss: 5.8556 | test_loss: 5.8322 | \n",
      "Epoch: 50 | train_loss: 5.5252 | test_loss: 5.4906 | \n",
      "Epoch: 60 | train_loss: 5.2525 | test_loss: 5.2189 | \n",
      "Epoch: 70 | train_loss: 5.0189 | test_loss: 5.0041 | \n",
      "Epoch: 80 | train_loss: 4.8172 | test_loss: 4.8049 | \n",
      "Epoch: 90 | train_loss: 4.6360 | test_loss: 4.6300 | \n",
      "Epoch: 100 | train_loss: 4.4737 | test_loss: 4.4471 | \n",
      "Epoch: 110 | train_loss: 4.3223 | test_loss: 4.3168 | \n",
      "Epoch: 120 | train_loss: 4.1859 | test_loss: 4.1746 | \n",
      "Epoch: 130 | train_loss: 4.0612 | test_loss: 4.0395 | \n",
      "Epoch: 140 | train_loss: 3.9396 | test_loss: 3.9380 | \n",
      "Epoch: 150 | train_loss: 3.8279 | test_loss: 3.8146 | \n",
      "Epoch: 160 | train_loss: 3.7217 | test_loss: 3.7048 | \n",
      "Epoch: 170 | train_loss: 3.6237 | test_loss: 3.5974 | \n",
      "Epoch: 180 | train_loss: 3.5290 | test_loss: 3.5218 | \n",
      "Epoch: 190 | train_loss: 3.4369 | test_loss: 3.4252 | \n",
      "Epoch: 200 | train_loss: 3.3504 | test_loss: 3.3430 | \n",
      "Epoch: 210 | train_loss: 3.2686 | test_loss: 3.2521 | \n",
      "Epoch: 220 | train_loss: 3.1875 | test_loss: 3.1508 | \n",
      "Epoch: 230 | train_loss: 3.1110 | test_loss: 3.0827 | \n",
      "Epoch: 240 | train_loss: 3.0401 | test_loss: 3.0450 | \n",
      "Epoch: 250 | train_loss: 2.9637 | test_loss: 2.9572 | \n",
      "Epoch: 260 | train_loss: 2.8939 | test_loss: 2.8801 | \n",
      "Epoch: 270 | train_loss: 2.8255 | test_loss: 2.8084 | \n",
      "Epoch: 280 | train_loss: 2.7602 | test_loss: 2.7411 | \n",
      "Epoch: 290 | train_loss: 2.6937 | test_loss: 2.6831 | \n",
      "Epoch: 300 | train_loss: 2.6309 | test_loss: 2.6183 | \n",
      "Epoch: 310 | train_loss: 2.5708 | test_loss: 2.5541 | \n",
      "Epoch: 320 | train_loss: 2.5108 | test_loss: 2.4914 | \n",
      "Epoch: 330 | train_loss: 2.4519 | test_loss: 2.4408 | \n",
      "Epoch: 340 | train_loss: 2.3972 | test_loss: 2.3780 | \n",
      "Epoch: 350 | train_loss: 2.3416 | test_loss: 2.3286 | \n",
      "Epoch: 360 | train_loss: 2.2842 | test_loss: 2.2730 | \n",
      "Epoch: 370 | train_loss: 2.2301 | test_loss: 2.2195 | \n",
      "Epoch: 380 | train_loss: 2.1768 | test_loss: 2.1655 | \n",
      "Epoch: 390 | train_loss: 2.1257 | test_loss: 2.1060 | \n",
      "Epoch: 400 | train_loss: 2.0748 | test_loss: 2.0621 | \n",
      "Epoch: 410 | train_loss: 2.0240 | test_loss: 2.0081 | \n",
      "Epoch: 420 | train_loss: 1.9743 | test_loss: 1.9604 | \n",
      "Epoch: 430 | train_loss: 1.9270 | test_loss: 1.9177 | \n",
      "Epoch: 440 | train_loss: 1.8781 | test_loss: 1.8728 | \n",
      "Epoch: 450 | train_loss: 1.8303 | test_loss: 1.8074 | \n",
      "Epoch: 460 | train_loss: 1.7842 | test_loss: 1.7730 | \n",
      "Epoch: 470 | train_loss: 1.7386 | test_loss: 1.7265 | \n",
      "Epoch: 480 | train_loss: 1.6922 | test_loss: 1.6757 | \n",
      "Epoch: 490 | train_loss: 1.6468 | test_loss: 1.6317 | \n",
      "Epoch: 500 | train_loss: 1.6019 | test_loss: 1.5834 | \n",
      "Epoch: 510 | train_loss: 1.5595 | test_loss: 1.5363 | \n",
      "Epoch: 520 | train_loss: 1.5150 | test_loss: 1.5076 | \n",
      "Epoch: 530 | train_loss: 1.4724 | test_loss: 1.4612 | \n",
      "Epoch: 540 | train_loss: 1.4286 | test_loss: 1.4113 | \n",
      "Epoch: 550 | train_loss: 1.3871 | test_loss: 1.3937 | \n",
      "Epoch: 560 | train_loss: 1.3451 | test_loss: 1.3405 | \n",
      "Epoch: 570 | train_loss: 1.3055 | test_loss: 1.2988 | \n",
      "Epoch: 580 | train_loss: 1.2634 | test_loss: 1.2529 | \n",
      "Epoch: 590 | train_loss: 1.2243 | test_loss: 1.2329 | \n",
      "Epoch: 600 | train_loss: 1.1837 | test_loss: 1.1702 | \n",
      "Epoch: 610 | train_loss: 1.1438 | test_loss: 1.1390 | \n",
      "Epoch: 620 | train_loss: 1.1041 | test_loss: 1.1082 | \n",
      "Epoch: 630 | train_loss: 1.0663 | test_loss: 1.0558 | \n",
      "Epoch: 640 | train_loss: 1.0278 | test_loss: 1.0183 | \n",
      "Epoch: 650 | train_loss: 0.9890 | test_loss: 0.9744 | \n",
      "Epoch: 660 | train_loss: 0.9515 | test_loss: 0.9500 | \n",
      "Epoch: 670 | train_loss: 0.9134 | test_loss: 0.9036 | \n",
      "Epoch: 680 | train_loss: 0.8777 | test_loss: 0.8851 | \n",
      "Epoch: 690 | train_loss: 0.8403 | test_loss: 0.8355 | \n",
      "Epoch: 700 | train_loss: 0.8040 | test_loss: 0.8046 | \n",
      "Epoch: 710 | train_loss: 0.7685 | test_loss: 0.7507 | \n",
      "Epoch: 720 | train_loss: 0.7323 | test_loss: 0.7314 | \n",
      "Epoch: 730 | train_loss: 0.6974 | test_loss: 0.6955 | \n",
      "Epoch: 740 | train_loss: 0.6620 | test_loss: 0.6749 | \n",
      "Epoch: 750 | train_loss: 0.6275 | test_loss: 0.6297 | \n",
      "Epoch: 760 | train_loss: 0.5935 | test_loss: 0.5882 | \n",
      "Epoch: 770 | train_loss: 0.5585 | test_loss: 0.5595 | \n",
      "Epoch: 780 | train_loss: 0.5253 | test_loss: 0.5384 | \n",
      "Epoch: 790 | train_loss: 0.4925 | test_loss: 0.5118 | \n",
      "Epoch: 800 | train_loss: 0.4616 | test_loss: 0.4549 | \n",
      "Epoch: 810 | train_loss: 0.4260 | test_loss: 0.4278 | \n",
      "Epoch: 820 | train_loss: 0.3949 | test_loss: 0.4047 | \n",
      "Epoch: 830 | train_loss: 0.3622 | test_loss: 0.3654 | \n",
      "Epoch: 840 | train_loss: 0.3372 | test_loss: 0.3829 | \n",
      "Epoch: 850 | train_loss: 0.3021 | test_loss: 0.3285 | \n",
      "Epoch: 860 | train_loss: 0.2705 | test_loss: 0.2899 | \n",
      "Epoch: 870 | train_loss: 0.2413 | test_loss: 0.2798 | \n",
      "Epoch: 880 | train_loss: 0.2121 | test_loss: 0.2551 | \n",
      "Epoch: 890 | train_loss: 0.1832 | test_loss: 0.2353 | \n",
      "Epoch: 900 | train_loss: 0.1568 | test_loss: 0.2061 | \n",
      "Epoch: 910 | train_loss: 0.1312 | test_loss: 0.1917 | \n",
      "Epoch: 920 | train_loss: 0.1165 | test_loss: 0.1604 | \n",
      "Epoch: 930 | train_loss: 0.1208 | test_loss: 0.1635 | \n",
      "Epoch: 940 | train_loss: 0.0745 | test_loss: 0.1510 | \n",
      "Epoch: 950 | train_loss: 0.0571 | test_loss: 0.1517 | \n",
      "Epoch: 960 | train_loss: 0.0509 | test_loss: 0.1479 | \n",
      "Epoch: 970 | train_loss: 0.0458 | test_loss: 0.1445 | \n",
      "Epoch: 980 | train_loss: 0.0346 | test_loss: 0.1459 | \n",
      "Epoch: 990 | train_loss: 0.0387 | test_loss: 0.1430 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8766 | test_loss: 9.5987 | \n",
      "Epoch: 10 | train_loss: 7.7276 | test_loss: 7.6640 | \n",
      "Epoch: 20 | train_loss: 6.8400 | test_loss: 6.7969 | \n",
      "Epoch: 30 | train_loss: 6.2792 | test_loss: 6.2379 | \n",
      "Epoch: 40 | train_loss: 5.8588 | test_loss: 5.8372 | \n",
      "Epoch: 50 | train_loss: 5.5264 | test_loss: 5.4934 | \n",
      "Epoch: 60 | train_loss: 5.2567 | test_loss: 5.2372 | \n",
      "Epoch: 70 | train_loss: 5.0230 | test_loss: 5.0052 | \n",
      "Epoch: 80 | train_loss: 4.8177 | test_loss: 4.7968 | \n",
      "Epoch: 90 | train_loss: 4.6364 | test_loss: 4.6162 | \n",
      "Epoch: 100 | train_loss: 4.4719 | test_loss: 4.4455 | \n",
      "Epoch: 110 | train_loss: 4.3215 | test_loss: 4.2982 | \n",
      "Epoch: 120 | train_loss: 4.1846 | test_loss: 4.1698 | \n",
      "Epoch: 130 | train_loss: 4.0572 | test_loss: 4.0271 | \n",
      "Epoch: 140 | train_loss: 3.9376 | test_loss: 3.9134 | \n",
      "Epoch: 150 | train_loss: 3.8256 | test_loss: 3.8108 | \n",
      "Epoch: 160 | train_loss: 3.7185 | test_loss: 3.6933 | \n",
      "Epoch: 170 | train_loss: 3.6198 | test_loss: 3.5958 | \n",
      "Epoch: 180 | train_loss: 3.5244 | test_loss: 3.5096 | \n",
      "Epoch: 190 | train_loss: 3.4343 | test_loss: 3.4093 | \n",
      "Epoch: 200 | train_loss: 3.3462 | test_loss: 3.3262 | \n",
      "Epoch: 210 | train_loss: 3.2639 | test_loss: 3.2527 | \n",
      "Epoch: 220 | train_loss: 3.1830 | test_loss: 3.1685 | \n",
      "Epoch: 230 | train_loss: 3.1051 | test_loss: 3.0889 | \n",
      "Epoch: 240 | train_loss: 3.0308 | test_loss: 3.0167 | \n",
      "Epoch: 250 | train_loss: 2.9583 | test_loss: 2.9495 | \n",
      "Epoch: 260 | train_loss: 2.8878 | test_loss: 2.8799 | \n",
      "Epoch: 270 | train_loss: 2.8202 | test_loss: 2.8032 | \n",
      "Epoch: 280 | train_loss: 2.7539 | test_loss: 2.7359 | \n",
      "Epoch: 290 | train_loss: 2.6888 | test_loss: 2.6754 | \n",
      "Epoch: 300 | train_loss: 2.6254 | test_loss: 2.6164 | \n",
      "Epoch: 310 | train_loss: 2.5645 | test_loss: 2.5665 | \n",
      "Epoch: 320 | train_loss: 2.5040 | test_loss: 2.4907 | \n",
      "Epoch: 330 | train_loss: 2.4461 | test_loss: 2.4332 | \n",
      "Epoch: 340 | train_loss: 2.3879 | test_loss: 2.3705 | \n",
      "Epoch: 350 | train_loss: 2.3323 | test_loss: 2.3161 | \n",
      "Epoch: 360 | train_loss: 2.2773 | test_loss: 2.2619 | \n",
      "Epoch: 370 | train_loss: 2.2231 | test_loss: 2.2104 | \n",
      "Epoch: 380 | train_loss: 2.1696 | test_loss: 2.1618 | \n",
      "Epoch: 390 | train_loss: 2.1178 | test_loss: 2.1001 | \n",
      "Epoch: 400 | train_loss: 2.0663 | test_loss: 2.0513 | \n",
      "Epoch: 410 | train_loss: 2.0156 | test_loss: 2.0027 | \n",
      "Epoch: 420 | train_loss: 1.9660 | test_loss: 1.9542 | \n",
      "Epoch: 430 | train_loss: 1.9167 | test_loss: 1.9156 | \n",
      "Epoch: 440 | train_loss: 1.8691 | test_loss: 1.8611 | \n",
      "Epoch: 450 | train_loss: 1.8213 | test_loss: 1.7999 | \n",
      "Epoch: 460 | train_loss: 1.7738 | test_loss: 1.7629 | \n",
      "Epoch: 470 | train_loss: 1.7270 | test_loss: 1.7136 | \n",
      "Epoch: 480 | train_loss: 1.6821 | test_loss: 1.6790 | \n",
      "Epoch: 490 | train_loss: 1.6364 | test_loss: 1.6307 | \n",
      "Epoch: 500 | train_loss: 1.5922 | test_loss: 1.5895 | \n",
      "Epoch: 510 | train_loss: 1.5477 | test_loss: 1.5378 | \n",
      "Epoch: 520 | train_loss: 1.5041 | test_loss: 1.5028 | \n",
      "Epoch: 530 | train_loss: 1.4602 | test_loss: 1.4556 | \n",
      "Epoch: 540 | train_loss: 1.4183 | test_loss: 1.4035 | \n",
      "Epoch: 550 | train_loss: 1.3765 | test_loss: 1.3670 | \n",
      "Epoch: 560 | train_loss: 1.3344 | test_loss: 1.3301 | \n",
      "Epoch: 570 | train_loss: 1.2932 | test_loss: 1.2910 | \n",
      "Epoch: 580 | train_loss: 1.2535 | test_loss: 1.2459 | \n",
      "Epoch: 590 | train_loss: 1.2131 | test_loss: 1.2138 | \n",
      "Epoch: 600 | train_loss: 1.1729 | test_loss: 1.1741 | \n",
      "Epoch: 610 | train_loss: 1.1330 | test_loss: 1.1307 | \n",
      "Epoch: 620 | train_loss: 1.0951 | test_loss: 1.0913 | \n",
      "Epoch: 630 | train_loss: 1.0542 | test_loss: 1.0510 | \n",
      "Epoch: 640 | train_loss: 1.0167 | test_loss: 1.0231 | \n",
      "Epoch: 650 | train_loss: 0.9780 | test_loss: 0.9793 | \n",
      "Epoch: 660 | train_loss: 0.9401 | test_loss: 0.9463 | \n",
      "Epoch: 670 | train_loss: 0.9030 | test_loss: 0.9122 | \n",
      "Epoch: 680 | train_loss: 0.8656 | test_loss: 0.8702 | \n",
      "Epoch: 690 | train_loss: 0.8296 | test_loss: 0.8343 | \n",
      "Epoch: 700 | train_loss: 0.7925 | test_loss: 0.7951 | \n",
      "Epoch: 710 | train_loss: 0.7568 | test_loss: 0.7593 | \n",
      "Epoch: 720 | train_loss: 0.7212 | test_loss: 0.7163 | \n",
      "Epoch: 730 | train_loss: 0.6859 | test_loss: 0.6957 | \n",
      "Epoch: 740 | train_loss: 0.6510 | test_loss: 0.6621 | \n",
      "Epoch: 750 | train_loss: 0.6168 | test_loss: 0.6282 | \n",
      "Epoch: 760 | train_loss: 0.5826 | test_loss: 0.5945 | \n",
      "Epoch: 770 | train_loss: 0.5488 | test_loss: 0.5580 | \n",
      "Epoch: 780 | train_loss: 0.5160 | test_loss: 0.5295 | \n",
      "Epoch: 790 | train_loss: 0.4824 | test_loss: 0.4921 | \n",
      "Epoch: 800 | train_loss: 0.4491 | test_loss: 0.4752 | \n",
      "Epoch: 810 | train_loss: 0.4166 | test_loss: 0.4400 | \n",
      "Epoch: 820 | train_loss: 0.3858 | test_loss: 0.4097 | \n",
      "Epoch: 830 | train_loss: 0.3530 | test_loss: 0.3742 | \n",
      "Epoch: 840 | train_loss: 0.3220 | test_loss: 0.3614 | \n",
      "Epoch: 850 | train_loss: 0.2928 | test_loss: 0.3160 | \n",
      "Epoch: 860 | train_loss: 0.2622 | test_loss: 0.2923 | \n",
      "Epoch: 870 | train_loss: 0.2325 | test_loss: 0.2724 | \n",
      "Epoch: 880 | train_loss: 0.2026 | test_loss: 0.2442 | \n",
      "Epoch: 890 | train_loss: 0.1767 | test_loss: 0.2139 | \n",
      "Epoch: 900 | train_loss: 0.1487 | test_loss: 0.1926 | \n",
      "Epoch: 910 | train_loss: 0.1276 | test_loss: 0.1781 | \n",
      "Epoch: 920 | train_loss: 0.1009 | test_loss: 0.1665 | \n",
      "Epoch: 930 | train_loss: 0.0844 | test_loss: 0.1529 | \n",
      "Epoch: 940 | train_loss: 0.0694 | test_loss: 0.1570 | \n",
      "Epoch: 950 | train_loss: 0.0529 | test_loss: 0.1489 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8428 | test_loss: 9.9482 | \n",
      "Epoch: 10 | train_loss: 7.7217 | test_loss: 7.6411 | \n",
      "Epoch: 20 | train_loss: 6.8320 | test_loss: 6.7762 | \n",
      "Epoch: 30 | train_loss: 6.2514 | test_loss: 6.1987 | \n",
      "Epoch: 40 | train_loss: 5.8416 | test_loss: 5.7926 | \n",
      "Epoch: 50 | train_loss: 5.5037 | test_loss: 5.4682 | \n",
      "Epoch: 60 | train_loss: 5.2364 | test_loss: 5.2021 | \n",
      "Epoch: 70 | train_loss: 4.9984 | test_loss: 4.9708 | \n",
      "Epoch: 80 | train_loss: 4.7914 | test_loss: 4.7687 | \n",
      "Epoch: 90 | train_loss: 4.6165 | test_loss: 4.5902 | \n",
      "Epoch: 100 | train_loss: 4.4451 | test_loss: 4.4271 | \n",
      "Epoch: 110 | train_loss: 4.3057 | test_loss: 4.2791 | \n",
      "Epoch: 120 | train_loss: 4.1619 | test_loss: 4.1365 | \n",
      "Epoch: 130 | train_loss: 4.0390 | test_loss: 4.0115 | \n",
      "Epoch: 140 | train_loss: 3.9137 | test_loss: 3.8950 | \n",
      "Epoch: 150 | train_loss: 3.8044 | test_loss: 3.7865 | \n",
      "Epoch: 160 | train_loss: 3.6989 | test_loss: 3.6855 | \n",
      "Epoch: 170 | train_loss: 3.5971 | test_loss: 3.5829 | \n",
      "Epoch: 180 | train_loss: 3.4996 | test_loss: 3.4879 | \n",
      "Epoch: 190 | train_loss: 3.4125 | test_loss: 3.3983 | \n",
      "Epoch: 200 | train_loss: 3.3278 | test_loss: 3.3110 | \n",
      "Epoch: 210 | train_loss: 3.2430 | test_loss: 3.2280 | \n",
      "Epoch: 220 | train_loss: 3.1660 | test_loss: 3.1485 | \n",
      "Epoch: 230 | train_loss: 3.0834 | test_loss: 3.0705 | \n",
      "Epoch: 240 | train_loss: 3.0163 | test_loss: 3.0023 | \n",
      "Epoch: 250 | train_loss: 2.9424 | test_loss: 2.9262 | \n",
      "Epoch: 260 | train_loss: 2.8658 | test_loss: 2.8575 | \n",
      "Epoch: 270 | train_loss: 2.7992 | test_loss: 2.7902 | \n",
      "Epoch: 280 | train_loss: 2.7337 | test_loss: 2.7249 | \n",
      "Epoch: 290 | train_loss: 2.6745 | test_loss: 2.6577 | \n",
      "Epoch: 300 | train_loss: 2.6080 | test_loss: 2.5939 | \n",
      "Epoch: 310 | train_loss: 2.5467 | test_loss: 2.5322 | \n",
      "Epoch: 320 | train_loss: 2.4877 | test_loss: 2.4734 | \n",
      "Epoch: 330 | train_loss: 2.4296 | test_loss: 2.4136 | \n",
      "Epoch: 340 | train_loss: 2.3758 | test_loss: 2.3576 | \n",
      "Epoch: 350 | train_loss: 2.3174 | test_loss: 2.3042 | \n",
      "Epoch: 360 | train_loss: 2.2636 | test_loss: 2.2465 | \n",
      "Epoch: 370 | train_loss: 2.2026 | test_loss: 2.1927 | \n",
      "Epoch: 380 | train_loss: 2.1570 | test_loss: 2.1405 | \n",
      "Epoch: 390 | train_loss: 2.1044 | test_loss: 2.0885 | \n",
      "Epoch: 400 | train_loss: 2.0542 | test_loss: 2.0361 | \n",
      "Epoch: 410 | train_loss: 1.9977 | test_loss: 1.9883 | \n",
      "Epoch: 420 | train_loss: 1.9464 | test_loss: 1.9373 | \n",
      "Epoch: 430 | train_loss: 1.9076 | test_loss: 1.8902 | \n",
      "Epoch: 440 | train_loss: 1.8534 | test_loss: 1.8411 | \n",
      "Epoch: 450 | train_loss: 1.8076 | test_loss: 1.7938 | \n",
      "Epoch: 460 | train_loss: 1.7634 | test_loss: 1.7468 | \n",
      "Epoch: 470 | train_loss: 1.7156 | test_loss: 1.7035 | \n",
      "Epoch: 480 | train_loss: 1.6683 | test_loss: 1.6564 | \n",
      "Epoch: 490 | train_loss: 1.6247 | test_loss: 1.6113 | \n",
      "Epoch: 500 | train_loss: 1.5815 | test_loss: 1.5670 | \n",
      "Epoch: 510 | train_loss: 1.5360 | test_loss: 1.5212 | \n",
      "Epoch: 520 | train_loss: 1.4963 | test_loss: 1.4807 | \n",
      "Epoch: 530 | train_loss: 1.4508 | test_loss: 1.4367 | \n",
      "Epoch: 540 | train_loss: 1.4069 | test_loss: 1.3992 | \n",
      "Epoch: 550 | train_loss: 1.3727 | test_loss: 1.3591 | \n",
      "Epoch: 560 | train_loss: 1.3300 | test_loss: 1.3117 | \n",
      "Epoch: 570 | train_loss: 1.2822 | test_loss: 1.2720 | \n",
      "Epoch: 580 | train_loss: 1.2414 | test_loss: 1.2317 | \n",
      "Epoch: 590 | train_loss: 1.2025 | test_loss: 1.1933 | \n",
      "Epoch: 600 | train_loss: 1.1657 | test_loss: 1.1473 | \n",
      "Epoch: 610 | train_loss: 1.1312 | test_loss: 1.1126 | \n",
      "Epoch: 620 | train_loss: 1.0874 | test_loss: 1.0783 | \n",
      "Epoch: 630 | train_loss: 1.0493 | test_loss: 1.0418 | \n",
      "Epoch: 640 | train_loss: 1.0082 | test_loss: 0.9972 | \n",
      "Epoch: 650 | train_loss: 0.9754 | test_loss: 0.9615 | \n",
      "Epoch: 660 | train_loss: 0.9408 | test_loss: 0.9231 | \n",
      "Epoch: 670 | train_loss: 0.9005 | test_loss: 0.8925 | \n",
      "Epoch: 680 | train_loss: 0.8619 | test_loss: 0.8574 | \n",
      "Epoch: 690 | train_loss: 0.8252 | test_loss: 0.8092 | \n",
      "Epoch: 700 | train_loss: 0.7936 | test_loss: 0.7794 | \n",
      "Epoch: 710 | train_loss: 0.7546 | test_loss: 0.7501 | \n",
      "Epoch: 720 | train_loss: 0.7172 | test_loss: 0.7103 | \n",
      "Epoch: 730 | train_loss: 0.6854 | test_loss: 0.6816 | \n",
      "Epoch: 740 | train_loss: 0.6498 | test_loss: 0.6431 | \n",
      "Epoch: 750 | train_loss: 0.6221 | test_loss: 0.6108 | \n",
      "Epoch: 760 | train_loss: 0.5853 | test_loss: 0.5694 | \n",
      "Epoch: 770 | train_loss: 0.5561 | test_loss: 0.5445 | \n",
      "Epoch: 780 | train_loss: 0.5251 | test_loss: 0.5069 | \n",
      "Epoch: 790 | train_loss: 0.4885 | test_loss: 0.4845 | \n",
      "Epoch: 800 | train_loss: 0.4583 | test_loss: 0.4512 | \n",
      "Epoch: 810 | train_loss: 0.4288 | test_loss: 0.4221 | \n",
      "Epoch: 820 | train_loss: 0.4024 | test_loss: 0.3998 | \n",
      "Epoch: 830 | train_loss: 0.3717 | test_loss: 0.3680 | \n",
      "Epoch: 840 | train_loss: 0.3423 | test_loss: 0.3433 | \n",
      "Epoch: 850 | train_loss: 0.3104 | test_loss: 0.3144 | \n",
      "Epoch: 860 | train_loss: 0.2821 | test_loss: 0.2895 | \n",
      "Epoch: 870 | train_loss: 0.2630 | test_loss: 0.2731 | \n",
      "Epoch: 880 | train_loss: 0.2394 | test_loss: 0.2370 | \n",
      "Epoch: 890 | train_loss: 0.2177 | test_loss: 0.2231 | \n",
      "Epoch: 900 | train_loss: 0.1965 | test_loss: 0.2006 | \n",
      "Epoch: 910 | train_loss: 0.1774 | test_loss: 0.1995 | \n",
      "Epoch: 920 | train_loss: 0.1630 | test_loss: 0.1725 | \n",
      "Epoch: 930 | train_loss: 0.1442 | test_loss: 0.1596 | \n",
      "Epoch: 940 | train_loss: 0.1343 | test_loss: 0.1572 | \n",
      "Epoch: 950 | train_loss: 0.1300 | test_loss: 0.1524 | \n",
      "Epoch: 960 | train_loss: 0.1133 | test_loss: 0.1445 | \n",
      "Epoch: 970 | train_loss: 0.1157 | test_loss: 0.1491 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8904 | test_loss: 9.5161 | \n",
      "Epoch: 10 | train_loss: 7.7585 | test_loss: 7.6742 | \n",
      "Epoch: 20 | train_loss: 6.8700 | test_loss: 6.8071 | \n",
      "Epoch: 30 | train_loss: 6.2899 | test_loss: 6.2197 | \n",
      "Epoch: 40 | train_loss: 5.8610 | test_loss: 5.8177 | \n",
      "Epoch: 50 | train_loss: 5.5297 | test_loss: 5.4956 | \n",
      "Epoch: 60 | train_loss: 5.2628 | test_loss: 5.2283 | \n",
      "Epoch: 70 | train_loss: 5.0282 | test_loss: 4.9939 | \n",
      "Epoch: 80 | train_loss: 4.8218 | test_loss: 4.7909 | \n",
      "Epoch: 90 | train_loss: 4.6462 | test_loss: 4.6083 | \n",
      "Epoch: 100 | train_loss: 4.4761 | test_loss: 4.4489 | \n",
      "Epoch: 110 | train_loss: 4.3318 | test_loss: 4.3005 | \n",
      "Epoch: 120 | train_loss: 4.1901 | test_loss: 4.1552 | \n",
      "Epoch: 130 | train_loss: 4.0644 | test_loss: 4.0350 | \n",
      "Epoch: 140 | train_loss: 3.9422 | test_loss: 3.9197 | \n",
      "Epoch: 150 | train_loss: 3.8346 | test_loss: 3.8039 | \n",
      "Epoch: 160 | train_loss: 3.7215 | test_loss: 3.6970 | \n",
      "Epoch: 170 | train_loss: 3.6219 | test_loss: 3.6003 | \n",
      "Epoch: 180 | train_loss: 3.5284 | test_loss: 3.5058 | \n",
      "Epoch: 190 | train_loss: 3.4305 | test_loss: 3.4179 | \n",
      "Epoch: 200 | train_loss: 3.3497 | test_loss: 3.3273 | \n",
      "Epoch: 210 | train_loss: 3.2647 | test_loss: 3.2469 | \n",
      "Epoch: 220 | train_loss: 3.1927 | test_loss: 3.1667 | \n",
      "Epoch: 230 | train_loss: 3.1055 | test_loss: 3.0884 | \n",
      "Epoch: 240 | train_loss: 3.0369 | test_loss: 3.0113 | \n",
      "Epoch: 250 | train_loss: 2.9590 | test_loss: 2.9390 | \n",
      "Epoch: 260 | train_loss: 2.8906 | test_loss: 2.8699 | \n",
      "Epoch: 270 | train_loss: 2.8220 | test_loss: 2.8045 | \n",
      "Epoch: 280 | train_loss: 2.7592 | test_loss: 2.7391 | \n",
      "Epoch: 290 | train_loss: 2.6977 | test_loss: 2.6799 | \n",
      "Epoch: 300 | train_loss: 2.6316 | test_loss: 2.6114 | \n",
      "Epoch: 310 | train_loss: 2.5735 | test_loss: 2.5538 | \n",
      "Epoch: 320 | train_loss: 2.5137 | test_loss: 2.4906 | \n",
      "Epoch: 330 | train_loss: 2.4578 | test_loss: 2.4358 | \n",
      "Epoch: 340 | train_loss: 2.3974 | test_loss: 2.3737 | \n",
      "Epoch: 350 | train_loss: 2.3425 | test_loss: 2.3206 | \n",
      "Epoch: 360 | train_loss: 2.2860 | test_loss: 2.2613 | \n",
      "Epoch: 370 | train_loss: 2.2335 | test_loss: 2.2096 | \n",
      "Epoch: 380 | train_loss: 2.1803 | test_loss: 2.1606 | \n",
      "Epoch: 390 | train_loss: 2.1236 | test_loss: 2.1053 | \n",
      "Epoch: 400 | train_loss: 2.0792 | test_loss: 2.0561 | \n",
      "Epoch: 410 | train_loss: 2.0254 | test_loss: 2.0076 | \n",
      "Epoch: 420 | train_loss: 1.9752 | test_loss: 1.9482 | \n",
      "Epoch: 430 | train_loss: 1.9264 | test_loss: 1.9061 | \n",
      "Epoch: 440 | train_loss: 1.8801 | test_loss: 1.8571 | \n",
      "Epoch: 450 | train_loss: 1.8305 | test_loss: 1.8098 | \n",
      "Epoch: 460 | train_loss: 1.7827 | test_loss: 1.7649 | \n",
      "Epoch: 470 | train_loss: 1.7409 | test_loss: 1.7164 | \n",
      "Epoch: 480 | train_loss: 1.6951 | test_loss: 1.6752 | \n",
      "Epoch: 490 | train_loss: 1.6498 | test_loss: 1.6274 | \n",
      "Epoch: 500 | train_loss: 1.6039 | test_loss: 1.5822 | \n",
      "Epoch: 510 | train_loss: 1.5560 | test_loss: 1.5406 | \n",
      "Epoch: 520 | train_loss: 1.5220 | test_loss: 1.4951 | \n",
      "Epoch: 530 | train_loss: 1.4740 | test_loss: 1.4560 | \n",
      "Epoch: 540 | train_loss: 1.4323 | test_loss: 1.4125 | \n",
      "Epoch: 550 | train_loss: 1.3925 | test_loss: 1.3593 | \n",
      "Epoch: 560 | train_loss: 1.3488 | test_loss: 1.3255 | \n",
      "Epoch: 570 | train_loss: 1.3092 | test_loss: 1.2864 | \n",
      "Epoch: 580 | train_loss: 1.2686 | test_loss: 1.2504 | \n",
      "Epoch: 590 | train_loss: 1.2245 | test_loss: 1.1997 | \n",
      "Epoch: 600 | train_loss: 1.1924 | test_loss: 1.1687 | \n",
      "Epoch: 610 | train_loss: 1.1532 | test_loss: 1.1242 | \n",
      "Epoch: 620 | train_loss: 1.1110 | test_loss: 1.0825 | \n",
      "Epoch: 630 | train_loss: 1.0704 | test_loss: 1.0472 | \n",
      "Epoch: 640 | train_loss: 1.0310 | test_loss: 1.0137 | \n",
      "Epoch: 650 | train_loss: 0.9961 | test_loss: 0.9771 | \n",
      "Epoch: 660 | train_loss: 0.9543 | test_loss: 0.9408 | \n",
      "Epoch: 670 | train_loss: 0.9190 | test_loss: 0.9086 | \n",
      "Epoch: 680 | train_loss: 0.8882 | test_loss: 0.8765 | \n",
      "Epoch: 690 | train_loss: 0.8511 | test_loss: 0.8414 | \n",
      "Epoch: 700 | train_loss: 0.8095 | test_loss: 0.8357 | \n",
      "Epoch: 710 | train_loss: 0.7755 | test_loss: 0.7797 | \n",
      "Epoch: 720 | train_loss: 0.7376 | test_loss: 0.7371 | \n",
      "Epoch: 730 | train_loss: 0.7095 | test_loss: 0.7018 | \n",
      "Epoch: 740 | train_loss: 0.6671 | test_loss: 0.6660 | \n",
      "Epoch: 750 | train_loss: 0.6385 | test_loss: 0.6403 | \n",
      "Epoch: 760 | train_loss: 0.6096 | test_loss: 0.6247 | \n",
      "Epoch: 770 | train_loss: 0.5717 | test_loss: 0.5721 | \n",
      "Epoch: 780 | train_loss: 0.5346 | test_loss: 0.5362 | \n",
      "Epoch: 790 | train_loss: 0.5077 | test_loss: 0.5060 | \n",
      "Epoch: 800 | train_loss: 0.4807 | test_loss: 0.4749 | \n",
      "Epoch: 810 | train_loss: 0.4434 | test_loss: 0.4420 | \n",
      "Epoch: 820 | train_loss: 0.4193 | test_loss: 0.4096 | \n",
      "Epoch: 830 | train_loss: 0.3859 | test_loss: 0.3785 | \n",
      "Epoch: 840 | train_loss: 0.3573 | test_loss: 0.3525 | \n",
      "Epoch: 850 | train_loss: 0.3331 | test_loss: 0.3266 | \n",
      "Epoch: 860 | train_loss: 0.3051 | test_loss: 0.2974 | \n",
      "Epoch: 870 | train_loss: 0.2833 | test_loss: 0.2695 | \n",
      "Epoch: 880 | train_loss: 0.2487 | test_loss: 0.2509 | \n",
      "Epoch: 890 | train_loss: 0.2302 | test_loss: 0.2335 | \n",
      "Epoch: 900 | train_loss: 0.2063 | test_loss: 0.2179 | \n",
      "Epoch: 910 | train_loss: 0.1867 | test_loss: 0.1895 | \n",
      "Epoch: 920 | train_loss: 0.1695 | test_loss: 0.1804 | \n",
      "Epoch: 930 | train_loss: 0.1508 | test_loss: 0.1751 | \n",
      "Epoch: 940 | train_loss: 0.1429 | test_loss: 0.1643 | \n",
      "Epoch: 950 | train_loss: 0.1291 | test_loss: 0.1538 | \n",
      "Epoch: 960 | train_loss: 0.1141 | test_loss: 0.1520 | \n",
      "Epoch: 970 | train_loss: 0.1113 | test_loss: 0.1445 | \n",
      "Epoch: 980 | train_loss: 0.1150 | test_loss: 0.1438 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.8984 | test_loss: 2.4176 | \n",
      "Epoch: 10 | train_loss: 0.1487 | test_loss: 0.1545 | \n",
      "Epoch: 20 | train_loss: 0.1285 | test_loss: 0.1512 | \n",
      "Epoch: 30 | train_loss: 0.1221 | test_loss: 0.1500 | \n",
      "Epoch: 40 | train_loss: 0.1131 | test_loss: 0.1469 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.3238 | test_loss: 0.3438 | \n",
      "Epoch: 10 | train_loss: 0.1266 | test_loss: 0.1508 | \n",
      "Epoch: 20 | train_loss: 0.1113 | test_loss: 0.1484 | \n",
      "Epoch: 30 | train_loss: 0.1008 | test_loss: 0.1489 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 2.0502 | test_loss: 0.5119 | \n",
      "Epoch: 10 | train_loss: 0.1241 | test_loss: 0.1581 | \n",
      "Epoch: 20 | train_loss: 0.1152 | test_loss: 0.1467 | \n",
      "Epoch: 30 | train_loss: 0.0769 | test_loss: 0.1630 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6303 | test_loss: 8.6501 | \n",
      "Epoch: 10 | train_loss: 5.9284 | test_loss: 5.8013 | \n",
      "Epoch: 20 | train_loss: 4.8753 | test_loss: 4.8174 | \n",
      "Epoch: 30 | train_loss: 4.2280 | test_loss: 4.1910 | \n",
      "Epoch: 40 | train_loss: 3.7570 | test_loss: 3.7230 | \n",
      "Epoch: 50 | train_loss: 3.3801 | test_loss: 3.3759 | \n",
      "Epoch: 60 | train_loss: 3.0620 | test_loss: 3.0437 | \n",
      "Epoch: 70 | train_loss: 2.7872 | test_loss: 2.7720 | \n",
      "Epoch: 80 | train_loss: 2.5361 | test_loss: 2.5180 | \n",
      "Epoch: 90 | train_loss: 2.3084 | test_loss: 2.2840 | \n",
      "Epoch: 100 | train_loss: 2.0953 | test_loss: 2.0777 | \n",
      "Epoch: 110 | train_loss: 1.8985 | test_loss: 1.8822 | \n",
      "Epoch: 120 | train_loss: 1.7119 | test_loss: 1.7114 | \n",
      "Epoch: 130 | train_loss: 1.5362 | test_loss: 1.5148 | \n",
      "Epoch: 140 | train_loss: 1.3645 | test_loss: 1.3410 | \n",
      "Epoch: 150 | train_loss: 1.2011 | test_loss: 1.2003 | \n",
      "Epoch: 160 | train_loss: 1.0475 | test_loss: 1.0307 | \n",
      "Epoch: 170 | train_loss: 0.8951 | test_loss: 0.8925 | \n",
      "Epoch: 180 | train_loss: 0.7498 | test_loss: 0.7383 | \n",
      "Epoch: 190 | train_loss: 0.6143 | test_loss: 0.6280 | \n",
      "Epoch: 200 | train_loss: 0.4780 | test_loss: 0.4895 | \n",
      "Epoch: 210 | train_loss: 0.3789 | test_loss: 0.3704 | \n",
      "Epoch: 220 | train_loss: 0.2458 | test_loss: 0.2535 | \n",
      "Epoch: 230 | train_loss: 0.1560 | test_loss: 0.1935 | \n",
      "Epoch: 240 | train_loss: 0.1013 | test_loss: 0.1619 | \n",
      "Epoch: 250 | train_loss: 0.0812 | test_loss: 0.1510 | \n",
      "Epoch: 260 | train_loss: 0.0803 | test_loss: 0.1521 | \n",
      "Epoch: 270 | train_loss: 0.0818 | test_loss: 0.1576 | \n",
      "Epoch: 280 | train_loss: 0.0637 | test_loss: 0.1465 | \n",
      "Epoch: 290 | train_loss: 0.0747 | test_loss: 0.1523 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6186 | test_loss: 8.7144 | \n",
      "Epoch: 10 | train_loss: 5.9280 | test_loss: 5.8436 | \n",
      "Epoch: 20 | train_loss: 4.8659 | test_loss: 4.8050 | \n",
      "Epoch: 30 | train_loss: 4.2227 | test_loss: 4.1980 | \n",
      "Epoch: 40 | train_loss: 3.7548 | test_loss: 3.7201 | \n",
      "Epoch: 50 | train_loss: 3.3786 | test_loss: 3.3529 | \n",
      "Epoch: 60 | train_loss: 3.0604 | test_loss: 3.0230 | \n",
      "Epoch: 70 | train_loss: 2.7846 | test_loss: 2.7790 | \n",
      "Epoch: 80 | train_loss: 2.5339 | test_loss: 2.5240 | \n",
      "Epoch: 90 | train_loss: 2.3079 | test_loss: 2.2915 | \n",
      "Epoch: 100 | train_loss: 2.0962 | test_loss: 2.0856 | \n",
      "Epoch: 110 | train_loss: 1.8974 | test_loss: 1.8747 | \n",
      "Epoch: 120 | train_loss: 1.7143 | test_loss: 1.6800 | \n",
      "Epoch: 130 | train_loss: 1.5326 | test_loss: 1.5177 | \n",
      "Epoch: 140 | train_loss: 1.3668 | test_loss: 1.3969 | \n",
      "Epoch: 150 | train_loss: 1.2050 | test_loss: 1.1753 | \n",
      "Epoch: 160 | train_loss: 1.0456 | test_loss: 1.0317 | \n",
      "Epoch: 170 | train_loss: 0.8948 | test_loss: 0.8838 | \n",
      "Epoch: 180 | train_loss: 0.7540 | test_loss: 0.7416 | \n",
      "Epoch: 190 | train_loss: 0.6152 | test_loss: 0.6172 | \n",
      "Epoch: 200 | train_loss: 0.4819 | test_loss: 0.4847 | \n",
      "Epoch: 210 | train_loss: 0.3561 | test_loss: 0.3789 | \n",
      "Epoch: 220 | train_loss: 0.2520 | test_loss: 0.2737 | \n",
      "Epoch: 230 | train_loss: 0.1569 | test_loss: 0.1971 | \n",
      "Epoch: 240 | train_loss: 0.1024 | test_loss: 0.1552 | \n",
      "Epoch: 250 | train_loss: 0.0866 | test_loss: 0.1532 | \n",
      "Epoch: 260 | train_loss: 0.0705 | test_loss: 0.1497 | \n",
      "Epoch: 270 | train_loss: 0.0788 | test_loss: 0.1430 | \n",
      "Epoch: 280 | train_loss: 0.0779 | test_loss: 0.1438 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.7193 | test_loss: 8.6403 | \n",
      "Epoch: 10 | train_loss: 5.9897 | test_loss: 5.8897 | \n",
      "Epoch: 20 | train_loss: 4.9184 | test_loss: 4.8553 | \n",
      "Epoch: 30 | train_loss: 4.2778 | test_loss: 4.2261 | \n",
      "Epoch: 40 | train_loss: 3.8075 | test_loss: 3.7669 | \n",
      "Epoch: 50 | train_loss: 3.4332 | test_loss: 3.3953 | \n",
      "Epoch: 60 | train_loss: 3.1145 | test_loss: 3.0803 | \n",
      "Epoch: 70 | train_loss: 2.8381 | test_loss: 2.8054 | \n",
      "Epoch: 80 | train_loss: 2.5914 | test_loss: 2.5568 | \n",
      "Epoch: 90 | train_loss: 2.3576 | test_loss: 2.3342 | \n",
      "Epoch: 100 | train_loss: 2.1489 | test_loss: 2.1210 | \n",
      "Epoch: 110 | train_loss: 1.9509 | test_loss: 1.9229 | \n",
      "Epoch: 120 | train_loss: 1.7690 | test_loss: 1.7478 | \n",
      "Epoch: 130 | train_loss: 1.5907 | test_loss: 1.5622 | \n",
      "Epoch: 140 | train_loss: 1.4165 | test_loss: 1.4009 | \n",
      "Epoch: 150 | train_loss: 1.2587 | test_loss: 1.2360 | \n",
      "Epoch: 160 | train_loss: 1.1026 | test_loss: 1.0836 | \n",
      "Epoch: 170 | train_loss: 0.9582 | test_loss: 0.9476 | \n",
      "Epoch: 180 | train_loss: 0.8072 | test_loss: 0.7901 | \n",
      "Epoch: 190 | train_loss: 0.6713 | test_loss: 0.6479 | \n",
      "Epoch: 200 | train_loss: 0.5515 | test_loss: 0.5328 | \n",
      "Epoch: 210 | train_loss: 0.4270 | test_loss: 0.4096 | \n",
      "Epoch: 220 | train_loss: 0.3217 | test_loss: 0.3204 | \n",
      "Epoch: 230 | train_loss: 0.2389 | test_loss: 0.2174 | \n",
      "Epoch: 240 | train_loss: 0.1889 | test_loss: 0.1784 | \n",
      "Epoch: 250 | train_loss: 0.1626 | test_loss: 0.1590 | \n",
      "Epoch: 260 | train_loss: 0.1504 | test_loss: 0.1532 | \n",
      "Epoch: 270 | train_loss: 0.1523 | test_loss: 0.1531 | \n",
      "Epoch: 280 | train_loss: 0.1477 | test_loss: 0.1457 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.7183 | test_loss: 8.6660 | \n",
      "Epoch: 10 | train_loss: 6.0073 | test_loss: 5.9164 | \n",
      "Epoch: 20 | train_loss: 4.9423 | test_loss: 4.8949 | \n",
      "Epoch: 30 | train_loss: 4.3009 | test_loss: 4.2454 | \n",
      "Epoch: 40 | train_loss: 3.8287 | test_loss: 3.7846 | \n",
      "Epoch: 50 | train_loss: 3.4478 | test_loss: 3.4181 | \n",
      "Epoch: 60 | train_loss: 3.1337 | test_loss: 3.0968 | \n",
      "Epoch: 70 | train_loss: 2.8574 | test_loss: 2.8304 | \n",
      "Epoch: 80 | train_loss: 2.6047 | test_loss: 2.5752 | \n",
      "Epoch: 90 | train_loss: 2.3781 | test_loss: 2.3521 | \n",
      "Epoch: 100 | train_loss: 2.1698 | test_loss: 2.1382 | \n",
      "Epoch: 110 | train_loss: 1.9694 | test_loss: 1.9346 | \n",
      "Epoch: 120 | train_loss: 1.7825 | test_loss: 1.7603 | \n",
      "Epoch: 130 | train_loss: 1.6042 | test_loss: 1.5793 | \n",
      "Epoch: 140 | train_loss: 1.4359 | test_loss: 1.4121 | \n",
      "Epoch: 150 | train_loss: 1.2764 | test_loss: 1.2513 | \n",
      "Epoch: 160 | train_loss: 1.1143 | test_loss: 1.0966 | \n",
      "Epoch: 170 | train_loss: 0.9687 | test_loss: 0.9447 | \n",
      "Epoch: 180 | train_loss: 0.8289 | test_loss: 0.8091 | \n",
      "Epoch: 190 | train_loss: 0.6888 | test_loss: 0.6688 | \n",
      "Epoch: 200 | train_loss: 0.5594 | test_loss: 0.5495 | \n",
      "Epoch: 210 | train_loss: 0.4414 | test_loss: 0.4245 | \n",
      "Epoch: 220 | train_loss: 0.3279 | test_loss: 0.3255 | \n",
      "Epoch: 230 | train_loss: 0.2359 | test_loss: 0.2210 | \n",
      "Epoch: 240 | train_loss: 0.1925 | test_loss: 0.1828 | \n",
      "Epoch: 250 | train_loss: 0.1593 | test_loss: 0.1610 | \n",
      "Epoch: 260 | train_loss: 0.1410 | test_loss: 0.1465 | \n",
      "Epoch: 270 | train_loss: 0.1371 | test_loss: 0.1523 | \n",
      "Epoch: 280 | train_loss: 0.1484 | test_loss: 0.1493 | \n",
      "Epoch: 290 | train_loss: 0.1414 | test_loss: 0.1404 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.3174 | test_loss: 4.6929 | \n",
      "Epoch: 10 | train_loss: 0.1743 | test_loss: 0.1663 | \n",
      "Epoch: 20 | train_loss: 0.1440 | test_loss: 0.1563 | \n",
      "Epoch: 30 | train_loss: 0.1326 | test_loss: 0.1548 | \n",
      "Epoch: 40 | train_loss: 0.1278 | test_loss: 0.1510 | \n",
      "Epoch: 50 | train_loss: 0.1227 | test_loss: 0.1501 | \n",
      "Epoch: 60 | train_loss: 0.1191 | test_loss: 0.1495 | \n",
      "Epoch: 70 | train_loss: 0.1138 | test_loss: 0.1462 | \n",
      "Epoch: 80 | train_loss: 0.1113 | test_loss: 0.1448 | \n",
      "Epoch: 90 | train_loss: 0.1089 | test_loss: 0.1437 | \n",
      "Epoch: 100 | train_loss: 0.1038 | test_loss: 0.1428 | \n",
      "Epoch: 110 | train_loss: 0.1031 | test_loss: 0.1432 | \n",
      "Epoch: 120 | train_loss: 0.1002 | test_loss: 0.1412 | \n",
      "Epoch: 130 | train_loss: 0.0942 | test_loss: 0.1456 | \n",
      "Epoch: 140 | train_loss: 0.0946 | test_loss: 0.1399 | \n",
      "Epoch: 150 | train_loss: 0.0906 | test_loss: 0.1403 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.6494 | test_loss: 1.7997 | \n",
      "Epoch: 10 | train_loss: 0.1430 | test_loss: 0.1507 | \n",
      "Epoch: 20 | train_loss: 0.1259 | test_loss: 0.1490 | \n",
      "Epoch: 30 | train_loss: 0.1141 | test_loss: 0.1457 | \n",
      "Epoch: 40 | train_loss: 0.1073 | test_loss: 0.1497 | \n",
      "Epoch: 50 | train_loss: 0.0986 | test_loss: 0.1449 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.0976 | test_loss: 1.6612 | \n",
      "Epoch: 10 | train_loss: 0.1242 | test_loss: 0.1531 | \n",
      "Epoch: 20 | train_loss: 0.1276 | test_loss: 0.1617 | \n",
      "Epoch: 30 | train_loss: 0.1036 | test_loss: 0.1537 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2853 | test_loss: 9.1886 | \n",
      "Epoch: 10 | train_loss: 6.8796 | test_loss: 6.8067 | \n",
      "Epoch: 20 | train_loss: 5.8833 | test_loss: 5.7870 | \n",
      "Epoch: 30 | train_loss: 5.2731 | test_loss: 5.2330 | \n",
      "Epoch: 40 | train_loss: 4.8345 | test_loss: 4.8130 | \n",
      "Epoch: 50 | train_loss: 4.4902 | test_loss: 4.4684 | \n",
      "Epoch: 60 | train_loss: 4.2031 | test_loss: 4.1899 | \n",
      "Epoch: 70 | train_loss: 3.9556 | test_loss: 3.9347 | \n",
      "Epoch: 80 | train_loss: 3.7401 | test_loss: 3.7155 | \n",
      "Epoch: 90 | train_loss: 3.5413 | test_loss: 3.5268 | \n",
      "Epoch: 100 | train_loss: 3.3617 | test_loss: 3.3537 | \n",
      "Epoch: 110 | train_loss: 3.1992 | test_loss: 3.1710 | \n",
      "Epoch: 120 | train_loss: 3.0455 | test_loss: 3.0272 | \n",
      "Epoch: 130 | train_loss: 2.9037 | test_loss: 2.9020 | \n",
      "Epoch: 140 | train_loss: 2.7672 | test_loss: 2.7525 | \n",
      "Epoch: 150 | train_loss: 2.6401 | test_loss: 2.6287 | \n",
      "Epoch: 160 | train_loss: 2.5194 | test_loss: 2.5009 | \n",
      "Epoch: 170 | train_loss: 2.4022 | test_loss: 2.3908 | \n",
      "Epoch: 180 | train_loss: 2.2915 | test_loss: 2.2736 | \n",
      "Epoch: 190 | train_loss: 2.1851 | test_loss: 2.1756 | \n",
      "Epoch: 200 | train_loss: 2.0799 | test_loss: 2.0663 | \n",
      "Epoch: 210 | train_loss: 1.9798 | test_loss: 1.9673 | \n",
      "Epoch: 220 | train_loss: 1.8844 | test_loss: 1.8700 | \n",
      "Epoch: 230 | train_loss: 1.7888 | test_loss: 1.7745 | \n",
      "Epoch: 240 | train_loss: 1.6955 | test_loss: 1.6877 | \n",
      "Epoch: 250 | train_loss: 1.6071 | test_loss: 1.6015 | \n",
      "Epoch: 260 | train_loss: 1.5180 | test_loss: 1.5089 | \n",
      "Epoch: 270 | train_loss: 1.4345 | test_loss: 1.4209 | \n",
      "Epoch: 280 | train_loss: 1.3484 | test_loss: 1.3434 | \n",
      "Epoch: 290 | train_loss: 1.2661 | test_loss: 1.2496 | \n",
      "Epoch: 300 | train_loss: 1.1867 | test_loss: 1.1866 | \n",
      "Epoch: 310 | train_loss: 1.1072 | test_loss: 1.1126 | \n",
      "Epoch: 320 | train_loss: 1.0294 | test_loss: 1.0296 | \n",
      "Epoch: 330 | train_loss: 0.9535 | test_loss: 0.9579 | \n",
      "Epoch: 340 | train_loss: 0.8804 | test_loss: 0.8806 | \n",
      "Epoch: 350 | train_loss: 0.8060 | test_loss: 0.8060 | \n",
      "Epoch: 360 | train_loss: 0.7345 | test_loss: 0.7400 | \n",
      "Epoch: 370 | train_loss: 0.6637 | test_loss: 0.6647 | \n",
      "Epoch: 380 | train_loss: 0.5947 | test_loss: 0.6022 | \n",
      "Epoch: 390 | train_loss: 0.5281 | test_loss: 0.5344 | \n",
      "Epoch: 400 | train_loss: 0.4609 | test_loss: 0.4777 | \n",
      "Epoch: 410 | train_loss: 0.3970 | test_loss: 0.4119 | \n",
      "Epoch: 420 | train_loss: 0.3344 | test_loss: 0.3557 | \n",
      "Epoch: 430 | train_loss: 0.2750 | test_loss: 0.2909 | \n",
      "Epoch: 440 | train_loss: 0.2167 | test_loss: 0.2701 | \n",
      "Epoch: 450 | train_loss: 0.1681 | test_loss: 0.2003 | \n",
      "Epoch: 460 | train_loss: 0.1205 | test_loss: 0.1743 | \n",
      "Epoch: 470 | train_loss: 0.0912 | test_loss: 0.1757 | \n",
      "Epoch: 480 | train_loss: 0.0710 | test_loss: 0.1521 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2746 | test_loss: 9.2749 | \n",
      "Epoch: 10 | train_loss: 6.8847 | test_loss: 6.7959 | \n",
      "Epoch: 20 | train_loss: 5.8847 | test_loss: 5.8085 | \n",
      "Epoch: 30 | train_loss: 5.2745 | test_loss: 5.2529 | \n",
      "Epoch: 40 | train_loss: 4.8373 | test_loss: 4.8037 | \n",
      "Epoch: 50 | train_loss: 4.4927 | test_loss: 4.4718 | \n",
      "Epoch: 60 | train_loss: 4.2047 | test_loss: 4.1898 | \n",
      "Epoch: 70 | train_loss: 3.9568 | test_loss: 3.9489 | \n",
      "Epoch: 80 | train_loss: 3.7384 | test_loss: 3.7191 | \n",
      "Epoch: 90 | train_loss: 3.5412 | test_loss: 3.5123 | \n",
      "Epoch: 100 | train_loss: 3.3632 | test_loss: 3.3432 | \n",
      "Epoch: 110 | train_loss: 3.1985 | test_loss: 3.1649 | \n",
      "Epoch: 120 | train_loss: 3.0470 | test_loss: 3.0428 | \n",
      "Epoch: 130 | train_loss: 2.9054 | test_loss: 2.8775 | \n",
      "Epoch: 140 | train_loss: 2.7703 | test_loss: 2.7482 | \n",
      "Epoch: 150 | train_loss: 2.6426 | test_loss: 2.6282 | \n",
      "Epoch: 160 | train_loss: 2.5218 | test_loss: 2.5218 | \n",
      "Epoch: 170 | train_loss: 2.4061 | test_loss: 2.3936 | \n",
      "Epoch: 180 | train_loss: 2.2959 | test_loss: 2.2864 | \n",
      "Epoch: 190 | train_loss: 2.1895 | test_loss: 2.1734 | \n",
      "Epoch: 200 | train_loss: 2.0841 | test_loss: 2.0486 | \n",
      "Epoch: 210 | train_loss: 1.9819 | test_loss: 1.9805 | \n",
      "Epoch: 220 | train_loss: 1.8878 | test_loss: 1.8864 | \n",
      "Epoch: 230 | train_loss: 1.7929 | test_loss: 1.7627 | \n",
      "Epoch: 240 | train_loss: 1.7009 | test_loss: 1.6935 | \n",
      "Epoch: 250 | train_loss: 1.6090 | test_loss: 1.5877 | \n",
      "Epoch: 260 | train_loss: 1.5208 | test_loss: 1.5080 | \n",
      "Epoch: 270 | train_loss: 1.4363 | test_loss: 1.4187 | \n",
      "Epoch: 280 | train_loss: 1.3509 | test_loss: 1.3576 | \n",
      "Epoch: 290 | train_loss: 1.2693 | test_loss: 1.2615 | \n",
      "Epoch: 300 | train_loss: 1.1880 | test_loss: 1.1962 | \n",
      "Epoch: 310 | train_loss: 1.1096 | test_loss: 1.1032 | \n",
      "Epoch: 320 | train_loss: 1.0329 | test_loss: 1.0213 | \n",
      "Epoch: 330 | train_loss: 0.9566 | test_loss: 0.9575 | \n",
      "Epoch: 340 | train_loss: 0.8815 | test_loss: 0.8698 | \n",
      "Epoch: 350 | train_loss: 0.8093 | test_loss: 0.8370 | \n",
      "Epoch: 360 | train_loss: 0.7378 | test_loss: 0.7326 | \n",
      "Epoch: 370 | train_loss: 0.6666 | test_loss: 0.6699 | \n",
      "Epoch: 380 | train_loss: 0.5981 | test_loss: 0.5932 | \n",
      "Epoch: 390 | train_loss: 0.5284 | test_loss: 0.5278 | \n",
      "Epoch: 400 | train_loss: 0.4618 | test_loss: 0.4884 | \n",
      "Epoch: 410 | train_loss: 0.3972 | test_loss: 0.4154 | \n",
      "Epoch: 420 | train_loss: 0.3369 | test_loss: 0.3519 | \n",
      "Epoch: 430 | train_loss: 0.2761 | test_loss: 0.3065 | \n",
      "Epoch: 440 | train_loss: 0.2204 | test_loss: 0.2534 | \n",
      "Epoch: 450 | train_loss: 0.1649 | test_loss: 0.1895 | \n",
      "Epoch: 460 | train_loss: 0.1205 | test_loss: 0.1671 | \n",
      "Epoch: 470 | train_loss: 0.0848 | test_loss: 0.1588 | \n",
      "Epoch: 480 | train_loss: 0.0755 | test_loss: 0.1590 | \n",
      "Epoch: 490 | train_loss: 0.0587 | test_loss: 0.1502 | \n",
      "Epoch: 500 | train_loss: 0.0648 | test_loss: 0.1655 | \n",
      "Epoch: 510 | train_loss: 0.0525 | test_loss: 0.1515 | \n",
      "Epoch: 520 | train_loss: 0.0487 | test_loss: 0.1447 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3525 | test_loss: 9.1368 | \n",
      "Epoch: 10 | train_loss: 6.9214 | test_loss: 6.8302 | \n",
      "Epoch: 20 | train_loss: 5.9168 | test_loss: 5.8447 | \n",
      "Epoch: 30 | train_loss: 5.3013 | test_loss: 5.2459 | \n",
      "Epoch: 40 | train_loss: 4.8628 | test_loss: 4.8089 | \n",
      "Epoch: 50 | train_loss: 4.5168 | test_loss: 4.4720 | \n",
      "Epoch: 60 | train_loss: 4.2242 | test_loss: 4.1863 | \n",
      "Epoch: 70 | train_loss: 3.9766 | test_loss: 3.9384 | \n",
      "Epoch: 80 | train_loss: 3.7578 | test_loss: 3.7240 | \n",
      "Epoch: 90 | train_loss: 3.5581 | test_loss: 3.5318 | \n",
      "Epoch: 100 | train_loss: 3.3887 | test_loss: 3.3559 | \n",
      "Epoch: 110 | train_loss: 3.2205 | test_loss: 3.1940 | \n",
      "Epoch: 120 | train_loss: 3.0667 | test_loss: 3.0419 | \n",
      "Epoch: 130 | train_loss: 2.9248 | test_loss: 2.9032 | \n",
      "Epoch: 140 | train_loss: 2.7938 | test_loss: 2.7662 | \n",
      "Epoch: 150 | train_loss: 2.6728 | test_loss: 2.6453 | \n",
      "Epoch: 160 | train_loss: 2.5400 | test_loss: 2.5199 | \n",
      "Epoch: 170 | train_loss: 2.4266 | test_loss: 2.4070 | \n",
      "Epoch: 180 | train_loss: 2.3177 | test_loss: 2.2894 | \n",
      "Epoch: 190 | train_loss: 2.2144 | test_loss: 2.1887 | \n",
      "Epoch: 200 | train_loss: 2.1072 | test_loss: 2.0836 | \n",
      "Epoch: 210 | train_loss: 2.0066 | test_loss: 1.9808 | \n",
      "Epoch: 220 | train_loss: 1.9086 | test_loss: 1.8814 | \n",
      "Epoch: 230 | train_loss: 1.8154 | test_loss: 1.7950 | \n",
      "Epoch: 240 | train_loss: 1.7257 | test_loss: 1.6992 | \n",
      "Epoch: 250 | train_loss: 1.6332 | test_loss: 1.6124 | \n",
      "Epoch: 260 | train_loss: 1.5476 | test_loss: 1.5253 | \n",
      "Epoch: 270 | train_loss: 1.4613 | test_loss: 1.4463 | \n",
      "Epoch: 280 | train_loss: 1.3758 | test_loss: 1.3594 | \n",
      "Epoch: 290 | train_loss: 1.3005 | test_loss: 1.2667 | \n",
      "Epoch: 300 | train_loss: 1.2173 | test_loss: 1.1921 | \n",
      "Epoch: 310 | train_loss: 1.1438 | test_loss: 1.1230 | \n",
      "Epoch: 320 | train_loss: 1.0615 | test_loss: 1.0381 | \n",
      "Epoch: 330 | train_loss: 0.9898 | test_loss: 0.9649 | \n",
      "Epoch: 340 | train_loss: 0.9141 | test_loss: 0.8968 | \n",
      "Epoch: 350 | train_loss: 0.8445 | test_loss: 0.8236 | \n",
      "Epoch: 360 | train_loss: 0.7756 | test_loss: 0.7549 | \n",
      "Epoch: 370 | train_loss: 0.7024 | test_loss: 0.6829 | \n",
      "Epoch: 380 | train_loss: 0.6382 | test_loss: 0.6184 | \n",
      "Epoch: 390 | train_loss: 0.5686 | test_loss: 0.5548 | \n",
      "Epoch: 400 | train_loss: 0.5038 | test_loss: 0.4927 | \n",
      "Epoch: 410 | train_loss: 0.4470 | test_loss: 0.4260 | \n",
      "Epoch: 420 | train_loss: 0.3844 | test_loss: 0.3745 | \n",
      "Epoch: 430 | train_loss: 0.3282 | test_loss: 0.3227 | \n",
      "Epoch: 440 | train_loss: 0.2789 | test_loss: 0.2731 | \n",
      "Epoch: 450 | train_loss: 0.2338 | test_loss: 0.2410 | \n",
      "Epoch: 460 | train_loss: 0.1924 | test_loss: 0.1976 | \n",
      "Epoch: 470 | train_loss: 0.1649 | test_loss: 0.1741 | \n",
      "Epoch: 480 | train_loss: 0.1547 | test_loss: 0.1484 | \n",
      "Epoch: 490 | train_loss: 0.1357 | test_loss: 0.1476 | \n",
      "Epoch: 500 | train_loss: 0.1303 | test_loss: 0.1448 | \n",
      "Epoch: 510 | train_loss: 0.1252 | test_loss: 0.1465 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2481 | test_loss: 8.9349 | \n",
      "Epoch: 10 | train_loss: 6.8547 | test_loss: 6.7614 | \n",
      "Epoch: 20 | train_loss: 5.8473 | test_loss: 5.7815 | \n",
      "Epoch: 30 | train_loss: 5.2396 | test_loss: 5.1853 | \n",
      "Epoch: 40 | train_loss: 4.8037 | test_loss: 4.7562 | \n",
      "Epoch: 50 | train_loss: 4.4529 | test_loss: 4.4261 | \n",
      "Epoch: 60 | train_loss: 4.1631 | test_loss: 4.1338 | \n",
      "Epoch: 70 | train_loss: 3.9227 | test_loss: 3.8877 | \n",
      "Epoch: 80 | train_loss: 3.6972 | test_loss: 3.6805 | \n",
      "Epoch: 90 | train_loss: 3.5071 | test_loss: 3.4813 | \n",
      "Epoch: 100 | train_loss: 3.3342 | test_loss: 3.3058 | \n",
      "Epoch: 110 | train_loss: 3.1625 | test_loss: 3.1450 | \n",
      "Epoch: 120 | train_loss: 3.0168 | test_loss: 2.9922 | \n",
      "Epoch: 130 | train_loss: 2.8688 | test_loss: 2.8513 | \n",
      "Epoch: 140 | train_loss: 2.7378 | test_loss: 2.7175 | \n",
      "Epoch: 150 | train_loss: 2.6124 | test_loss: 2.5873 | \n",
      "Epoch: 160 | train_loss: 2.4882 | test_loss: 2.4701 | \n",
      "Epoch: 170 | train_loss: 2.3716 | test_loss: 2.3530 | \n",
      "Epoch: 180 | train_loss: 2.2620 | test_loss: 2.2386 | \n",
      "Epoch: 190 | train_loss: 2.1557 | test_loss: 2.1325 | \n",
      "Epoch: 200 | train_loss: 2.0517 | test_loss: 2.0292 | \n",
      "Epoch: 210 | train_loss: 1.9517 | test_loss: 1.9337 | \n",
      "Epoch: 220 | train_loss: 1.8567 | test_loss: 1.8334 | \n",
      "Epoch: 230 | train_loss: 1.7590 | test_loss: 1.7424 | \n",
      "Epoch: 240 | train_loss: 1.6721 | test_loss: 1.6528 | \n",
      "Epoch: 250 | train_loss: 1.5816 | test_loss: 1.5677 | \n",
      "Epoch: 260 | train_loss: 1.5015 | test_loss: 1.4720 | \n",
      "Epoch: 270 | train_loss: 1.4092 | test_loss: 1.3986 | \n",
      "Epoch: 280 | train_loss: 1.3264 | test_loss: 1.3054 | \n",
      "Epoch: 290 | train_loss: 1.2444 | test_loss: 1.2212 | \n",
      "Epoch: 300 | train_loss: 1.1636 | test_loss: 1.1622 | \n",
      "Epoch: 310 | train_loss: 1.0828 | test_loss: 1.0719 | \n",
      "Epoch: 320 | train_loss: 1.0076 | test_loss: 0.9966 | \n",
      "Epoch: 330 | train_loss: 0.9305 | test_loss: 0.9121 | \n",
      "Epoch: 340 | train_loss: 0.8669 | test_loss: 0.8466 | \n",
      "Epoch: 350 | train_loss: 0.7905 | test_loss: 0.7703 | \n",
      "Epoch: 360 | train_loss: 0.7214 | test_loss: 0.7100 | \n",
      "Epoch: 370 | train_loss: 0.6549 | test_loss: 0.6365 | \n",
      "Epoch: 380 | train_loss: 0.5847 | test_loss: 0.5713 | \n",
      "Epoch: 390 | train_loss: 0.5226 | test_loss: 0.5051 | \n",
      "Epoch: 400 | train_loss: 0.4551 | test_loss: 0.4438 | \n",
      "Epoch: 410 | train_loss: 0.3983 | test_loss: 0.3884 | \n",
      "Epoch: 420 | train_loss: 0.3399 | test_loss: 0.3445 | \n",
      "Epoch: 430 | train_loss: 0.2911 | test_loss: 0.2837 | \n",
      "Epoch: 440 | train_loss: 0.2435 | test_loss: 0.2554 | \n",
      "Epoch: 450 | train_loss: 0.2027 | test_loss: 0.2105 | \n",
      "Epoch: 460 | train_loss: 0.1655 | test_loss: 0.1823 | \n",
      "Epoch: 470 | train_loss: 0.1484 | test_loss: 0.1636 | \n",
      "Epoch: 480 | train_loss: 0.1372 | test_loss: 0.1629 | \n",
      "Epoch: 490 | train_loss: 0.1290 | test_loss: 0.1504 | \n",
      "Epoch: 500 | train_loss: 0.1221 | test_loss: 0.1465 | \n",
      "Epoch: 510 | train_loss: 0.1267 | test_loss: 0.1412 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3489 | test_loss: 7.3486 | \n",
      "Epoch: 10 | train_loss: 0.2650 | test_loss: 0.2245 | \n",
      "Epoch: 20 | train_loss: 0.1706 | test_loss: 0.1669 | \n",
      "Epoch: 30 | train_loss: 0.1515 | test_loss: 0.1584 | \n",
      "Epoch: 40 | train_loss: 0.1421 | test_loss: 0.1557 | \n",
      "Epoch: 50 | train_loss: 0.1349 | test_loss: 0.1550 | \n",
      "Epoch: 60 | train_loss: 0.1318 | test_loss: 0.1548 | \n",
      "Epoch: 70 | train_loss: 0.1291 | test_loss: 0.1540 | \n",
      "Epoch: 80 | train_loss: 0.1260 | test_loss: 0.1536 | \n",
      "Epoch: 90 | train_loss: 0.1238 | test_loss: 0.1536 | \n",
      "Epoch: 100 | train_loss: 0.1216 | test_loss: 0.1524 | \n",
      "Epoch: 110 | train_loss: 0.1194 | test_loss: 0.1516 | \n",
      "Epoch: 120 | train_loss: 0.1173 | test_loss: 0.1504 | \n",
      "Epoch: 130 | train_loss: 0.1146 | test_loss: 0.1499 | \n",
      "Epoch: 140 | train_loss: 0.1126 | test_loss: 0.1489 | \n",
      "Epoch: 150 | train_loss: 0.1108 | test_loss: 0.1481 | \n",
      "Epoch: 160 | train_loss: 0.1093 | test_loss: 0.1475 | \n",
      "Epoch: 170 | train_loss: 0.1075 | test_loss: 0.1460 | \n",
      "Epoch: 180 | train_loss: 0.1012 | test_loss: 0.1458 | \n",
      "Epoch: 190 | train_loss: 0.1018 | test_loss: 0.1449 | \n",
      "Epoch: 200 | train_loss: 0.1005 | test_loss: 0.1452 | \n",
      "Epoch: 210 | train_loss: 0.0964 | test_loss: 0.1446 | \n",
      "Epoch: 220 | train_loss: 0.0970 | test_loss: 0.1450 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.1375 | test_loss: 4.2755 | \n",
      "Epoch: 10 | train_loss: 0.1794 | test_loss: 0.1765 | \n",
      "Epoch: 20 | train_loss: 0.1432 | test_loss: 0.1552 | \n",
      "Epoch: 30 | train_loss: 0.1296 | test_loss: 0.1517 | \n",
      "Epoch: 40 | train_loss: 0.1224 | test_loss: 0.1511 | \n",
      "Epoch: 50 | train_loss: 0.1175 | test_loss: 0.1511 | \n",
      "Epoch: 60 | train_loss: 0.1110 | test_loss: 0.1513 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 4.8477 | test_loss: 0.5146 | \n",
      "Epoch: 10 | train_loss: 0.1551 | test_loss: 0.1562 | \n",
      "Epoch: 20 | train_loss: 0.1084 | test_loss: 0.1534 | \n",
      "Epoch: 30 | train_loss: 0.0947 | test_loss: 0.1514 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8194 | test_loss: 9.3948 | \n",
      "Epoch: 10 | train_loss: 7.7266 | test_loss: 7.6559 | \n",
      "Epoch: 20 | train_loss: 6.8180 | test_loss: 6.7684 | \n",
      "Epoch: 30 | train_loss: 6.2408 | test_loss: 6.1884 | \n",
      "Epoch: 40 | train_loss: 5.8232 | test_loss: 5.7511 | \n",
      "Epoch: 50 | train_loss: 5.4952 | test_loss: 5.4735 | \n",
      "Epoch: 60 | train_loss: 5.2231 | test_loss: 5.2029 | \n",
      "Epoch: 70 | train_loss: 4.9934 | test_loss: 4.9818 | \n",
      "Epoch: 80 | train_loss: 4.7890 | test_loss: 4.7729 | \n",
      "Epoch: 90 | train_loss: 4.6068 | test_loss: 4.5690 | \n",
      "Epoch: 100 | train_loss: 4.4418 | test_loss: 4.4262 | \n",
      "Epoch: 110 | train_loss: 4.2927 | test_loss: 4.2793 | \n",
      "Epoch: 120 | train_loss: 4.1574 | test_loss: 4.1188 | \n",
      "Epoch: 130 | train_loss: 4.0298 | test_loss: 4.0136 | \n",
      "Epoch: 140 | train_loss: 3.9110 | test_loss: 3.8992 | \n",
      "Epoch: 150 | train_loss: 3.7987 | test_loss: 3.7822 | \n",
      "Epoch: 160 | train_loss: 3.6949 | test_loss: 3.6774 | \n",
      "Epoch: 170 | train_loss: 3.5945 | test_loss: 3.5965 | \n",
      "Epoch: 180 | train_loss: 3.4987 | test_loss: 3.4826 | \n",
      "Epoch: 190 | train_loss: 3.4077 | test_loss: 3.3929 | \n",
      "Epoch: 200 | train_loss: 3.3202 | test_loss: 3.3082 | \n",
      "Epoch: 210 | train_loss: 3.2375 | test_loss: 3.2238 | \n",
      "Epoch: 220 | train_loss: 3.1578 | test_loss: 3.1424 | \n",
      "Epoch: 230 | train_loss: 3.0809 | test_loss: 3.0645 | \n",
      "Epoch: 240 | train_loss: 3.0072 | test_loss: 2.9968 | \n",
      "Epoch: 250 | train_loss: 2.9344 | test_loss: 2.9275 | \n",
      "Epoch: 260 | train_loss: 2.8646 | test_loss: 2.8580 | \n",
      "Epoch: 270 | train_loss: 2.7972 | test_loss: 2.7808 | \n",
      "Epoch: 280 | train_loss: 2.7306 | test_loss: 2.7194 | \n",
      "Epoch: 290 | train_loss: 2.6669 | test_loss: 2.6522 | \n",
      "Epoch: 300 | train_loss: 2.6061 | test_loss: 2.5917 | \n",
      "Epoch: 310 | train_loss: 2.5446 | test_loss: 2.5225 | \n",
      "Epoch: 320 | train_loss: 2.4857 | test_loss: 2.4747 | \n",
      "Epoch: 330 | train_loss: 2.4264 | test_loss: 2.4140 | \n",
      "Epoch: 340 | train_loss: 2.3692 | test_loss: 2.3542 | \n",
      "Epoch: 350 | train_loss: 2.3139 | test_loss: 2.2959 | \n",
      "Epoch: 360 | train_loss: 2.2584 | test_loss: 2.2473 | \n",
      "Epoch: 370 | train_loss: 2.2042 | test_loss: 2.1918 | \n",
      "Epoch: 380 | train_loss: 2.1518 | test_loss: 2.1358 | \n",
      "Epoch: 390 | train_loss: 2.1002 | test_loss: 2.0893 | \n",
      "Epoch: 400 | train_loss: 2.0489 | test_loss: 2.0374 | \n",
      "Epoch: 410 | train_loss: 1.9995 | test_loss: 1.9813 | \n",
      "Epoch: 420 | train_loss: 1.9498 | test_loss: 1.9630 | \n",
      "Epoch: 430 | train_loss: 1.9000 | test_loss: 1.8844 | \n",
      "Epoch: 440 | train_loss: 1.8520 | test_loss: 1.8562 | \n",
      "Epoch: 450 | train_loss: 1.8044 | test_loss: 1.7966 | \n",
      "Epoch: 460 | train_loss: 1.7574 | test_loss: 1.7428 | \n",
      "Epoch: 470 | train_loss: 1.7120 | test_loss: 1.7072 | \n",
      "Epoch: 480 | train_loss: 1.6663 | test_loss: 1.6564 | \n",
      "Epoch: 490 | train_loss: 1.6218 | test_loss: 1.6257 | \n",
      "Epoch: 500 | train_loss: 1.5781 | test_loss: 1.5510 | \n",
      "Epoch: 510 | train_loss: 1.5326 | test_loss: 1.5309 | \n",
      "Epoch: 520 | train_loss: 1.4881 | test_loss: 1.4914 | \n",
      "Epoch: 530 | train_loss: 1.4472 | test_loss: 1.4426 | \n",
      "Epoch: 540 | train_loss: 1.4027 | test_loss: 1.3930 | \n",
      "Epoch: 550 | train_loss: 1.3607 | test_loss: 1.3582 | \n",
      "Epoch: 560 | train_loss: 1.3189 | test_loss: 1.3197 | \n",
      "Epoch: 570 | train_loss: 1.2781 | test_loss: 1.2746 | \n",
      "Epoch: 580 | train_loss: 1.2370 | test_loss: 1.2447 | \n",
      "Epoch: 590 | train_loss: 1.1966 | test_loss: 1.1967 | \n",
      "Epoch: 600 | train_loss: 1.1568 | test_loss: 1.1508 | \n",
      "Epoch: 610 | train_loss: 1.1176 | test_loss: 1.1148 | \n",
      "Epoch: 620 | train_loss: 1.0783 | test_loss: 1.0789 | \n",
      "Epoch: 630 | train_loss: 1.0401 | test_loss: 1.0269 | \n",
      "Epoch: 640 | train_loss: 1.0014 | test_loss: 0.9963 | \n",
      "Epoch: 650 | train_loss: 0.9635 | test_loss: 0.9606 | \n",
      "Epoch: 660 | train_loss: 0.9256 | test_loss: 0.9266 | \n",
      "Epoch: 670 | train_loss: 0.8884 | test_loss: 0.8977 | \n",
      "Epoch: 680 | train_loss: 0.8512 | test_loss: 0.8452 | \n",
      "Epoch: 690 | train_loss: 0.8162 | test_loss: 0.8194 | \n",
      "Epoch: 700 | train_loss: 0.7790 | test_loss: 0.7815 | \n",
      "Epoch: 710 | train_loss: 0.7431 | test_loss: 0.7501 | \n",
      "Epoch: 720 | train_loss: 0.7080 | test_loss: 0.7081 | \n",
      "Epoch: 730 | train_loss: 0.6735 | test_loss: 0.6715 | \n",
      "Epoch: 740 | train_loss: 0.6379 | test_loss: 0.6414 | \n",
      "Epoch: 750 | train_loss: 0.6033 | test_loss: 0.6098 | \n",
      "Epoch: 760 | train_loss: 0.5682 | test_loss: 0.5677 | \n",
      "Epoch: 770 | train_loss: 0.5351 | test_loss: 0.5370 | \n",
      "Epoch: 780 | train_loss: 0.5013 | test_loss: 0.5131 | \n",
      "Epoch: 790 | train_loss: 0.4683 | test_loss: 0.4745 | \n",
      "Epoch: 800 | train_loss: 0.4353 | test_loss: 0.4396 | \n",
      "Epoch: 810 | train_loss: 0.4035 | test_loss: 0.4071 | \n",
      "Epoch: 820 | train_loss: 0.3725 | test_loss: 0.3915 | \n",
      "Epoch: 830 | train_loss: 0.3412 | test_loss: 0.3663 | \n",
      "Epoch: 840 | train_loss: 0.3126 | test_loss: 0.3289 | \n",
      "Epoch: 850 | train_loss: 0.2808 | test_loss: 0.3082 | \n",
      "Epoch: 860 | train_loss: 0.2497 | test_loss: 0.2774 | \n",
      "Epoch: 870 | train_loss: 0.2191 | test_loss: 0.2611 | \n",
      "Epoch: 880 | train_loss: 0.1921 | test_loss: 0.2358 | \n",
      "Epoch: 890 | train_loss: 0.1659 | test_loss: 0.1904 | \n",
      "Epoch: 900 | train_loss: 0.1396 | test_loss: 0.2086 | \n",
      "Epoch: 910 | train_loss: 0.1144 | test_loss: 0.1639 | \n",
      "Epoch: 920 | train_loss: 0.0891 | test_loss: 0.1545 | \n",
      "Epoch: 930 | train_loss: 0.0763 | test_loss: 0.1511 | \n",
      "Epoch: 940 | train_loss: 0.0651 | test_loss: 0.1453 | \n",
      "Epoch: 950 | train_loss: 0.0521 | test_loss: 0.1423 | \n",
      "Epoch: 960 | train_loss: 0.0396 | test_loss: 0.1390 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8901 | test_loss: 9.3415 | \n",
      "Epoch: 10 | train_loss: 7.7342 | test_loss: 7.6655 | \n",
      "Epoch: 20 | train_loss: 6.8479 | test_loss: 6.8211 | \n",
      "Epoch: 30 | train_loss: 6.2583 | test_loss: 6.2344 | \n",
      "Epoch: 40 | train_loss: 5.8404 | test_loss: 5.7978 | \n",
      "Epoch: 50 | train_loss: 5.5069 | test_loss: 5.4749 | \n",
      "Epoch: 60 | train_loss: 5.2364 | test_loss: 5.1984 | \n",
      "Epoch: 70 | train_loss: 5.0032 | test_loss: 4.9674 | \n",
      "Epoch: 80 | train_loss: 4.7991 | test_loss: 4.7685 | \n",
      "Epoch: 90 | train_loss: 4.6183 | test_loss: 4.6120 | \n",
      "Epoch: 100 | train_loss: 4.4546 | test_loss: 4.4439 | \n",
      "Epoch: 110 | train_loss: 4.3053 | test_loss: 4.2931 | \n",
      "Epoch: 120 | train_loss: 4.1670 | test_loss: 4.1444 | \n",
      "Epoch: 130 | train_loss: 4.0404 | test_loss: 4.0188 | \n",
      "Epoch: 140 | train_loss: 3.9207 | test_loss: 3.9101 | \n",
      "Epoch: 150 | train_loss: 3.8115 | test_loss: 3.7836 | \n",
      "Epoch: 160 | train_loss: 3.7023 | test_loss: 3.6780 | \n",
      "Epoch: 170 | train_loss: 3.6043 | test_loss: 3.5848 | \n",
      "Epoch: 180 | train_loss: 3.5075 | test_loss: 3.4915 | \n",
      "Epoch: 190 | train_loss: 3.4177 | test_loss: 3.4064 | \n",
      "Epoch: 200 | train_loss: 3.3308 | test_loss: 3.3237 | \n",
      "Epoch: 210 | train_loss: 3.2479 | test_loss: 3.2284 | \n",
      "Epoch: 220 | train_loss: 3.1674 | test_loss: 3.1642 | \n",
      "Epoch: 230 | train_loss: 3.0903 | test_loss: 3.0686 | \n",
      "Epoch: 240 | train_loss: 3.0153 | test_loss: 3.0011 | \n",
      "Epoch: 250 | train_loss: 2.9423 | test_loss: 2.9344 | \n",
      "Epoch: 260 | train_loss: 2.8739 | test_loss: 2.8666 | \n",
      "Epoch: 270 | train_loss: 2.8050 | test_loss: 2.7848 | \n",
      "Epoch: 280 | train_loss: 2.7401 | test_loss: 2.7180 | \n",
      "Epoch: 290 | train_loss: 2.6757 | test_loss: 2.6698 | \n",
      "Epoch: 300 | train_loss: 2.6131 | test_loss: 2.5966 | \n",
      "Epoch: 310 | train_loss: 2.5518 | test_loss: 2.5383 | \n",
      "Epoch: 320 | train_loss: 2.4914 | test_loss: 2.4787 | \n",
      "Epoch: 330 | train_loss: 2.4343 | test_loss: 2.4222 | \n",
      "Epoch: 340 | train_loss: 2.3755 | test_loss: 2.3633 | \n",
      "Epoch: 350 | train_loss: 2.3190 | test_loss: 2.3070 | \n",
      "Epoch: 360 | train_loss: 2.2653 | test_loss: 2.2563 | \n",
      "Epoch: 370 | train_loss: 2.2108 | test_loss: 2.2016 | \n",
      "Epoch: 380 | train_loss: 2.1579 | test_loss: 2.1500 | \n",
      "Epoch: 390 | train_loss: 2.1062 | test_loss: 2.0968 | \n",
      "Epoch: 400 | train_loss: 2.0560 | test_loss: 2.0466 | \n",
      "Epoch: 410 | train_loss: 2.0042 | test_loss: 2.0064 | \n",
      "Epoch: 420 | train_loss: 1.9549 | test_loss: 1.9604 | \n",
      "Epoch: 430 | train_loss: 1.9061 | test_loss: 1.9052 | \n",
      "Epoch: 440 | train_loss: 1.8578 | test_loss: 1.8484 | \n",
      "Epoch: 450 | train_loss: 1.8103 | test_loss: 1.7962 | \n",
      "Epoch: 460 | train_loss: 1.7634 | test_loss: 1.7516 | \n",
      "Epoch: 470 | train_loss: 1.7184 | test_loss: 1.7126 | \n",
      "Epoch: 480 | train_loss: 1.6719 | test_loss: 1.6614 | \n",
      "Epoch: 490 | train_loss: 1.6268 | test_loss: 1.6249 | \n",
      "Epoch: 500 | train_loss: 1.5880 | test_loss: 1.6207 | \n",
      "Epoch: 510 | train_loss: 1.5393 | test_loss: 1.5288 | \n",
      "Epoch: 520 | train_loss: 1.4946 | test_loss: 1.4841 | \n",
      "Epoch: 530 | train_loss: 1.4540 | test_loss: 1.4472 | \n",
      "Epoch: 540 | train_loss: 1.4112 | test_loss: 1.4044 | \n",
      "Epoch: 550 | train_loss: 1.3685 | test_loss: 1.3616 | \n",
      "Epoch: 560 | train_loss: 1.3264 | test_loss: 1.3212 | \n",
      "Epoch: 570 | train_loss: 1.2846 | test_loss: 1.2794 | \n",
      "Epoch: 580 | train_loss: 1.2450 | test_loss: 1.2417 | \n",
      "Epoch: 590 | train_loss: 1.2040 | test_loss: 1.1983 | \n",
      "Epoch: 600 | train_loss: 1.1640 | test_loss: 1.1556 | \n",
      "Epoch: 610 | train_loss: 1.1252 | test_loss: 1.1251 | \n",
      "Epoch: 620 | train_loss: 1.0870 | test_loss: 1.0811 | \n",
      "Epoch: 630 | train_loss: 1.0467 | test_loss: 1.0441 | \n",
      "Epoch: 640 | train_loss: 1.0084 | test_loss: 1.0021 | \n",
      "Epoch: 650 | train_loss: 0.9708 | test_loss: 0.9673 | \n",
      "Epoch: 660 | train_loss: 0.9324 | test_loss: 0.9363 | \n",
      "Epoch: 670 | train_loss: 0.8956 | test_loss: 0.8900 | \n",
      "Epoch: 680 | train_loss: 0.8585 | test_loss: 0.8642 | \n",
      "Epoch: 690 | train_loss: 0.8230 | test_loss: 0.8299 | \n",
      "Epoch: 700 | train_loss: 0.7854 | test_loss: 0.7951 | \n",
      "Epoch: 710 | train_loss: 0.7490 | test_loss: 0.7561 | \n",
      "Epoch: 720 | train_loss: 0.7146 | test_loss: 0.7212 | \n",
      "Epoch: 730 | train_loss: 0.6819 | test_loss: 0.6967 | \n",
      "Epoch: 740 | train_loss: 0.6441 | test_loss: 0.6593 | \n",
      "Epoch: 750 | train_loss: 0.6108 | test_loss: 0.6031 | \n",
      "Epoch: 760 | train_loss: 0.5762 | test_loss: 0.5828 | \n",
      "Epoch: 770 | train_loss: 0.5409 | test_loss: 0.5545 | \n",
      "Epoch: 780 | train_loss: 0.5080 | test_loss: 0.5103 | \n",
      "Epoch: 790 | train_loss: 0.4749 | test_loss: 0.4926 | \n",
      "Epoch: 800 | train_loss: 0.4426 | test_loss: 0.4556 | \n",
      "Epoch: 810 | train_loss: 0.4099 | test_loss: 0.4320 | \n",
      "Epoch: 820 | train_loss: 0.3794 | test_loss: 0.3941 | \n",
      "Epoch: 830 | train_loss: 0.3474 | test_loss: 0.3753 | \n",
      "Epoch: 840 | train_loss: 0.3169 | test_loss: 0.3459 | \n",
      "Epoch: 850 | train_loss: 0.2859 | test_loss: 0.3094 | \n",
      "Epoch: 860 | train_loss: 0.2565 | test_loss: 0.2998 | \n",
      "Epoch: 870 | train_loss: 0.2272 | test_loss: 0.2648 | \n",
      "Epoch: 880 | train_loss: 0.2001 | test_loss: 0.2519 | \n",
      "Epoch: 890 | train_loss: 0.1720 | test_loss: 0.2271 | \n",
      "Epoch: 900 | train_loss: 0.1472 | test_loss: 0.1970 | \n",
      "Epoch: 910 | train_loss: 0.1217 | test_loss: 0.1812 | \n",
      "Epoch: 920 | train_loss: 0.1094 | test_loss: 0.1610 | \n",
      "Epoch: 930 | train_loss: 0.0762 | test_loss: 0.1654 | \n",
      "Epoch: 940 | train_loss: 0.0659 | test_loss: 0.1637 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8427 | test_loss: 10.0114 | \n",
      "Epoch: 10 | train_loss: 7.7305 | test_loss: 7.6498 | \n",
      "Epoch: 20 | train_loss: 6.8396 | test_loss: 6.7964 | \n",
      "Epoch: 30 | train_loss: 6.2703 | test_loss: 6.2168 | \n",
      "Epoch: 40 | train_loss: 5.8411 | test_loss: 5.7918 | \n",
      "Epoch: 50 | train_loss: 5.5120 | test_loss: 5.4765 | \n",
      "Epoch: 60 | train_loss: 5.2492 | test_loss: 5.2012 | \n",
      "Epoch: 70 | train_loss: 5.0191 | test_loss: 4.9803 | \n",
      "Epoch: 80 | train_loss: 4.8116 | test_loss: 4.7711 | \n",
      "Epoch: 90 | train_loss: 4.6267 | test_loss: 4.6035 | \n",
      "Epoch: 100 | train_loss: 4.4658 | test_loss: 4.4336 | \n",
      "Epoch: 110 | train_loss: 4.3136 | test_loss: 4.2888 | \n",
      "Epoch: 120 | train_loss: 4.1775 | test_loss: 4.1519 | \n",
      "Epoch: 130 | train_loss: 4.0482 | test_loss: 4.0246 | \n",
      "Epoch: 140 | train_loss: 3.9297 | test_loss: 3.9066 | \n",
      "Epoch: 150 | train_loss: 3.8147 | test_loss: 3.7960 | \n",
      "Epoch: 160 | train_loss: 3.7118 | test_loss: 3.6944 | \n",
      "Epoch: 170 | train_loss: 3.6113 | test_loss: 3.5925 | \n",
      "Epoch: 180 | train_loss: 3.5193 | test_loss: 3.4993 | \n",
      "Epoch: 190 | train_loss: 3.4274 | test_loss: 3.4101 | \n",
      "Epoch: 200 | train_loss: 3.3361 | test_loss: 3.3215 | \n",
      "Epoch: 210 | train_loss: 3.2564 | test_loss: 3.2415 | \n",
      "Epoch: 220 | train_loss: 3.1757 | test_loss: 3.1589 | \n",
      "Epoch: 230 | train_loss: 3.0953 | test_loss: 3.0825 | \n",
      "Epoch: 240 | train_loss: 3.0263 | test_loss: 3.0055 | \n",
      "Epoch: 250 | train_loss: 2.9518 | test_loss: 2.9370 | \n",
      "Epoch: 260 | train_loss: 2.8792 | test_loss: 2.8627 | \n",
      "Epoch: 270 | train_loss: 2.8127 | test_loss: 2.7938 | \n",
      "Epoch: 280 | train_loss: 2.7492 | test_loss: 2.7298 | \n",
      "Epoch: 290 | train_loss: 2.6801 | test_loss: 2.6650 | \n",
      "Epoch: 300 | train_loss: 2.6170 | test_loss: 2.6020 | \n",
      "Epoch: 310 | train_loss: 2.5616 | test_loss: 2.5420 | \n",
      "Epoch: 320 | train_loss: 2.5009 | test_loss: 2.4804 | \n",
      "Epoch: 330 | train_loss: 2.4439 | test_loss: 2.4225 | \n",
      "Epoch: 340 | train_loss: 2.3892 | test_loss: 2.3669 | \n",
      "Epoch: 350 | train_loss: 2.3269 | test_loss: 2.3070 | \n",
      "Epoch: 360 | train_loss: 2.2691 | test_loss: 2.2500 | \n",
      "Epoch: 370 | train_loss: 2.2201 | test_loss: 2.1962 | \n",
      "Epoch: 380 | train_loss: 2.1697 | test_loss: 2.1488 | \n",
      "Epoch: 390 | train_loss: 2.1122 | test_loss: 2.0967 | \n",
      "Epoch: 400 | train_loss: 2.0595 | test_loss: 2.0453 | \n",
      "Epoch: 410 | train_loss: 2.0094 | test_loss: 1.9958 | \n",
      "Epoch: 420 | train_loss: 1.9600 | test_loss: 1.9461 | \n",
      "Epoch: 430 | train_loss: 1.9134 | test_loss: 1.8951 | \n",
      "Epoch: 440 | train_loss: 1.8683 | test_loss: 1.8505 | \n",
      "Epoch: 450 | train_loss: 1.8259 | test_loss: 1.8016 | \n",
      "Epoch: 460 | train_loss: 1.7764 | test_loss: 1.7583 | \n",
      "Epoch: 470 | train_loss: 1.7254 | test_loss: 1.7068 | \n",
      "Epoch: 480 | train_loss: 1.6826 | test_loss: 1.6615 | \n",
      "Epoch: 490 | train_loss: 1.6348 | test_loss: 1.6163 | \n",
      "Epoch: 500 | train_loss: 1.5920 | test_loss: 1.5735 | \n",
      "Epoch: 510 | train_loss: 1.5448 | test_loss: 1.5303 | \n",
      "Epoch: 520 | train_loss: 1.5064 | test_loss: 1.4895 | \n",
      "Epoch: 530 | train_loss: 1.4622 | test_loss: 1.4400 | \n",
      "Epoch: 540 | train_loss: 1.4191 | test_loss: 1.4047 | \n",
      "Epoch: 550 | train_loss: 1.3747 | test_loss: 1.3579 | \n",
      "Epoch: 560 | train_loss: 1.3365 | test_loss: 1.3209 | \n",
      "Epoch: 570 | train_loss: 1.2967 | test_loss: 1.2794 | \n",
      "Epoch: 580 | train_loss: 1.2576 | test_loss: 1.2457 | \n",
      "Epoch: 590 | train_loss: 1.2115 | test_loss: 1.1973 | \n",
      "Epoch: 600 | train_loss: 1.1788 | test_loss: 1.1560 | \n",
      "Epoch: 610 | train_loss: 1.1367 | test_loss: 1.1194 | \n",
      "Epoch: 620 | train_loss: 1.0911 | test_loss: 1.0810 | \n",
      "Epoch: 630 | train_loss: 1.0614 | test_loss: 1.0453 | \n",
      "Epoch: 640 | train_loss: 1.0194 | test_loss: 1.0032 | \n",
      "Epoch: 650 | train_loss: 0.9807 | test_loss: 0.9715 | \n",
      "Epoch: 660 | train_loss: 0.9492 | test_loss: 0.9370 | \n",
      "Epoch: 670 | train_loss: 0.9058 | test_loss: 0.8927 | \n",
      "Epoch: 680 | train_loss: 0.8737 | test_loss: 0.8631 | \n",
      "Epoch: 690 | train_loss: 0.8379 | test_loss: 0.8286 | \n",
      "Epoch: 700 | train_loss: 0.7981 | test_loss: 0.7956 | \n",
      "Epoch: 710 | train_loss: 0.7651 | test_loss: 0.7539 | \n",
      "Epoch: 720 | train_loss: 0.7279 | test_loss: 0.7185 | \n",
      "Epoch: 730 | train_loss: 0.6940 | test_loss: 0.6797 | \n",
      "Epoch: 740 | train_loss: 0.6621 | test_loss: 0.6544 | \n",
      "Epoch: 750 | train_loss: 0.6292 | test_loss: 0.6111 | \n",
      "Epoch: 760 | train_loss: 0.5982 | test_loss: 0.5864 | \n",
      "Epoch: 770 | train_loss: 0.5602 | test_loss: 0.5539 | \n",
      "Epoch: 780 | train_loss: 0.5273 | test_loss: 0.5181 | \n",
      "Epoch: 790 | train_loss: 0.4945 | test_loss: 0.4964 | \n",
      "Epoch: 800 | train_loss: 0.4682 | test_loss: 0.4504 | \n",
      "Epoch: 810 | train_loss: 0.4349 | test_loss: 0.4174 | \n",
      "Epoch: 820 | train_loss: 0.4086 | test_loss: 0.4094 | \n",
      "Epoch: 830 | train_loss: 0.3724 | test_loss: 0.3758 | \n",
      "Epoch: 840 | train_loss: 0.3445 | test_loss: 0.3458 | \n",
      "Epoch: 850 | train_loss: 0.3133 | test_loss: 0.3113 | \n",
      "Epoch: 860 | train_loss: 0.2893 | test_loss: 0.2915 | \n",
      "Epoch: 870 | train_loss: 0.2568 | test_loss: 0.2683 | \n",
      "Epoch: 880 | train_loss: 0.2371 | test_loss: 0.2455 | \n",
      "Epoch: 890 | train_loss: 0.2172 | test_loss: 0.2299 | \n",
      "Epoch: 900 | train_loss: 0.1993 | test_loss: 0.2007 | \n",
      "Epoch: 910 | train_loss: 0.1803 | test_loss: 0.1868 | \n",
      "Epoch: 920 | train_loss: 0.1571 | test_loss: 0.1696 | \n",
      "Epoch: 930 | train_loss: 0.1493 | test_loss: 0.1664 | \n",
      "Epoch: 940 | train_loss: 0.1377 | test_loss: 0.1567 | \n",
      "Epoch: 950 | train_loss: 0.1248 | test_loss: 0.1618 | \n",
      "Epoch: 960 | train_loss: 0.1204 | test_loss: 0.1458 | \n",
      "Epoch: 970 | train_loss: 0.1184 | test_loss: 0.1439 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8843 | test_loss: 9.6397 | \n",
      "Epoch: 10 | train_loss: 7.7433 | test_loss: 7.6671 | \n",
      "Epoch: 20 | train_loss: 6.8650 | test_loss: 6.8098 | \n",
      "Epoch: 30 | train_loss: 6.2867 | test_loss: 6.2271 | \n",
      "Epoch: 40 | train_loss: 5.8682 | test_loss: 5.8240 | \n",
      "Epoch: 50 | train_loss: 5.5376 | test_loss: 5.4927 | \n",
      "Epoch: 60 | train_loss: 5.2648 | test_loss: 5.2236 | \n",
      "Epoch: 70 | train_loss: 5.0285 | test_loss: 4.9976 | \n",
      "Epoch: 80 | train_loss: 4.8228 | test_loss: 4.7924 | \n",
      "Epoch: 90 | train_loss: 4.6413 | test_loss: 4.6134 | \n",
      "Epoch: 100 | train_loss: 4.4756 | test_loss: 4.4506 | \n",
      "Epoch: 110 | train_loss: 4.3318 | test_loss: 4.2958 | \n",
      "Epoch: 120 | train_loss: 4.1894 | test_loss: 4.1622 | \n",
      "Epoch: 130 | train_loss: 4.0595 | test_loss: 4.0357 | \n",
      "Epoch: 140 | train_loss: 3.9415 | test_loss: 3.9139 | \n",
      "Epoch: 150 | train_loss: 3.8282 | test_loss: 3.8046 | \n",
      "Epoch: 160 | train_loss: 3.7222 | test_loss: 3.7017 | \n",
      "Epoch: 170 | train_loss: 3.6189 | test_loss: 3.6050 | \n",
      "Epoch: 180 | train_loss: 3.5279 | test_loss: 3.5074 | \n",
      "Epoch: 190 | train_loss: 3.4371 | test_loss: 3.4165 | \n",
      "Epoch: 200 | train_loss: 3.3541 | test_loss: 3.3269 | \n",
      "Epoch: 210 | train_loss: 3.2698 | test_loss: 3.2462 | \n",
      "Epoch: 220 | train_loss: 3.1854 | test_loss: 3.1687 | \n",
      "Epoch: 230 | train_loss: 3.1124 | test_loss: 3.0910 | \n",
      "Epoch: 240 | train_loss: 3.0336 | test_loss: 3.0166 | \n",
      "Epoch: 250 | train_loss: 2.9646 | test_loss: 2.9362 | \n",
      "Epoch: 260 | train_loss: 2.8949 | test_loss: 2.8691 | \n",
      "Epoch: 270 | train_loss: 2.8239 | test_loss: 2.8013 | \n",
      "Epoch: 280 | train_loss: 2.7630 | test_loss: 2.7348 | \n",
      "Epoch: 290 | train_loss: 2.6981 | test_loss: 2.6728 | \n",
      "Epoch: 300 | train_loss: 2.6324 | test_loss: 2.6152 | \n",
      "Epoch: 310 | train_loss: 2.5718 | test_loss: 2.5480 | \n",
      "Epoch: 320 | train_loss: 2.5094 | test_loss: 2.4934 | \n",
      "Epoch: 330 | train_loss: 2.4510 | test_loss: 2.4342 | \n",
      "Epoch: 340 | train_loss: 2.3942 | test_loss: 2.3770 | \n",
      "Epoch: 350 | train_loss: 2.3390 | test_loss: 2.3226 | \n",
      "Epoch: 360 | train_loss: 2.2780 | test_loss: 2.2626 | \n",
      "Epoch: 370 | train_loss: 2.2300 | test_loss: 2.2099 | \n",
      "Epoch: 380 | train_loss: 2.1735 | test_loss: 2.1611 | \n",
      "Epoch: 390 | train_loss: 2.1312 | test_loss: 2.1049 | \n",
      "Epoch: 400 | train_loss: 2.0723 | test_loss: 2.0561 | \n",
      "Epoch: 410 | train_loss: 2.0260 | test_loss: 2.0042 | \n",
      "Epoch: 420 | train_loss: 1.9736 | test_loss: 1.9541 | \n",
      "Epoch: 430 | train_loss: 1.9268 | test_loss: 1.9083 | \n",
      "Epoch: 440 | train_loss: 1.8774 | test_loss: 1.8558 | \n",
      "Epoch: 450 | train_loss: 1.8340 | test_loss: 1.8149 | \n",
      "Epoch: 460 | train_loss: 1.7851 | test_loss: 1.7675 | \n",
      "Epoch: 470 | train_loss: 1.7355 | test_loss: 1.7205 | \n",
      "Epoch: 480 | train_loss: 1.6927 | test_loss: 1.6774 | \n",
      "Epoch: 490 | train_loss: 1.6496 | test_loss: 1.6334 | \n",
      "Epoch: 500 | train_loss: 1.6051 | test_loss: 1.5865 | \n",
      "Epoch: 510 | train_loss: 1.5605 | test_loss: 1.5468 | \n",
      "Epoch: 520 | train_loss: 1.5192 | test_loss: 1.5013 | \n",
      "Epoch: 530 | train_loss: 1.4756 | test_loss: 1.4572 | \n",
      "Epoch: 540 | train_loss: 1.4354 | test_loss: 1.4163 | \n",
      "Epoch: 550 | train_loss: 1.3894 | test_loss: 1.3757 | \n",
      "Epoch: 560 | train_loss: 1.3496 | test_loss: 1.3330 | \n",
      "Epoch: 570 | train_loss: 1.3067 | test_loss: 1.2915 | \n",
      "Epoch: 580 | train_loss: 1.2693 | test_loss: 1.2548 | \n",
      "Epoch: 590 | train_loss: 1.2262 | test_loss: 1.2131 | \n",
      "Epoch: 600 | train_loss: 1.1882 | test_loss: 1.1731 | \n",
      "Epoch: 610 | train_loss: 1.1531 | test_loss: 1.1324 | \n",
      "Epoch: 620 | train_loss: 1.1065 | test_loss: 1.0970 | \n",
      "Epoch: 630 | train_loss: 1.0710 | test_loss: 1.0551 | \n",
      "Epoch: 640 | train_loss: 1.0366 | test_loss: 1.0131 | \n",
      "Epoch: 650 | train_loss: 0.9926 | test_loss: 0.9815 | \n",
      "Epoch: 660 | train_loss: 0.9546 | test_loss: 0.9449 | \n",
      "Epoch: 670 | train_loss: 0.9202 | test_loss: 0.9095 | \n",
      "Epoch: 680 | train_loss: 0.8860 | test_loss: 0.8720 | \n",
      "Epoch: 690 | train_loss: 0.8481 | test_loss: 0.8368 | \n",
      "Epoch: 700 | train_loss: 0.8161 | test_loss: 0.8034 | \n",
      "Epoch: 710 | train_loss: 0.7801 | test_loss: 0.7705 | \n",
      "Epoch: 720 | train_loss: 0.7446 | test_loss: 0.7300 | \n",
      "Epoch: 730 | train_loss: 0.7092 | test_loss: 0.6991 | \n",
      "Epoch: 740 | train_loss: 0.6773 | test_loss: 0.6682 | \n",
      "Epoch: 750 | train_loss: 0.6379 | test_loss: 0.6375 | \n",
      "Epoch: 760 | train_loss: 0.6012 | test_loss: 0.6024 | \n",
      "Epoch: 770 | train_loss: 0.5735 | test_loss: 0.5617 | \n",
      "Epoch: 780 | train_loss: 0.5385 | test_loss: 0.5420 | \n",
      "Epoch: 790 | train_loss: 0.5168 | test_loss: 0.5028 | \n",
      "Epoch: 800 | train_loss: 0.4780 | test_loss: 0.4790 | \n",
      "Epoch: 810 | train_loss: 0.4466 | test_loss: 0.4436 | \n",
      "Epoch: 820 | train_loss: 0.4191 | test_loss: 0.4150 | \n",
      "Epoch: 830 | train_loss: 0.3885 | test_loss: 0.3927 | \n",
      "Epoch: 840 | train_loss: 0.3607 | test_loss: 0.3544 | \n",
      "Epoch: 850 | train_loss: 0.3258 | test_loss: 0.3255 | \n",
      "Epoch: 860 | train_loss: 0.3022 | test_loss: 0.3008 | \n",
      "Epoch: 870 | train_loss: 0.2736 | test_loss: 0.2904 | \n",
      "Epoch: 880 | train_loss: 0.2495 | test_loss: 0.2637 | \n",
      "Epoch: 890 | train_loss: 0.2311 | test_loss: 0.2397 | \n",
      "Epoch: 900 | train_loss: 0.2065 | test_loss: 0.2161 | \n",
      "Epoch: 910 | train_loss: 0.1900 | test_loss: 0.1968 | \n",
      "Epoch: 920 | train_loss: 0.1646 | test_loss: 0.1820 | \n",
      "Epoch: 930 | train_loss: 0.1511 | test_loss: 0.1685 | \n",
      "Epoch: 940 | train_loss: 0.1358 | test_loss: 0.1675 | \n",
      "Epoch: 950 | train_loss: 0.1300 | test_loss: 0.1605 | \n",
      "Epoch: 960 | train_loss: 0.1234 | test_loss: 0.1569 | \n",
      "Epoch: 970 | train_loss: 0.1154 | test_loss: 0.1489 | \n",
      "Epoch: 980 | train_loss: 0.1117 | test_loss: 0.1463 | \n",
      "Epoch: 990 | train_loss: 0.1121 | test_loss: 0.1436 | \n",
      "Epoch: 1000 | train_loss: 0.1019 | test_loss: 0.1419 | \n",
      "Epoch: 1010 | train_loss: 0.1049 | test_loss: 0.1445 | \n",
      "Epoch: 1020 | train_loss: 0.1041 | test_loss: 0.1407 | \n",
      "Epoch: 1030 | train_loss: 0.1043 | test_loss: 0.1447 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.9070 | test_loss: 2.3702 | \n",
      "Epoch: 10 | train_loss: 0.1461 | test_loss: 0.1511 | \n",
      "Epoch: 20 | train_loss: 0.1264 | test_loss: 0.1463 | \n",
      "Epoch: 30 | train_loss: 0.1148 | test_loss: 0.1462 | \n",
      "Epoch: 40 | train_loss: 0.1119 | test_loss: 0.1449 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.2471 | test_loss: 0.3851 | \n",
      "Epoch: 10 | train_loss: 0.1205 | test_loss: 0.1460 | \n",
      "Epoch: 20 | train_loss: 0.1062 | test_loss: 0.1491 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 2.0425 | test_loss: 0.5445 | \n",
      "Epoch: 10 | train_loss: 0.1411 | test_loss: 0.2013 | \n",
      "Epoch: 20 | train_loss: 0.1035 | test_loss: 0.1436 | \n",
      "Epoch: 30 | train_loss: 0.0957 | test_loss: 0.1875 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6526 | test_loss: 8.6851 | \n",
      "Epoch: 10 | train_loss: 5.9566 | test_loss: 5.8823 | \n",
      "Epoch: 20 | train_loss: 4.8891 | test_loss: 4.8717 | \n",
      "Epoch: 30 | train_loss: 4.2528 | test_loss: 4.2313 | \n",
      "Epoch: 40 | train_loss: 3.7796 | test_loss: 3.7774 | \n",
      "Epoch: 50 | train_loss: 3.4021 | test_loss: 3.3902 | \n",
      "Epoch: 60 | train_loss: 3.0849 | test_loss: 3.0646 | \n",
      "Epoch: 70 | train_loss: 2.8066 | test_loss: 2.7939 | \n",
      "Epoch: 80 | train_loss: 2.5587 | test_loss: 2.5304 | \n",
      "Epoch: 90 | train_loss: 2.3310 | test_loss: 2.3319 | \n",
      "Epoch: 100 | train_loss: 2.1186 | test_loss: 2.1216 | \n",
      "Epoch: 110 | train_loss: 1.9193 | test_loss: 1.9030 | \n",
      "Epoch: 120 | train_loss: 1.7299 | test_loss: 1.7269 | \n",
      "Epoch: 130 | train_loss: 1.5525 | test_loss: 1.5481 | \n",
      "Epoch: 140 | train_loss: 1.3876 | test_loss: 1.4023 | \n",
      "Epoch: 150 | train_loss: 1.2223 | test_loss: 1.2192 | \n",
      "Epoch: 160 | train_loss: 1.0641 | test_loss: 1.0602 | \n",
      "Epoch: 170 | train_loss: 0.9168 | test_loss: 0.9108 | \n",
      "Epoch: 180 | train_loss: 0.7758 | test_loss: 0.7666 | \n",
      "Epoch: 190 | train_loss: 0.6371 | test_loss: 0.6166 | \n",
      "Epoch: 200 | train_loss: 0.4994 | test_loss: 0.4994 | \n",
      "Epoch: 210 | train_loss: 0.3752 | test_loss: 0.3825 | \n",
      "Epoch: 220 | train_loss: 0.2561 | test_loss: 0.2825 | \n",
      "Epoch: 230 | train_loss: 0.1626 | test_loss: 0.2027 | \n",
      "Epoch: 240 | train_loss: 0.1068 | test_loss: 0.1756 | \n",
      "Epoch: 250 | train_loss: 0.0869 | test_loss: 0.1642 | \n",
      "Epoch: 260 | train_loss: 0.0873 | test_loss: 0.1536 | \n",
      "Epoch: 270 | train_loss: 0.0829 | test_loss: 0.1667 | \n",
      "Epoch: 280 | train_loss: 0.0748 | test_loss: 0.1491 | \n",
      "Epoch: 290 | train_loss: 0.0920 | test_loss: 0.1452 | \n",
      "Epoch: 300 | train_loss: 0.0767 | test_loss: 0.1524 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6179 | test_loss: 8.6776 | \n",
      "Epoch: 10 | train_loss: 5.8979 | test_loss: 5.8262 | \n",
      "Epoch: 20 | train_loss: 4.8393 | test_loss: 4.8097 | \n",
      "Epoch: 30 | train_loss: 4.2016 | test_loss: 4.1650 | \n",
      "Epoch: 40 | train_loss: 3.7294 | test_loss: 3.7054 | \n",
      "Epoch: 50 | train_loss: 3.3545 | test_loss: 3.2986 | \n",
      "Epoch: 60 | train_loss: 3.0345 | test_loss: 3.0243 | \n",
      "Epoch: 70 | train_loss: 2.7619 | test_loss: 2.7383 | \n",
      "Epoch: 80 | train_loss: 2.5083 | test_loss: 2.4868 | \n",
      "Epoch: 90 | train_loss: 2.2806 | test_loss: 2.2624 | \n",
      "Epoch: 100 | train_loss: 2.0709 | test_loss: 2.0606 | \n",
      "Epoch: 110 | train_loss: 1.8741 | test_loss: 1.8496 | \n",
      "Epoch: 120 | train_loss: 1.6862 | test_loss: 1.6623 | \n",
      "Epoch: 130 | train_loss: 1.5080 | test_loss: 1.4965 | \n",
      "Epoch: 140 | train_loss: 1.3395 | test_loss: 1.3319 | \n",
      "Epoch: 150 | train_loss: 1.1760 | test_loss: 1.1673 | \n",
      "Epoch: 160 | train_loss: 1.0203 | test_loss: 1.0149 | \n",
      "Epoch: 170 | train_loss: 0.8710 | test_loss: 0.8758 | \n",
      "Epoch: 180 | train_loss: 0.7264 | test_loss: 0.7179 | \n",
      "Epoch: 190 | train_loss: 0.5914 | test_loss: 0.5905 | \n",
      "Epoch: 200 | train_loss: 0.4574 | test_loss: 0.4685 | \n",
      "Epoch: 210 | train_loss: 0.3318 | test_loss: 0.3538 | \n",
      "Epoch: 220 | train_loss: 0.2221 | test_loss: 0.2460 | \n",
      "Epoch: 230 | train_loss: 0.1378 | test_loss: 0.1853 | \n",
      "Epoch: 240 | train_loss: 0.0994 | test_loss: 0.1581 | \n",
      "Epoch: 250 | train_loss: 0.0805 | test_loss: 0.1597 | \n",
      "Epoch: 260 | train_loss: 0.0795 | test_loss: 0.1484 | \n",
      "Epoch: 270 | train_loss: 0.0856 | test_loss: 0.1543 | \n",
      "Epoch: 280 | train_loss: 0.0784 | test_loss: 0.1471 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.7147 | test_loss: 8.6276 | \n",
      "Epoch: 10 | train_loss: 5.9727 | test_loss: 5.8652 | \n",
      "Epoch: 20 | train_loss: 4.9072 | test_loss: 4.8418 | \n",
      "Epoch: 30 | train_loss: 4.2639 | test_loss: 4.2084 | \n",
      "Epoch: 40 | train_loss: 3.7965 | test_loss: 3.7512 | \n",
      "Epoch: 50 | train_loss: 3.4195 | test_loss: 3.3845 | \n",
      "Epoch: 60 | train_loss: 3.1045 | test_loss: 3.0768 | \n",
      "Epoch: 70 | train_loss: 2.8243 | test_loss: 2.7947 | \n",
      "Epoch: 80 | train_loss: 2.5717 | test_loss: 2.5492 | \n",
      "Epoch: 90 | train_loss: 2.3483 | test_loss: 2.3246 | \n",
      "Epoch: 100 | train_loss: 2.1421 | test_loss: 2.1191 | \n",
      "Epoch: 110 | train_loss: 1.9379 | test_loss: 1.9145 | \n",
      "Epoch: 120 | train_loss: 1.7465 | test_loss: 1.7225 | \n",
      "Epoch: 130 | train_loss: 1.5788 | test_loss: 1.5512 | \n",
      "Epoch: 140 | train_loss: 1.4025 | test_loss: 1.3845 | \n",
      "Epoch: 150 | train_loss: 1.2425 | test_loss: 1.2250 | \n",
      "Epoch: 160 | train_loss: 1.0887 | test_loss: 1.0647 | \n",
      "Epoch: 170 | train_loss: 0.9369 | test_loss: 0.9215 | \n",
      "Epoch: 180 | train_loss: 0.7989 | test_loss: 0.7871 | \n",
      "Epoch: 190 | train_loss: 0.6624 | test_loss: 0.6463 | \n",
      "Epoch: 200 | train_loss: 0.5340 | test_loss: 0.5133 | \n",
      "Epoch: 210 | train_loss: 0.4183 | test_loss: 0.3945 | \n",
      "Epoch: 220 | train_loss: 0.3140 | test_loss: 0.2893 | \n",
      "Epoch: 230 | train_loss: 0.2255 | test_loss: 0.2233 | \n",
      "Epoch: 240 | train_loss: 0.1895 | test_loss: 0.1760 | \n",
      "Epoch: 250 | train_loss: 0.1652 | test_loss: 0.1502 | \n",
      "Epoch: 260 | train_loss: 0.1560 | test_loss: 0.1412 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6984 | test_loss: 8.5944 | \n",
      "Epoch: 10 | train_loss: 5.9616 | test_loss: 5.8574 | \n",
      "Epoch: 20 | train_loss: 4.8952 | test_loss: 4.8222 | \n",
      "Epoch: 30 | train_loss: 4.2503 | test_loss: 4.1964 | \n",
      "Epoch: 40 | train_loss: 3.7831 | test_loss: 3.7373 | \n",
      "Epoch: 50 | train_loss: 3.4048 | test_loss: 3.3612 | \n",
      "Epoch: 60 | train_loss: 3.0875 | test_loss: 3.0467 | \n",
      "Epoch: 70 | train_loss: 2.8089 | test_loss: 2.7793 | \n",
      "Epoch: 80 | train_loss: 2.5618 | test_loss: 2.5278 | \n",
      "Epoch: 90 | train_loss: 2.3339 | test_loss: 2.3033 | \n",
      "Epoch: 100 | train_loss: 2.1245 | test_loss: 2.0921 | \n",
      "Epoch: 110 | train_loss: 1.9173 | test_loss: 1.8881 | \n",
      "Epoch: 120 | train_loss: 1.7356 | test_loss: 1.7027 | \n",
      "Epoch: 130 | train_loss: 1.5680 | test_loss: 1.5293 | \n",
      "Epoch: 140 | train_loss: 1.3949 | test_loss: 1.3756 | \n",
      "Epoch: 150 | train_loss: 1.2307 | test_loss: 1.2044 | \n",
      "Epoch: 160 | train_loss: 1.0804 | test_loss: 1.0533 | \n",
      "Epoch: 170 | train_loss: 0.9253 | test_loss: 0.9042 | \n",
      "Epoch: 180 | train_loss: 0.7942 | test_loss: 0.7660 | \n",
      "Epoch: 190 | train_loss: 0.6529 | test_loss: 0.6305 | \n",
      "Epoch: 200 | train_loss: 0.5237 | test_loss: 0.5071 | \n",
      "Epoch: 210 | train_loss: 0.4125 | test_loss: 0.4016 | \n",
      "Epoch: 220 | train_loss: 0.3037 | test_loss: 0.2832 | \n",
      "Epoch: 230 | train_loss: 0.2215 | test_loss: 0.2186 | \n",
      "Epoch: 240 | train_loss: 0.1762 | test_loss: 0.1740 | \n",
      "Epoch: 250 | train_loss: 0.1594 | test_loss: 0.1476 | \n",
      "Epoch: 260 | train_loss: 0.1431 | test_loss: 0.1454 | \n",
      "Epoch: 270 | train_loss: 0.1394 | test_loss: 0.1427 | \n",
      "Epoch: 280 | train_loss: 0.1474 | test_loss: 0.1470 | \n",
      "Epoch: 290 | train_loss: 0.1428 | test_loss: 0.1396 | \n",
      "Epoch: 300 | train_loss: 0.1406 | test_loss: 0.1518 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.2243 | test_loss: 4.5781 | \n",
      "Epoch: 10 | train_loss: 0.1721 | test_loss: 0.1660 | \n",
      "Epoch: 20 | train_loss: 0.1416 | test_loss: 0.1516 | \n",
      "Epoch: 30 | train_loss: 0.1292 | test_loss: 0.1505 | \n",
      "Epoch: 40 | train_loss: 0.1242 | test_loss: 0.1501 | \n",
      "Epoch: 50 | train_loss: 0.1170 | test_loss: 0.1481 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.6484 | test_loss: 1.7814 | \n",
      "Epoch: 10 | train_loss: 0.1404 | test_loss: 0.1510 | \n",
      "Epoch: 20 | train_loss: 0.1211 | test_loss: 0.1453 | \n",
      "Epoch: 30 | train_loss: 0.1130 | test_loss: 0.1452 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.1453 | test_loss: 1.6520 | \n",
      "Epoch: 10 | train_loss: 0.1271 | test_loss: 0.1592 | \n",
      "Epoch: 20 | train_loss: 0.0951 | test_loss: 0.1468 | \n",
      "Epoch: 30 | train_loss: 0.0881 | test_loss: 0.1552 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2693 | test_loss: 9.1646 | \n",
      "Epoch: 10 | train_loss: 6.8682 | test_loss: 6.8151 | \n",
      "Epoch: 20 | train_loss: 5.8497 | test_loss: 5.8176 | \n",
      "Epoch: 30 | train_loss: 5.2432 | test_loss: 5.2132 | \n",
      "Epoch: 40 | train_loss: 4.8100 | test_loss: 4.7787 | \n",
      "Epoch: 50 | train_loss: 4.4604 | test_loss: 4.4384 | \n",
      "Epoch: 60 | train_loss: 4.1742 | test_loss: 4.1394 | \n",
      "Epoch: 70 | train_loss: 3.9276 | test_loss: 3.9238 | \n",
      "Epoch: 80 | train_loss: 3.7102 | test_loss: 3.7074 | \n",
      "Epoch: 90 | train_loss: 3.5141 | test_loss: 3.5043 | \n",
      "Epoch: 100 | train_loss: 3.3374 | test_loss: 3.3314 | \n",
      "Epoch: 110 | train_loss: 3.1726 | test_loss: 3.1581 | \n",
      "Epoch: 120 | train_loss: 3.0207 | test_loss: 3.0090 | \n",
      "Epoch: 130 | train_loss: 2.8795 | test_loss: 2.8683 | \n",
      "Epoch: 140 | train_loss: 2.7444 | test_loss: 2.7481 | \n",
      "Epoch: 150 | train_loss: 2.6166 | test_loss: 2.6035 | \n",
      "Epoch: 160 | train_loss: 2.4959 | test_loss: 2.4918 | \n",
      "Epoch: 170 | train_loss: 2.3804 | test_loss: 2.3735 | \n",
      "Epoch: 180 | train_loss: 2.2678 | test_loss: 2.2579 | \n",
      "Epoch: 190 | train_loss: 2.1605 | test_loss: 2.1493 | \n",
      "Epoch: 200 | train_loss: 2.0581 | test_loss: 2.0410 | \n",
      "Epoch: 210 | train_loss: 1.9572 | test_loss: 1.9428 | \n",
      "Epoch: 220 | train_loss: 1.8597 | test_loss: 1.8427 | \n",
      "Epoch: 230 | train_loss: 1.7657 | test_loss: 1.7422 | \n",
      "Epoch: 240 | train_loss: 1.6733 | test_loss: 1.6654 | \n",
      "Epoch: 250 | train_loss: 1.5851 | test_loss: 1.5725 | \n",
      "Epoch: 260 | train_loss: 1.4961 | test_loss: 1.4811 | \n",
      "Epoch: 270 | train_loss: 1.4105 | test_loss: 1.3885 | \n",
      "Epoch: 280 | train_loss: 1.3276 | test_loss: 1.3052 | \n",
      "Epoch: 290 | train_loss: 1.2464 | test_loss: 1.2607 | \n",
      "Epoch: 300 | train_loss: 1.1650 | test_loss: 1.1572 | \n",
      "Epoch: 310 | train_loss: 1.0871 | test_loss: 1.0760 | \n",
      "Epoch: 320 | train_loss: 1.0103 | test_loss: 1.0216 | \n",
      "Epoch: 330 | train_loss: 0.9338 | test_loss: 0.9386 | \n",
      "Epoch: 340 | train_loss: 0.8586 | test_loss: 0.8531 | \n",
      "Epoch: 350 | train_loss: 0.7860 | test_loss: 0.7722 | \n",
      "Epoch: 360 | train_loss: 0.7149 | test_loss: 0.7304 | \n",
      "Epoch: 370 | train_loss: 0.6452 | test_loss: 0.6628 | \n",
      "Epoch: 380 | train_loss: 0.5795 | test_loss: 0.5853 | \n",
      "Epoch: 390 | train_loss: 0.5096 | test_loss: 0.5215 | \n",
      "Epoch: 400 | train_loss: 0.4440 | test_loss: 0.4535 | \n",
      "Epoch: 410 | train_loss: 0.3806 | test_loss: 0.4085 | \n",
      "Epoch: 420 | train_loss: 0.3201 | test_loss: 0.3381 | \n",
      "Epoch: 430 | train_loss: 0.2617 | test_loss: 0.2721 | \n",
      "Epoch: 440 | train_loss: 0.2049 | test_loss: 0.2226 | \n",
      "Epoch: 450 | train_loss: 0.1498 | test_loss: 0.2129 | \n",
      "Epoch: 460 | train_loss: 0.1163 | test_loss: 0.1638 | \n",
      "Epoch: 470 | train_loss: 0.0782 | test_loss: 0.1655 | \n",
      "Epoch: 480 | train_loss: 0.0666 | test_loss: 0.1510 | \n",
      "Epoch: 490 | train_loss: 0.0569 | test_loss: 0.1571 | \n",
      "Epoch: 500 | train_loss: 0.0480 | test_loss: 0.1437 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2771 | test_loss: 9.1354 | \n",
      "Epoch: 10 | train_loss: 6.9013 | test_loss: 6.8504 | \n",
      "Epoch: 20 | train_loss: 5.8851 | test_loss: 5.7811 | \n",
      "Epoch: 30 | train_loss: 5.2743 | test_loss: 5.2225 | \n",
      "Epoch: 40 | train_loss: 4.8329 | test_loss: 4.7840 | \n",
      "Epoch: 50 | train_loss: 4.4874 | test_loss: 4.4338 | \n",
      "Epoch: 60 | train_loss: 4.1998 | test_loss: 4.1693 | \n",
      "Epoch: 70 | train_loss: 3.9522 | test_loss: 3.9192 | \n",
      "Epoch: 80 | train_loss: 3.7355 | test_loss: 3.6956 | \n",
      "Epoch: 90 | train_loss: 3.5378 | test_loss: 3.4717 | \n",
      "Epoch: 100 | train_loss: 3.3602 | test_loss: 3.3705 | \n",
      "Epoch: 110 | train_loss: 3.1970 | test_loss: 3.1747 | \n",
      "Epoch: 120 | train_loss: 3.0427 | test_loss: 3.0420 | \n",
      "Epoch: 130 | train_loss: 2.8990 | test_loss: 2.8991 | \n",
      "Epoch: 140 | train_loss: 2.7662 | test_loss: 2.7720 | \n",
      "Epoch: 150 | train_loss: 2.6391 | test_loss: 2.5888 | \n",
      "Epoch: 160 | train_loss: 2.5181 | test_loss: 2.4950 | \n",
      "Epoch: 170 | train_loss: 2.4027 | test_loss: 2.3500 | \n",
      "Epoch: 180 | train_loss: 2.2902 | test_loss: 2.3130 | \n",
      "Epoch: 190 | train_loss: 2.1828 | test_loss: 2.1561 | \n",
      "Epoch: 200 | train_loss: 2.0805 | test_loss: 2.0654 | \n",
      "Epoch: 210 | train_loss: 1.9798 | test_loss: 2.0035 | \n",
      "Epoch: 220 | train_loss: 1.8831 | test_loss: 1.9018 | \n",
      "Epoch: 230 | train_loss: 1.7886 | test_loss: 1.7555 | \n",
      "Epoch: 240 | train_loss: 1.6963 | test_loss: 1.6535 | \n",
      "Epoch: 250 | train_loss: 1.6074 | test_loss: 1.5440 | \n",
      "Epoch: 260 | train_loss: 1.5199 | test_loss: 1.5033 | \n",
      "Epoch: 270 | train_loss: 1.4351 | test_loss: 1.4814 | \n",
      "Epoch: 280 | train_loss: 1.3499 | test_loss: 1.3468 | \n",
      "Epoch: 290 | train_loss: 1.2695 | test_loss: 1.2643 | \n",
      "Epoch: 300 | train_loss: 1.1889 | test_loss: 1.1825 | \n",
      "Epoch: 310 | train_loss: 1.1108 | test_loss: 1.1384 | \n",
      "Epoch: 320 | train_loss: 1.0355 | test_loss: 1.0263 | \n",
      "Epoch: 330 | train_loss: 0.9585 | test_loss: 0.9764 | \n",
      "Epoch: 340 | train_loss: 0.8842 | test_loss: 0.9181 | \n",
      "Epoch: 350 | train_loss: 0.8121 | test_loss: 0.8578 | \n",
      "Epoch: 360 | train_loss: 0.7392 | test_loss: 0.7663 | \n",
      "Epoch: 370 | train_loss: 0.6693 | test_loss: 0.6476 | \n",
      "Epoch: 380 | train_loss: 0.5999 | test_loss: 0.5606 | \n",
      "Epoch: 390 | train_loss: 0.5313 | test_loss: 0.5658 | \n",
      "Epoch: 400 | train_loss: 0.4648 | test_loss: 0.4490 | \n",
      "Epoch: 410 | train_loss: 0.4010 | test_loss: 0.4210 | \n",
      "Epoch: 420 | train_loss: 0.3378 | test_loss: 0.3309 | \n",
      "Epoch: 430 | train_loss: 0.2787 | test_loss: 0.2839 | \n",
      "Epoch: 440 | train_loss: 0.2202 | test_loss: 0.2333 | \n",
      "Epoch: 450 | train_loss: 0.1702 | test_loss: 0.2155 | \n",
      "Epoch: 460 | train_loss: 0.1343 | test_loss: 0.1953 | \n",
      "Epoch: 470 | train_loss: 0.0947 | test_loss: 0.1634 | \n",
      "Epoch: 480 | train_loss: 0.0736 | test_loss: 0.1525 | \n",
      "Epoch: 490 | train_loss: 0.0587 | test_loss: 0.1538 | \n",
      "Epoch: 500 | train_loss: 0.0625 | test_loss: 0.1497 | \n",
      "Epoch: 510 | train_loss: 0.0883 | test_loss: 0.1521 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3178 | test_loss: 9.0531 | \n",
      "Epoch: 10 | train_loss: 6.9059 | test_loss: 6.8245 | \n",
      "Epoch: 20 | train_loss: 5.8950 | test_loss: 5.8305 | \n",
      "Epoch: 30 | train_loss: 5.2827 | test_loss: 5.2441 | \n",
      "Epoch: 40 | train_loss: 4.8520 | test_loss: 4.8066 | \n",
      "Epoch: 50 | train_loss: 4.5022 | test_loss: 4.4668 | \n",
      "Epoch: 60 | train_loss: 4.2111 | test_loss: 4.1829 | \n",
      "Epoch: 70 | train_loss: 3.9652 | test_loss: 3.9395 | \n",
      "Epoch: 80 | train_loss: 3.7490 | test_loss: 3.7138 | \n",
      "Epoch: 90 | train_loss: 3.5467 | test_loss: 3.5315 | \n",
      "Epoch: 100 | train_loss: 3.3719 | test_loss: 3.3503 | \n",
      "Epoch: 110 | train_loss: 3.2105 | test_loss: 3.1892 | \n",
      "Epoch: 120 | train_loss: 3.0550 | test_loss: 3.0349 | \n",
      "Epoch: 130 | train_loss: 2.9123 | test_loss: 2.8957 | \n",
      "Epoch: 140 | train_loss: 2.7772 | test_loss: 2.7670 | \n",
      "Epoch: 150 | train_loss: 2.6555 | test_loss: 2.6304 | \n",
      "Epoch: 160 | train_loss: 2.5330 | test_loss: 2.5193 | \n",
      "Epoch: 170 | train_loss: 2.4148 | test_loss: 2.3938 | \n",
      "Epoch: 180 | train_loss: 2.3015 | test_loss: 2.2879 | \n",
      "Epoch: 190 | train_loss: 2.1984 | test_loss: 2.1826 | \n",
      "Epoch: 200 | train_loss: 2.0899 | test_loss: 2.0738 | \n",
      "Epoch: 210 | train_loss: 1.9926 | test_loss: 1.9754 | \n",
      "Epoch: 220 | train_loss: 1.8921 | test_loss: 1.8727 | \n",
      "Epoch: 230 | train_loss: 1.8036 | test_loss: 1.7797 | \n",
      "Epoch: 240 | train_loss: 1.7093 | test_loss: 1.6882 | \n",
      "Epoch: 250 | train_loss: 1.6318 | test_loss: 1.6307 | \n",
      "Epoch: 260 | train_loss: 1.5359 | test_loss: 1.5118 | \n",
      "Epoch: 270 | train_loss: 1.4508 | test_loss: 1.4260 | \n",
      "Epoch: 280 | train_loss: 1.3705 | test_loss: 1.3514 | \n",
      "Epoch: 290 | train_loss: 1.2883 | test_loss: 1.2646 | \n",
      "Epoch: 300 | train_loss: 1.2057 | test_loss: 1.1821 | \n",
      "Epoch: 310 | train_loss: 1.1245 | test_loss: 1.1037 | \n",
      "Epoch: 320 | train_loss: 1.0453 | test_loss: 1.0299 | \n",
      "Epoch: 330 | train_loss: 0.9755 | test_loss: 0.9565 | \n",
      "Epoch: 340 | train_loss: 0.9048 | test_loss: 0.8882 | \n",
      "Epoch: 350 | train_loss: 0.8272 | test_loss: 0.8134 | \n",
      "Epoch: 360 | train_loss: 0.7623 | test_loss: 0.7481 | \n",
      "Epoch: 370 | train_loss: 0.6882 | test_loss: 0.6711 | \n",
      "Epoch: 380 | train_loss: 0.6211 | test_loss: 0.6084 | \n",
      "Epoch: 390 | train_loss: 0.5563 | test_loss: 0.5486 | \n",
      "Epoch: 400 | train_loss: 0.4949 | test_loss: 0.4907 | \n",
      "Epoch: 410 | train_loss: 0.4342 | test_loss: 0.4231 | \n",
      "Epoch: 420 | train_loss: 0.3761 | test_loss: 0.3770 | \n",
      "Epoch: 430 | train_loss: 0.3231 | test_loss: 0.3091 | \n",
      "Epoch: 440 | train_loss: 0.2720 | test_loss: 0.2672 | \n",
      "Epoch: 450 | train_loss: 0.2278 | test_loss: 0.2342 | \n",
      "Epoch: 460 | train_loss: 0.1874 | test_loss: 0.1884 | \n",
      "Epoch: 470 | train_loss: 0.1592 | test_loss: 0.1639 | \n",
      "Epoch: 480 | train_loss: 0.1507 | test_loss: 0.1552 | \n",
      "Epoch: 490 | train_loss: 0.1322 | test_loss: 0.1471 | \n",
      "Epoch: 500 | train_loss: 0.1401 | test_loss: 0.1424 | \n",
      "Epoch: 510 | train_loss: 0.1314 | test_loss: 0.1401 | \n",
      "Epoch: 520 | train_loss: 0.1240 | test_loss: 0.1456 | \n",
      "Epoch: 530 | train_loss: 0.1177 | test_loss: 0.1428 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3225 | test_loss: 9.0725 | \n",
      "Epoch: 10 | train_loss: 6.9228 | test_loss: 6.8233 | \n",
      "Epoch: 20 | train_loss: 5.9073 | test_loss: 5.8362 | \n",
      "Epoch: 30 | train_loss: 5.2965 | test_loss: 5.2439 | \n",
      "Epoch: 40 | train_loss: 4.8582 | test_loss: 4.8120 | \n",
      "Epoch: 50 | train_loss: 4.5076 | test_loss: 4.4676 | \n",
      "Epoch: 60 | train_loss: 4.2195 | test_loss: 4.1870 | \n",
      "Epoch: 70 | train_loss: 3.9726 | test_loss: 3.9394 | \n",
      "Epoch: 80 | train_loss: 3.7546 | test_loss: 3.7252 | \n",
      "Epoch: 90 | train_loss: 3.5561 | test_loss: 3.5335 | \n",
      "Epoch: 100 | train_loss: 3.3798 | test_loss: 3.3545 | \n",
      "Epoch: 110 | train_loss: 3.2121 | test_loss: 3.1905 | \n",
      "Epoch: 120 | train_loss: 3.0651 | test_loss: 3.0366 | \n",
      "Epoch: 130 | train_loss: 2.9211 | test_loss: 2.8982 | \n",
      "Epoch: 140 | train_loss: 2.7822 | test_loss: 2.7595 | \n",
      "Epoch: 150 | train_loss: 2.6636 | test_loss: 2.6358 | \n",
      "Epoch: 160 | train_loss: 2.5387 | test_loss: 2.5135 | \n",
      "Epoch: 170 | train_loss: 2.4191 | test_loss: 2.4006 | \n",
      "Epoch: 180 | train_loss: 2.3156 | test_loss: 2.2877 | \n",
      "Epoch: 190 | train_loss: 2.2035 | test_loss: 2.1778 | \n",
      "Epoch: 200 | train_loss: 2.0964 | test_loss: 2.0771 | \n",
      "Epoch: 210 | train_loss: 2.0023 | test_loss: 1.9770 | \n",
      "Epoch: 220 | train_loss: 1.9022 | test_loss: 1.8788 | \n",
      "Epoch: 230 | train_loss: 1.8103 | test_loss: 1.7871 | \n",
      "Epoch: 240 | train_loss: 1.7155 | test_loss: 1.6971 | \n",
      "Epoch: 250 | train_loss: 1.6212 | test_loss: 1.6096 | \n",
      "Epoch: 260 | train_loss: 1.5386 | test_loss: 1.5187 | \n",
      "Epoch: 270 | train_loss: 1.4523 | test_loss: 1.4313 | \n",
      "Epoch: 280 | train_loss: 1.3704 | test_loss: 1.3495 | \n",
      "Epoch: 290 | train_loss: 1.2835 | test_loss: 1.2712 | \n",
      "Epoch: 300 | train_loss: 1.2105 | test_loss: 1.1918 | \n",
      "Epoch: 310 | train_loss: 1.1321 | test_loss: 1.1128 | \n",
      "Epoch: 320 | train_loss: 1.0520 | test_loss: 1.0373 | \n",
      "Epoch: 330 | train_loss: 0.9809 | test_loss: 0.9629 | \n",
      "Epoch: 340 | train_loss: 0.9051 | test_loss: 0.8912 | \n",
      "Epoch: 350 | train_loss: 0.8359 | test_loss: 0.8179 | \n",
      "Epoch: 360 | train_loss: 0.7650 | test_loss: 0.7507 | \n",
      "Epoch: 370 | train_loss: 0.6960 | test_loss: 0.6834 | \n",
      "Epoch: 380 | train_loss: 0.6270 | test_loss: 0.6119 | \n",
      "Epoch: 390 | train_loss: 0.5616 | test_loss: 0.5499 | \n",
      "Epoch: 400 | train_loss: 0.5060 | test_loss: 0.4780 | \n",
      "Epoch: 410 | train_loss: 0.4434 | test_loss: 0.4334 | \n",
      "Epoch: 420 | train_loss: 0.3842 | test_loss: 0.3717 | \n",
      "Epoch: 430 | train_loss: 0.3306 | test_loss: 0.3234 | \n",
      "Epoch: 440 | train_loss: 0.2774 | test_loss: 0.2718 | \n",
      "Epoch: 450 | train_loss: 0.2300 | test_loss: 0.2320 | \n",
      "Epoch: 460 | train_loss: 0.1858 | test_loss: 0.2001 | \n",
      "Epoch: 470 | train_loss: 0.1631 | test_loss: 0.1665 | \n",
      "Epoch: 480 | train_loss: 0.1504 | test_loss: 0.1534 | \n",
      "Epoch: 490 | train_loss: 0.1270 | test_loss: 0.1426 | \n",
      "Epoch: 500 | train_loss: 0.1282 | test_loss: 0.1408 | \n",
      "Epoch: 510 | train_loss: 0.1194 | test_loss: 0.1397 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.5700 | test_loss: 7.6847 | \n",
      "Epoch: 10 | train_loss: 0.3627 | test_loss: 0.2761 | \n",
      "Epoch: 20 | train_loss: 0.1709 | test_loss: 0.1677 | \n",
      "Epoch: 30 | train_loss: 0.1533 | test_loss: 0.1586 | \n",
      "Epoch: 40 | train_loss: 0.1419 | test_loss: 0.1543 | \n",
      "Epoch: 50 | train_loss: 0.1353 | test_loss: 0.1527 | \n",
      "Epoch: 60 | train_loss: 0.1308 | test_loss: 0.1528 | \n",
      "Epoch: 70 | train_loss: 0.1282 | test_loss: 0.1525 | \n",
      "Epoch: 80 | train_loss: 0.1258 | test_loss: 0.1521 | \n",
      "Epoch: 90 | train_loss: 0.1233 | test_loss: 0.1511 | \n",
      "Epoch: 100 | train_loss: 0.1218 | test_loss: 0.1514 | \n",
      "Epoch: 110 | train_loss: 0.1184 | test_loss: 0.1505 | \n",
      "Epoch: 120 | train_loss: 0.1178 | test_loss: 0.1494 | \n",
      "Epoch: 130 | train_loss: 0.1152 | test_loss: 0.1494 | \n",
      "Epoch: 140 | train_loss: 0.1146 | test_loss: 0.1493 | \n",
      "Epoch: 150 | train_loss: 0.1105 | test_loss: 0.1486 | \n",
      "Epoch: 160 | train_loss: 0.1091 | test_loss: 0.1480 | \n",
      "Epoch: 170 | train_loss: 0.1084 | test_loss: 0.1471 | \n",
      "Epoch: 180 | train_loss: 0.1061 | test_loss: 0.1474 | \n",
      "Epoch: 190 | train_loss: 0.1070 | test_loss: 0.1471 | \n",
      "Epoch: 200 | train_loss: 0.1034 | test_loss: 0.1465 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.2913 | test_loss: 4.4110 | \n",
      "Epoch: 10 | train_loss: 0.1814 | test_loss: 0.1754 | \n",
      "Epoch: 20 | train_loss: 0.1389 | test_loss: 0.1512 | \n",
      "Epoch: 30 | train_loss: 0.1269 | test_loss: 0.1486 | \n",
      "Epoch: 40 | train_loss: 0.1182 | test_loss: 0.1474 | \n",
      "Epoch: 50 | train_loss: 0.1152 | test_loss: 0.1473 | \n",
      "Epoch: 60 | train_loss: 0.1093 | test_loss: 0.1450 | \n",
      "Epoch: 70 | train_loss: 0.1045 | test_loss: 0.1444 | \n",
      "Epoch: 80 | train_loss: 0.1025 | test_loss: 0.1475 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 4.9918 | test_loss: 0.4531 | \n",
      "Epoch: 10 | train_loss: 0.1466 | test_loss: 0.1519 | \n",
      "Epoch: 20 | train_loss: 0.1083 | test_loss: 0.1506 | \n",
      "Epoch: 30 | train_loss: 0.0969 | test_loss: 0.1524 | \n",
      "Epoch: 40 | train_loss: 0.0742 | test_loss: 0.1589 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8166 | test_loss: 9.4726 | \n",
      "Epoch: 10 | train_loss: 7.7241 | test_loss: 7.6843 | \n",
      "Epoch: 20 | train_loss: 6.8213 | test_loss: 6.7852 | \n",
      "Epoch: 30 | train_loss: 6.2301 | test_loss: 6.1857 | \n",
      "Epoch: 40 | train_loss: 5.8115 | test_loss: 5.7844 | \n",
      "Epoch: 50 | train_loss: 5.4864 | test_loss: 5.4661 | \n",
      "Epoch: 60 | train_loss: 5.2169 | test_loss: 5.1965 | \n",
      "Epoch: 70 | train_loss: 4.9853 | test_loss: 4.9534 | \n",
      "Epoch: 80 | train_loss: 4.7817 | test_loss: 4.7508 | \n",
      "Epoch: 90 | train_loss: 4.6050 | test_loss: 4.5717 | \n",
      "Epoch: 100 | train_loss: 4.4384 | test_loss: 4.4250 | \n",
      "Epoch: 110 | train_loss: 4.2921 | test_loss: 4.2737 | \n",
      "Epoch: 120 | train_loss: 4.1545 | test_loss: 4.1455 | \n",
      "Epoch: 130 | train_loss: 4.0265 | test_loss: 4.0117 | \n",
      "Epoch: 140 | train_loss: 3.9098 | test_loss: 3.8935 | \n",
      "Epoch: 150 | train_loss: 3.7968 | test_loss: 3.7805 | \n",
      "Epoch: 160 | train_loss: 3.6923 | test_loss: 3.6790 | \n",
      "Epoch: 170 | train_loss: 3.5923 | test_loss: 3.5813 | \n",
      "Epoch: 180 | train_loss: 3.4985 | test_loss: 3.4883 | \n",
      "Epoch: 190 | train_loss: 3.4068 | test_loss: 3.4036 | \n",
      "Epoch: 200 | train_loss: 3.3206 | test_loss: 3.3079 | \n",
      "Epoch: 210 | train_loss: 3.2377 | test_loss: 3.2234 | \n",
      "Epoch: 220 | train_loss: 3.1583 | test_loss: 3.1455 | \n",
      "Epoch: 230 | train_loss: 3.0799 | test_loss: 3.0593 | \n",
      "Epoch: 240 | train_loss: 3.0068 | test_loss: 2.9952 | \n",
      "Epoch: 250 | train_loss: 2.9343 | test_loss: 2.9252 | \n",
      "Epoch: 260 | train_loss: 2.8649 | test_loss: 2.8421 | \n",
      "Epoch: 270 | train_loss: 2.7959 | test_loss: 2.7859 | \n",
      "Epoch: 280 | train_loss: 2.7307 | test_loss: 2.7205 | \n",
      "Epoch: 290 | train_loss: 2.6664 | test_loss: 2.6536 | \n",
      "Epoch: 300 | train_loss: 2.6038 | test_loss: 2.5831 | \n",
      "Epoch: 310 | train_loss: 2.5420 | test_loss: 2.5297 | \n",
      "Epoch: 320 | train_loss: 2.4824 | test_loss: 2.4701 | \n",
      "Epoch: 330 | train_loss: 2.4242 | test_loss: 2.4074 | \n",
      "Epoch: 340 | train_loss: 2.3679 | test_loss: 2.3485 | \n",
      "Epoch: 350 | train_loss: 2.3131 | test_loss: 2.3068 | \n",
      "Epoch: 360 | train_loss: 2.2566 | test_loss: 2.2429 | \n",
      "Epoch: 370 | train_loss: 2.2021 | test_loss: 2.1838 | \n",
      "Epoch: 380 | train_loss: 2.1488 | test_loss: 2.1338 | \n",
      "Epoch: 390 | train_loss: 2.0962 | test_loss: 2.0823 | \n",
      "Epoch: 400 | train_loss: 2.0462 | test_loss: 2.0307 | \n",
      "Epoch: 410 | train_loss: 1.9955 | test_loss: 1.9776 | \n",
      "Epoch: 420 | train_loss: 1.9459 | test_loss: 1.9387 | \n",
      "Epoch: 430 | train_loss: 1.8964 | test_loss: 1.8828 | \n",
      "Epoch: 440 | train_loss: 1.8499 | test_loss: 1.8367 | \n",
      "Epoch: 450 | train_loss: 1.8025 | test_loss: 1.7930 | \n",
      "Epoch: 460 | train_loss: 1.7552 | test_loss: 1.7524 | \n",
      "Epoch: 470 | train_loss: 1.7095 | test_loss: 1.6920 | \n",
      "Epoch: 480 | train_loss: 1.6638 | test_loss: 1.6559 | \n",
      "Epoch: 490 | train_loss: 1.6183 | test_loss: 1.6032 | \n",
      "Epoch: 500 | train_loss: 1.5742 | test_loss: 1.5665 | \n",
      "Epoch: 510 | train_loss: 1.5310 | test_loss: 1.5156 | \n",
      "Epoch: 520 | train_loss: 1.4865 | test_loss: 1.4761 | \n",
      "Epoch: 530 | train_loss: 1.4439 | test_loss: 1.4319 | \n",
      "Epoch: 540 | train_loss: 1.4018 | test_loss: 1.3902 | \n",
      "Epoch: 550 | train_loss: 1.3606 | test_loss: 1.3474 | \n",
      "Epoch: 560 | train_loss: 1.3184 | test_loss: 1.3113 | \n",
      "Epoch: 570 | train_loss: 1.2767 | test_loss: 1.2608 | \n",
      "Epoch: 580 | train_loss: 1.2372 | test_loss: 1.2309 | \n",
      "Epoch: 590 | train_loss: 1.1972 | test_loss: 1.1951 | \n",
      "Epoch: 600 | train_loss: 1.1567 | test_loss: 1.1510 | \n",
      "Epoch: 610 | train_loss: 1.1187 | test_loss: 1.1070 | \n",
      "Epoch: 620 | train_loss: 1.0795 | test_loss: 1.0819 | \n",
      "Epoch: 630 | train_loss: 1.0405 | test_loss: 1.0258 | \n",
      "Epoch: 640 | train_loss: 1.0011 | test_loss: 1.0044 | \n",
      "Epoch: 650 | train_loss: 0.9653 | test_loss: 0.9466 | \n",
      "Epoch: 660 | train_loss: 0.9264 | test_loss: 0.9274 | \n",
      "Epoch: 670 | train_loss: 0.8915 | test_loss: 0.8945 | \n",
      "Epoch: 680 | train_loss: 0.8538 | test_loss: 0.8616 | \n",
      "Epoch: 690 | train_loss: 0.8170 | test_loss: 0.8087 | \n",
      "Epoch: 700 | train_loss: 0.7798 | test_loss: 0.7816 | \n",
      "Epoch: 710 | train_loss: 0.7438 | test_loss: 0.7462 | \n",
      "Epoch: 720 | train_loss: 0.7102 | test_loss: 0.7136 | \n",
      "Epoch: 730 | train_loss: 0.6736 | test_loss: 0.6807 | \n",
      "Epoch: 740 | train_loss: 0.6391 | test_loss: 0.6484 | \n",
      "Epoch: 750 | train_loss: 0.6036 | test_loss: 0.6123 | \n",
      "Epoch: 760 | train_loss: 0.5704 | test_loss: 0.5681 | \n",
      "Epoch: 770 | train_loss: 0.5362 | test_loss: 0.5517 | \n",
      "Epoch: 780 | train_loss: 0.5028 | test_loss: 0.5147 | \n",
      "Epoch: 790 | train_loss: 0.4709 | test_loss: 0.4946 | \n",
      "Epoch: 800 | train_loss: 0.4372 | test_loss: 0.4606 | \n",
      "Epoch: 810 | train_loss: 0.4065 | test_loss: 0.4242 | \n",
      "Epoch: 820 | train_loss: 0.3752 | test_loss: 0.4021 | \n",
      "Epoch: 830 | train_loss: 0.3421 | test_loss: 0.3610 | \n",
      "Epoch: 840 | train_loss: 0.3110 | test_loss: 0.3352 | \n",
      "Epoch: 850 | train_loss: 0.2822 | test_loss: 0.3014 | \n",
      "Epoch: 860 | train_loss: 0.2534 | test_loss: 0.2816 | \n",
      "Epoch: 870 | train_loss: 0.2212 | test_loss: 0.2606 | \n",
      "Epoch: 880 | train_loss: 0.1927 | test_loss: 0.2303 | \n",
      "Epoch: 890 | train_loss: 0.1667 | test_loss: 0.2084 | \n",
      "Epoch: 900 | train_loss: 0.1404 | test_loss: 0.1821 | \n",
      "Epoch: 910 | train_loss: 0.1156 | test_loss: 0.1667 | \n",
      "Epoch: 920 | train_loss: 0.0934 | test_loss: 0.1603 | \n",
      "Epoch: 930 | train_loss: 0.0816 | test_loss: 0.1597 | \n",
      "Epoch: 940 | train_loss: 0.0639 | test_loss: 0.1508 | \n",
      "Epoch: 950 | train_loss: 0.0519 | test_loss: 0.1478 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8312 | test_loss: 9.1648 | \n",
      "Epoch: 10 | train_loss: 7.6785 | test_loss: 7.6179 | \n",
      "Epoch: 20 | train_loss: 6.7759 | test_loss: 6.7338 | \n",
      "Epoch: 30 | train_loss: 6.1974 | test_loss: 6.1643 | \n",
      "Epoch: 40 | train_loss: 5.7825 | test_loss: 5.7481 | \n",
      "Epoch: 50 | train_loss: 5.4565 | test_loss: 5.4297 | \n",
      "Epoch: 60 | train_loss: 5.1893 | test_loss: 5.1600 | \n",
      "Epoch: 70 | train_loss: 4.9577 | test_loss: 4.9380 | \n",
      "Epoch: 80 | train_loss: 4.7568 | test_loss: 4.7394 | \n",
      "Epoch: 90 | train_loss: 4.5760 | test_loss: 4.5653 | \n",
      "Epoch: 100 | train_loss: 4.4137 | test_loss: 4.4047 | \n",
      "Epoch: 110 | train_loss: 4.2646 | test_loss: 4.2355 | \n",
      "Epoch: 120 | train_loss: 4.1264 | test_loss: 4.1116 | \n",
      "Epoch: 130 | train_loss: 4.0008 | test_loss: 3.9805 | \n",
      "Epoch: 140 | train_loss: 3.8822 | test_loss: 3.8682 | \n",
      "Epoch: 150 | train_loss: 3.7719 | test_loss: 3.7531 | \n",
      "Epoch: 160 | train_loss: 3.6655 | test_loss: 3.6539 | \n",
      "Epoch: 170 | train_loss: 3.5661 | test_loss: 3.5459 | \n",
      "Epoch: 180 | train_loss: 3.4705 | test_loss: 3.4422 | \n",
      "Epoch: 190 | train_loss: 3.3803 | test_loss: 3.3703 | \n",
      "Epoch: 200 | train_loss: 3.2920 | test_loss: 3.2822 | \n",
      "Epoch: 210 | train_loss: 3.2090 | test_loss: 3.1827 | \n",
      "Epoch: 220 | train_loss: 3.1296 | test_loss: 3.1174 | \n",
      "Epoch: 230 | train_loss: 3.0519 | test_loss: 3.0422 | \n",
      "Epoch: 240 | train_loss: 2.9767 | test_loss: 2.9620 | \n",
      "Epoch: 250 | train_loss: 2.9064 | test_loss: 2.8863 | \n",
      "Epoch: 260 | train_loss: 2.8339 | test_loss: 2.8141 | \n",
      "Epoch: 270 | train_loss: 2.7672 | test_loss: 2.7534 | \n",
      "Epoch: 280 | train_loss: 2.7019 | test_loss: 2.6783 | \n",
      "Epoch: 290 | train_loss: 2.6360 | test_loss: 2.6262 | \n",
      "Epoch: 300 | train_loss: 2.5745 | test_loss: 2.5678 | \n",
      "Epoch: 310 | train_loss: 2.5129 | test_loss: 2.4946 | \n",
      "Epoch: 320 | train_loss: 2.4541 | test_loss: 2.4431 | \n",
      "Epoch: 330 | train_loss: 2.3949 | test_loss: 2.3840 | \n",
      "Epoch: 340 | train_loss: 2.3371 | test_loss: 2.3249 | \n",
      "Epoch: 350 | train_loss: 2.2812 | test_loss: 2.2760 | \n",
      "Epoch: 360 | train_loss: 2.2257 | test_loss: 2.2135 | \n",
      "Epoch: 370 | train_loss: 2.1726 | test_loss: 2.1680 | \n",
      "Epoch: 380 | train_loss: 2.1194 | test_loss: 2.1101 | \n",
      "Epoch: 390 | train_loss: 2.0665 | test_loss: 2.0543 | \n",
      "Epoch: 400 | train_loss: 2.0172 | test_loss: 2.0085 | \n",
      "Epoch: 410 | train_loss: 1.9661 | test_loss: 1.9552 | \n",
      "Epoch: 420 | train_loss: 1.9159 | test_loss: 1.8993 | \n",
      "Epoch: 430 | train_loss: 1.8678 | test_loss: 1.8555 | \n",
      "Epoch: 440 | train_loss: 1.8184 | test_loss: 1.8135 | \n",
      "Epoch: 450 | train_loss: 1.7718 | test_loss: 1.7650 | \n",
      "Epoch: 460 | train_loss: 1.7248 | test_loss: 1.7150 | \n",
      "Epoch: 470 | train_loss: 1.6794 | test_loss: 1.6730 | \n",
      "Epoch: 480 | train_loss: 1.6326 | test_loss: 1.6200 | \n",
      "Epoch: 490 | train_loss: 1.5873 | test_loss: 1.5792 | \n",
      "Epoch: 500 | train_loss: 1.5434 | test_loss: 1.5430 | \n",
      "Epoch: 510 | train_loss: 1.5008 | test_loss: 1.4958 | \n",
      "Epoch: 520 | train_loss: 1.4558 | test_loss: 1.4474 | \n",
      "Epoch: 530 | train_loss: 1.4136 | test_loss: 1.4089 | \n",
      "Epoch: 540 | train_loss: 1.3710 | test_loss: 1.3692 | \n",
      "Epoch: 550 | train_loss: 1.3294 | test_loss: 1.3217 | \n",
      "Epoch: 560 | train_loss: 1.2875 | test_loss: 1.2788 | \n",
      "Epoch: 570 | train_loss: 1.2466 | test_loss: 1.2428 | \n",
      "Epoch: 580 | train_loss: 1.2060 | test_loss: 1.2050 | \n",
      "Epoch: 590 | train_loss: 1.1667 | test_loss: 1.1494 | \n",
      "Epoch: 600 | train_loss: 1.1257 | test_loss: 1.1123 | \n",
      "Epoch: 610 | train_loss: 1.0883 | test_loss: 1.0944 | \n",
      "Epoch: 620 | train_loss: 1.0477 | test_loss: 1.0466 | \n",
      "Epoch: 630 | train_loss: 1.0082 | test_loss: 1.0068 | \n",
      "Epoch: 640 | train_loss: 0.9702 | test_loss: 0.9650 | \n",
      "Epoch: 650 | train_loss: 0.9324 | test_loss: 0.9406 | \n",
      "Epoch: 660 | train_loss: 0.8951 | test_loss: 0.9097 | \n",
      "Epoch: 670 | train_loss: 0.8581 | test_loss: 0.8398 | \n",
      "Epoch: 680 | train_loss: 0.8222 | test_loss: 0.8219 | \n",
      "Epoch: 690 | train_loss: 0.7838 | test_loss: 0.7899 | \n",
      "Epoch: 700 | train_loss: 0.7484 | test_loss: 0.7530 | \n",
      "Epoch: 710 | train_loss: 0.7120 | test_loss: 0.7265 | \n",
      "Epoch: 720 | train_loss: 0.6769 | test_loss: 0.6807 | \n",
      "Epoch: 730 | train_loss: 0.6420 | test_loss: 0.6584 | \n",
      "Epoch: 740 | train_loss: 0.6080 | test_loss: 0.6218 | \n",
      "Epoch: 750 | train_loss: 0.5728 | test_loss: 0.5854 | \n",
      "Epoch: 760 | train_loss: 0.5394 | test_loss: 0.5460 | \n",
      "Epoch: 770 | train_loss: 0.5050 | test_loss: 0.5090 | \n",
      "Epoch: 780 | train_loss: 0.4726 | test_loss: 0.5066 | \n",
      "Epoch: 790 | train_loss: 0.4401 | test_loss: 0.4482 | \n",
      "Epoch: 800 | train_loss: 0.4081 | test_loss: 0.4369 | \n",
      "Epoch: 810 | train_loss: 0.3757 | test_loss: 0.3915 | \n",
      "Epoch: 820 | train_loss: 0.3433 | test_loss: 0.3595 | \n",
      "Epoch: 830 | train_loss: 0.3137 | test_loss: 0.3417 | \n",
      "Epoch: 840 | train_loss: 0.2821 | test_loss: 0.3099 | \n",
      "Epoch: 850 | train_loss: 0.2521 | test_loss: 0.2848 | \n",
      "Epoch: 860 | train_loss: 0.2230 | test_loss: 0.2581 | \n",
      "Epoch: 870 | train_loss: 0.1949 | test_loss: 0.2308 | \n",
      "Epoch: 880 | train_loss: 0.1675 | test_loss: 0.2117 | \n",
      "Epoch: 890 | train_loss: 0.1397 | test_loss: 0.1914 | \n",
      "Epoch: 900 | train_loss: 0.1172 | test_loss: 0.1739 | \n",
      "Epoch: 910 | train_loss: 0.0942 | test_loss: 0.1565 | \n",
      "Epoch: 920 | train_loss: 0.0801 | test_loss: 0.1650 | \n",
      "Epoch: 930 | train_loss: 0.0628 | test_loss: 0.1459 | \n",
      "Epoch: 940 | train_loss: 0.0467 | test_loss: 0.1452 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8426 | test_loss: 10.0281 | \n",
      "Epoch: 10 | train_loss: 7.7258 | test_loss: 7.6418 | \n",
      "Epoch: 20 | train_loss: 6.8291 | test_loss: 6.7775 | \n",
      "Epoch: 30 | train_loss: 6.2569 | test_loss: 6.2056 | \n",
      "Epoch: 40 | train_loss: 5.8390 | test_loss: 5.7957 | \n",
      "Epoch: 50 | train_loss: 5.5098 | test_loss: 5.4680 | \n",
      "Epoch: 60 | train_loss: 5.2332 | test_loss: 5.1962 | \n",
      "Epoch: 70 | train_loss: 5.0011 | test_loss: 4.9610 | \n",
      "Epoch: 80 | train_loss: 4.7950 | test_loss: 4.7727 | \n",
      "Epoch: 90 | train_loss: 4.6151 | test_loss: 4.5852 | \n",
      "Epoch: 100 | train_loss: 4.4589 | test_loss: 4.4289 | \n",
      "Epoch: 110 | train_loss: 4.3031 | test_loss: 4.2792 | \n",
      "Epoch: 120 | train_loss: 4.1688 | test_loss: 4.1414 | \n",
      "Epoch: 130 | train_loss: 4.0359 | test_loss: 4.0157 | \n",
      "Epoch: 140 | train_loss: 3.9221 | test_loss: 3.8903 | \n",
      "Epoch: 150 | train_loss: 3.8047 | test_loss: 3.7820 | \n",
      "Epoch: 160 | train_loss: 3.7008 | test_loss: 3.6791 | \n",
      "Epoch: 170 | train_loss: 3.6039 | test_loss: 3.5748 | \n",
      "Epoch: 180 | train_loss: 3.5064 | test_loss: 3.4761 | \n",
      "Epoch: 190 | train_loss: 3.4167 | test_loss: 3.3884 | \n",
      "Epoch: 200 | train_loss: 3.3292 | test_loss: 3.3096 | \n",
      "Epoch: 210 | train_loss: 3.2472 | test_loss: 3.2236 | \n",
      "Epoch: 220 | train_loss: 3.1589 | test_loss: 3.1417 | \n",
      "Epoch: 230 | train_loss: 3.0888 | test_loss: 3.0691 | \n",
      "Epoch: 240 | train_loss: 3.0107 | test_loss: 2.9880 | \n",
      "Epoch: 250 | train_loss: 2.9362 | test_loss: 2.9202 | \n",
      "Epoch: 260 | train_loss: 2.8715 | test_loss: 2.8495 | \n",
      "Epoch: 270 | train_loss: 2.8061 | test_loss: 2.7832 | \n",
      "Epoch: 280 | train_loss: 2.7389 | test_loss: 2.7167 | \n",
      "Epoch: 290 | train_loss: 2.6741 | test_loss: 2.6526 | \n",
      "Epoch: 300 | train_loss: 2.6085 | test_loss: 2.5881 | \n",
      "Epoch: 310 | train_loss: 2.5437 | test_loss: 2.5285 | \n",
      "Epoch: 320 | train_loss: 2.4876 | test_loss: 2.4756 | \n",
      "Epoch: 330 | train_loss: 2.4303 | test_loss: 2.4160 | \n",
      "Epoch: 340 | train_loss: 2.3729 | test_loss: 2.3559 | \n",
      "Epoch: 350 | train_loss: 2.3182 | test_loss: 2.2963 | \n",
      "Epoch: 360 | train_loss: 2.2641 | test_loss: 2.2453 | \n",
      "Epoch: 370 | train_loss: 2.2053 | test_loss: 2.1944 | \n",
      "Epoch: 380 | train_loss: 2.1530 | test_loss: 2.1367 | \n",
      "Epoch: 390 | train_loss: 2.1008 | test_loss: 2.0839 | \n",
      "Epoch: 400 | train_loss: 2.0537 | test_loss: 2.0261 | \n",
      "Epoch: 410 | train_loss: 2.0016 | test_loss: 1.9818 | \n",
      "Epoch: 420 | train_loss: 1.9485 | test_loss: 1.9365 | \n",
      "Epoch: 430 | train_loss: 1.9066 | test_loss: 1.8845 | \n",
      "Epoch: 440 | train_loss: 1.8598 | test_loss: 1.8412 | \n",
      "Epoch: 450 | train_loss: 1.8122 | test_loss: 1.7874 | \n",
      "Epoch: 460 | train_loss: 1.7637 | test_loss: 1.7449 | \n",
      "Epoch: 470 | train_loss: 1.7183 | test_loss: 1.6936 | \n",
      "Epoch: 480 | train_loss: 1.6674 | test_loss: 1.6545 | \n",
      "Epoch: 490 | train_loss: 1.6290 | test_loss: 1.6075 | \n",
      "Epoch: 500 | train_loss: 1.5832 | test_loss: 1.5618 | \n",
      "Epoch: 510 | train_loss: 1.5378 | test_loss: 1.5225 | \n",
      "Epoch: 520 | train_loss: 1.4912 | test_loss: 1.4808 | \n",
      "Epoch: 530 | train_loss: 1.4495 | test_loss: 1.4371 | \n",
      "Epoch: 540 | train_loss: 1.4084 | test_loss: 1.3881 | \n",
      "Epoch: 550 | train_loss: 1.3707 | test_loss: 1.3496 | \n",
      "Epoch: 560 | train_loss: 1.3217 | test_loss: 1.3142 | \n",
      "Epoch: 570 | train_loss: 1.2869 | test_loss: 1.2715 | \n",
      "Epoch: 580 | train_loss: 1.2441 | test_loss: 1.2289 | \n",
      "Epoch: 590 | train_loss: 1.2094 | test_loss: 1.1895 | \n",
      "Epoch: 600 | train_loss: 1.1595 | test_loss: 1.1531 | \n",
      "Epoch: 610 | train_loss: 1.1274 | test_loss: 1.1105 | \n",
      "Epoch: 620 | train_loss: 1.0825 | test_loss: 1.0732 | \n",
      "Epoch: 630 | train_loss: 1.0466 | test_loss: 1.0332 | \n",
      "Epoch: 640 | train_loss: 1.0088 | test_loss: 0.9984 | \n",
      "Epoch: 650 | train_loss: 0.9770 | test_loss: 0.9573 | \n",
      "Epoch: 660 | train_loss: 0.9336 | test_loss: 0.9234 | \n",
      "Epoch: 670 | train_loss: 0.9000 | test_loss: 0.8871 | \n",
      "Epoch: 680 | train_loss: 0.8650 | test_loss: 0.8547 | \n",
      "Epoch: 690 | train_loss: 0.8250 | test_loss: 0.8120 | \n",
      "Epoch: 700 | train_loss: 0.7961 | test_loss: 0.7847 | \n",
      "Epoch: 710 | train_loss: 0.7598 | test_loss: 0.7497 | \n",
      "Epoch: 720 | train_loss: 0.7220 | test_loss: 0.7093 | \n",
      "Epoch: 730 | train_loss: 0.6887 | test_loss: 0.6774 | \n",
      "Epoch: 740 | train_loss: 0.6505 | test_loss: 0.6446 | \n",
      "Epoch: 750 | train_loss: 0.6248 | test_loss: 0.6101 | \n",
      "Epoch: 760 | train_loss: 0.5820 | test_loss: 0.5763 | \n",
      "Epoch: 770 | train_loss: 0.5515 | test_loss: 0.5472 | \n",
      "Epoch: 780 | train_loss: 0.5246 | test_loss: 0.5107 | \n",
      "Epoch: 790 | train_loss: 0.4899 | test_loss: 0.4812 | \n",
      "Epoch: 800 | train_loss: 0.4600 | test_loss: 0.4507 | \n",
      "Epoch: 810 | train_loss: 0.4310 | test_loss: 0.4315 | \n",
      "Epoch: 820 | train_loss: 0.3952 | test_loss: 0.3956 | \n",
      "Epoch: 830 | train_loss: 0.3664 | test_loss: 0.3708 | \n",
      "Epoch: 840 | train_loss: 0.3408 | test_loss: 0.3399 | \n",
      "Epoch: 850 | train_loss: 0.3121 | test_loss: 0.3214 | \n",
      "Epoch: 860 | train_loss: 0.2879 | test_loss: 0.2841 | \n",
      "Epoch: 870 | train_loss: 0.2617 | test_loss: 0.2675 | \n",
      "Epoch: 880 | train_loss: 0.2372 | test_loss: 0.2368 | \n",
      "Epoch: 890 | train_loss: 0.2124 | test_loss: 0.2189 | \n",
      "Epoch: 900 | train_loss: 0.1933 | test_loss: 0.2028 | \n",
      "Epoch: 910 | train_loss: 0.1748 | test_loss: 0.1991 | \n",
      "Epoch: 920 | train_loss: 0.1602 | test_loss: 0.1789 | \n",
      "Epoch: 930 | train_loss: 0.1446 | test_loss: 0.1658 | \n",
      "Epoch: 940 | train_loss: 0.1392 | test_loss: 0.1552 | \n",
      "Epoch: 950 | train_loss: 0.1266 | test_loss: 0.1525 | \n",
      "Epoch: 960 | train_loss: 0.1312 | test_loss: 0.1494 | \n",
      "Epoch: 970 | train_loss: 0.1174 | test_loss: 0.1463 | \n",
      "Epoch: 980 | train_loss: 0.1146 | test_loss: 0.1456 | \n",
      "Epoch: 990 | train_loss: 0.1159 | test_loss: 0.1435 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8755 | test_loss: 9.6172 | \n",
      "Epoch: 10 | train_loss: 7.7425 | test_loss: 7.6588 | \n",
      "Epoch: 20 | train_loss: 6.8527 | test_loss: 6.7896 | \n",
      "Epoch: 30 | train_loss: 6.2763 | test_loss: 6.2078 | \n",
      "Epoch: 40 | train_loss: 5.8504 | test_loss: 5.8060 | \n",
      "Epoch: 50 | train_loss: 5.5319 | test_loss: 5.4834 | \n",
      "Epoch: 60 | train_loss: 5.2564 | test_loss: 5.2076 | \n",
      "Epoch: 70 | train_loss: 5.0275 | test_loss: 4.9908 | \n",
      "Epoch: 80 | train_loss: 4.8178 | test_loss: 4.7818 | \n",
      "Epoch: 90 | train_loss: 4.6413 | test_loss: 4.6003 | \n",
      "Epoch: 100 | train_loss: 4.4765 | test_loss: 4.4411 | \n",
      "Epoch: 110 | train_loss: 4.3275 | test_loss: 4.2894 | \n",
      "Epoch: 120 | train_loss: 4.1898 | test_loss: 4.1490 | \n",
      "Epoch: 130 | train_loss: 4.0630 | test_loss: 4.0385 | \n",
      "Epoch: 140 | train_loss: 3.9401 | test_loss: 3.9078 | \n",
      "Epoch: 150 | train_loss: 3.8276 | test_loss: 3.7995 | \n",
      "Epoch: 160 | train_loss: 3.7189 | test_loss: 3.6971 | \n",
      "Epoch: 170 | train_loss: 3.6248 | test_loss: 3.5960 | \n",
      "Epoch: 180 | train_loss: 3.5235 | test_loss: 3.4972 | \n",
      "Epoch: 190 | train_loss: 3.4309 | test_loss: 3.4120 | \n",
      "Epoch: 200 | train_loss: 3.3463 | test_loss: 3.3205 | \n",
      "Epoch: 210 | train_loss: 3.2643 | test_loss: 3.2399 | \n",
      "Epoch: 220 | train_loss: 3.1830 | test_loss: 3.1615 | \n",
      "Epoch: 230 | train_loss: 3.1126 | test_loss: 3.0872 | \n",
      "Epoch: 240 | train_loss: 3.0347 | test_loss: 3.0118 | \n",
      "Epoch: 250 | train_loss: 2.9534 | test_loss: 2.9380 | \n",
      "Epoch: 260 | train_loss: 2.8915 | test_loss: 2.8687 | \n",
      "Epoch: 270 | train_loss: 2.8241 | test_loss: 2.8010 | \n",
      "Epoch: 280 | train_loss: 2.7519 | test_loss: 2.7336 | \n",
      "Epoch: 290 | train_loss: 2.6854 | test_loss: 2.6680 | \n",
      "Epoch: 300 | train_loss: 2.6282 | test_loss: 2.6030 | \n",
      "Epoch: 310 | train_loss: 2.5681 | test_loss: 2.5434 | \n",
      "Epoch: 320 | train_loss: 2.5108 | test_loss: 2.4852 | \n",
      "Epoch: 330 | train_loss: 2.4482 | test_loss: 2.4219 | \n",
      "Epoch: 340 | train_loss: 2.3954 | test_loss: 2.3689 | \n",
      "Epoch: 350 | train_loss: 2.3372 | test_loss: 2.3153 | \n",
      "Epoch: 360 | train_loss: 2.2811 | test_loss: 2.2670 | \n",
      "Epoch: 370 | train_loss: 2.2239 | test_loss: 2.2050 | \n",
      "Epoch: 380 | train_loss: 2.1792 | test_loss: 2.1630 | \n",
      "Epoch: 390 | train_loss: 2.1164 | test_loss: 2.1054 | \n",
      "Epoch: 400 | train_loss: 2.0651 | test_loss: 2.0478 | \n",
      "Epoch: 410 | train_loss: 2.0190 | test_loss: 1.9951 | \n",
      "Epoch: 420 | train_loss: 1.9673 | test_loss: 1.9486 | \n",
      "Epoch: 430 | train_loss: 1.9191 | test_loss: 1.9024 | \n",
      "Epoch: 440 | train_loss: 1.8767 | test_loss: 1.8534 | \n",
      "Epoch: 450 | train_loss: 1.8247 | test_loss: 1.8063 | \n",
      "Epoch: 460 | train_loss: 1.7762 | test_loss: 1.7609 | \n",
      "Epoch: 470 | train_loss: 1.7333 | test_loss: 1.7172 | \n",
      "Epoch: 480 | train_loss: 1.6892 | test_loss: 1.6711 | \n",
      "Epoch: 490 | train_loss: 1.6443 | test_loss: 1.6307 | \n",
      "Epoch: 500 | train_loss: 1.5969 | test_loss: 1.5802 | \n",
      "Epoch: 510 | train_loss: 1.5531 | test_loss: 1.5374 | \n",
      "Epoch: 520 | train_loss: 1.5145 | test_loss: 1.4975 | \n",
      "Epoch: 530 | train_loss: 1.4715 | test_loss: 1.4538 | \n",
      "Epoch: 540 | train_loss: 1.4232 | test_loss: 1.4073 | \n",
      "Epoch: 550 | train_loss: 1.3810 | test_loss: 1.3634 | \n",
      "Epoch: 560 | train_loss: 1.3436 | test_loss: 1.3284 | \n",
      "Epoch: 570 | train_loss: 1.3016 | test_loss: 1.2880 | \n",
      "Epoch: 580 | train_loss: 1.2610 | test_loss: 1.2468 | \n",
      "Epoch: 590 | train_loss: 1.2240 | test_loss: 1.2069 | \n",
      "Epoch: 600 | train_loss: 1.1815 | test_loss: 1.1687 | \n",
      "Epoch: 610 | train_loss: 1.1425 | test_loss: 1.1308 | \n",
      "Epoch: 620 | train_loss: 1.1026 | test_loss: 1.0896 | \n",
      "Epoch: 630 | train_loss: 1.0617 | test_loss: 1.0565 | \n",
      "Epoch: 640 | train_loss: 1.0268 | test_loss: 1.0148 | \n",
      "Epoch: 650 | train_loss: 0.9874 | test_loss: 0.9770 | \n",
      "Epoch: 660 | train_loss: 0.9497 | test_loss: 0.9393 | \n",
      "Epoch: 670 | train_loss: 0.9166 | test_loss: 0.9087 | \n",
      "Epoch: 680 | train_loss: 0.8804 | test_loss: 0.8645 | \n",
      "Epoch: 690 | train_loss: 0.8420 | test_loss: 0.8272 | \n",
      "Epoch: 700 | train_loss: 0.8076 | test_loss: 0.7938 | \n",
      "Epoch: 710 | train_loss: 0.7703 | test_loss: 0.7587 | \n",
      "Epoch: 720 | train_loss: 0.7355 | test_loss: 0.7250 | \n",
      "Epoch: 730 | train_loss: 0.7044 | test_loss: 0.6892 | \n",
      "Epoch: 740 | train_loss: 0.6672 | test_loss: 0.6579 | \n",
      "Epoch: 750 | train_loss: 0.6301 | test_loss: 0.6248 | \n",
      "Epoch: 760 | train_loss: 0.6008 | test_loss: 0.5914 | \n",
      "Epoch: 770 | train_loss: 0.5667 | test_loss: 0.5648 | \n",
      "Epoch: 780 | train_loss: 0.5318 | test_loss: 0.5356 | \n",
      "Epoch: 790 | train_loss: 0.5035 | test_loss: 0.4955 | \n",
      "Epoch: 800 | train_loss: 0.4714 | test_loss: 0.4658 | \n",
      "Epoch: 810 | train_loss: 0.4357 | test_loss: 0.4300 | \n",
      "Epoch: 820 | train_loss: 0.4115 | test_loss: 0.4055 | \n",
      "Epoch: 830 | train_loss: 0.3790 | test_loss: 0.3776 | \n",
      "Epoch: 840 | train_loss: 0.3537 | test_loss: 0.3447 | \n",
      "Epoch: 850 | train_loss: 0.3207 | test_loss: 0.3214 | \n",
      "Epoch: 860 | train_loss: 0.3003 | test_loss: 0.2991 | \n",
      "Epoch: 870 | train_loss: 0.2694 | test_loss: 0.2696 | \n",
      "Epoch: 880 | train_loss: 0.2448 | test_loss: 0.2451 | \n",
      "Epoch: 890 | train_loss: 0.2299 | test_loss: 0.2219 | \n",
      "Epoch: 900 | train_loss: 0.2000 | test_loss: 0.2049 | \n",
      "Epoch: 910 | train_loss: 0.1805 | test_loss: 0.1952 | \n",
      "Epoch: 920 | train_loss: 0.1654 | test_loss: 0.1797 | \n",
      "Epoch: 930 | train_loss: 0.1497 | test_loss: 0.1650 | \n",
      "Epoch: 940 | train_loss: 0.1348 | test_loss: 0.1564 | \n",
      "Epoch: 950 | train_loss: 0.1335 | test_loss: 0.1478 | \n",
      "Epoch: 960 | train_loss: 0.1233 | test_loss: 0.1468 | \n",
      "Epoch: 970 | train_loss: 0.1233 | test_loss: 0.1455 | \n",
      "Epoch: 980 | train_loss: 0.1181 | test_loss: 0.1423 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.7509 | test_loss: 2.2257 | \n",
      "Epoch: 10 | train_loss: 0.1389 | test_loss: 0.1469 | \n",
      "Epoch: 20 | train_loss: 0.1224 | test_loss: 0.1466 | \n",
      "Epoch: 30 | train_loss: 0.1151 | test_loss: 0.1431 | \n",
      "Epoch: 40 | train_loss: 0.1066 | test_loss: 0.1435 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.1739 | test_loss: 0.4224 | \n",
      "Epoch: 10 | train_loss: 0.1206 | test_loss: 0.1461 | \n",
      "Epoch: 20 | train_loss: 0.1070 | test_loss: 0.1479 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 2.0348 | test_loss: 0.4265 | \n",
      "Epoch: 10 | train_loss: 0.1372 | test_loss: 0.1968 | \n",
      "Epoch: 20 | train_loss: 0.1032 | test_loss: 0.1497 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6426 | test_loss: 8.6979 | \n",
      "Epoch: 10 | train_loss: 5.9166 | test_loss: 5.8589 | \n",
      "Epoch: 20 | train_loss: 4.8603 | test_loss: 4.8038 | \n",
      "Epoch: 30 | train_loss: 4.2237 | test_loss: 4.1742 | \n",
      "Epoch: 40 | train_loss: 3.7543 | test_loss: 3.7317 | \n",
      "Epoch: 50 | train_loss: 3.3787 | test_loss: 3.3641 | \n",
      "Epoch: 60 | train_loss: 3.0628 | test_loss: 3.0528 | \n",
      "Epoch: 70 | train_loss: 2.7839 | test_loss: 2.7607 | \n",
      "Epoch: 80 | train_loss: 2.5342 | test_loss: 2.5141 | \n",
      "Epoch: 90 | train_loss: 2.3059 | test_loss: 2.2932 | \n",
      "Epoch: 100 | train_loss: 2.1173 | test_loss: 2.0880 | \n",
      "Epoch: 110 | train_loss: 1.9009 | test_loss: 1.8810 | \n",
      "Epoch: 120 | train_loss: 1.7118 | test_loss: 1.6922 | \n",
      "Epoch: 130 | train_loss: 1.5356 | test_loss: 1.5256 | \n",
      "Epoch: 140 | train_loss: 1.3638 | test_loss: 1.3457 | \n",
      "Epoch: 150 | train_loss: 1.2014 | test_loss: 1.1924 | \n",
      "Epoch: 160 | train_loss: 1.0471 | test_loss: 1.0425 | \n",
      "Epoch: 170 | train_loss: 0.8954 | test_loss: 0.8687 | \n",
      "Epoch: 180 | train_loss: 0.7491 | test_loss: 0.7517 | \n",
      "Epoch: 190 | train_loss: 0.6119 | test_loss: 0.6272 | \n",
      "Epoch: 200 | train_loss: 0.4782 | test_loss: 0.5001 | \n",
      "Epoch: 210 | train_loss: 0.3550 | test_loss: 0.3817 | \n",
      "Epoch: 220 | train_loss: 0.2446 | test_loss: 0.2560 | \n",
      "Epoch: 230 | train_loss: 0.1523 | test_loss: 0.1968 | \n",
      "Epoch: 240 | train_loss: 0.1102 | test_loss: 0.1584 | \n",
      "Epoch: 250 | train_loss: 0.0887 | test_loss: 0.1601 | \n",
      "Epoch: 260 | train_loss: 0.0871 | test_loss: 0.1633 | \n",
      "Epoch: 270 | train_loss: 0.0785 | test_loss: 0.1418 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.6351 | test_loss: 8.6292 | \n",
      "Epoch: 10 | train_loss: 5.9075 | test_loss: 5.8112 | \n",
      "Epoch: 20 | train_loss: 4.8469 | test_loss: 4.8104 | \n",
      "Epoch: 30 | train_loss: 4.2054 | test_loss: 4.1585 | \n",
      "Epoch: 40 | train_loss: 3.7380 | test_loss: 3.6629 | \n",
      "Epoch: 50 | train_loss: 3.3624 | test_loss: 3.3351 | \n",
      "Epoch: 60 | train_loss: 3.0459 | test_loss: 3.0256 | \n",
      "Epoch: 70 | train_loss: 2.7684 | test_loss: 2.7384 | \n",
      "Epoch: 80 | train_loss: 2.5272 | test_loss: 2.4740 | \n",
      "Epoch: 90 | train_loss: 2.2943 | test_loss: 2.2670 | \n",
      "Epoch: 100 | train_loss: 2.0791 | test_loss: 2.0548 | \n",
      "Epoch: 110 | train_loss: 1.8822 | test_loss: 1.8694 | \n",
      "Epoch: 120 | train_loss: 1.6926 | test_loss: 1.6727 | \n",
      "Epoch: 130 | train_loss: 1.5175 | test_loss: 1.4902 | \n",
      "Epoch: 140 | train_loss: 1.3465 | test_loss: 1.3279 | \n",
      "Epoch: 150 | train_loss: 1.1840 | test_loss: 1.1752 | \n",
      "Epoch: 160 | train_loss: 1.0288 | test_loss: 1.0084 | \n",
      "Epoch: 170 | train_loss: 0.8815 | test_loss: 0.8637 | \n",
      "Epoch: 180 | train_loss: 0.7365 | test_loss: 0.7400 | \n",
      "Epoch: 190 | train_loss: 0.5964 | test_loss: 0.5833 | \n",
      "Epoch: 200 | train_loss: 0.4664 | test_loss: 0.4757 | \n",
      "Epoch: 210 | train_loss: 0.3408 | test_loss: 0.3484 | \n",
      "Epoch: 220 | train_loss: 0.2283 | test_loss: 0.2358 | \n",
      "Epoch: 230 | train_loss: 0.1512 | test_loss: 0.1912 | \n",
      "Epoch: 240 | train_loss: 0.1008 | test_loss: 0.1527 | \n",
      "Epoch: 250 | train_loss: 0.0843 | test_loss: 0.1543 | \n",
      "Epoch: 260 | train_loss: 0.0744 | test_loss: 0.1513 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.7163 | test_loss: 8.6638 | \n",
      "Epoch: 10 | train_loss: 5.9798 | test_loss: 5.8781 | \n",
      "Epoch: 20 | train_loss: 4.9130 | test_loss: 4.8511 | \n",
      "Epoch: 30 | train_loss: 4.2753 | test_loss: 4.2211 | \n",
      "Epoch: 40 | train_loss: 3.8010 | test_loss: 3.7562 | \n",
      "Epoch: 50 | train_loss: 3.4213 | test_loss: 3.3922 | \n",
      "Epoch: 60 | train_loss: 3.1071 | test_loss: 3.0724 | \n",
      "Epoch: 70 | train_loss: 2.8251 | test_loss: 2.8029 | \n",
      "Epoch: 80 | train_loss: 2.5758 | test_loss: 2.5513 | \n",
      "Epoch: 90 | train_loss: 2.3488 | test_loss: 2.3246 | \n",
      "Epoch: 100 | train_loss: 2.1385 | test_loss: 2.1125 | \n",
      "Epoch: 110 | train_loss: 1.9411 | test_loss: 1.9146 | \n",
      "Epoch: 120 | train_loss: 1.7588 | test_loss: 1.7290 | \n",
      "Epoch: 130 | train_loss: 1.5771 | test_loss: 1.5532 | \n",
      "Epoch: 140 | train_loss: 1.4088 | test_loss: 1.3812 | \n",
      "Epoch: 150 | train_loss: 1.2457 | test_loss: 1.2249 | \n",
      "Epoch: 160 | train_loss: 1.0885 | test_loss: 1.0640 | \n",
      "Epoch: 170 | train_loss: 0.9440 | test_loss: 0.9127 | \n",
      "Epoch: 180 | train_loss: 0.8032 | test_loss: 0.7880 | \n",
      "Epoch: 190 | train_loss: 0.6664 | test_loss: 0.6424 | \n",
      "Epoch: 200 | train_loss: 0.5379 | test_loss: 0.5172 | \n",
      "Epoch: 210 | train_loss: 0.4257 | test_loss: 0.4026 | \n",
      "Epoch: 220 | train_loss: 0.3147 | test_loss: 0.3047 | \n",
      "Epoch: 230 | train_loss: 0.2407 | test_loss: 0.2213 | \n",
      "Epoch: 240 | train_loss: 0.1860 | test_loss: 0.1734 | \n",
      "Epoch: 250 | train_loss: 0.1635 | test_loss: 0.1605 | \n",
      "Epoch: 260 | train_loss: 0.1505 | test_loss: 0.1470 | \n",
      "Epoch: 270 | train_loss: 0.1510 | test_loss: 0.1389 | \n",
      "Epoch: 280 | train_loss: 0.1410 | test_loss: 0.1467 | \n",
      "Epoch: 290 | train_loss: 0.1362 | test_loss: 0.1447 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 9.7229 | test_loss: 8.6500 | \n",
      "Epoch: 10 | train_loss: 5.9886 | test_loss: 5.8901 | \n",
      "Epoch: 20 | train_loss: 4.9254 | test_loss: 4.8646 | \n",
      "Epoch: 30 | train_loss: 4.2886 | test_loss: 4.2344 | \n",
      "Epoch: 40 | train_loss: 3.8223 | test_loss: 3.7718 | \n",
      "Epoch: 50 | train_loss: 3.4413 | test_loss: 3.4066 | \n",
      "Epoch: 60 | train_loss: 3.1244 | test_loss: 3.0914 | \n",
      "Epoch: 70 | train_loss: 2.8480 | test_loss: 2.8196 | \n",
      "Epoch: 80 | train_loss: 2.5966 | test_loss: 2.5594 | \n",
      "Epoch: 90 | train_loss: 2.3678 | test_loss: 2.3361 | \n",
      "Epoch: 100 | train_loss: 2.1570 | test_loss: 2.1264 | \n",
      "Epoch: 110 | train_loss: 1.9561 | test_loss: 1.9374 | \n",
      "Epoch: 120 | train_loss: 1.7657 | test_loss: 1.7568 | \n",
      "Epoch: 130 | train_loss: 1.5910 | test_loss: 1.5790 | \n",
      "Epoch: 140 | train_loss: 1.4232 | test_loss: 1.3984 | \n",
      "Epoch: 150 | train_loss: 1.2580 | test_loss: 1.2510 | \n",
      "Epoch: 160 | train_loss: 1.1089 | test_loss: 1.0770 | \n",
      "Epoch: 170 | train_loss: 0.9557 | test_loss: 0.9347 | \n",
      "Epoch: 180 | train_loss: 0.8158 | test_loss: 0.8032 | \n",
      "Epoch: 190 | train_loss: 0.6798 | test_loss: 0.6582 | \n",
      "Epoch: 200 | train_loss: 0.5520 | test_loss: 0.5303 | \n",
      "Epoch: 210 | train_loss: 0.4292 | test_loss: 0.4104 | \n",
      "Epoch: 220 | train_loss: 0.3294 | test_loss: 0.3179 | \n",
      "Epoch: 230 | train_loss: 0.2427 | test_loss: 0.2227 | \n",
      "Epoch: 240 | train_loss: 0.1747 | test_loss: 0.1812 | \n",
      "Epoch: 250 | train_loss: 0.1552 | test_loss: 0.1539 | \n",
      "Epoch: 260 | train_loss: 0.1470 | test_loss: 0.1472 | \n",
      "Epoch: 270 | train_loss: 0.1426 | test_loss: 0.1539 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.0703 | test_loss: 4.4225 | \n",
      "Epoch: 10 | train_loss: 0.1684 | test_loss: 0.1629 | \n",
      "Epoch: 20 | train_loss: 0.1396 | test_loss: 0.1537 | \n",
      "Epoch: 30 | train_loss: 0.1285 | test_loss: 0.1496 | \n",
      "Epoch: 40 | train_loss: 0.1206 | test_loss: 0.1492 | \n",
      "Epoch: 50 | train_loss: 0.1184 | test_loss: 0.1482 | \n",
      "Epoch: 60 | train_loss: 0.1126 | test_loss: 0.1459 | \n",
      "Epoch: 70 | train_loss: 0.1110 | test_loss: 0.1470 | \n",
      "Epoch: 80 | train_loss: 0.1076 | test_loss: 0.1455 | \n",
      "Epoch: 90 | train_loss: 0.1039 | test_loss: 0.1458 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 5.4769 | test_loss: 1.6437 | \n",
      "Epoch: 10 | train_loss: 0.1383 | test_loss: 0.1475 | \n",
      "Epoch: 20 | train_loss: 0.1190 | test_loss: 0.1451 | \n",
      "Epoch: 30 | train_loss: 0.1115 | test_loss: 0.1468 | \n",
      "Epoch: 40 | train_loss: 0.1033 | test_loss: 0.1448 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 3.0379 | test_loss: 1.6606 | \n",
      "Epoch: 10 | train_loss: 0.1229 | test_loss: 0.1589 | \n",
      "Epoch: 20 | train_loss: 0.0891 | test_loss: 0.1521 | \n",
      "Epoch: 30 | train_loss: 0.0808 | test_loss: 0.1544 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2215 | test_loss: 9.2215 | \n",
      "Epoch: 10 | train_loss: 6.8488 | test_loss: 6.7819 | \n",
      "Epoch: 20 | train_loss: 5.8329 | test_loss: 5.7909 | \n",
      "Epoch: 30 | train_loss: 5.2282 | test_loss: 5.1802 | \n",
      "Epoch: 40 | train_loss: 4.7882 | test_loss: 4.7575 | \n",
      "Epoch: 50 | train_loss: 4.4406 | test_loss: 4.4293 | \n",
      "Epoch: 60 | train_loss: 4.1517 | test_loss: 4.1184 | \n",
      "Epoch: 70 | train_loss: 3.9060 | test_loss: 3.8782 | \n",
      "Epoch: 80 | train_loss: 3.6885 | test_loss: 3.6703 | \n",
      "Epoch: 90 | train_loss: 3.4935 | test_loss: 3.4808 | \n",
      "Epoch: 100 | train_loss: 3.3148 | test_loss: 3.2957 | \n",
      "Epoch: 110 | train_loss: 3.1519 | test_loss: 3.1447 | \n",
      "Epoch: 120 | train_loss: 3.0000 | test_loss: 2.9949 | \n",
      "Epoch: 130 | train_loss: 2.8582 | test_loss: 2.8422 | \n",
      "Epoch: 140 | train_loss: 2.7237 | test_loss: 2.7014 | \n",
      "Epoch: 150 | train_loss: 2.5970 | test_loss: 2.5896 | \n",
      "Epoch: 160 | train_loss: 2.4774 | test_loss: 2.4673 | \n",
      "Epoch: 170 | train_loss: 2.3607 | test_loss: 2.3438 | \n",
      "Epoch: 180 | train_loss: 2.2493 | test_loss: 2.2303 | \n",
      "Epoch: 190 | train_loss: 2.1416 | test_loss: 2.1352 | \n",
      "Epoch: 200 | train_loss: 2.0403 | test_loss: 2.0252 | \n",
      "Epoch: 210 | train_loss: 1.9396 | test_loss: 1.9260 | \n",
      "Epoch: 220 | train_loss: 1.8426 | test_loss: 1.8287 | \n",
      "Epoch: 230 | train_loss: 1.7473 | test_loss: 1.7382 | \n",
      "Epoch: 240 | train_loss: 1.6576 | test_loss: 1.6419 | \n",
      "Epoch: 250 | train_loss: 1.5680 | test_loss: 1.5645 | \n",
      "Epoch: 260 | train_loss: 1.4815 | test_loss: 1.4535 | \n",
      "Epoch: 270 | train_loss: 1.3945 | test_loss: 1.4005 | \n",
      "Epoch: 280 | train_loss: 1.3107 | test_loss: 1.3092 | \n",
      "Epoch: 290 | train_loss: 1.2281 | test_loss: 1.1986 | \n",
      "Epoch: 300 | train_loss: 1.1481 | test_loss: 1.1355 | \n",
      "Epoch: 310 | train_loss: 1.0706 | test_loss: 1.0665 | \n",
      "Epoch: 320 | train_loss: 0.9957 | test_loss: 1.0022 | \n",
      "Epoch: 330 | train_loss: 0.9187 | test_loss: 0.9139 | \n",
      "Epoch: 340 | train_loss: 0.8448 | test_loss: 0.8452 | \n",
      "Epoch: 350 | train_loss: 0.7713 | test_loss: 0.7662 | \n",
      "Epoch: 360 | train_loss: 0.6998 | test_loss: 0.7021 | \n",
      "Epoch: 370 | train_loss: 0.6295 | test_loss: 0.6325 | \n",
      "Epoch: 380 | train_loss: 0.5616 | test_loss: 0.5716 | \n",
      "Epoch: 390 | train_loss: 0.4997 | test_loss: 0.5282 | \n",
      "Epoch: 400 | train_loss: 0.4292 | test_loss: 0.4707 | \n",
      "Epoch: 410 | train_loss: 0.3676 | test_loss: 0.3646 | \n",
      "Epoch: 420 | train_loss: 0.3075 | test_loss: 0.3398 | \n",
      "Epoch: 430 | train_loss: 0.2467 | test_loss: 0.2725 | \n",
      "Epoch: 440 | train_loss: 0.1918 | test_loss: 0.2339 | \n",
      "Epoch: 450 | train_loss: 0.1433 | test_loss: 0.2071 | \n",
      "Epoch: 460 | train_loss: 0.1074 | test_loss: 0.1745 | \n",
      "Epoch: 470 | train_loss: 0.0848 | test_loss: 0.1502 | \n",
      "Epoch: 480 | train_loss: 0.0738 | test_loss: 0.1436 | \n",
      "Epoch: 490 | train_loss: 0.0552 | test_loss: 0.1395 | \n",
      "Epoch: 500 | train_loss: 0.0570 | test_loss: 0.1424 | \n",
      "Epoch: 510 | train_loss: 0.0648 | test_loss: 0.1436 | \n",
      "Epoch: 520 | train_loss: 0.0607 | test_loss: 0.1391 | \n",
      "Epoch: 530 | train_loss: 0.0602 | test_loss: 0.1421 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2641 | test_loss: 9.1107 | \n",
      "Epoch: 10 | train_loss: 6.8846 | test_loss: 6.7980 | \n",
      "Epoch: 20 | train_loss: 5.8666 | test_loss: 5.7921 | \n",
      "Epoch: 30 | train_loss: 5.2522 | test_loss: 5.2272 | \n",
      "Epoch: 40 | train_loss: 4.8133 | test_loss: 4.7755 | \n",
      "Epoch: 50 | train_loss: 4.4671 | test_loss: 4.4492 | \n",
      "Epoch: 60 | train_loss: 4.1832 | test_loss: 4.1499 | \n",
      "Epoch: 70 | train_loss: 3.9340 | test_loss: 3.9069 | \n",
      "Epoch: 80 | train_loss: 3.7167 | test_loss: 3.7003 | \n",
      "Epoch: 90 | train_loss: 3.5217 | test_loss: 3.5043 | \n",
      "Epoch: 100 | train_loss: 3.3440 | test_loss: 3.3256 | \n",
      "Epoch: 110 | train_loss: 3.1811 | test_loss: 3.1476 | \n",
      "Epoch: 120 | train_loss: 3.0289 | test_loss: 3.0139 | \n",
      "Epoch: 130 | train_loss: 2.8863 | test_loss: 2.8900 | \n",
      "Epoch: 140 | train_loss: 2.7517 | test_loss: 2.7273 | \n",
      "Epoch: 150 | train_loss: 2.6240 | test_loss: 2.6100 | \n",
      "Epoch: 160 | train_loss: 2.5024 | test_loss: 2.4851 | \n",
      "Epoch: 170 | train_loss: 2.3871 | test_loss: 2.3762 | \n",
      "Epoch: 180 | train_loss: 2.2735 | test_loss: 2.2505 | \n",
      "Epoch: 190 | train_loss: 2.1666 | test_loss: 2.1455 | \n",
      "Epoch: 200 | train_loss: 2.0630 | test_loss: 2.0359 | \n",
      "Epoch: 210 | train_loss: 1.9630 | test_loss: 1.9438 | \n",
      "Epoch: 220 | train_loss: 1.8658 | test_loss: 1.8419 | \n",
      "Epoch: 230 | train_loss: 1.7710 | test_loss: 1.7397 | \n",
      "Epoch: 240 | train_loss: 1.6792 | test_loss: 1.6675 | \n",
      "Epoch: 250 | train_loss: 1.5895 | test_loss: 1.5968 | \n",
      "Epoch: 260 | train_loss: 1.5013 | test_loss: 1.4836 | \n",
      "Epoch: 270 | train_loss: 1.4154 | test_loss: 1.4199 | \n",
      "Epoch: 280 | train_loss: 1.3322 | test_loss: 1.3402 | \n",
      "Epoch: 290 | train_loss: 1.2500 | test_loss: 1.2541 | \n",
      "Epoch: 300 | train_loss: 1.1689 | test_loss: 1.1583 | \n",
      "Epoch: 310 | train_loss: 1.0901 | test_loss: 1.0945 | \n",
      "Epoch: 320 | train_loss: 1.0138 | test_loss: 0.9912 | \n",
      "Epoch: 330 | train_loss: 0.9373 | test_loss: 0.9286 | \n",
      "Epoch: 340 | train_loss: 0.8649 | test_loss: 0.8417 | \n",
      "Epoch: 350 | train_loss: 0.7909 | test_loss: 0.7913 | \n",
      "Epoch: 360 | train_loss: 0.7192 | test_loss: 0.7288 | \n",
      "Epoch: 370 | train_loss: 0.6479 | test_loss: 0.6570 | \n",
      "Epoch: 380 | train_loss: 0.5802 | test_loss: 0.5985 | \n",
      "Epoch: 390 | train_loss: 0.5124 | test_loss: 0.5347 | \n",
      "Epoch: 400 | train_loss: 0.4482 | test_loss: 0.4738 | \n",
      "Epoch: 410 | train_loss: 0.3855 | test_loss: 0.4029 | \n",
      "Epoch: 420 | train_loss: 0.3225 | test_loss: 0.3525 | \n",
      "Epoch: 430 | train_loss: 0.2657 | test_loss: 0.2877 | \n",
      "Epoch: 440 | train_loss: 0.2062 | test_loss: 0.2447 | \n",
      "Epoch: 450 | train_loss: 0.1526 | test_loss: 0.2245 | \n",
      "Epoch: 460 | train_loss: 0.1111 | test_loss: 0.1774 | \n",
      "Epoch: 470 | train_loss: 0.0895 | test_loss: 0.1515 | \n",
      "Epoch: 480 | train_loss: 0.0710 | test_loss: 0.1437 | \n",
      "Epoch: 490 | train_loss: 0.0551 | test_loss: 0.1479 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3022 | test_loss: 9.0999 | \n",
      "Epoch: 10 | train_loss: 6.8958 | test_loss: 6.8089 | \n",
      "Epoch: 20 | train_loss: 5.8931 | test_loss: 5.8299 | \n",
      "Epoch: 30 | train_loss: 5.2828 | test_loss: 5.2197 | \n",
      "Epoch: 40 | train_loss: 4.8384 | test_loss: 4.7929 | \n",
      "Epoch: 50 | train_loss: 4.4890 | test_loss: 4.4542 | \n",
      "Epoch: 60 | train_loss: 4.2121 | test_loss: 4.1718 | \n",
      "Epoch: 70 | train_loss: 3.9562 | test_loss: 3.9305 | \n",
      "Epoch: 80 | train_loss: 3.7444 | test_loss: 3.7129 | \n",
      "Epoch: 90 | train_loss: 3.5473 | test_loss: 3.5188 | \n",
      "Epoch: 100 | train_loss: 3.3652 | test_loss: 3.3435 | \n",
      "Epoch: 110 | train_loss: 3.2057 | test_loss: 3.1822 | \n",
      "Epoch: 120 | train_loss: 3.0563 | test_loss: 3.0239 | \n",
      "Epoch: 130 | train_loss: 2.9102 | test_loss: 2.8840 | \n",
      "Epoch: 140 | train_loss: 2.7766 | test_loss: 2.7498 | \n",
      "Epoch: 150 | train_loss: 2.6490 | test_loss: 2.6257 | \n",
      "Epoch: 160 | train_loss: 2.5254 | test_loss: 2.5000 | \n",
      "Epoch: 170 | train_loss: 2.4154 | test_loss: 2.3887 | \n",
      "Epoch: 180 | train_loss: 2.3032 | test_loss: 2.2839 | \n",
      "Epoch: 190 | train_loss: 2.1919 | test_loss: 2.1719 | \n",
      "Epoch: 200 | train_loss: 2.0830 | test_loss: 2.0704 | \n",
      "Epoch: 210 | train_loss: 1.9853 | test_loss: 1.9670 | \n",
      "Epoch: 220 | train_loss: 1.8950 | test_loss: 1.8692 | \n",
      "Epoch: 230 | train_loss: 1.7982 | test_loss: 1.7732 | \n",
      "Epoch: 240 | train_loss: 1.7085 | test_loss: 1.6882 | \n",
      "Epoch: 250 | train_loss: 1.6170 | test_loss: 1.6001 | \n",
      "Epoch: 260 | train_loss: 1.5241 | test_loss: 1.5056 | \n",
      "Epoch: 270 | train_loss: 1.4470 | test_loss: 1.4265 | \n",
      "Epoch: 280 | train_loss: 1.3642 | test_loss: 1.3507 | \n",
      "Epoch: 290 | train_loss: 1.2788 | test_loss: 1.2629 | \n",
      "Epoch: 300 | train_loss: 1.1999 | test_loss: 1.1861 | \n",
      "Epoch: 310 | train_loss: 1.1208 | test_loss: 1.1008 | \n",
      "Epoch: 320 | train_loss: 1.0473 | test_loss: 1.0314 | \n",
      "Epoch: 330 | train_loss: 0.9696 | test_loss: 0.9513 | \n",
      "Epoch: 340 | train_loss: 0.8989 | test_loss: 0.8788 | \n",
      "Epoch: 350 | train_loss: 0.8233 | test_loss: 0.8065 | \n",
      "Epoch: 360 | train_loss: 0.7544 | test_loss: 0.7327 | \n",
      "Epoch: 370 | train_loss: 0.6818 | test_loss: 0.6738 | \n",
      "Epoch: 380 | train_loss: 0.6167 | test_loss: 0.6088 | \n",
      "Epoch: 390 | train_loss: 0.5510 | test_loss: 0.5319 | \n",
      "Epoch: 400 | train_loss: 0.4857 | test_loss: 0.4687 | \n",
      "Epoch: 410 | train_loss: 0.4279 | test_loss: 0.4231 | \n",
      "Epoch: 420 | train_loss: 0.3734 | test_loss: 0.3692 | \n",
      "Epoch: 430 | train_loss: 0.3150 | test_loss: 0.3107 | \n",
      "Epoch: 440 | train_loss: 0.2639 | test_loss: 0.2666 | \n",
      "Epoch: 450 | train_loss: 0.2260 | test_loss: 0.2312 | \n",
      "Epoch: 460 | train_loss: 0.1865 | test_loss: 0.1803 | \n",
      "Epoch: 470 | train_loss: 0.1609 | test_loss: 0.1655 | \n",
      "Epoch: 480 | train_loss: 0.1515 | test_loss: 0.1638 | \n",
      "Epoch: 490 | train_loss: 0.1359 | test_loss: 0.1456 | \n",
      "Epoch: 500 | train_loss: 0.1344 | test_loss: 0.1435 | \n",
      "Epoch: 510 | train_loss: 0.1212 | test_loss: 0.1428 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.2735 | test_loss: 9.0218 | \n",
      "Epoch: 10 | train_loss: 6.8770 | test_loss: 6.7864 | \n",
      "Epoch: 20 | train_loss: 5.8682 | test_loss: 5.7933 | \n",
      "Epoch: 30 | train_loss: 5.2556 | test_loss: 5.2063 | \n",
      "Epoch: 40 | train_loss: 4.8258 | test_loss: 4.7753 | \n",
      "Epoch: 50 | train_loss: 4.4792 | test_loss: 4.4378 | \n",
      "Epoch: 60 | train_loss: 4.1902 | test_loss: 4.1521 | \n",
      "Epoch: 70 | train_loss: 3.9351 | test_loss: 3.9139 | \n",
      "Epoch: 80 | train_loss: 3.7162 | test_loss: 3.6880 | \n",
      "Epoch: 90 | train_loss: 3.5218 | test_loss: 3.4948 | \n",
      "Epoch: 100 | train_loss: 3.3487 | test_loss: 3.3222 | \n",
      "Epoch: 110 | train_loss: 3.1818 | test_loss: 3.1568 | \n",
      "Epoch: 120 | train_loss: 3.0306 | test_loss: 3.0111 | \n",
      "Epoch: 130 | train_loss: 2.8907 | test_loss: 2.8637 | \n",
      "Epoch: 140 | train_loss: 2.7589 | test_loss: 2.7270 | \n",
      "Epoch: 150 | train_loss: 2.6257 | test_loss: 2.5985 | \n",
      "Epoch: 160 | train_loss: 2.5100 | test_loss: 2.4788 | \n",
      "Epoch: 170 | train_loss: 2.3943 | test_loss: 2.3612 | \n",
      "Epoch: 180 | train_loss: 2.2813 | test_loss: 2.2617 | \n",
      "Epoch: 190 | train_loss: 2.1765 | test_loss: 2.1485 | \n",
      "Epoch: 200 | train_loss: 2.0661 | test_loss: 2.0439 | \n",
      "Epoch: 210 | train_loss: 1.9717 | test_loss: 1.9383 | \n",
      "Epoch: 220 | train_loss: 1.8775 | test_loss: 1.8495 | \n",
      "Epoch: 230 | train_loss: 1.7782 | test_loss: 1.7513 | \n",
      "Epoch: 240 | train_loss: 1.6877 | test_loss: 1.6567 | \n",
      "Epoch: 250 | train_loss: 1.6006 | test_loss: 1.5717 | \n",
      "Epoch: 260 | train_loss: 1.5113 | test_loss: 1.4823 | \n",
      "Epoch: 270 | train_loss: 1.4313 | test_loss: 1.4022 | \n",
      "Epoch: 280 | train_loss: 1.3452 | test_loss: 1.3225 | \n",
      "Epoch: 290 | train_loss: 1.2615 | test_loss: 1.2378 | \n",
      "Epoch: 300 | train_loss: 1.1887 | test_loss: 1.1585 | \n",
      "Epoch: 310 | train_loss: 1.1052 | test_loss: 1.0815 | \n",
      "Epoch: 320 | train_loss: 1.0271 | test_loss: 1.0016 | \n",
      "Epoch: 330 | train_loss: 0.9560 | test_loss: 0.9363 | \n",
      "Epoch: 340 | train_loss: 0.8820 | test_loss: 0.8647 | \n",
      "Epoch: 350 | train_loss: 0.8104 | test_loss: 0.7842 | \n",
      "Epoch: 360 | train_loss: 0.7392 | test_loss: 0.7206 | \n",
      "Epoch: 370 | train_loss: 0.6785 | test_loss: 0.6560 | \n",
      "Epoch: 380 | train_loss: 0.6033 | test_loss: 0.5934 | \n",
      "Epoch: 390 | train_loss: 0.5341 | test_loss: 0.5263 | \n",
      "Epoch: 400 | train_loss: 0.4746 | test_loss: 0.4700 | \n",
      "Epoch: 410 | train_loss: 0.4243 | test_loss: 0.4107 | \n",
      "Epoch: 420 | train_loss: 0.3637 | test_loss: 0.3610 | \n",
      "Epoch: 430 | train_loss: 0.3068 | test_loss: 0.2935 | \n",
      "Epoch: 440 | train_loss: 0.2541 | test_loss: 0.2563 | \n",
      "Epoch: 450 | train_loss: 0.2191 | test_loss: 0.2114 | \n",
      "Epoch: 460 | train_loss: 0.1827 | test_loss: 0.1790 | \n",
      "Epoch: 470 | train_loss: 0.1598 | test_loss: 0.1602 | \n",
      "Epoch: 480 | train_loss: 0.1402 | test_loss: 0.1518 | \n",
      "Epoch: 490 | train_loss: 0.1279 | test_loss: 0.1403 | \n",
      "Epoch: 500 | train_loss: 0.1218 | test_loss: 0.1438 | \n",
      "Epoch: 510 | train_loss: 0.1188 | test_loss: 0.1394 | \n",
      "Epoch: 520 | train_loss: 0.1251 | test_loss: 0.1390 | \n",
      "Epoch: 530 | train_loss: 0.1247 | test_loss: 0.1385 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.3825 | test_loss: 7.3884 | \n",
      "Epoch: 10 | train_loss: 0.2549 | test_loss: 0.2197 | \n",
      "Epoch: 20 | train_loss: 0.1674 | test_loss: 0.1646 | \n",
      "Epoch: 30 | train_loss: 0.1499 | test_loss: 0.1554 | \n",
      "Epoch: 40 | train_loss: 0.1395 | test_loss: 0.1521 | \n",
      "Epoch: 50 | train_loss: 0.1322 | test_loss: 0.1504 | \n",
      "Epoch: 60 | train_loss: 0.1274 | test_loss: 0.1506 | \n",
      "Epoch: 70 | train_loss: 0.1243 | test_loss: 0.1501 | \n",
      "Epoch: 80 | train_loss: 0.1202 | test_loss: 0.1492 | \n",
      "Epoch: 90 | train_loss: 0.1184 | test_loss: 0.1484 | \n",
      "Epoch: 100 | train_loss: 0.1161 | test_loss: 0.1483 | \n",
      "Epoch: 110 | train_loss: 0.1126 | test_loss: 0.1473 | \n",
      "Epoch: 120 | train_loss: 0.1133 | test_loss: 0.1464 | \n",
      "Epoch: 130 | train_loss: 0.1115 | test_loss: 0.1465 | \n",
      "Epoch: 140 | train_loss: 0.1091 | test_loss: 0.1456 | \n",
      "Epoch: 150 | train_loss: 0.1098 | test_loss: 0.1473 | \n",
      "Epoch: 160 | train_loss: 0.1062 | test_loss: 0.1461 | \n",
      "Epoch: 170 | train_loss: 0.1036 | test_loss: 0.1452 | \n",
      "Epoch: 180 | train_loss: 0.1026 | test_loss: 0.1457 | \n",
      "Epoch: 190 | train_loss: 0.0976 | test_loss: 0.1450 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 8.1622 | test_loss: 4.2957 | \n",
      "Epoch: 10 | train_loss: 0.1756 | test_loss: 0.1730 | \n",
      "Epoch: 20 | train_loss: 0.1357 | test_loss: 0.1508 | \n",
      "Epoch: 30 | train_loss: 0.1249 | test_loss: 0.1482 | \n",
      "Epoch: 40 | train_loss: 0.1168 | test_loss: 0.1463 | \n",
      "Epoch: 50 | train_loss: 0.1113 | test_loss: 0.1460 | \n",
      "Epoch: 60 | train_loss: 0.1055 | test_loss: 0.1472 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 4.9584 | test_loss: 0.5073 | \n",
      "Epoch: 10 | train_loss: 0.1489 | test_loss: 0.1506 | \n",
      "Epoch: 20 | train_loss: 0.1054 | test_loss: 0.1473 | \n",
      "Epoch: 30 | train_loss: 0.0892 | test_loss: 0.1470 | \n",
      "Epoch: 40 | train_loss: 0.0780 | test_loss: 0.1535 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.9333 | test_loss: 9.3037 | \n",
      "Epoch: 10 | train_loss: 7.7464 | test_loss: 7.7055 | \n",
      "Epoch: 20 | train_loss: 6.8385 | test_loss: 6.7879 | \n",
      "Epoch: 30 | train_loss: 6.2619 | test_loss: 6.2411 | \n",
      "Epoch: 40 | train_loss: 5.8461 | test_loss: 5.8126 | \n",
      "Epoch: 50 | train_loss: 5.5215 | test_loss: 5.4858 | \n",
      "Epoch: 60 | train_loss: 5.2527 | test_loss: 5.2241 | \n",
      "Epoch: 70 | train_loss: 5.0222 | test_loss: 5.0008 | \n",
      "Epoch: 80 | train_loss: 4.8168 | test_loss: 4.7932 | \n",
      "Epoch: 90 | train_loss: 4.6371 | test_loss: 4.6120 | \n",
      "Epoch: 100 | train_loss: 4.4735 | test_loss: 4.4328 | \n",
      "Epoch: 110 | train_loss: 4.3222 | test_loss: 4.2945 | \n",
      "Epoch: 120 | train_loss: 4.1841 | test_loss: 4.1724 | \n",
      "Epoch: 130 | train_loss: 4.0566 | test_loss: 4.0476 | \n",
      "Epoch: 140 | train_loss: 3.9383 | test_loss: 3.9243 | \n",
      "Epoch: 150 | train_loss: 3.8253 | test_loss: 3.8073 | \n",
      "Epoch: 160 | train_loss: 3.7203 | test_loss: 3.7058 | \n",
      "Epoch: 170 | train_loss: 3.6241 | test_loss: 3.6169 | \n",
      "Epoch: 180 | train_loss: 3.5259 | test_loss: 3.5301 | \n",
      "Epoch: 190 | train_loss: 3.4329 | test_loss: 3.4215 | \n",
      "Epoch: 200 | train_loss: 3.3455 | test_loss: 3.3264 | \n",
      "Epoch: 210 | train_loss: 3.2618 | test_loss: 3.2463 | \n",
      "Epoch: 220 | train_loss: 3.1822 | test_loss: 3.1668 | \n",
      "Epoch: 230 | train_loss: 3.1061 | test_loss: 3.0944 | \n",
      "Epoch: 240 | train_loss: 3.0310 | test_loss: 3.0205 | \n",
      "Epoch: 250 | train_loss: 2.9584 | test_loss: 2.9463 | \n",
      "Epoch: 260 | train_loss: 2.8888 | test_loss: 2.8717 | \n",
      "Epoch: 270 | train_loss: 2.8205 | test_loss: 2.8064 | \n",
      "Epoch: 280 | train_loss: 2.7536 | test_loss: 2.7361 | \n",
      "Epoch: 290 | train_loss: 2.6893 | test_loss: 2.6819 | \n",
      "Epoch: 300 | train_loss: 2.6285 | test_loss: 2.6188 | \n",
      "Epoch: 310 | train_loss: 2.5665 | test_loss: 2.5540 | \n",
      "Epoch: 320 | train_loss: 2.5055 | test_loss: 2.4896 | \n",
      "Epoch: 330 | train_loss: 2.4486 | test_loss: 2.4314 | \n",
      "Epoch: 340 | train_loss: 2.3899 | test_loss: 2.3809 | \n",
      "Epoch: 350 | train_loss: 2.3348 | test_loss: 2.3160 | \n",
      "Epoch: 360 | train_loss: 2.2791 | test_loss: 2.2667 | \n",
      "Epoch: 370 | train_loss: 2.2254 | test_loss: 2.2170 | \n",
      "Epoch: 380 | train_loss: 2.1723 | test_loss: 2.1656 | \n",
      "Epoch: 390 | train_loss: 2.1206 | test_loss: 2.1109 | \n",
      "Epoch: 400 | train_loss: 2.0699 | test_loss: 2.0585 | \n",
      "Epoch: 410 | train_loss: 2.0182 | test_loss: 2.0122 | \n",
      "Epoch: 420 | train_loss: 1.9696 | test_loss: 1.9644 | \n",
      "Epoch: 430 | train_loss: 1.9224 | test_loss: 1.9096 | \n",
      "Epoch: 440 | train_loss: 1.8722 | test_loss: 1.8684 | \n",
      "Epoch: 450 | train_loss: 1.8252 | test_loss: 1.8188 | \n",
      "Epoch: 460 | train_loss: 1.7789 | test_loss: 1.7783 | \n",
      "Epoch: 470 | train_loss: 1.7325 | test_loss: 1.7317 | \n",
      "Epoch: 480 | train_loss: 1.6855 | test_loss: 1.6824 | \n",
      "Epoch: 490 | train_loss: 1.6483 | test_loss: 1.6252 | \n",
      "Epoch: 500 | train_loss: 1.5973 | test_loss: 1.5830 | \n",
      "Epoch: 510 | train_loss: 1.5541 | test_loss: 1.5354 | \n",
      "Epoch: 520 | train_loss: 1.5092 | test_loss: 1.4959 | \n",
      "Epoch: 530 | train_loss: 1.4670 | test_loss: 1.4565 | \n",
      "Epoch: 540 | train_loss: 1.4240 | test_loss: 1.4251 | \n",
      "Epoch: 550 | train_loss: 1.3829 | test_loss: 1.3828 | \n",
      "Epoch: 560 | train_loss: 1.3406 | test_loss: 1.3378 | \n",
      "Epoch: 570 | train_loss: 1.3015 | test_loss: 1.3056 | \n",
      "Epoch: 580 | train_loss: 1.2581 | test_loss: 1.2491 | \n",
      "Epoch: 590 | train_loss: 1.2187 | test_loss: 1.2162 | \n",
      "Epoch: 600 | train_loss: 1.1792 | test_loss: 1.1782 | \n",
      "Epoch: 610 | train_loss: 1.1391 | test_loss: 1.1283 | \n",
      "Epoch: 620 | train_loss: 1.1000 | test_loss: 1.1100 | \n",
      "Epoch: 630 | train_loss: 1.0597 | test_loss: 1.0602 | \n",
      "Epoch: 640 | train_loss: 1.0199 | test_loss: 1.0188 | \n",
      "Epoch: 650 | train_loss: 0.9878 | test_loss: 0.9809 | \n",
      "Epoch: 660 | train_loss: 0.9450 | test_loss: 0.9487 | \n",
      "Epoch: 670 | train_loss: 0.9068 | test_loss: 0.9060 | \n",
      "Epoch: 680 | train_loss: 0.8704 | test_loss: 0.8664 | \n",
      "Epoch: 690 | train_loss: 0.8346 | test_loss: 0.8325 | \n",
      "Epoch: 700 | train_loss: 0.7970 | test_loss: 0.7961 | \n",
      "Epoch: 710 | train_loss: 0.7611 | test_loss: 0.7615 | \n",
      "Epoch: 720 | train_loss: 0.7246 | test_loss: 0.7193 | \n",
      "Epoch: 730 | train_loss: 0.6887 | test_loss: 0.6934 | \n",
      "Epoch: 740 | train_loss: 0.6541 | test_loss: 0.6605 | \n",
      "Epoch: 750 | train_loss: 0.6202 | test_loss: 0.6167 | \n",
      "Epoch: 760 | train_loss: 0.5852 | test_loss: 0.5905 | \n",
      "Epoch: 770 | train_loss: 0.5511 | test_loss: 0.5565 | \n",
      "Epoch: 780 | train_loss: 0.5180 | test_loss: 0.5311 | \n",
      "Epoch: 790 | train_loss: 0.4860 | test_loss: 0.5083 | \n",
      "Epoch: 800 | train_loss: 0.4561 | test_loss: 0.4782 | \n",
      "Epoch: 810 | train_loss: 0.4193 | test_loss: 0.4301 | \n",
      "Epoch: 820 | train_loss: 0.3872 | test_loss: 0.4049 | \n",
      "Epoch: 830 | train_loss: 0.3556 | test_loss: 0.3745 | \n",
      "Epoch: 840 | train_loss: 0.3243 | test_loss: 0.3497 | \n",
      "Epoch: 850 | train_loss: 0.2939 | test_loss: 0.3234 | \n",
      "Epoch: 860 | train_loss: 0.2643 | test_loss: 0.2950 | \n",
      "Epoch: 870 | train_loss: 0.2352 | test_loss: 0.2761 | \n",
      "Epoch: 880 | train_loss: 0.2063 | test_loss: 0.2482 | \n",
      "Epoch: 890 | train_loss: 0.1780 | test_loss: 0.2143 | \n",
      "Epoch: 900 | train_loss: 0.1518 | test_loss: 0.2020 | \n",
      "Epoch: 910 | train_loss: 0.1258 | test_loss: 0.1903 | \n",
      "Epoch: 920 | train_loss: 0.1072 | test_loss: 0.1853 | \n",
      "Epoch: 930 | train_loss: 0.0869 | test_loss: 0.1765 | \n",
      "Epoch: 940 | train_loss: 0.0644 | test_loss: 0.1514 | \n",
      "Epoch: 950 | train_loss: 0.0611 | test_loss: 0.1503 | \n",
      "Epoch: 960 | train_loss: 0.0524 | test_loss: 0.1476 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8592 | test_loss: 9.3225 | \n",
      "Epoch: 10 | train_loss: 7.7453 | test_loss: 7.6938 | \n",
      "Epoch: 20 | train_loss: 6.8465 | test_loss: 6.8031 | \n",
      "Epoch: 30 | train_loss: 6.2645 | test_loss: 6.2664 | \n",
      "Epoch: 40 | train_loss: 5.8481 | test_loss: 5.7818 | \n",
      "Epoch: 50 | train_loss: 5.5181 | test_loss: 5.4942 | \n",
      "Epoch: 60 | train_loss: 5.2433 | test_loss: 5.2296 | \n",
      "Epoch: 70 | train_loss: 5.0120 | test_loss: 4.9812 | \n",
      "Epoch: 80 | train_loss: 4.8122 | test_loss: 4.7864 | \n",
      "Epoch: 90 | train_loss: 4.6297 | test_loss: 4.6001 | \n",
      "Epoch: 100 | train_loss: 4.4641 | test_loss: 4.4498 | \n",
      "Epoch: 110 | train_loss: 4.3172 | test_loss: 4.2911 | \n",
      "Epoch: 120 | train_loss: 4.1777 | test_loss: 4.1606 | \n",
      "Epoch: 130 | train_loss: 4.0496 | test_loss: 4.0161 | \n",
      "Epoch: 140 | train_loss: 3.9334 | test_loss: 3.9221 | \n",
      "Epoch: 150 | train_loss: 3.8218 | test_loss: 3.8151 | \n",
      "Epoch: 160 | train_loss: 3.7160 | test_loss: 3.6898 | \n",
      "Epoch: 170 | train_loss: 3.6170 | test_loss: 3.6163 | \n",
      "Epoch: 180 | train_loss: 3.5221 | test_loss: 3.5161 | \n",
      "Epoch: 190 | train_loss: 3.4300 | test_loss: 3.4179 | \n",
      "Epoch: 200 | train_loss: 3.3426 | test_loss: 3.3310 | \n",
      "Epoch: 210 | train_loss: 3.2588 | test_loss: 3.2464 | \n",
      "Epoch: 220 | train_loss: 3.1797 | test_loss: 3.1621 | \n",
      "Epoch: 230 | train_loss: 3.1024 | test_loss: 3.0824 | \n",
      "Epoch: 240 | train_loss: 3.0284 | test_loss: 3.0000 | \n",
      "Epoch: 250 | train_loss: 2.9563 | test_loss: 2.9538 | \n",
      "Epoch: 260 | train_loss: 2.8856 | test_loss: 2.8696 | \n",
      "Epoch: 270 | train_loss: 2.8225 | test_loss: 2.8251 | \n",
      "Epoch: 280 | train_loss: 2.7523 | test_loss: 2.7365 | \n",
      "Epoch: 290 | train_loss: 2.6879 | test_loss: 2.6777 | \n",
      "Epoch: 300 | train_loss: 2.6249 | test_loss: 2.6157 | \n",
      "Epoch: 310 | train_loss: 2.5637 | test_loss: 2.5423 | \n",
      "Epoch: 320 | train_loss: 2.5042 | test_loss: 2.4876 | \n",
      "Epoch: 330 | train_loss: 2.4485 | test_loss: 2.4335 | \n",
      "Epoch: 340 | train_loss: 2.3894 | test_loss: 2.3858 | \n",
      "Epoch: 350 | train_loss: 2.3322 | test_loss: 2.3284 | \n",
      "Epoch: 360 | train_loss: 2.2781 | test_loss: 2.2635 | \n",
      "Epoch: 370 | train_loss: 2.2243 | test_loss: 2.2114 | \n",
      "Epoch: 380 | train_loss: 2.1709 | test_loss: 2.1545 | \n",
      "Epoch: 390 | train_loss: 2.1198 | test_loss: 2.1065 | \n",
      "Epoch: 400 | train_loss: 2.0668 | test_loss: 2.0557 | \n",
      "Epoch: 410 | train_loss: 2.0168 | test_loss: 2.0075 | \n",
      "Epoch: 420 | train_loss: 1.9682 | test_loss: 1.9562 | \n",
      "Epoch: 430 | train_loss: 1.9191 | test_loss: 1.9098 | \n",
      "Epoch: 440 | train_loss: 1.8694 | test_loss: 1.8627 | \n",
      "Epoch: 450 | train_loss: 1.8237 | test_loss: 1.8151 | \n",
      "Epoch: 460 | train_loss: 1.7772 | test_loss: 1.7838 | \n",
      "Epoch: 470 | train_loss: 1.7301 | test_loss: 1.7167 | \n",
      "Epoch: 480 | train_loss: 1.6853 | test_loss: 1.6669 | \n",
      "Epoch: 490 | train_loss: 1.6423 | test_loss: 1.6336 | \n",
      "Epoch: 500 | train_loss: 1.5958 | test_loss: 1.5873 | \n",
      "Epoch: 510 | train_loss: 1.5512 | test_loss: 1.5491 | \n",
      "Epoch: 520 | train_loss: 1.5078 | test_loss: 1.4969 | \n",
      "Epoch: 530 | train_loss: 1.4647 | test_loss: 1.4485 | \n",
      "Epoch: 540 | train_loss: 1.4235 | test_loss: 1.4089 | \n",
      "Epoch: 550 | train_loss: 1.3808 | test_loss: 1.3713 | \n",
      "Epoch: 560 | train_loss: 1.3389 | test_loss: 1.3221 | \n",
      "Epoch: 570 | train_loss: 1.2979 | test_loss: 1.2783 | \n",
      "Epoch: 580 | train_loss: 1.2575 | test_loss: 1.2551 | \n",
      "Epoch: 590 | train_loss: 1.2153 | test_loss: 1.2063 | \n",
      "Epoch: 600 | train_loss: 1.1763 | test_loss: 1.1652 | \n",
      "Epoch: 610 | train_loss: 1.1366 | test_loss: 1.1336 | \n",
      "Epoch: 620 | train_loss: 1.0978 | test_loss: 1.1075 | \n",
      "Epoch: 630 | train_loss: 1.0583 | test_loss: 1.0498 | \n",
      "Epoch: 640 | train_loss: 1.0195 | test_loss: 1.0074 | \n",
      "Epoch: 650 | train_loss: 0.9805 | test_loss: 0.9859 | \n",
      "Epoch: 660 | train_loss: 0.9450 | test_loss: 0.9413 | \n",
      "Epoch: 670 | train_loss: 0.9064 | test_loss: 0.9157 | \n",
      "Epoch: 680 | train_loss: 0.8713 | test_loss: 0.8941 | \n",
      "Epoch: 690 | train_loss: 0.8334 | test_loss: 0.8212 | \n",
      "Epoch: 700 | train_loss: 0.8044 | test_loss: 0.8204 | \n",
      "Epoch: 710 | train_loss: 0.7672 | test_loss: 0.7817 | \n",
      "Epoch: 720 | train_loss: 0.7291 | test_loss: 0.7505 | \n",
      "Epoch: 730 | train_loss: 0.6931 | test_loss: 0.6951 | \n",
      "Epoch: 740 | train_loss: 0.6572 | test_loss: 0.6673 | \n",
      "Epoch: 750 | train_loss: 0.6223 | test_loss: 0.6315 | \n",
      "Epoch: 760 | train_loss: 0.5885 | test_loss: 0.5932 | \n",
      "Epoch: 770 | train_loss: 0.5565 | test_loss: 0.5641 | \n",
      "Epoch: 780 | train_loss: 0.5222 | test_loss: 0.5395 | \n",
      "Epoch: 790 | train_loss: 0.4886 | test_loss: 0.5003 | \n",
      "Epoch: 800 | train_loss: 0.4563 | test_loss: 0.4669 | \n",
      "Epoch: 810 | train_loss: 0.4230 | test_loss: 0.4425 | \n",
      "Epoch: 820 | train_loss: 0.3924 | test_loss: 0.4170 | \n",
      "Epoch: 830 | train_loss: 0.3603 | test_loss: 0.3880 | \n",
      "Epoch: 840 | train_loss: 0.3296 | test_loss: 0.3564 | \n",
      "Epoch: 850 | train_loss: 0.2996 | test_loss: 0.3355 | \n",
      "Epoch: 860 | train_loss: 0.2706 | test_loss: 0.2975 | \n",
      "Epoch: 870 | train_loss: 0.2420 | test_loss: 0.2888 | \n",
      "Epoch: 880 | train_loss: 0.2103 | test_loss: 0.2531 | \n",
      "Epoch: 890 | train_loss: 0.1838 | test_loss: 0.2328 | \n",
      "Epoch: 900 | train_loss: 0.1585 | test_loss: 0.2003 | \n",
      "Epoch: 910 | train_loss: 0.1328 | test_loss: 0.2050 | \n",
      "Epoch: 920 | train_loss: 0.1118 | test_loss: 0.1796 | \n",
      "Epoch: 930 | train_loss: 0.0877 | test_loss: 0.1613 | \n",
      "Epoch: 940 | train_loss: 0.0780 | test_loss: 0.1542 | \n",
      "Epoch: 950 | train_loss: 0.0643 | test_loss: 0.1517 | \n",
      "Epoch: 960 | train_loss: 0.0591 | test_loss: 0.1550 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.8868 | test_loss: 10.0846 | \n",
      "Epoch: 10 | train_loss: 7.7574 | test_loss: 7.6734 | \n",
      "Epoch: 20 | train_loss: 6.8674 | test_loss: 6.8096 | \n",
      "Epoch: 30 | train_loss: 6.2981 | test_loss: 6.2500 | \n",
      "Epoch: 40 | train_loss: 5.8738 | test_loss: 5.8356 | \n",
      "Epoch: 50 | train_loss: 5.5380 | test_loss: 5.4971 | \n",
      "Epoch: 60 | train_loss: 5.2666 | test_loss: 5.2299 | \n",
      "Epoch: 70 | train_loss: 5.0283 | test_loss: 5.0005 | \n",
      "Epoch: 80 | train_loss: 4.8260 | test_loss: 4.7915 | \n",
      "Epoch: 90 | train_loss: 4.6565 | test_loss: 4.6206 | \n",
      "Epoch: 100 | train_loss: 4.4812 | test_loss: 4.4533 | \n",
      "Epoch: 110 | train_loss: 4.3353 | test_loss: 4.3071 | \n",
      "Epoch: 120 | train_loss: 4.1909 | test_loss: 4.1748 | \n",
      "Epoch: 130 | train_loss: 4.0712 | test_loss: 4.0449 | \n",
      "Epoch: 140 | train_loss: 3.9500 | test_loss: 3.9291 | \n",
      "Epoch: 150 | train_loss: 3.8405 | test_loss: 3.8178 | \n",
      "Epoch: 160 | train_loss: 3.7327 | test_loss: 3.7148 | \n",
      "Epoch: 170 | train_loss: 3.6337 | test_loss: 3.6149 | \n",
      "Epoch: 180 | train_loss: 3.5378 | test_loss: 3.5158 | \n",
      "Epoch: 190 | train_loss: 3.4440 | test_loss: 3.4264 | \n",
      "Epoch: 200 | train_loss: 3.3575 | test_loss: 3.3384 | \n",
      "Epoch: 210 | train_loss: 3.2742 | test_loss: 3.2569 | \n",
      "Epoch: 220 | train_loss: 3.1962 | test_loss: 3.1781 | \n",
      "Epoch: 230 | train_loss: 3.1178 | test_loss: 3.0999 | \n",
      "Epoch: 240 | train_loss: 3.0445 | test_loss: 3.0258 | \n",
      "Epoch: 250 | train_loss: 2.9719 | test_loss: 2.9556 | \n",
      "Epoch: 260 | train_loss: 2.8995 | test_loss: 2.8893 | \n",
      "Epoch: 270 | train_loss: 2.8311 | test_loss: 2.8128 | \n",
      "Epoch: 280 | train_loss: 2.7687 | test_loss: 2.7458 | \n",
      "Epoch: 290 | train_loss: 2.7028 | test_loss: 2.6831 | \n",
      "Epoch: 300 | train_loss: 2.6427 | test_loss: 2.6195 | \n",
      "Epoch: 310 | train_loss: 2.5755 | test_loss: 2.5601 | \n",
      "Epoch: 320 | train_loss: 2.5177 | test_loss: 2.5061 | \n",
      "Epoch: 330 | train_loss: 2.4619 | test_loss: 2.4459 | \n",
      "Epoch: 340 | train_loss: 2.4040 | test_loss: 2.3875 | \n",
      "Epoch: 350 | train_loss: 2.3508 | test_loss: 2.3319 | \n",
      "Epoch: 360 | train_loss: 2.2890 | test_loss: 2.2743 | \n",
      "Epoch: 370 | train_loss: 2.2379 | test_loss: 2.2245 | \n",
      "Epoch: 380 | train_loss: 2.1869 | test_loss: 2.1641 | \n",
      "Epoch: 390 | train_loss: 2.1334 | test_loss: 2.1157 | \n",
      "Epoch: 400 | train_loss: 2.0804 | test_loss: 2.0633 | \n",
      "Epoch: 410 | train_loss: 2.0367 | test_loss: 2.0140 | \n",
      "Epoch: 420 | train_loss: 1.9813 | test_loss: 1.9605 | \n",
      "Epoch: 430 | train_loss: 1.9354 | test_loss: 1.9156 | \n",
      "Epoch: 440 | train_loss: 1.8852 | test_loss: 1.8687 | \n",
      "Epoch: 450 | train_loss: 1.8434 | test_loss: 1.8235 | \n",
      "Epoch: 460 | train_loss: 1.7920 | test_loss: 1.7743 | \n",
      "Epoch: 470 | train_loss: 1.7501 | test_loss: 1.7278 | \n",
      "Epoch: 480 | train_loss: 1.6975 | test_loss: 1.6823 | \n",
      "Epoch: 490 | train_loss: 1.6515 | test_loss: 1.6365 | \n",
      "Epoch: 500 | train_loss: 1.6093 | test_loss: 1.5966 | \n",
      "Epoch: 510 | train_loss: 1.5632 | test_loss: 1.5501 | \n",
      "Epoch: 520 | train_loss: 1.5224 | test_loss: 1.5102 | \n",
      "Epoch: 530 | train_loss: 1.4813 | test_loss: 1.4665 | \n",
      "Epoch: 540 | train_loss: 1.4376 | test_loss: 1.4218 | \n",
      "Epoch: 550 | train_loss: 1.3925 | test_loss: 1.3805 | \n",
      "Epoch: 560 | train_loss: 1.3563 | test_loss: 1.3424 | \n",
      "Epoch: 570 | train_loss: 1.3111 | test_loss: 1.3006 | \n",
      "Epoch: 580 | train_loss: 1.2688 | test_loss: 1.2569 | \n",
      "Epoch: 590 | train_loss: 1.2376 | test_loss: 1.2161 | \n",
      "Epoch: 600 | train_loss: 1.1944 | test_loss: 1.1862 | \n",
      "Epoch: 610 | train_loss: 1.1531 | test_loss: 1.1344 | \n",
      "Epoch: 620 | train_loss: 1.1136 | test_loss: 1.1062 | \n",
      "Epoch: 630 | train_loss: 1.0782 | test_loss: 1.0617 | \n",
      "Epoch: 640 | train_loss: 1.0389 | test_loss: 1.0223 | \n",
      "Epoch: 650 | train_loss: 1.0014 | test_loss: 0.9876 | \n",
      "Epoch: 660 | train_loss: 0.9592 | test_loss: 0.9483 | \n",
      "Epoch: 670 | train_loss: 0.9280 | test_loss: 0.9107 | \n",
      "Epoch: 680 | train_loss: 0.8940 | test_loss: 0.8937 | \n",
      "Epoch: 690 | train_loss: 0.8541 | test_loss: 0.8381 | \n",
      "Epoch: 700 | train_loss: 0.8203 | test_loss: 0.8112 | \n",
      "Epoch: 710 | train_loss: 0.7815 | test_loss: 0.7755 | \n",
      "Epoch: 720 | train_loss: 0.7480 | test_loss: 0.7400 | \n",
      "Epoch: 730 | train_loss: 0.7139 | test_loss: 0.7039 | \n",
      "Epoch: 740 | train_loss: 0.6773 | test_loss: 0.6733 | \n",
      "Epoch: 750 | train_loss: 0.6443 | test_loss: 0.6394 | \n",
      "Epoch: 760 | train_loss: 0.6128 | test_loss: 0.6060 | \n",
      "Epoch: 770 | train_loss: 0.5775 | test_loss: 0.5716 | \n",
      "Epoch: 780 | train_loss: 0.5458 | test_loss: 0.5392 | \n",
      "Epoch: 790 | train_loss: 0.5155 | test_loss: 0.5151 | \n",
      "Epoch: 800 | train_loss: 0.4872 | test_loss: 0.4788 | \n",
      "Epoch: 810 | train_loss: 0.4487 | test_loss: 0.4440 | \n",
      "Epoch: 820 | train_loss: 0.4229 | test_loss: 0.4158 | \n",
      "Epoch: 830 | train_loss: 0.3906 | test_loss: 0.3901 | \n",
      "Epoch: 840 | train_loss: 0.3647 | test_loss: 0.3637 | \n",
      "Epoch: 850 | train_loss: 0.3336 | test_loss: 0.3373 | \n",
      "Epoch: 860 | train_loss: 0.3076 | test_loss: 0.3150 | \n",
      "Epoch: 870 | train_loss: 0.2796 | test_loss: 0.2889 | \n",
      "Epoch: 880 | train_loss: 0.2496 | test_loss: 0.2613 | \n",
      "Epoch: 890 | train_loss: 0.2354 | test_loss: 0.2410 | \n",
      "Epoch: 900 | train_loss: 0.2108 | test_loss: 0.2182 | \n",
      "Epoch: 910 | train_loss: 0.1894 | test_loss: 0.1972 | \n",
      "Epoch: 920 | train_loss: 0.1728 | test_loss: 0.1825 | \n",
      "Epoch: 930 | train_loss: 0.1590 | test_loss: 0.1771 | \n",
      "Epoch: 940 | train_loss: 0.1434 | test_loss: 0.1679 | \n",
      "Epoch: 950 | train_loss: 0.1371 | test_loss: 0.1597 | \n",
      "Epoch: 960 | train_loss: 0.1269 | test_loss: 0.1505 | \n",
      "Epoch: 970 | train_loss: 0.1234 | test_loss: 0.1469 | \n",
      "Epoch: 980 | train_loss: 0.1104 | test_loss: 0.1423 | \n",
      "Epoch: 990 | train_loss: 0.1124 | test_loss: 0.1493 | \n",
      "Early stopping: No improvement in 15 epochs.\n",
      "Epoch: 1 | train_loss: 10.9043 | test_loss: 9.5941 | \n",
      "Epoch: 10 | train_loss: 7.7561 | test_loss: 7.6715 | \n",
      "Epoch: 20 | train_loss: 6.8656 | test_loss: 6.8060 | \n",
      "Epoch: 30 | train_loss: 6.2949 | test_loss: 6.2304 | \n",
      "Epoch: 40 | train_loss: 5.8638 | test_loss: 5.8025 | \n",
      "Epoch: 50 | train_loss: 5.5342 | test_loss: 5.4917 | \n",
      "Epoch: 60 | train_loss: 5.2601 | test_loss: 5.2140 | \n",
      "Epoch: 70 | train_loss: 5.0282 | test_loss: 4.9925 | \n",
      "Epoch: 80 | train_loss: 4.8283 | test_loss: 4.7845 | \n",
      "Epoch: 90 | train_loss: 4.6392 | test_loss: 4.6066 | \n",
      "Epoch: 100 | train_loss: 4.4768 | test_loss: 4.4486 | \n",
      "Epoch: 110 | train_loss: 4.3296 | test_loss: 4.3032 | \n",
      "Epoch: 120 | train_loss: 4.1872 | test_loss: 4.1623 | \n",
      "Epoch: 130 | train_loss: 4.0634 | test_loss: 4.0386 | \n",
      "Epoch: 140 | train_loss: 3.9475 | test_loss: 3.9237 | \n",
      "Epoch: 150 | train_loss: 3.8340 | test_loss: 3.8057 | \n",
      "Epoch: 160 | train_loss: 3.7267 | test_loss: 3.7002 | \n",
      "Epoch: 170 | train_loss: 3.6247 | test_loss: 3.6052 | \n",
      "Epoch: 180 | train_loss: 3.5346 | test_loss: 3.5110 | \n",
      "Epoch: 190 | train_loss: 3.4397 | test_loss: 3.4176 | \n",
      "Epoch: 200 | train_loss: 3.3540 | test_loss: 3.3305 | \n",
      "Epoch: 210 | train_loss: 3.2671 | test_loss: 3.2510 | \n",
      "Epoch: 220 | train_loss: 3.1896 | test_loss: 3.1669 | \n",
      "Epoch: 230 | train_loss: 3.1108 | test_loss: 3.0962 | \n",
      "Epoch: 240 | train_loss: 3.0369 | test_loss: 3.0199 | \n",
      "Epoch: 250 | train_loss: 2.9665 | test_loss: 2.9420 | \n",
      "Epoch: 260 | train_loss: 2.8938 | test_loss: 2.8762 | \n",
      "Epoch: 270 | train_loss: 2.8264 | test_loss: 2.8083 | \n",
      "Epoch: 280 | train_loss: 2.7617 | test_loss: 2.7446 | \n",
      "Epoch: 290 | train_loss: 2.6953 | test_loss: 2.6800 | \n",
      "Epoch: 300 | train_loss: 2.6309 | test_loss: 2.6157 | \n",
      "Epoch: 310 | train_loss: 2.5739 | test_loss: 2.5511 | \n",
      "Epoch: 320 | train_loss: 2.5117 | test_loss: 2.4934 | \n",
      "Epoch: 330 | train_loss: 2.4573 | test_loss: 2.4397 | \n",
      "Epoch: 340 | train_loss: 2.3949 | test_loss: 2.3800 | \n",
      "Epoch: 350 | train_loss: 2.3481 | test_loss: 2.3249 | \n",
      "Epoch: 360 | train_loss: 2.2856 | test_loss: 2.2655 | \n",
      "Epoch: 370 | train_loss: 2.2304 | test_loss: 2.2200 | \n",
      "Epoch: 380 | train_loss: 2.1795 | test_loss: 2.1638 | \n",
      "Epoch: 390 | train_loss: 2.1309 | test_loss: 2.1097 | \n",
      "Epoch: 400 | train_loss: 2.0769 | test_loss: 2.0629 | \n",
      "Epoch: 410 | train_loss: 2.0266 | test_loss: 2.0131 | \n",
      "Epoch: 420 | train_loss: 1.9810 | test_loss: 1.9607 | \n",
      "Epoch: 430 | train_loss: 1.9285 | test_loss: 1.9110 | \n",
      "Epoch: 440 | train_loss: 1.8783 | test_loss: 1.8681 | \n",
      "Epoch: 450 | train_loss: 1.8276 | test_loss: 1.8156 | \n",
      "Epoch: 460 | train_loss: 1.7900 | test_loss: 1.7718 | \n",
      "Epoch: 470 | train_loss: 1.7412 | test_loss: 1.7247 | \n",
      "Epoch: 480 | train_loss: 1.6894 | test_loss: 1.6769 | \n",
      "Epoch: 490 | train_loss: 1.6502 | test_loss: 1.6334 | \n",
      "Epoch: 500 | train_loss: 1.6061 | test_loss: 1.5898 | \n",
      "Epoch: 510 | train_loss: 1.5565 | test_loss: 1.5482 | \n",
      "Epoch: 520 | train_loss: 1.5158 | test_loss: 1.5016 | \n",
      "Epoch: 530 | train_loss: 1.4768 | test_loss: 1.4603 | \n",
      "Epoch: 540 | train_loss: 1.4358 | test_loss: 1.4186 | \n",
      "Epoch: 550 | train_loss: 1.3921 | test_loss: 1.3773 | \n",
      "Epoch: 560 | train_loss: 1.3514 | test_loss: 1.3378 | \n",
      "Epoch: 570 | train_loss: 1.3107 | test_loss: 1.2952 | \n",
      "Epoch: 580 | train_loss: 1.2670 | test_loss: 1.2485 | \n",
      "Epoch: 590 | train_loss: 1.2296 | test_loss: 1.2184 | \n",
      "Epoch: 600 | train_loss: 1.1904 | test_loss: 1.1767 | \n",
      "Epoch: 610 | train_loss: 1.1491 | test_loss: 1.1369 | \n",
      "Epoch: 620 | train_loss: 1.1102 | test_loss: 1.0955 | \n",
      "Epoch: 630 | train_loss: 1.0746 | test_loss: 1.0621 | \n",
      "Epoch: 640 | train_loss: 1.0335 | test_loss: 1.0239 | \n",
      "Epoch: 650 | train_loss: 0.9979 | test_loss: 0.9818 | \n",
      "Epoch: 660 | train_loss: 0.9598 | test_loss: 0.9482 | \n",
      "Epoch: 670 | train_loss: 0.9203 | test_loss: 0.9217 | \n",
      "Epoch: 680 | train_loss: 0.8846 | test_loss: 0.8770 | \n",
      "Epoch: 690 | train_loss: 0.8536 | test_loss: 0.8402 | \n",
      "Epoch: 700 | train_loss: 0.8101 | test_loss: 0.8073 | \n",
      "Epoch: 710 | train_loss: 0.7799 | test_loss: 0.7645 | \n",
      "Epoch: 720 | train_loss: 0.7431 | test_loss: 0.7326 | \n",
      "Epoch: 730 | train_loss: 0.7056 | test_loss: 0.6997 | \n",
      "Epoch: 740 | train_loss: 0.6713 | test_loss: 0.6674 | \n",
      "Epoch: 750 | train_loss: 0.6419 | test_loss: 0.6228 | \n",
      "Epoch: 760 | train_loss: 0.6090 | test_loss: 0.5924 | \n",
      "Epoch: 770 | train_loss: 0.5752 | test_loss: 0.5678 | \n",
      "Epoch: 780 | train_loss: 0.5429 | test_loss: 0.5435 | \n",
      "Epoch: 790 | train_loss: 0.5084 | test_loss: 0.5075 | \n",
      "Epoch: 800 | train_loss: 0.4776 | test_loss: 0.4755 | \n",
      "Epoch: 810 | train_loss: 0.4496 | test_loss: 0.4459 | \n",
      "Epoch: 820 | train_loss: 0.4185 | test_loss: 0.4160 | \n",
      "Epoch: 830 | train_loss: 0.3900 | test_loss: 0.3891 | \n",
      "Epoch: 840 | train_loss: 0.3577 | test_loss: 0.3591 | \n",
      "Epoch: 850 | train_loss: 0.3318 | test_loss: 0.3389 | \n",
      "Epoch: 860 | train_loss: 0.3017 | test_loss: 0.3115 | \n",
      "Epoch: 870 | train_loss: 0.2733 | test_loss: 0.2824 | \n",
      "Epoch: 880 | train_loss: 0.2521 | test_loss: 0.2739 | \n",
      "Epoch: 890 | train_loss: 0.2257 | test_loss: 0.2329 | \n",
      "Epoch: 900 | train_loss: 0.2074 | test_loss: 0.2227 | \n",
      "Epoch: 910 | train_loss: 0.1795 | test_loss: 0.2025 | \n",
      "Epoch: 920 | train_loss: 0.1709 | test_loss: 0.1818 | \n",
      "Epoch: 930 | train_loss: 0.1508 | test_loss: 0.1731 | \n",
      "Epoch: 940 | train_loss: 0.1400 | test_loss: 0.1614 | \n",
      "Epoch: 950 | train_loss: 0.1324 | test_loss: 0.1562 | \n",
      "Epoch: 960 | train_loss: 0.1233 | test_loss: 0.1500 | \n",
      "Epoch: 970 | train_loss: 0.1115 | test_loss: 0.1445 | \n",
      "Epoch: 980 | train_loss: 0.1066 | test_loss: 0.1398 | \n",
      "Epoch: 990 | train_loss: 0.1089 | test_loss: 0.1421 | \n",
      "Early stopping: No improvement in 15 epochs.\n"
     ]
    }
   ],
   "source": [
    "for top_n_feature in range(60,160,10):\n",
    "    for batch_size in [32,64,128]:\n",
    "        for model_number in [0,1,2,3,4,5,6]:\n",
    "            train_a_model(\n",
    "                top_n_feature,\n",
    "                batch_size,\n",
    "                model_number,\n",
    "                show_plots=False,\n",
    "                append_result_list=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>weight_init</th>\n",
       "      <th>input_size</th>\n",
       "      <th>hidden_sizes</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>run_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FeedFowardModel5</td>\n",
       "      <td>normal</td>\n",
       "      <td>70</td>\n",
       "      <td>[500, 2000, 2000, 200]</td>\n",
       "      <td>128</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.107549</td>\n",
       "      <td>0.133403</td>\n",
       "      <td>17.924668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FeedFowardModel5</td>\n",
       "      <td>normal</td>\n",
       "      <td>60</td>\n",
       "      <td>[500, 1000, 1000, 200]</td>\n",
       "      <td>64</td>\n",
       "      <td>525</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.133850</td>\n",
       "      <td>0.134132</td>\n",
       "      <td>8.701421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>FeedFowardModel5</td>\n",
       "      <td>normal</td>\n",
       "      <td>100</td>\n",
       "      <td>[500, 2000, 2000, 200]</td>\n",
       "      <td>128</td>\n",
       "      <td>1031</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.107312</td>\n",
       "      <td>0.134468</td>\n",
       "      <td>18.445971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>FeedFowardModel5</td>\n",
       "      <td>normal</td>\n",
       "      <td>110</td>\n",
       "      <td>[500, 1000, 1000, 200]</td>\n",
       "      <td>64</td>\n",
       "      <td>534</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.113407</td>\n",
       "      <td>0.134754</td>\n",
       "      <td>8.955775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FeedFowardModel1</td>\n",
       "      <td>normal</td>\n",
       "      <td>80</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>32</td>\n",
       "      <td>78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.099846</td>\n",
       "      <td>0.134981</td>\n",
       "      <td>1.307419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FeedFowardModel4</td>\n",
       "      <td>normal</td>\n",
       "      <td>70</td>\n",
       "      <td>[500, 1000, 1000, 200]</td>\n",
       "      <td>128</td>\n",
       "      <td>968</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>0.135125</td>\n",
       "      <td>9.244148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>FeedFowardModel5</td>\n",
       "      <td>normal</td>\n",
       "      <td>100</td>\n",
       "      <td>[500, 1000, 1000, 200]</td>\n",
       "      <td>32</td>\n",
       "      <td>283</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.146707</td>\n",
       "      <td>0.135146</td>\n",
       "      <td>8.601537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>FeedFowardModel4</td>\n",
       "      <td>normal</td>\n",
       "      <td>70</td>\n",
       "      <td>[500, 2000, 2000, 200]</td>\n",
       "      <td>128</td>\n",
       "      <td>964</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.047416</td>\n",
       "      <td>0.135647</td>\n",
       "      <td>17.208456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FeedFowardModel1</td>\n",
       "      <td>normal</td>\n",
       "      <td>60</td>\n",
       "      <td>[500, 250, 200]</td>\n",
       "      <td>128</td>\n",
       "      <td>111</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.106759</td>\n",
       "      <td>0.135898</td>\n",
       "      <td>0.781716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>FeedFowardModel4</td>\n",
       "      <td>normal</td>\n",
       "      <td>100</td>\n",
       "      <td>[500, 2000, 2000, 200]</td>\n",
       "      <td>64</td>\n",
       "      <td>519</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.054177</td>\n",
       "      <td>0.135927</td>\n",
       "      <td>16.034869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_type weight_init  input_size            hidden_sizes  \\\n",
       "41   FeedFowardModel5      normal          70  [500, 2000, 2000, 200]   \n",
       "12   FeedFowardModel5      normal          60  [500, 1000, 1000, 200]   \n",
       "104  FeedFowardModel5      normal         100  [500, 2000, 2000, 200]   \n",
       "117  FeedFowardModel5      normal         110  [500, 1000, 1000, 200]   \n",
       "42   FeedFowardModel1      normal          80          [200, 100, 50]   \n",
       "38   FeedFowardModel4      normal          70  [500, 1000, 1000, 200]   \n",
       "89   FeedFowardModel5      normal         100  [500, 1000, 1000, 200]   \n",
       "39   FeedFowardModel4      normal          70  [500, 2000, 2000, 200]   \n",
       "15   FeedFowardModel1      normal          60         [500, 250, 200]   \n",
       "95   FeedFowardModel4      normal         100  [500, 2000, 2000, 200]   \n",
       "\n",
       "     batch_size  epochs  learning_rate  train_loss  test_loss   run_time  \n",
       "41          128    1001           0.01    0.107549   0.133403  17.924668  \n",
       "12           64     525           0.01    0.133850   0.134132   8.701421  \n",
       "104         128    1031           0.01    0.107312   0.134468  18.445971  \n",
       "117          64     534           0.01    0.113407   0.134754   8.955775  \n",
       "42           32      78           0.01    0.099846   0.134981   1.307419  \n",
       "38          128     968           0.01    0.043883   0.135125   9.244148  \n",
       "89           32     283           0.01    0.146707   0.135146   8.601537  \n",
       "39          128     964           0.01    0.047416   0.135647  17.208456  \n",
       "15          128     111           0.01    0.106759   0.135898   0.781716  \n",
       "95           64     519           0.01    0.054177   0.135927  16.034869  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame.from_dict(list_of_results)\n",
    "df_results.sort_values(by='test_loss').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the top 10 model, we can make the following conclusions:\n",
    " - All of the first 10 model, has a really low test_loss\n",
    " - it's beneficial to reduce the complexity with cuting off the less/non important features\n",
    "\n",
    "I will go further with the one with the less test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 10.9007 | test_loss: 9.5738 | \n",
      "Epoch: 10 | train_loss: 7.7735 | test_loss: 7.6842 | \n",
      "Epoch: 20 | train_loss: 6.8828 | test_loss: 6.8269 | \n",
      "Epoch: 30 | train_loss: 6.3069 | test_loss: 6.2500 | \n",
      "Epoch: 40 | train_loss: 5.8930 | test_loss: 5.8394 | \n",
      "Epoch: 50 | train_loss: 5.5580 | test_loss: 5.5038 | \n",
      "Epoch: 60 | train_loss: 5.2864 | test_loss: 5.2344 | \n",
      "Epoch: 70 | train_loss: 5.0444 | test_loss: 5.0041 | \n",
      "Epoch: 80 | train_loss: 4.8421 | test_loss: 4.8084 | \n",
      "Epoch: 90 | train_loss: 4.6559 | test_loss: 4.6277 | \n",
      "Epoch: 100 | train_loss: 4.4885 | test_loss: 4.4700 | \n",
      "Epoch: 110 | train_loss: 4.3479 | test_loss: 4.3209 | \n",
      "Epoch: 120 | train_loss: 4.2083 | test_loss: 4.1777 | \n",
      "Epoch: 130 | train_loss: 4.0775 | test_loss: 4.0504 | \n",
      "Epoch: 140 | train_loss: 3.9593 | test_loss: 3.9386 | \n",
      "Epoch: 150 | train_loss: 3.8425 | test_loss: 3.8210 | \n",
      "Epoch: 160 | train_loss: 3.7382 | test_loss: 3.7194 | \n",
      "Epoch: 170 | train_loss: 3.6345 | test_loss: 3.6153 | \n",
      "Epoch: 180 | train_loss: 3.5500 | test_loss: 3.5244 | \n",
      "Epoch: 190 | train_loss: 3.4573 | test_loss: 3.4350 | \n",
      "Epoch: 200 | train_loss: 3.3681 | test_loss: 3.3496 | \n",
      "Epoch: 210 | train_loss: 3.2880 | test_loss: 3.2649 | \n",
      "Epoch: 220 | train_loss: 3.2050 | test_loss: 3.1866 | \n",
      "Epoch: 230 | train_loss: 3.1301 | test_loss: 3.1110 | \n",
      "Epoch: 240 | train_loss: 3.0475 | test_loss: 3.0340 | \n",
      "Epoch: 250 | train_loss: 2.9782 | test_loss: 2.9600 | \n",
      "Epoch: 260 | train_loss: 2.9102 | test_loss: 2.8883 | \n",
      "Epoch: 270 | train_loss: 2.8362 | test_loss: 2.8203 | \n",
      "Epoch: 280 | train_loss: 2.7760 | test_loss: 2.7551 | \n",
      "Epoch: 290 | train_loss: 2.7093 | test_loss: 2.6907 | \n",
      "Epoch: 300 | train_loss: 2.6488 | test_loss: 2.6277 | \n",
      "Epoch: 310 | train_loss: 2.5883 | test_loss: 2.5726 | \n",
      "Epoch: 320 | train_loss: 2.5293 | test_loss: 2.5162 | \n",
      "Epoch: 330 | train_loss: 2.4698 | test_loss: 2.4573 | \n",
      "Epoch: 340 | train_loss: 2.4077 | test_loss: 2.3977 | \n",
      "Epoch: 350 | train_loss: 2.3583 | test_loss: 2.3387 | \n",
      "Epoch: 360 | train_loss: 2.3037 | test_loss: 2.2844 | \n",
      "Epoch: 370 | train_loss: 2.2450 | test_loss: 2.2273 | \n",
      "Epoch: 380 | train_loss: 2.1912 | test_loss: 2.1778 | \n",
      "Epoch: 390 | train_loss: 2.1431 | test_loss: 2.1272 | \n",
      "Epoch: 400 | train_loss: 2.0919 | test_loss: 2.0760 | \n",
      "Epoch: 410 | train_loss: 2.0387 | test_loss: 2.0258 | \n",
      "Epoch: 420 | train_loss: 1.9889 | test_loss: 1.9740 | \n",
      "Epoch: 430 | train_loss: 1.9412 | test_loss: 1.9276 | \n",
      "Epoch: 440 | train_loss: 1.8952 | test_loss: 1.8800 | \n",
      "Epoch: 450 | train_loss: 1.8508 | test_loss: 1.8374 | \n",
      "Epoch: 460 | train_loss: 1.8015 | test_loss: 1.7818 | \n",
      "Epoch: 470 | train_loss: 1.7545 | test_loss: 1.7355 | \n",
      "Epoch: 480 | train_loss: 1.7119 | test_loss: 1.6891 | \n",
      "Epoch: 490 | train_loss: 1.6621 | test_loss: 1.6496 | \n",
      "Epoch: 500 | train_loss: 1.6217 | test_loss: 1.6042 | \n",
      "Epoch: 510 | train_loss: 1.5722 | test_loss: 1.5525 | \n",
      "Epoch: 520 | train_loss: 1.5290 | test_loss: 1.5153 | \n",
      "Epoch: 530 | train_loss: 1.4895 | test_loss: 1.4733 | \n",
      "Epoch: 540 | train_loss: 1.4464 | test_loss: 1.4271 | \n",
      "Epoch: 550 | train_loss: 1.4030 | test_loss: 1.3893 | \n",
      "Epoch: 560 | train_loss: 1.3637 | test_loss: 1.3410 | \n",
      "Epoch: 570 | train_loss: 1.3248 | test_loss: 1.3095 | \n",
      "Epoch: 580 | train_loss: 1.2840 | test_loss: 1.2694 | \n",
      "Epoch: 590 | train_loss: 1.2441 | test_loss: 1.2245 | \n",
      "Epoch: 600 | train_loss: 1.2033 | test_loss: 1.1866 | \n",
      "Epoch: 610 | train_loss: 1.1603 | test_loss: 1.1485 | \n",
      "Epoch: 620 | train_loss: 1.1207 | test_loss: 1.1058 | \n",
      "Epoch: 630 | train_loss: 1.0866 | test_loss: 1.0657 | \n",
      "Epoch: 640 | train_loss: 1.0455 | test_loss: 1.0317 | \n",
      "Epoch: 650 | train_loss: 1.0136 | test_loss: 0.9958 | \n",
      "Epoch: 660 | train_loss: 0.9807 | test_loss: 0.9549 | \n",
      "Epoch: 670 | train_loss: 0.9353 | test_loss: 0.9224 | \n",
      "Epoch: 680 | train_loss: 0.9040 | test_loss: 0.8855 | \n",
      "Epoch: 690 | train_loss: 0.8657 | test_loss: 0.8441 | \n",
      "Epoch: 700 | train_loss: 0.8274 | test_loss: 0.8096 | \n",
      "Epoch: 710 | train_loss: 0.7922 | test_loss: 0.7844 | \n",
      "Epoch: 720 | train_loss: 0.7627 | test_loss: 0.7478 | \n",
      "Epoch: 730 | train_loss: 0.7247 | test_loss: 0.7153 | \n",
      "Epoch: 740 | train_loss: 0.6857 | test_loss: 0.6809 | \n",
      "Epoch: 750 | train_loss: 0.6546 | test_loss: 0.6464 | \n",
      "Epoch: 760 | train_loss: 0.6216 | test_loss: 0.6064 | \n",
      "Epoch: 770 | train_loss: 0.5932 | test_loss: 0.5780 | \n",
      "Epoch: 780 | train_loss: 0.5594 | test_loss: 0.5498 | \n",
      "Epoch: 790 | train_loss: 0.5279 | test_loss: 0.5136 | \n",
      "Epoch: 800 | train_loss: 0.4961 | test_loss: 0.4770 | \n",
      "Epoch: 810 | train_loss: 0.4611 | test_loss: 0.4526 | \n",
      "Epoch: 820 | train_loss: 0.4414 | test_loss: 0.4200 | \n",
      "Epoch: 830 | train_loss: 0.4051 | test_loss: 0.3963 | \n",
      "Epoch: 840 | train_loss: 0.3729 | test_loss: 0.3673 | \n",
      "Epoch: 850 | train_loss: 0.3460 | test_loss: 0.3406 | \n",
      "Epoch: 860 | train_loss: 0.3192 | test_loss: 0.3216 | \n",
      "Epoch: 870 | train_loss: 0.2888 | test_loss: 0.2908 | \n",
      "Epoch: 880 | train_loss: 0.2638 | test_loss: 0.2617 | \n",
      "Epoch: 890 | train_loss: 0.2420 | test_loss: 0.2583 | \n",
      "Epoch: 900 | train_loss: 0.2181 | test_loss: 0.2232 | \n",
      "Epoch: 910 | train_loss: 0.1979 | test_loss: 0.2037 | \n",
      "Epoch: 920 | train_loss: 0.1863 | test_loss: 0.1879 | \n",
      "Epoch: 930 | train_loss: 0.1612 | test_loss: 0.1815 | \n",
      "Epoch: 940 | train_loss: 0.1505 | test_loss: 0.1605 | \n",
      "Epoch: 950 | train_loss: 0.1355 | test_loss: 0.1503 | \n",
      "Epoch: 960 | train_loss: 0.1345 | test_loss: 0.1464 | \n",
      "Epoch: 970 | train_loss: 0.1331 | test_loss: 0.1394 | \n",
      "Epoch: 980 | train_loss: 0.1176 | test_loss: 0.1388 | \n",
      "Epoch: 990 | train_loss: 0.1175 | test_loss: 0.1371 | \n",
      "Epoch: 1000 | train_loss: 0.1141 | test_loss: 0.1356 | \n",
      "Epoch: 1010 | train_loss: 0.1117 | test_loss: 0.1356 | \n",
      "Epoch: 1020 | train_loss: 0.1155 | test_loss: 0.1340 | \n",
      "Epoch: 1030 | train_loss: 0.1165 | test_loss: 0.1376 | \n",
      "Epoch: 1040 | train_loss: 0.1105 | test_loss: 0.1378 | \n",
      "Early stopping: No improvement in 15 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_final = train_a_model(\n",
    "            top_n_feature=70,\n",
    "            batch_size=128,\n",
    "            model_number=6,\n",
    "            show_plots=True,\n",
    "            append_result_list=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at our test datapoints and its predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the data \n",
    "df_preprocessed = DataPreprocessor(df, 'SalePrice', 70)\n",
    "X_train, X_test, y_train, y_test = df_preprocessed.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred</th>\n",
       "      <th>Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136632</td>\n",
       "      <td>154500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>299787</td>\n",
       "      <td>325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112807</td>\n",
       "      <td>115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160012</td>\n",
       "      <td>159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>337319</td>\n",
       "      <td>315500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>85919</td>\n",
       "      <td>75500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>227724</td>\n",
       "      <td>311500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>144988</td>\n",
       "      <td>146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81589</td>\n",
       "      <td>84500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123431</td>\n",
       "      <td>135500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>166424</td>\n",
       "      <td>145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>112742</td>\n",
       "      <td>130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>96404</td>\n",
       "      <td>81000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>208042</td>\n",
       "      <td>214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>162151</td>\n",
       "      <td>181000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>133723</td>\n",
       "      <td>134500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>186715</td>\n",
       "      <td>183500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>129711</td>\n",
       "      <td>135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>116961</td>\n",
       "      <td>118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>224928</td>\n",
       "      <td>226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>172977</td>\n",
       "      <td>155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>217637</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>175198</td>\n",
       "      <td>173500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>127074</td>\n",
       "      <td>129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>209223</td>\n",
       "      <td>192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>173016</td>\n",
       "      <td>153900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>193035</td>\n",
       "      <td>181134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>97107</td>\n",
       "      <td>141000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>160390</td>\n",
       "      <td>181000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>198224</td>\n",
       "      <td>208900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pred   Truth\n",
       "0   136632  154500\n",
       "1   299787  325000\n",
       "2   112807  115000\n",
       "3   160012  159000\n",
       "4   337319  315500\n",
       "5    85919   75500\n",
       "6   227724  311500\n",
       "7   144988  146000\n",
       "8    81589   84500\n",
       "9   123431  135500\n",
       "10  166424  145000\n",
       "11  112742  130000\n",
       "12   96404   81000\n",
       "13  208042  214000\n",
       "14  162151  181000\n",
       "15  133723  134500\n",
       "16  186715  183500\n",
       "17  129711  135000\n",
       "18  116961  118400\n",
       "19  224928  226000\n",
       "20  172977  155000\n",
       "21  217637  210000\n",
       "22  175198  173500\n",
       "23  127074  129000\n",
       "24  209223  192000\n",
       "25  173016  153900\n",
       "26  193035  181134\n",
       "27   97107  141000\n",
       "28  160390  181000\n",
       "29  198224  208900"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "pred = model_final(torch.tensor(X_test.values.astype('float32')).to(device)).ravel().to('cpu').detach()\n",
    "grund_truth = y_test.values\n",
    "\n",
    "pd.DataFrame({'Pred':pred,'Truth':grund_truth}).applymap(lambda x: round(x)).head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's a regression problem, let's evaluate the r2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.91\n"
     ]
    }
   ],
   "source": [
    "print(f'r2_score: {r2_score(grund_truth,pred):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an R-squared score of 0.91, the model shows a robust predictive ability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-data-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
